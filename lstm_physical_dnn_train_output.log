$ python3 ../train.py -read "SWaT_Dataset_Attack_v0-fixed-train-test.csv" -dimensionality 52 -optimizer sgd -result_column Normal/Attack -lstm true -lstmBatchSize 87484

Using TensorFlow backend.
[INFO] input_shape (21871, 52)
[INFO] LSTM first and last layer neurons: 2
2020-01-31 20:49:43.822469: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-01-31 20:49:43.853969: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa7f8426ed0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-01-31 20:49:43.854038: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
adding core layer 0
[INFO] created DNN
[INFO] epoch 1/1
[INFO] loading file 1-1/1 on epoch 1/1
[INFO] reading file SWaT_Dataset_Attack_v0-fixed-train-test.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (349936, 53)
[INFO] sampling 1.0
[INFO] columns: Index([' Timestamp', 'FIT101', 'LIT101', ' MV101', 'P101', 'P102', ' AIT201',
       'AIT202', 'AIT203', 'FIT201', ' MV201', ' P201', ' P202', 'P203',
       ' P204', 'P205', 'P206', 'DPIT301', 'FIT301', 'LIT301', 'MV301',
       'MV302', ' MV303', 'MV304', 'P301', 'P302', 'AIT401', 'AIT402',
       'FIT401', 'LIT401', 'P401', 'P402', 'P403', 'P404', 'UV401', 'AIT501',
       'AIT502', 'AIT503', 'AIT504', 'FIT501', 'FIT502', 'FIT503', 'FIT504',
       'P501', 'P502', 'PIT501', 'PIT502', 'PIT503', 'FIT601', 'P601', 'P602',
       'P603', 'Normal/Attack'],
      dtype='object')
[INFO] analyze dataset: (349936, 53)

[INFO] analyzing data
[INFO] 349936 rows
[INFO] **  Timestamp:349936 (100.0%)
[INFO] ** FIT101:2292 (0.65498%)
[INFO] ** LIT101:9094 (2.59876%)
[INFO] **  MV101:[2:65.34138%,1:34.18025%,0:0.47837%]
[INFO] ** P101:[2:67.64866%,1:32.35134%]
[INFO] ** P102:[1:99.13527%,2:0.86473%]
[INFO] **  AIT201:1964 (0.56125%)
[INFO] ** AIT202:889 (0.25405%)
[INFO] ** AIT203:2408 (0.68813%)
[INFO] ** FIT201:2524 (0.72127%)
[INFO] **  MV201:[2:67.73667%,1:31.88412%,0:0.37921%]
[INFO] **  P201:[1:90.94863%,2:9.05137%]
[INFO] **  P202:[1:100.0%]
[INFO] ** P203:[2:67.36832%,1:32.63168%]
[INFO] **  P204:[1:99.984%,2:0.016%]
[INFO] ** P205:[2:67.42519%,1:32.57481%]
[INFO] ** P206:[1:99.98428%,2:0.01572%]
[INFO] ** DPIT301:4071 (1.16336%)
[INFO] ** FIT301:4800 (1.37168%)
[INFO] ** LIT301:5536 (1.582%)
[INFO] ** MV301:[1:98.56002%,2:1.07705%,0:0.36292%]
[INFO] ** MV302:[2:73.87951%,1:25.4818%,0:0.63869%]
[INFO] **  MV303:[1:96.886%,2:2.64506%,0:0.46894%]
[INFO] ** MV304:[1:86.55783%,2:12.76862%,0:0.67355%]
[INFO] ** P301:[1:100.0%]
[INFO] ** P302:[2:75.41522%,1:24.58478%]
[INFO] ** AIT401:[148.808:61.9519%,148.8032:30.24382%,148.7936:3.64381%,148.8128:3.24774%,148.8176:0.36635%,148.7888:0.27405%,148.8272:0.08887%,148.784:0.08201%,148.7792:0.03715%,148.832:0.03629%,148.7695:0.01257%,148.8368:0.00514%,148.8416:0.00429%,148.8561:0.00229%,148.7599:0.002%,148.8513:0.00114%,148.7647:0.00057%]
[INFO] ** AIT402:2943 (0.84101%)
[INFO] ** FIT401:480 (0.13717%)
[INFO] ** LIT401:12771 (3.64952%)
[INFO] ** P401:[1:100.0%]
[INFO] ** P402:[2:90.84461%,1:9.15539%]
[INFO] ** P403:[1:99.98285%,2:0.01715%]
[INFO] ** P404:[1:100.0%]
[INFO] ** UV401:[2:90.55056%,1:9.44944%]
[INFO] ** AIT501:1431 (0.40893%)
[INFO] ** AIT502:2512 (0.71785%)
[INFO] ** AIT503:1088 (0.31091%)
[INFO] ** AIT504:296 (0.08459%)
[INFO] ** FIT501:531 (0.15174%)
[INFO] ** FIT502:1119 (0.31977%)
[INFO] ** FIT503:241 (0.06887%)
[INFO] ** FIT504:180 (0.05144%)
[INFO] ** P501:[2:90.55227%,1:9.44773%]
[INFO] ** P502:[1:100.0%]
[INFO] ** PIT501:831 (0.23747%)
[INFO] ** PIT502:[0.0:9.44916%,0.8009483000000001:6.25057%,0.9771569:5.43299%,1.5858780000000001:5.01435%,0.7849293:4.98748%,0.9611379999999999:4.50768%,0.8169672:4.11561%,1.009195:3.79898%,1.5698590000000001:3.60952%,1.601897:3.50293%,1.0252139999999998:2.87567%,0.945119:2.63334%,0.8490052:2.37472%,0.9291:2.24412%,1.409669:2.24241%,0.7689104:2.2387%,0.8970621:2.19869%,1.5378209999999999:2.13382%,0.8810431000000001:2.0438%,0.8650241:1.94778%,1.4256879999999998:1.7889%,1.441707:1.67431%,1.505783:1.6323%,1.521802:1.58372%,1.4897639999999999:1.48741%,1.457726:1.41826%,1.041233:1.21079%,1.617916:1.11335%,1.377631:1.03619%,0.7368724:1.01962%,1.730048:0.87702%,1.7460669999999998:0.81615%,1.6499529999999998:0.75071%,1.057252:0.72842%,1.201422:0.68641%,1.6980099999999998:0.60525%,0.7208535:0.56096%,1.665972:0.56039%,1.681991:0.51667%,1.0892899999999999:0.48037%,1.361612:0.47294%,1.185403:0.46723%,1.762086:0.45951%,1.105309:0.38007%,1.345593:0.35492%,1.121328:0.35064%,0.7048345:0.33606%,1.281517:0.29777%,1.169384:0.29177%,1.1373469999999999:0.29062%,1.217441:0.2892%,1.249479:0.28177%,1.7781049999999998:0.27262%,1.265498:0.2429%,1.297536:0.23347%,0.6888155:0.23233%,1.329574:0.21633%,0.6567776:0.09745%,1.810143:0.09687%,0.6407586:0.0763%,1.8261619999999998:0.04029%,0.6247397:0.02458%,1.842181:0.01486%,0.6087206999999999:0.01286%,1.8582:0.00629%,0.5766828:0.00514%,0.5446448:0.00114%,1.9703330000000001:0.00086%,0.5606638:0.00086%,0.1441707:0.00057%,1.9062569999999999:0.00057%,0.48056899999999997:0.00029%,0.44853109999999996:0.00029%,0.25630349999999996:0.00029%,0.41649309999999995:0.00029%,0.08009483:0.00029%,1.890238:0.00029%]
[INFO] ** PIT503:742 (0.21204%)
[INFO] ** FIT601:2875 (0.82158%)
[INFO] ** P601:[1:100.0%]
[INFO] ** P602:[1:99.15527%,2:0.84473%]
[INFO] ** P603:[1:100.0%]
[INFO] ** Normal/Attack:[Normal:85.73539%,Attack:14.26461%]
[INFO] processing batch 0-87484/349936 for LSTM
[INFO] breaking into predictors and prediction...
CHUNK ANALYZE

[INFO] analyzing data
[INFO] 87484 rows
[INFO] **  Timestamp:87484 (100.0%)
[INFO] ** FIT101:1244 (1.42197%)
[INFO] ** LIT101:7395 (8.45297%)
[INFO] **  MV101:[2:72.57441%,1:26.95807%,0:0.46751%]
[INFO] ** P101:[2:75.25033%,1:24.74967%]
[INFO] ** P102:[1:99.49134%,2:0.50866%]
[INFO] **  AIT201:196 (0.22404%)
[INFO] ** AIT202:323 (0.36921%)
[INFO] ** AIT203:710 (0.81158%)
[INFO] ** FIT201:1028 (1.17507%)
[INFO] **  MV201:[2:75.29948%,1:24.27415%,0:0.42636%]
[INFO] **  P201:[1:100.0%]
[INFO] **  P202:[1:100.0%]
[INFO] ** P203:[2:74.80796%,1:25.19204%]
[INFO] **  P204:[1:100.0%]
[INFO] ** P205:[2:75.03429%,1:24.96571%]
[INFO] ** P206:[1:100.0%]
[INFO] ** DPIT301:2118 (2.42101%)
[INFO] ** FIT301:2410 (2.75479%)
[INFO] ** LIT301:5090 (5.81821%)
[INFO] ** MV301:[1:98.37456%,2:1.17622%,0:0.44923%]
[INFO] ** MV302:[2:81.1817%,1:18.05016%,0:0.76814%]
[INFO] **  MV303:[1:96.14558%,2:3.27603%,0:0.57839%]
[INFO] ** MV304:[1:95.35344%,2:3.83956%,0:0.807%]
[INFO] ** P301:[1:100.0%]
[INFO] ** P302:[2:83.24379%,1:16.75621%]
[INFO] ** AIT401:[148.808:51.25852%,148.8032:40.02218%,148.7936:4.44196%,148.8128:3.15715%,148.7888:0.37378%,148.8176:0.36692%,148.784:0.15431%,148.8272:0.09259%,148.7792:0.05372%,148.832:0.03658%,148.7695:0.02515%,148.8416:0.00572%,148.8368:0.00457%,148.7599:0.00229%,148.8513:0.00229%,148.8561:0.00229%]
[INFO] ** AIT402:789 (0.90188%)
[INFO] ** FIT401:291 (0.33263%)
[INFO] ** LIT401:6978 (7.97632%)
[INFO] ** P401:[1:100.0%]
[INFO] ** P402:[2:99.99428%,1:0.00572%]
[INFO] ** P403:[1:100.0%]
[INFO] ** P404:[1:100.0%]
[INFO] ** UV401:[2:99.3576%,1:0.6424%]
[INFO] ** AIT501:329 (0.37607%)
[INFO] ** AIT502:746 (0.85273%)
[INFO] ** AIT503:651 (0.74414%)
[INFO] ** AIT504:122 (0.13945%)
[INFO] ** FIT501:388 (0.44351%)
[INFO] ** FIT502:927 (1.05962%)
[INFO] ** FIT503:160 (0.18289%)
[INFO] ** FIT504:133 (0.15203%)
[INFO] ** P501:[2:99.35988%,1:0.64012%]
[INFO] ** P502:[1:100.0%]
[INFO] ** PIT501:597 (0.68241%)
[INFO] ** PIT502:[0.9771569:9.95725%,0.9611379999999999:7.52366%,1.5858780000000001:7.36249%,1.601897:6.4949%,1.009195:5.99424%,1.0252139999999998:3.80641%,0.945119:3.78812%,1.730048:3.42577%,1.7460669999999998:3.22459%,1.5698590000000001:3.08971%,0.9291:2.74336%,1.6980099999999998:2.28385%,1.6499529999999998:2.0518%,0.8970621:2.02551%,1.617916:2.02437%,1.681991:1.82776%,1.762086:1.8209%,1.665972:1.77861%,1.041233:1.77175%,1.505783:1.61401%,1.5378209999999999:1.58658%,1.409669:1.44369%,0.8810431000000001:1.42083%,1.4897639999999999:1.30767%,1.201422:1.28366%,1.457726:1.19793%,0.8650241:1.16821%,1.7781049999999998:1.08477%,1.377631:1.08248%,1.4256879999999998:1.07448%,1.521802:0.98532%,0.8490052:0.94074%,1.441707:0.86644%,1.185403:0.77843%,0.8169672:0.73156%,1.361612:0.73156%,1.057252:0.64469%,0.0:0.63783%,1.121328:0.57953%,1.345593:0.56125%,1.0892899999999999:0.52695%,1.281517:0.52695%,1.169384:0.52238%,1.105309:0.51095%,1.217441:0.42979%,1.1373469999999999:0.39093%,1.810143:0.37835%,1.265498:0.35206%,1.249479:0.35092%,1.329574:0.34521%,0.8009483000000001:0.28234%,1.297536:0.24004%,1.8261619999999998:0.15546%,0.7849293:0.10745%,1.842181:0.05944%,0.7689104:0.03886%,1.8582:0.02515%,0.7368724:0.01372%,0.7208535:0.01257%,1.9703330000000001:0.00343%,0.7048345:0.00229%,1.9062569999999999:0.00229%,0.1441707:0.00229%,0.5766828:0.00114%,0.41649309999999995:0.00114%,1.890238:0.00114%]
[INFO] ** PIT503:533 (0.60925%)
[INFO] ** FIT601:1100 (1.25737%)
[INFO] ** P601:[1:100.0%]
[INFO] ** P602:[1:98.97581%,2:1.02419%]
[INFO] ** P603:[1:100.0%]
[INFO] ** Normal/Attack:[Normal:94.07092%,Attack:5.92908%]
[INFO] to_xy labeltype: Normal
[INFO] to_xy labeltype: Attack
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 3 samples, validate on 1 samples
Epoch 1/1
2020-01-31 20:50:07.460316: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_1_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_1_loss/categorical_crossentropy/weighted_loss/concat'.
2020-01-31 20:50:07.603807: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-01-31 20:50:07.666509: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-01-31 20:50:08.200324: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-01-31 20:50:08.242296: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_1_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_1_loss/categorical_crossentropy/weighted_loss/concat'.
2020-01-31 20:50:08.300221: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-01-31 20:50:08.348200: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-01-31 20:50:08.516199: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.








2020-01-31 20:57:45.423750: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_1_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_1_loss/categorical_crossentropy/weighted_loss/concat'.
2020-01-31 20:57:45.510599: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-01-31 20:57:45.539425: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-01-31 20:57:45.890049: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-01-31 20:57:45.914883: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_1_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_1_loss/categorical_crossentropy/weighted_loss/concat'.
2020-01-31 20:57:45.941752: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-01-31 20:57:45.985931: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-01-31 20:57:46.089035: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
 - 481s - loss: 0.6931 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 65613.0000 - fn: 65613.0000 - accuracy: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.6823 - val_tp: 21150.0000 - val_fp: 721.0000 - val_tn: 21150.0000 - val_fn: 721.0000 - val_accuracy: 0.9670 - val_precision: 0.9670 - val_recall: 0.9670 - val_auc: 0.9670
[INFO] saving weights to checkpoints/lstm-epoch-1-files-0-1-batch-0-87484
[INFO] processing batch 87484-174968/349936 for LSTM
[INFO] breaking into predictors and prediction...
CHUNK ANALYZE

[INFO] analyzing data
[INFO] 87484 rows
[INFO] **  Timestamp:87484 (100.0%)
[INFO] ** FIT101:1208 (1.38082%)
[INFO] ** LIT101:6649 (7.60025%)
[INFO] **  MV101:[2:70.63463%,1:28.64752%,0:0.71785%]
[INFO] ** P101:[2:73.45457%,1:26.54543%]
[INFO] ** P102:[1:100.0%]
[INFO] **  AIT201:866 (0.9899%)
[INFO] ** AIT202:535 (0.61154%)
[INFO] ** AIT203:834 (0.95332%)
[INFO] ** FIT201:821 (0.93846%)
[INFO] **  MV201:[2:73.50258%,1:26.11792%,0:0.3795%]
[INFO] **  P201:[1:94.25038%,2:5.74962%]
[INFO] **  P202:[1:100.0%]
[INFO] ** P203:[2:73.14938%,1:26.85062%]
[INFO] **  P204:[1:99.93599%,2:0.06401%]
[INFO] ** P205:[2:73.15052%,1:26.84948%]
[INFO] ** P206:[1:99.93713%,2:0.06287%]
[INFO] ** DPIT301:2079 (2.37643%)
[INFO] ** FIT301:2186 (2.49874%)
[INFO] ** LIT301:4821 (5.51072%)
[INFO] ** MV301:[1:98.19738%,2:1.44484%,0:0.35778%]
[INFO] ** MV302:[2:81.02853%,1:18.30392%,0:0.66755%]
[INFO] **  MV303:[1:96.91944%,2:2.62219%,0:0.45837%]
[INFO] ** MV304:[1:96.04842%,2:3.24859%,0:0.70299%]
[INFO] ** P301:[1:100.0%]
[INFO] ** P302:[2:82.04929%,1:17.95071%]
[INFO] ** AIT401:[148.808:75.5441%,148.8032:19.10521%,148.7936:2.78908%,148.8128:2.01294%,148.7888:0.19089%,148.8176:0.13374%,148.8272:0.09716%,148.832:0.04229%,148.784:0.02972%,148.7792:0.02858%,148.8368:0.00914%,148.8561:0.00457%,148.8416:0.00457%,148.7695:0.00457%,148.8513:0.00229%,148.7599:0.00114%]
[INFO] ** AIT402:736 (0.8413%)
[INFO] ** FIT401:346 (0.3955%)
[INFO] ** LIT401:7330 (8.37867%)
[INFO] ** P401:[1:100.0%]
[INFO] ** P402:[2:100.0%]
[INFO] ** P403:[1:100.0%]
[INFO] ** P404:[1:100.0%]
[INFO] ** UV401:[2:99.46505%,1:0.53495%]
[INFO] ** AIT501:427 (0.48809%)
[INFO] ** AIT502:418 (0.4778%)
[INFO] ** AIT503:765 (0.87445%)
[INFO] ** AIT504:133 (0.15203%)
[INFO] ** FIT501:308 (0.35206%)
[INFO] ** FIT502:824 (0.94189%)
[INFO] ** FIT503:136 (0.15546%)
[INFO] ** FIT504:117 (0.13374%)
[INFO] ** P501:[2:99.46733%,1:0.53267%]
[INFO] ** P502:[1:100.0%]
[INFO] ** PIT501:394 (0.45037%)
[INFO] ** PIT502:[0.7849293:7.01042%,0.8009483000000001:6.21714%,1.409669:6.0914%,1.4256879999999998:5.02378%,1.5698590000000001:5.02035%,1.441707:4.71058%,0.7689104:4.46939%,1.5858780000000001:4.45339%,0.8169672:4.03617%,1.5378209999999999:3.96415%,1.4897639999999999:3.44177%,1.505783:3.24288%,1.457726:3.21659%,1.521802:2.83709%,1.377631:2.70564%,0.7368724:2.33185%,0.8490052:2.30785%,0.9611379999999999:1.71574%,0.9771569:1.67916%,0.8650241:1.64259%,1.601897:1.48256%,1.0252139999999998:1.46998%,0.7208535:1.4174%,0.8810431000000001:1.3271%,1.201422:1.13735%,1.009195:1.12249%,0.8970621:1.10534%,1.057252:0.98418%,0.945119:0.9396%,1.361612:0.92245%,0.7048345:0.88359%,0.9291:0.83672%,0.6888155:0.77843%,1.0892899999999999:0.77157%,1.185403:0.75442%,1.345593:0.72356%,1.249479:0.65498%,1.105309:0.6104%,1.1373469999999999:0.58868%,1.121328:0.56239%,0.0:0.53724%,1.617916:0.46866%,1.041233:0.43665%,1.281517:0.41951%,1.169384:0.41379%,1.297536:0.39893%,1.217441:0.36121%,1.265498:0.35549%,1.329574:0.34978%,0.6567776:0.2972%,0.6407586:0.2549%,1.6499529999999998:0.21147%,1.665972:0.09145%,0.6247397:0.08802%,0.6087206999999999:0.03658%,1.681991:0.02629%,1.6980099999999998:0.01829%,0.5766828:0.01257%,1.730048:0.01029%,1.810143:0.00572%,1.7460669999999998:0.00343%,0.5606638:0.00343%,0.5446448:0.00343%,0.08009483:0.00114%,0.44853109999999996:0.00114%,0.25630349999999996:0.00114%,1.7781049999999998:0.00114%]
[INFO] ** PIT503:367 (0.41951%)
[INFO] ** FIT601:882 (1.00818%)
[INFO] ** P601:[1:100.0%]
[INFO] ** P602:[1:99.15756%,2:0.84244%]
[INFO] ** P603:[1:100.0%]
[INFO] ** Normal/Attack:[Normal:94.14179%,Attack:5.85821%]
[INFO] to_xy labeltype: Normal
[INFO] to_xy labeltype: Attack
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 3 samples, validate on 1 samples
Epoch 1/1




 - 460s - loss: 0.6830 - tp: 61421.0000 - fp: 4192.0000 - tn: 61421.0000 - fn: 4192.0000 - accuracy: 0.9361 - precision: 0.9361 - recall: 0.9361 - auc: 0.9361 - val_loss: 0.6720 - val_tp: 20938.0000 - val_fp: 933.0000 - val_tn: 20938.0000 - val_fn: 933.0000 - val_accuracy: 0.9573 - val_precision: 0.9573 - val_recall: 0.9573 - val_auc: 0.9573
[INFO] saving weights to checkpoints/lstm-epoch-1-files-0-1-batch-87484-174968
[INFO] processing batch 174968-262452/349936 for LSTM
[INFO] breaking into predictors and prediction...
CHUNK ANALYZE

[INFO] analyzing data
[INFO] 87484 rows
[INFO] **  Timestamp:87484 (100.0%)
[INFO] ** FIT101:1042 (1.19107%)
[INFO] ** LIT101:7076 (8.08834%)
[INFO] **  MV101:[1:52.69992%,2:47.00288%,0:0.2972%]
[INFO] ** P101:[1:52.2907%,2:47.7093%]
[INFO] ** P102:[1:98.35056%,2:1.64944%]
[INFO] **  AIT201:697 (0.79672%)
[INFO] ** AIT202:527 (0.6024%)
[INFO] ** AIT203:1502 (1.71689%)
[INFO] ** FIT201:831 (0.94989%)
[INFO] **  MV201:[1:51.96264%,2:47.74244%,0:0.29491%]
[INFO] **  P201:[1:90.78803%,2:9.21197%]
[INFO] **  P202:[1:100.0%]
[INFO] ** P203:[1:52.43816%,2:47.56184%]
[INFO] **  P204:[1:100.0%]
[INFO] ** P205:[1:52.43816%,2:47.56184%]
[INFO] ** P206:[1:100.0%]
[INFO] ** DPIT301:1735 (1.98322%)
[INFO] ** FIT301:1692 (1.93407%)
[INFO] ** LIT301:4583 (5.23867%)
[INFO] ** MV301:[1:99.02154%,2:0.7087%,0:0.26976%]
[INFO] ** MV302:[2:51.67573%,1:47.8819%,0:0.44237%]
[INFO] **  MV303:[1:97.68415%,2:1.96036%,0:0.35549%]
[INFO] ** MV304:[1:60.33446%,2:39.18545%,0:0.48009%]
[INFO] ** P301:[1:100.0%]
[INFO] ** P302:[2:52.88053%,1:47.11947%]
[INFO] ** AIT401:[148.808:68.62283%,148.8032:23.434%,148.8128:5.17923%,148.7936:1.79233%,148.8176:0.58296%,148.7888:0.13717%,148.8272:0.10859%,148.784:0.06287%,148.832:0.03315%,148.7792:0.024%,148.7695:0.01372%,148.8368:0.00457%,148.8561:0.00229%,148.8416:0.00229%]
[INFO] ** AIT402:1817 (2.07695%)
[INFO] ** FIT401:327 (0.37378%)
[INFO] ** LIT401:7101 (8.11691%)
[INFO] ** P401:[1:100.0%]
[INFO] ** P402:[2:64.91701%,1:35.08299%]
[INFO] ** P403:[1:100.0%]
[INFO] ** P404:[1:100.0%]
[INFO] ** UV401:[2:64.91473%,1:35.08527%]
[INFO] ** AIT501:824 (0.94189%)
[INFO] ** AIT502:1741 (1.99008%)
[INFO] ** AIT503:750 (0.8573%)
[INFO] ** AIT504:[15.688279999999999:7.60025%,15.611379999999999:6.20799%,15.57293:5.64217%,15.534479999999999:4.86603%,15.419120000000001:4.18019%,15.38067:4.10246%,15.49603:3.72182%,15.14996:3.01884%,15.72674:2.93768%,15.342220000000001:2.88281%,14.9577:2.44845%,15.03461:2.22669%,15.188410000000001:2.1924%,15.22686:2.15582%,14.99615:2.00608%,15.765189999999999:1.94207%,15.303770000000002:1.86205%,14.8039:1.81519%,15.11151:1.79347%,14.61164:1.76604%,14.650089999999999:1.61172%,14.91925:1.59686%,14.84235:1.558%,14.726989999999999:1.4917%,15.80364:1.45741%,15.918989999999999:1.44255%,16.18816:1.39454%,16.11125:1.36825%,15.88054:1.2288%,14.76544:1.20708%,15.95745:1.20708%,16.265060000000002:1.16821%,15.9959:1.06991%,16.34196:1.03905%,16.30351:1.02076%,14.419379999999999:0.99447%,14.573189999999999:0.98075%,16.0728:0.93731%,14.53473:0.93617%,14.45783:0.69956%,16.14971:0.69841%,14.342479999999998:0.68698%,13.95796:0.62297%,14.073310000000001:0.60811%,14.38093:0.60468%,13.996410000000001:0.49723%,14.03486:0.45608%,16.38041:0.43094%,16.457320000000003:0.42751%,14.227120000000001:0.40807%,14.26557:0.40807%,14.188670000000002:0.37835%,14.150220000000001:0.36235%,16.49577:0.29834%,13.7657:0.27434%,16.572670000000002:0.24576%,16.53422:0.24004%,13.65035:0.23204%,13.49654:0.22633%,16.64958:0.20689%,16.688029999999998:0.19889%,13.88106:0.19432%,13.57344:0.18518%,16.72648:0.13717%,13.458089999999999:0.1326%,13.611889999999999:0.12345%,13.41964:0.12231%,13.6888:0.11659%,13.381179999999999:0.11545%,13.8426:0.10059%,13.227379999999998:0.09602%,13.304279999999999:0.08573%,16.841839999999998:0.0823%,13.80415:0.0663%,16.76493:0.04572%,13.26583:0.04001%,13.112020000000001:0.03658%,13.03512:0.00914%,16.91874:0.00686%,17.03409:0.00572%,16.88029:0.00457%,16.95719:0.00229%]
[INFO] ** FIT501:328 (0.37493%)
[INFO] ** FIT502:707 (0.80815%)
[INFO] ** FIT503:136 (0.15546%)
[INFO] ** FIT504:129 (0.14746%)
[INFO] ** P501:[2:64.91701%,1:35.08299%]
[INFO] ** P502:[1:100.0%]
[INFO] ** PIT501:480 (0.54867%)
[INFO] ** PIT502:[0.0:35.08527%,1.5858780000000001:8.24151%,1.5698590000000001:6.32801%,1.601897:6.03425%,0.8169672:3.98359%,1.5378209999999999:2.98455%,1.521802:2.51246%,0.8490052:2.35014%,1.617916:1.96036%,0.8810431000000001:1.87806%,0.8009483000000001:1.86434%,0.8650241:1.74318%,1.505783:1.67231%,1.409669:1.43455%,0.9291:1.33282%,0.8970621:1.27909%,1.457726:1.25852%,0.945119:1.25852%,0.7849293:1.20708%,1.4897639999999999:1.20022%,1.441707:1.1202%,0.9771569:1.10077%,0.9611379999999999:1.06877%,1.4256879999999998:1.05734%,1.009195:1.03333%,1.0252139999999998:0.9316%,1.6499529999999998:0.73956%,1.057252:0.70527%,1.041233:0.70299%,0.7689104:0.42751%,1.0892899999999999:0.37607%,1.665972:0.3715%,1.217441:0.36578%,1.377631:0.35664%,1.185403:0.3292%,0.7368724:0.3212%,1.201422:0.32006%,1.297536:0.29491%,1.105309:0.27891%,1.265498:0.26062%,1.281517:0.24462%,1.361612:0.23776%,1.169384:0.2149%,1.121328:0.21261%,1.681991:0.21261%,1.329574:0.17032%,1.1373469999999999:0.16346%,1.345593:0.13488%,1.249479:0.12117%,1.6980099999999998:0.11888%,0.7208535:0.11774%,0.7048345:0.0743%,1.730048:0.07201%,1.7460669999999998:0.03658%,0.6888155:0.03658%,0.6407586:0.01715%,1.762086:0.01715%,1.8261619999999998:0.00572%,0.6087206999999999:0.00457%,1.7781049999999998:0.00457%,0.6567776:0.00457%,1.810143:0.00343%,0.5766828:0.00229%,0.5446448:0.00114%]
[INFO] ** PIT503:434 (0.49609%)
[INFO] ** FIT601:685 (0.783%)
[INFO] ** P601:[1:100.0%]
[INFO] ** P602:[1:99.36331%,2:0.63669%]
[INFO] ** P603:[1:100.0%]
[INFO] ** Normal/Attack:[Normal:58.77075%,Attack:41.22925%]
[INFO] to_xy labeltype: Normal
[INFO] to_xy labeltype: Attack
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 3 samples, validate on 1 samples
Epoch 1/1
 - 431s - loss: 0.6801 - tp: 51415.0000 - fp: 14198.0000 - tn: 51415.0000 - fn: 14198.0000 - accuracy: 0.7836 - precision: 0.7836 - recall: 0.7836 - auc: 0.7836 - val_loss: 0.7244 - val_tp: 0.0000e+00 - val_fp: 21871.0000 - val_tn: 0.0000e+00 - val_fn: 21871.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-1-files-0-1-batch-174968-262452
[INFO] processing batch 262452-349936/349936 for LSTM
[INFO] breaking into predictors and prediction...
CHUNK ANALYZE

[INFO] analyzing data
[INFO] 87484 rows
[INFO] **  Timestamp:87484 (100.0%)
[INFO] ** FIT101:1247 (1.4254%)
[INFO] ** LIT101:7700 (8.80161%)
[INFO] **  MV101:[2:71.15358%,1:28.41548%,0:0.43094%]
[INFO] ** P101:[2:74.18042%,1:25.81958%]
[INFO] ** P102:[1:98.69919%,2:1.30081%]
[INFO] **  AIT201:567 (0.64812%)
[INFO] ** AIT202:538 (0.61497%)
[INFO] ** AIT203:1831 (2.09295%)
[INFO] ** FIT201:1100 (1.25737%)
[INFO] **  MV201:[2:74.40218%,1:25.18175%,0:0.41608%]
[INFO] **  P201:[1:78.75612%,2:21.24388%]
[INFO] **  P202:[1:100.0%]
[INFO] ** P203:[2:73.95409%,1:26.04591%]
[INFO] **  P204:[1:100.0%]
[INFO] ** P205:[2:73.95409%,1:26.04591%]
[INFO] ** P206:[1:100.0%]
[INFO] ** DPIT301:2148 (2.45531%)
[INFO] ** FIT301:2215 (2.53189%)
[INFO] ** LIT301:4746 (5.42499%)
[INFO] ** MV301:[1:98.64661%,2:0.97846%,0:0.37493%]
[INFO] ** MV302:[2:81.63207%,1:17.69123%,0:0.6767%]
[INFO] **  MV303:[1:96.79484%,2:2.72164%,0:0.48352%]
[INFO] ** MV304:[1:94.49499%,2:4.80088%,0:0.70413%]
[INFO] ** P301:[1:100.0%]
[INFO] ** P302:[2:83.48727%,1:16.51273%]
[INFO] ** AIT401:[148.808:52.38215%,148.8032:38.41388%,148.7936:5.55187%,148.8128:2.64163%,148.7888:0.39436%,148.8176:0.38178%,148.784:0.08116%,148.8272:0.05715%,148.7792:0.04229%,148.832:0.03315%,148.7695:0.00686%,148.7599:0.00457%,148.8416:0.00457%,148.7647:0.00229%,148.8368:0.00229%]
[INFO] ** AIT402:755 (0.86301%)
[INFO] ** FIT401:233 (0.26633%)
[INFO] ** LIT401:10823 (12.37141%)
[INFO] ** P401:[1:100.0%]
[INFO] ** P402:[2:98.46715%,1:1.53285%]
[INFO] ** P403:[1:99.93142%,2:0.06858%]
[INFO] ** P404:[1:100.0%]
[INFO] ** UV401:[2:98.46486%,1:1.53514%]
[INFO] ** AIT501:619 (0.70756%)
[INFO] ** AIT502:603 (0.68927%)
[INFO] ** AIT503:1012 (1.15678%)
[INFO] ** AIT504:192 (0.21947%)
[INFO] ** FIT501:234 (0.26748%)
[INFO] ** FIT502:637 (0.72813%)
[INFO] ** FIT503:[0.7347566:16.19039%,0.7348846:14.80842%,0.7346286:10.35504%,0.7351406999999999:7.9466%,0.7345005:4.44081%,0.7352687:3.91729%,0.7325801:3.70239%,0.7323241:3.00969%,0.7327081999999999:2.8691%,0.7353967:2.10438%,0.732196:2.07581%,0.7342445:2.00722%,0.7328361999999999:1.80376%,0.7374451999999999:1.65745%,0.001152258:1.49856%,0.7378293:1.42426%,0.7377012:1.28595%,0.7329642:1.15107%,0.732068:1.00933%,0.7341164000000001:0.98761%,0.7379573:0.96018%,0.7355248000000001:0.9556%,0.7304036:0.90759%,0.7306597:0.791%,0.7373172:0.75557%,0.7332203:0.75442%,0.7371892:0.70527%,0.7302755999999999:0.67784%,0.7307876999999999:0.58182%,0.7357808000000001:0.54296%,0.7333483000000001:0.52695%,0.7339884:0.52124%,0.7319399999999999:0.47323%,0.7334763000000001:0.41951%,0.7301476:0.39321%,0.7336043999999999:0.38979%,0.7380853:0.37493%,0.7359089:0.3635%,0.7338604000000001:0.35778%,0.7370611:0.34978%,0.7316838999999999:0.3372%,0.7368051:0.27777%,0.7360369000000001:0.27548%,0.7309157:0.27205%,0.7300196:0.25833%,0.736421:0.25719%,0.7315559:0.2549%,0.7361649:0.25262%,0.7366771:0.18861%,0.736549:0.18289%,0.7310438:0.1806%,0.7383414:0.1726%,0.7312998:0.15774%,0.7314278000000001:0.14174%,0.7297635:0.0983%,0.7384694:0.0823%,0.7392376:0.05144%,0.7397497:0.05144%,0.7387255:0.04801%,0.7398778:0.04458%,0.7296355:0.04458%,0.7391095999999999:0.04229%,0.7385975:0.03658%,0.7288673000000001:0.03201%,0.7287393:0.02629%,0.7393656:0.024%,0.7396216999999999:0.02172%,0.001024229:0.02058%,0.7389815:0.01943%,0.7295074:0.01486%,0.7289953:0.01257%,0.7293794:0.01143%,0.000896201:0.00914%,0.7291234000000001:0.008%,0.7283552:0.00572%,0.001792402:0.00572%,0.7400058:0.00572%,0.7402619:0.00343%,0.7403899:0.00343%,0.0016643729999999998:0.00229%,0.7405179000000001:0.00229%,0.151586:0.00114%,0.07963384:0.00114%,0.6855935999999999:0.00114%,0.517876:0.00114%,0.03802452:0.00114%,0.7065903:0.00114%,0.2359569:0.00114%,0.6558909:0.00114%,0.7256666:0.00114%,0.5950773:0.00114%,0.43222479999999996:0.00114%,0.01446724:0.00114%,0.339276:0.00114%]
[INFO] ** FIT504:117 (0.13374%)
[INFO] ** P501:[2:98.46486%,1:1.53514%]
[INFO] ** P502:[1:100.0%]
[INFO] ** PIT501:347 (0.39664%)
[INFO] ** PIT502:[0.8009483000000001:16.63847%,0.7849293:11.62498%,0.9771569:8.99479%,0.9611379999999999:7.72255%,0.8169672:7.71112%,1.009195:7.04586%,1.0252139999999998:5.29468%,0.945119:4.54712%,0.8970621:4.3848%,0.9291:4.0636%,0.7689104:4.01902%,0.8490052:3.90014%,0.8810431000000001:3.54922%,0.8650241:3.23716%,1.041233:1.93178%,0.0:1.53628%,0.7368724:1.41169%,0.7208535:0.69613%,1.057252:0.57953%,0.7048345:0.38407%,1.0892899999999999:0.2469%,1.105309:0.12002%,0.6888155:0.11431%,0.6567776:0.08802%,1.121328:0.04801%,0.6407586:0.03315%,1.1373469999999999:0.01943%,1.169384:0.016%,0.6087206999999999:0.01029%,0.6247397:0.01029%,1.185403:0.00686%,0.5766828:0.00457%,1.201422:0.00457%,1.265498:0.00343%,0.48056899999999997:0.00114%]
[INFO] ** PIT503:288 (0.3292%)
[INFO] ** FIT601:923 (1.05505%)
[INFO] ** P601:[1:100.0%]
[INFO] ** P602:[1:99.12441%,2:0.87559%]
[INFO] ** P603:[1:100.0%]
[INFO] ** Normal/Attack:[Normal:95.95812%,Attack:4.04188%]
[INFO] to_xy labeltype: Normal
[INFO] to_xy labeltype: Attack
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 3 samples, validate on 1 samples
Epoch 1/1





 - 429s - loss: 0.6656 - tp: 62678.0000 - fp: 2935.0000 - tn: 62678.0000 - fn: 2935.0000 - accuracy: 0.9553 - precision: 0.9553 - recall: 0.9553 - auc: 0.9554 - val_loss: 0.6537 - val_tp: 21270.0000 - val_fp: 601.0000 - val_tn: 21270.0000 - val_fn: 601.0000 - val_accuracy: 0.9725 - val_precision: 0.9725 - val_recall: 0.9725 - val_auc: 0.9725
[INFO] saving weights to checkpoints/lstm-epoch-1-files-0-1-batch-262452-349936