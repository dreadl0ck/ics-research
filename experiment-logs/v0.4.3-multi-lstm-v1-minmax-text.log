2020-02-09 13:43:00.095435: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-09 13:43:00.108572: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb3f20d3f90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-09 13:43:00.108607: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow backend.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
2020-02-09 13:45:50.445003: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-09 13:45:50.471870: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 13:45:50.486650: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 13:45:50.605848: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-09 13:45:50.613454: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-09 13:45:50.622457: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 13:45:50.630313: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 13:45:50.664419: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-09 13:45:59.108938: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-09 13:45:59.115434: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 13:45:59.118678: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 13:45:59.144934: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-09 13:45:59.146420: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-09 13:45:59.148268: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 13:45:59.150135: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 13:45:59.161579: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
=================================================
        TRAINING v0.4.5 (binary)
=================================================
Date: 2020-02-09 13:43:00.090776
------------DNN info-------------
dnnBatchSize 16
wrapLayerSize 2
coreLayerSize 4
numCoreLayers 1
outputLayerActivation sigmoid
output_dim 2
loss binary_crossentropy
optimizer sgd
------------DNN info-------------
[INFO] input_shape (16, 107)
[INFO] LSTM first and last layer neurons: 2
[INFO] adding core layer 0
[INFO] created DNN
[33m[INFO] epoch 1/3[0m
[33m[INFO] loading file 1-50/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (24819975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] Shape when encoding dataset: (24819975, 17)
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
missing -1
len(df.columns) 108
numFeatures 107
[INFO] Shape AFTER encoding dataset: (24819975, 108)
[INFO] processing batch 0-256000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 11s - loss: 0.5173 - tp: 191488.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 512.0000 - accuracy: 0.9987 - precision: 1.0000 - recall: 0.9973 - auc: 0.9999 - val_loss: 0.3859 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-0-256000
[INFO] processing batch 256000-512000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.6900 - tp: 112918.0000 - fp: 79082.0000 - tn: 112918.0000 - fn: 79082.0000 - accuracy: 0.5881 - precision: 0.5881 - recall: 0.5881 - auc: 0.5884 - val_loss: 0.7208 - val_tp: 33927.0000 - val_fp: 30073.0000 - val_tn: 33927.0000 - val_fn: 30073.0000 - val_accuracy: 0.5301 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-256000-512000
[INFO] processing batch 512000-768000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.6008 - tp: 138284.0000 - fp: 53716.0000 - tn: 138284.0000 - fn: 53716.0000 - accuracy: 0.7202 - precision: 0.7202 - recall: 0.7202 - auc: 0.7208 - val_loss: 0.4178 - val_tp: 62058.0000 - val_fp: 1942.0000 - val_tn: 62058.0000 - val_fn: 1942.0000 - val_accuracy: 0.9697 - val_precision: 0.9697 - val_recall: 0.9697 - val_auc: 0.9697
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-512000-768000
[INFO] processing batch 768000-1024000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.6742 - tp: 117250.0000 - fp: 74750.0000 - tn: 117250.0000 - fn: 74750.0000 - accuracy: 0.6107 - precision: 0.6107 - recall: 0.6107 - auc: 0.6113 - val_loss: 0.5105 - val_tp: 55591.0000 - val_fp: 8409.0000 - val_tn: 55591.0000 - val_fn: 8409.0000 - val_accuracy: 0.8686 - val_precision: 0.8686 - val_recall: 0.8686 - val_auc: 0.8686
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-768000-1024000
[INFO] processing batch 1024000-1280000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.6160 - tp: 133967.0000 - fp: 58033.0000 - tn: 133967.0000 - fn: 58033.0000 - accuracy: 0.6977 - precision: 0.6977 - recall: 0.6977 - auc: 0.6977 - val_loss: 0.4042 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-1024000-1280000
[INFO] processing batch 1280000-1536000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.3234 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2601 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-1280000-1536000
[INFO] processing batch 1536000-1792000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.2199 - tp: 191999.0000 - fp: 1.0000 - tn: 191999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1867 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-1536000-1792000
[INFO] processing batch 1792000-2048000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.5451 - tp: 148221.0000 - fp: 43779.0000 - tn: 148221.0000 - fn: 43779.0000 - accuracy: 0.7720 - precision: 0.7720 - recall: 0.7720 - auc: 0.7743 - val_loss: 0.3445 - val_tp: 57941.0000 - val_fp: 6059.0000 - val_tn: 57941.0000 - val_fn: 6059.0000 - val_accuracy: 0.9053 - val_precision: 0.9053 - val_recall: 0.9053 - val_auc: 0.9053
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-1792000-2048000
[INFO] processing batch 2048000-2304000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 11s - loss: 0.5886 - tp: 141714.0000 - fp: 50286.0000 - tn: 141714.0000 - fn: 50286.0000 - accuracy: 0.7381 - precision: 0.7381 - recall: 0.7381 - auc: 0.7371 - val_loss: 0.2281 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-2048000-2304000
[INFO] processing batch 2304000-2560000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 10s - loss: 0.1957 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1686 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-2304000-2560000
[INFO] processing batch 2560000-2816000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.1492 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1324 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-2560000-2816000
[INFO] processing batch 2816000-3072000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 9s - loss: 0.5647 - tp: 148720.0000 - fp: 43280.0000 - tn: 148720.0000 - fn: 43280.0000 - accuracy: 0.7746 - precision: 0.7746 - recall: 0.7746 - auc: 0.7749 - val_loss: 0.7974 - val_tp: 40961.0000 - val_fp: 23039.0000 - val_tn: 40961.0000 - val_fn: 23039.0000 - val_accuracy: 0.6400 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.6400
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-2816000-3072000
[INFO] processing batch 3072000-3328000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 10s - loss: 0.6939 - tp: 131495.0000 - fp: 60505.0000 - tn: 131495.0000 - fn: 60505.0000 - accuracy: 0.6849 - precision: 0.6849 - recall: 0.6849 - auc: 0.6850 - val_loss: 0.2016 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-3072000-3328000
[INFO] processing batch 3328000-3584000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 10s - loss: 0.1753 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1529 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-3328000-3584000
[INFO] processing batch 3584000-3840000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 10s - loss: 0.1366 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1223 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-3584000-3840000
[INFO] processing batch 3840000-4096000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 10s - loss: 0.4850 - tp: 157534.0000 - fp: 34466.0000 - tn: 157534.0000 - fn: 34466.0000 - accuracy: 0.8205 - precision: 0.8205 - recall: 0.8205 - auc: 0.8208 - val_loss: 0.4908 - val_tp: 52219.0000 - val_fp: 11781.0000 - val_tn: 52219.0000 - val_fn: 11781.0000 - val_accuracy: 0.8159 - val_precision: 0.8159 - val_recall: 0.8159 - val_auc: 0.8159
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-3840000-4096000
[INFO] processing batch 4096000-4352000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 9s - loss: 0.1424 - tp: 190188.0000 - fp: 1812.0000 - tn: 190188.0000 - fn: 1812.0000 - accuracy: 0.9906 - precision: 0.9906 - recall: 0.9906 - auc: 0.9904 - val_loss: 0.1123 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-4096000-4352000
[INFO] processing batch 4352000-4608000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.1029 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0944 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-4352000-4608000
[INFO] processing batch 4608000-4864000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.4584 - tp: 161451.0000 - fp: 30549.0000 - tn: 161451.0000 - fn: 30549.0000 - accuracy: 0.8409 - precision: 0.8409 - recall: 0.8409 - auc: 0.8411 - val_loss: 0.1058 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-4608000-4864000
[INFO] processing batch 4864000-5120000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.0973 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0896 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-4864000-5120000
[INFO] processing batch 5120000-5376000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.0834 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0776 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-5120000-5376000
[INFO] processing batch 5376000-5632000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.0728 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0684 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-5376000-5632000
[INFO] processing batch 5632000-5888000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 9s - loss: 0.5547 - tp: 155809.0000 - fp: 36191.0000 - tn: 155809.0000 - fn: 36191.0000 - accuracy: 0.8115 - precision: 0.8115 - recall: 0.8115 - auc: 0.8093 - val_loss: 0.0841 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-5632000-5888000
[INFO] processing batch 5888000-6144000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 9s - loss: 0.0786 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0734 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-5888000-6144000
[INFO] processing batch 6144000-6400000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 9s - loss: 0.3123 - tp: 174156.0000 - fp: 17844.0000 - tn: 174156.0000 - fn: 17844.0000 - accuracy: 0.9071 - precision: 0.9071 - recall: 0.9071 - auc: 0.9071 - val_loss: 0.9831 - val_tp: 41108.0000 - val_fp: 22892.0000 - val_tn: 41108.0000 - val_fn: 22892.0000 - val_accuracy: 0.6423 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-6144000-6400000
[INFO] processing batch 6400000-6656000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.7437 - tp: 138766.0000 - fp: 53234.0000 - tn: 138766.0000 - fn: 53234.0000 - accuracy: 0.7227 - precision: 0.7227 - recall: 0.7227 - auc: 0.7230 - val_loss: 0.1072 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-6400000-6656000
[INFO] processing batch 6656000-6912000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 9s - loss: 0.0985 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0907 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-6656000-6912000
[INFO] processing batch 6912000-7168000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 9s - loss: 0.0843 - tp: 191998.0000 - fp: 2.0000 - tn: 191998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0785 - val_tp: 63999.0000 - val_fp: 1.0000 - val_tn: 63999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-6912000-7168000
[INFO] processing batch 7168000-7424000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.0735 - tp: 191999.0000 - fp: 1.0000 - tn: 191999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8795 - val_tp: 44344.0000 - val_fp: 19656.0000 - val_tn: 44344.0000 - val_fn: 19656.0000 - val_accuracy: 0.6929 - val_precision: 0.6929 - val_recall: 0.6929 - val_auc: 0.6929
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-7168000-7424000
[INFO] processing batch 7424000-7680000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 1.1672 - tp: 102062.0000 - fp: 89938.0000 - tn: 102062.0000 - fn: 89938.0000 - accuracy: 0.5316 - precision: 0.5316 - recall: 0.5316 - auc: 0.5311 - val_loss: 0.5627 - val_tp: 49859.0000 - val_fp: 14141.0000 - val_tn: 49859.0000 - val_fn: 14141.0000 - val_accuracy: 0.7790 - val_precision: 0.7790 - val_recall: 0.7790 - val_auc: 0.7790
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-7424000-7680000
[INFO] processing batch 7680000-7936000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 9s - loss: 0.1215 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1100 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-7680000-7936000
[INFO] processing batch 7936000-8192000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 10s - loss: 0.1009 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0927 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-7936000-8192000
[INFO] processing batch 8192000-8448000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 10s - loss: 0.4557 - tp: 161781.0000 - fp: 30219.0000 - tn: 161781.0000 - fn: 30219.0000 - accuracy: 0.8426 - precision: 0.8426 - recall: 0.8426 - auc: 0.8425 - val_loss: 0.1257 - val_tp: 63369.0000 - val_fp: 631.0000 - val_tn: 63369.0000 - val_fn: 631.0000 - val_accuracy: 0.9901 - val_precision: 0.9901 - val_recall: 0.9901 - val_auc: 0.9901
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-8192000-8448000
[INFO] processing batch 8448000-8704000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 10s - loss: 0.8398 - tp: 123282.0000 - fp: 68718.0000 - tn: 123282.0000 - fn: 68718.0000 - accuracy: 0.6421 - precision: 0.6421 - recall: 0.6421 - auc: 0.6421 - val_loss: 0.8294 - val_tp: 39692.0000 - val_fp: 24308.0000 - val_tn: 39692.0000 - val_fn: 24308.0000 - val_accuracy: 0.6202 - val_precision: 0.6202 - val_recall: 0.6202 - val_auc: 0.6202
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-8448000-8704000
[INFO] processing batch 8704000-8960000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 9s - loss: 0.1814 - tp: 188028.0000 - fp: 3972.0000 - tn: 188028.0000 - fn: 3972.0000 - accuracy: 0.9793 - precision: 0.9793 - recall: 0.9793 - auc: 0.9797 - val_loss: 0.1294 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-8704000-8960000
[INFO] processing batch 8960000-9216000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.1172 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1064 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-8960000-9216000
[INFO] processing batch 9216000-9472000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.8602 - tp: 120440.0000 - fp: 71560.0000 - tn: 120440.0000 - fn: 71560.0000 - accuracy: 0.6273 - precision: 0.6273 - recall: 0.6273 - auc: 0.6281 - val_loss: 0.1642 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-9216000-9472000
[INFO] processing batch 9472000-9728000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.4375 - tp: 161553.0000 - fp: 30447.0000 - tn: 161553.0000 - fn: 30447.0000 - accuracy: 0.8414 - precision: 0.8414 - recall: 0.8414 - auc: 0.8414 - val_loss: 0.4477 - val_tp: 53468.0000 - val_fp: 10532.0000 - val_tn: 53468.0000 - val_fn: 10532.0000 - val_accuracy: 0.8354 - val_precision: 0.8354 - val_recall: 0.8354 - val_auc: 0.8354
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-9472000-9728000
[INFO] processing batch 9728000-9984000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.1472 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1308 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-9728000-9984000
[INFO] processing batch 9984000-10240000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 7s - loss: 0.1184 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1074 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-9984000-10240000
[INFO] processing batch 10240000-10496000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.1290 - tp: 189510.0000 - fp: 2490.0000 - tn: 189510.0000 - fn: 2490.0000 - accuracy: 0.9870 - precision: 0.9870 - recall: 0.9870 - auc: 0.9872 - val_loss: 1.1863 - val_tp: 33975.0000 - val_fp: 30025.0000 - val_tn: 33975.0000 - val_fn: 30025.0000 - val_accuracy: 0.5309 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.5309
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-10240000-10496000
[INFO] processing batch 10496000-10752000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 1.0675 - tp: 101670.0000 - fp: 90330.0000 - tn: 101670.0000 - fn: 90330.0000 - accuracy: 0.5295 - precision: 0.5295 - recall: 0.5295 - auc: 0.5295 - val_loss: 0.9569 - val_tp: 34015.0000 - val_fp: 29985.0000 - val_tn: 34015.0000 - val_fn: 29985.0000 - val_accuracy: 0.5315 - val_precision: 0.5315 - val_recall: 0.5315 - val_auc: 0.5315
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-10496000-10752000
[INFO] processing batch 10752000-11008000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.8829 - tp: 101693.0000 - fp: 90307.0000 - tn: 101693.0000 - fn: 90307.0000 - accuracy: 0.5297 - precision: 0.5297 - recall: 0.5297 - auc: 0.5303 - val_loss: 0.3992 - val_tp: 56989.0000 - val_fp: 7011.0000 - val_tn: 56989.0000 - val_fn: 7011.0000 - val_accuracy: 0.8905 - val_precision: 0.8905 - val_recall: 0.8905 - val_auc: 0.8905
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-10752000-11008000
[INFO] processing batch 11008000-11264000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.2284 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1930 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-11008000-11264000
[INFO] processing batch 11264000-11520000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.1686 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1477 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-11264000-11520000
[INFO] processing batch 11520000-11776000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.1323 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1188 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-11520000-11776000
[INFO] processing batch 11776000-12032000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.4981 - tp: 156412.0000 - fp: 35588.0000 - tn: 156412.0000 - fn: 35588.0000 - accuracy: 0.8146 - precision: 0.8146 - recall: 0.8146 - auc: 0.8156 - val_loss: 0.8285 - val_tp: 41134.0000 - val_fp: 22866.0000 - val_tn: 41134.0000 - val_fn: 22866.0000 - val_accuracy: 0.6427 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.6427
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-11776000-12032000
[INFO] processing batch 12032000-12288000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.7838 - tp: 123527.0000 - fp: 68473.0000 - tn: 123527.0000 - fn: 68473.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6427 - val_loss: 0.7454 - val_tp: 41219.0000 - val_fp: 22781.0000 - val_tn: 41219.0000 - val_fn: 22781.0000 - val_accuracy: 0.6440 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.6440
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-12032000-12288000
[INFO] processing batch 12288000-12544000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.7202 - tp: 123560.0000 - fp: 68440.0000 - tn: 123560.0000 - fn: 68440.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6432 - val_loss: 0.6972 - val_tp: 41268.0000 - val_fp: 22732.0000 - val_tn: 41268.0000 - val_fn: 22732.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-12288000-12544000
[INFO] processing batch 12544000-12800000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.6847 - tp: 123588.0000 - fp: 68412.0000 - tn: 123588.0000 - fn: 68412.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6442 - val_loss: 0.6724 - val_tp: 41269.0000 - val_fp: 22731.0000 - val_tn: 41269.0000 - val_fn: 22731.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-12544000-12800000
[INFO] processing batch 12800000-13056000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.6670 - tp: 123531.0000 - fp: 68469.0000 - tn: 123531.0000 - fn: 68469.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6432 - val_loss: 0.6616 - val_tp: 41181.0000 - val_fp: 22819.0000 - val_tn: 41181.0000 - val_fn: 22819.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-12800000-13056000
[INFO] processing batch 13056000-13312000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.6581 - tp: 123615.0000 - fp: 68385.0000 - tn: 123615.0000 - fn: 68385.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6439 - val_loss: 0.6558 - val_tp: 41192.0000 - val_fp: 22808.0000 - val_tn: 41192.0000 - val_fn: 22808.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-13056000-13312000
[INFO] processing batch 13312000-13568000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.6549 - tp: 123437.0000 - fp: 68563.0000 - tn: 123437.0000 - fn: 68563.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6429 - val_loss: 0.6534 - val_tp: 41179.0000 - val_fp: 22821.0000 - val_tn: 41179.0000 - val_fn: 22821.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-13312000-13568000
[INFO] processing batch 13568000-13824000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 9s - loss: 0.6527 - tp: 123539.0000 - fp: 68461.0000 - tn: 123539.0000 - fn: 68461.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6435 - val_loss: 0.6519 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-13568000-13824000
[INFO] processing batch 13824000-14080000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 9s - loss: 0.6519 - tp: 123556.0000 - fp: 68444.0000 - tn: 123556.0000 - fn: 68444.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6436 - val_loss: 0.6518 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 41173.0000 - val_fn: 22827.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-13824000-14080000
[INFO] processing batch 14080000-14336000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 9s - loss: 0.6512 - tp: 123681.0000 - fp: 68319.0000 - tn: 123681.0000 - fn: 68319.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6441 - val_loss: 0.6512 - val_tp: 41221.0000 - val_fp: 22779.0000 - val_tn: 41221.0000 - val_fn: 22779.0000 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.6441
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-14080000-14336000
[INFO] processing batch 14336000-14592000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.6516 - tp: 123523.0000 - fp: 68477.0000 - tn: 123523.0000 - fn: 68477.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6433 - val_loss: 0.6513 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 41197.0000 - val_fn: 22803.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-14336000-14592000
[INFO] processing batch 14592000-14848000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.6511 - tp: 123652.0000 - fp: 68348.0000 - tn: 123652.0000 - fn: 68348.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6443 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-14592000-14848000
[INFO] processing batch 14848000-15104000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.6513 - tp: 123594.0000 - fp: 68406.0000 - tn: 123594.0000 - fn: 68406.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6512 - val_tp: 41205.0000 - val_fp: 22795.0000 - val_tn: 41205.0000 - val_fn: 22795.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-14848000-15104000
[INFO] processing batch 15104000-15360000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.6511 - tp: 123629.0000 - fp: 68371.0000 - tn: 123629.0000 - fn: 68371.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6509 - val_tp: 41234.0000 - val_fp: 22766.0000 - val_tn: 41234.0000 - val_fn: 22766.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-15104000-15360000
[INFO] processing batch 15360000-15616000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.6511 - tp: 123632.0000 - fp: 68368.0000 - tn: 123632.0000 - fn: 68368.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6506 - val_tp: 41266.0000 - val_fp: 22734.0000 - val_tn: 41266.0000 - val_fn: 22734.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-15360000-15616000
[INFO] processing batch 15616000-15872000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 9s - loss: 0.6515 - tp: 123527.0000 - fp: 68473.0000 - tn: 123527.0000 - fn: 68473.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6434 - val_loss: 0.6513 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 41197.0000 - val_fn: 22803.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-15616000-15872000
[INFO] processing batch 15872000-16128000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 10s - loss: 0.6514 - tp: 123531.0000 - fp: 68469.0000 - tn: 123531.0000 - fn: 68469.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6434 - val_loss: 0.6515 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 41173.0000 - val_fn: 22827.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-15872000-16128000
[INFO] processing batch 16128000-16384000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 10s - loss: 0.6507 - tp: 123781.0000 - fp: 68219.0000 - tn: 123781.0000 - fn: 68219.0000 - accuracy: 0.6447 - precision: 0.6447 - recall: 0.6447 - auc: 0.6447 - val_loss: 0.6513 - val_tp: 41195.0000 - val_fp: 22805.0000 - val_tn: 41195.0000 - val_fn: 22805.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-16128000-16384000
[INFO] processing batch 16384000-16640000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 9s - loss: 0.6512 - tp: 123621.0000 - fp: 68379.0000 - tn: 123621.0000 - fn: 68379.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6516 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 41165.0000 - val_fn: 22835.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-16384000-16640000
[INFO] processing batch 16640000-16896000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 9s - loss: 0.6518 - tp: 123417.0000 - fp: 68583.0000 - tn: 123417.0000 - fn: 68583.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6428 - val_loss: 0.6510 - val_tp: 41230.0000 - val_fp: 22770.0000 - val_tn: 41230.0000 - val_fn: 22770.0000 - val_accuracy: 0.6442 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.6442
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-16640000-16896000
[INFO] processing batch 16896000-17152000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.6512 - tp: 123600.0000 - fp: 68400.0000 - tn: 123600.0000 - fn: 68400.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6437 - val_loss: 0.6512 - val_tp: 41198.0000 - val_fp: 22802.0000 - val_tn: 41198.0000 - val_fn: 22802.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-16896000-17152000
[INFO] processing batch 17152000-17408000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 9s - loss: 0.6509 - tp: 123711.0000 - fp: 68289.0000 - tn: 123711.0000 - fn: 68289.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6443 - val_loss: 0.6515 - val_tp: 41168.0000 - val_fp: 22832.0000 - val_tn: 41168.0000 - val_fn: 22832.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-17152000-17408000
[INFO] processing batch 17408000-17664000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 9s - loss: 0.6509 - tp: 123701.0000 - fp: 68299.0000 - tn: 123701.0000 - fn: 68299.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6443 - val_loss: 0.6520 - val_tp: 41118.0000 - val_fp: 22882.0000 - val_tn: 41118.0000 - val_fn: 22882.0000 - val_accuracy: 0.6425 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.6425
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-17408000-17664000
[INFO] processing batch 17664000-17920000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 9s - loss: 0.6514 - tp: 123546.0000 - fp: 68454.0000 - tn: 123546.0000 - fn: 68454.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6523 - val_tp: 41089.0000 - val_fp: 22911.0000 - val_tn: 41089.0000 - val_fn: 22911.0000 - val_accuracy: 0.6420 - val_precision: 0.6420 - val_recall: 0.6420 - val_auc: 0.6420
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-17664000-17920000
[INFO] processing batch 17920000-18176000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 9s - loss: 0.6510 - tp: 123681.0000 - fp: 68319.0000 - tn: 123681.0000 - fn: 68319.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6509 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 41233.0000 - val_fn: 22767.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-17920000-18176000
[INFO] processing batch 18176000-18432000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 9s - loss: 0.6511 - tp: 123640.0000 - fp: 68360.0000 - tn: 123640.0000 - fn: 68360.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6440 - val_loss: 0.6503 - val_tp: 41298.0000 - val_fp: 22702.0000 - val_tn: 41298.0000 - val_fn: 22702.0000 - val_accuracy: 0.6453 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.6453
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-18176000-18432000
[INFO] processing batch 18432000-18688000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 11s - loss: 0.6512 - tp: 123615.0000 - fp: 68385.0000 - tn: 123615.0000 - fn: 68385.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6438 - val_loss: 0.6509 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 41233.0000 - val_fn: 22767.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-18432000-18688000
[INFO] processing batch 18688000-18944000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 9s - loss: 0.6511 - tp: 123645.0000 - fp: 68355.0000 - tn: 123645.0000 - fn: 68355.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6440 - val_loss: 0.6514 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 41184.0000 - val_fn: 22816.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
