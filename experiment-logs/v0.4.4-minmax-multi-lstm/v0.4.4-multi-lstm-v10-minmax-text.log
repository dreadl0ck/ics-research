2020-02-09 03:03:48.648051: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-09 03:03:48.660212: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8495191950 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-09 03:03:48.660250: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow backend.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
=================================================
        TRAINING v0.4.4 (multi-class)
=================================================
Date: 2020-02-09 03:03:48.643689
MULTI-CLASS num classes: 5
------------DNN info-------------
wrapLayerSize 8
coreLayerSize 32
numCoreLayers 3
outputLayerActivation softmax
output_dim 5
loss categorical_crossentropy
optimizer adam
------------DNN info-------------
[INFO] input_shape (128, 107)
[INFO] LSTM first and last layer neurons: 8
[INFO] adding core layer 0
[INFO] adding core layer 1
[INFO] adding core layer 2
[INFO] created DNN
[33m[INFO] epoch 1/10[0m
[33m[INFO] loading file 1-50/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (24819975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
len(df.columns) 108
numFeatures 107
[INFO] columns: Index(['unixtime', 'modbus_function_code', 'modbus_transaction_id', 'service',
       's_port', 'classification', 'orig-192.168.1.48', 'orig-192.168.1.87',
       'orig-192.168.1.88', 'type-alert',
       ...
       'modbus_function_description-Read Tag Service',
       'modbus_function_description-Read Tag Service - Response',
       'modbus_function_description-Unknown Function Code',
       'modbus_function_description-Write Tag Service', 'scada_tag-0',
       'scada_tag-HMI_AIT202', 'scada_tag-HMI_FIT201', 'scada_tag-HMI_LIT101',
       'scada_tag-HMI_LIT301', 'scada_tag-HMI_LIT401'],
      dtype='object', length=108)
[INFO] processing batch 0-256000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers2020-02-09 03:07:02.932775: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-09 03:07:02.980718: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 03:07:03.000882: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 03:07:03.181884: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-09 03:07:03.194129: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-09 03:07:03.207834: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 03:07:03.222362: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 03:07:03.278828: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-09 03:07:22.046699: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-09 03:07:22.057725: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 03:07:22.063820: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 03:07:22.103119: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-09 03:07:22.106004: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-09 03:07:22.109209: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 03:07:22.112497: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 03:07:22.130325: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.

[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 23s - loss: 1.5730 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 192000.0000 - accuracy: 0.8000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.9572 - val_loss: 1.5351 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 64000.0000 - val_accuracy: 0.8000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-0-256000
[INFO] processing batch 256000-512000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.5526 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 192000.0000 - accuracy: 0.8000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.8925 - val_loss: 1.5346 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 64000.0000 - val_accuracy: 0.8000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8825
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-256000-512000
[INFO] processing batch 512000-768000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.4948 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 192000.0000 - accuracy: 0.8000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.9303 - val_loss: 1.4448 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 64000.0000 - val_accuracy: 0.8000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9924
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-512000-768000
[INFO] processing batch 768000-1024000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.4617 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 192000.0000 - accuracy: 0.8000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.9025 - val_loss: 1.4138 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 64000.0000 - val_accuracy: 0.8000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9672
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-768000-1024000
[INFO] processing batch 1024000-1280000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.4100 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 192000.0000 - accuracy: 0.8000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.9242 - val_loss: 1.3547 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 64000.0000 - val_accuracy: 0.8000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-1024000-1280000
[INFO] processing batch 1280000-1536000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.3191 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 192000.0000 - accuracy: 0.8000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 1.0000 - val_loss: 1.2786 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 64000.0000 - val_accuracy: 0.8000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-1280000-1536000
[INFO] processing batch 1536000-1792000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.2412 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 192000.0000 - accuracy: 0.8000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 1.0000 - val_loss: 1.2032 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 64000.0000 - val_accuracy: 0.8000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-1536000-1792000
[INFO] processing batch 1792000-2048000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.2599 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 192000.0000 - accuracy: 0.8000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.9429 - val_loss: 1.1890 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 64000.0000 - val_accuracy: 0.8000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9763
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-1792000-2048000
[INFO] processing batch 2048000-2304000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.2365 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 192000.0000 - accuracy: 0.8000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.9342 - val_loss: 1.1118 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 64000.0000 - val_accuracy: 0.8000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-2048000-2304000
[INFO] processing batch 2304000-2560000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.0827 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 192000.0000 - accuracy: 0.8000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 1.0000 - val_loss: 1.0492 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 64000.0000 - val_accuracy: 0.8000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-2304000-2560000
[INFO] processing batch 2560000-2816000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.0181 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 192000.0000 - accuracy: 0.8000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 1.0000 - val_loss: 0.9862 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 64000.0000 - val_accuracy: 0.8000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-2560000-2816000
[INFO] processing batch 2816000-3072000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.1103 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 192000.0000 - accuracy: 0.8000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.9438 - val_loss: 1.1839 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 64000.0000 - val_accuracy: 0.8000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9100
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-2816000-3072000
[INFO] processing batch 3072000-3328000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.1412 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 192000.0000 - accuracy: 0.8000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.9212 - val_loss: 0.9199 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 64000.0000 - val_accuracy: 0.8000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-3072000-3328000
[INFO] processing batch 3328000-3584000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.8969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 192000.0000 - accuracy: 0.8000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 1.0000 - val_loss: 0.8691 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 64000.0000 - val_accuracy: 0.8000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-3328000-3584000
[INFO] processing batch 3584000-3840000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.8429 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 192000.0000 - accuracy: 0.8000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 1.0000 - val_loss: 0.8161 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 64000.0000 - val_accuracy: 0.8000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-3584000-3840000
[INFO] processing batch 3840000-4096000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.9558 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 192000.0000 - accuracy: 0.8000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.9552 - val_loss: 0.9468 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 64000.0000 - val_accuracy: 0.8000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9540
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-3840000-4096000
[INFO] processing batch 4096000-4352000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7693 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 192000.0000 - accuracy: 0.8000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.9976 - val_loss: 0.7375 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 64000.0000 - val_accuracy: 0.8000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-4096000-4352000
[INFO] processing batch 4352000-4608000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7158 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 192000.0000 - accuracy: 0.8000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 1.0000 - val_loss: 0.6935 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 64000.0000 - val_accuracy: 0.8000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-4352000-4608000
[INFO] processing batch 4608000-4864000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.8543 - tp: 157996.0000 - fp: 29908.0000 - tn: 738092.0000 - fn: 34004.0000 - accuracy: 0.9334 - precision: 0.8408 - recall: 0.8229 - auc: 0.9607 - val_loss: 0.6642 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-4608000-4864000
[INFO] processing batch 4864000-5120000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6467 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6272 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-4864000-5120000
[INFO] processing batch 5120000-5376000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6091 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5906 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-5120000-5376000
[INFO] processing batch 5376000-5632000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.5738 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5567 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-5376000-5632000
[INFO] processing batch 5632000-5888000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.8101 - tp: 155809.0000 - fp: 36191.0000 - tn: 731809.0000 - fn: 36191.0000 - accuracy: 0.9246 - precision: 0.8115 - recall: 0.8115 - auc: 0.9527 - val_loss: 0.5374 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-5632000-5888000
[INFO] processing batch 5888000-6144000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.5246 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5096 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-5888000-6144000
[INFO] processing batch 6144000-6400000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6376 - tp: 174156.0000 - fp: 17844.0000 - tn: 750156.0000 - fn: 17844.0000 - accuracy: 0.9628 - precision: 0.9071 - recall: 0.9071 - auc: 0.9764 - val_loss: 1.0328 - val_tp: 41108.0000 - val_fp: 22892.0000 - val_tn: 233108.0000 - val_fn: 22892.0000 - val_accuracy: 0.8569 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-6144000-6400000
[INFO] processing batch 6400000-6656000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.9035 - tp: 138766.0000 - fp: 53234.0000 - tn: 714766.0000 - fn: 53234.0000 - accuracy: 0.8891 - precision: 0.7227 - recall: 0.7227 - auc: 0.9306 - val_loss: 0.4786 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-6400000-6656000
[INFO] processing batch 6656000-6912000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.4685 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4555 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-6656000-6912000
[INFO] processing batch 6912000-7168000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.4429 - tp: 191998.0000 - fp: 2.0000 - tn: 767998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4300 - val_tp: 63999.0000 - val_fp: 1.0000 - val_tn: 255999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-6912000-7168000
[INFO] processing batch 7168000-7424000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.4183 - tp: 191999.0000 - fp: 1.0000 - tn: 767999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0911 - val_tp: 44344.0000 - val_fp: 19656.0000 - val_tn: 236344.0000 - val_fn: 19656.0000 - val_accuracy: 0.8772 - val_precision: 0.6929 - val_recall: 0.6929 - val_auc: 0.7697
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-7168000-7424000
[INFO] processing batch 7424000-7680000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.4298 - tp: 102062.0000 - fp: 89938.0000 - tn: 678062.0000 - fn: 89938.0000 - accuracy: 0.8126 - precision: 0.5316 - recall: 0.5316 - auc: 0.7168 - val_loss: 0.8760 - val_tp: 49859.0000 - val_fp: 14141.0000 - val_tn: 241859.0000 - val_fn: 14141.0000 - val_accuracy: 0.9116 - val_precision: 0.7790 - val_recall: 0.7790 - val_auc: 0.8895
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-7424000-7680000
[INFO] processing batch 7680000-7936000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.4007 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3906 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-7680000-7936000
[INFO] processing batch 7936000-8192000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.3804 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3700 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-7936000-8192000
[INFO] processing batch 8192000-8448000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7370 - tp: 161781.0000 - fp: 30219.0000 - tn: 737781.0000 - fn: 30219.0000 - accuracy: 0.9370 - precision: 0.8426 - recall: 0.8426 - auc: 0.8656 - val_loss: 0.3817 - val_tp: 63369.0000 - val_fp: 631.0000 - val_tn: 255369.0000 - val_fn: 631.0000 - val_accuracy: 0.9961 - val_precision: 0.9901 - val_recall: 0.9901 - val_auc: 0.9926
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-8192000-8448000
[INFO] processing batch 8448000-8704000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.1883 - tp: 123282.0000 - fp: 68718.0000 - tn: 699282.0000 - fn: 68718.0000 - accuracy: 0.8568 - precision: 0.6421 - recall: 0.6421 - auc: 0.7438 - val_loss: 1.2190 - val_tp: 39692.0000 - val_fp: 24308.0000 - val_tn: 231692.0000 - val_fn: 24308.0000 - val_accuracy: 0.8481 - val_precision: 0.6202 - val_recall: 0.6202 - val_auc: 0.7626
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-8448000-8704000
[INFO] processing batch 8704000-8960000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.4003 - tp: 188028.0000 - fp: 3972.0000 - tn: 764028.0000 - fn: 3972.0000 - accuracy: 0.9917 - precision: 0.9793 - recall: 0.9793 - auc: 0.9878 - val_loss: 0.3452 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-8704000-8960000
[INFO] processing batch 8960000-9216000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.3367 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3277 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-8960000-9216000
[INFO] processing batch 9216000-9472000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.2029 - tp: 120440.0000 - fp: 71560.0000 - tn: 696440.0000 - fn: 71560.0000 - accuracy: 0.8509 - precision: 0.6273 - recall: 0.6273 - auc: 0.7777 - val_loss: 0.3280 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-9216000-9472000
[INFO] processing batch 9472000-9728000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6876 - tp: 161553.0000 - fp: 30447.0000 - tn: 737553.0000 - fn: 30447.0000 - accuracy: 0.9366 - precision: 0.8414 - recall: 0.8414 - auc: 0.9207 - val_loss: 0.6961 - val_tp: 53468.0000 - val_fp: 10532.0000 - val_tn: 245468.0000 - val_fn: 10532.0000 - val_accuracy: 0.9342 - val_precision: 0.8354 - val_recall: 0.8354 - val_auc: 0.9177
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-9472000-9728000
[INFO] processing batch 9728000-9984000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.3155 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3075 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-9728000-9984000
[INFO] processing batch 9984000-10240000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2998 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2919 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-9984000-10240000
[INFO] processing batch 10240000-10496000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.3207 - tp: 189510.0000 - fp: 2490.0000 - tn: 765510.0000 - fn: 2490.0000 - accuracy: 0.9948 - precision: 0.9870 - recall: 0.9870 - auc: 0.9872 - val_loss: 1.5804 - val_tp: 33975.0000 - val_fp: 30025.0000 - val_tn: 225975.0000 - val_fn: 30025.0000 - val_accuracy: 0.8123 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.5309
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-10240000-10496000
[INFO] processing batch 10496000-10752000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.5562 - tp: 101670.0000 - fp: 90330.0000 - tn: 677670.0000 - fn: 90330.0000 - accuracy: 0.8118 - precision: 0.5295 - recall: 0.5295 - auc: 0.5295 - val_loss: 1.5139 - val_tp: 34015.0000 - val_fp: 29985.0000 - val_tn: 226015.0000 - val_fn: 29985.0000 - val_accuracy: 0.8126 - val_precision: 0.5315 - val_recall: 0.5315 - val_auc: 0.5315
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-10496000-10752000
[INFO] processing batch 10752000-11008000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.4857 - tp: 101693.0000 - fp: 90307.0000 - tn: 677693.0000 - fn: 90307.0000 - accuracy: 0.8119 - precision: 0.5297 - recall: 0.5297 - auc: 0.6032 - val_loss: 0.5646 - val_tp: 56989.0000 - val_fp: 7011.0000 - val_tn: 248989.0000 - val_fn: 7011.0000 - val_accuracy: 0.9562 - val_precision: 0.8905 - val_recall: 0.8905 - val_auc: 0.9178
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-10752000-11008000
[INFO] processing batch 11008000-11264000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.2914 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2848 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-11008000-11264000
[INFO] processing batch 11264000-11520000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.2779 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2708 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-11264000-11520000
[INFO] processing batch 11520000-11776000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2644 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2578 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-11520000-11776000
[INFO] processing batch 11776000-12032000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7329 - tp: 156412.0000 - fp: 35588.0000 - tn: 732412.0000 - fn: 35588.0000 - accuracy: 0.9259 - precision: 0.8146 - recall: 0.8146 - auc: 0.9024 - val_loss: 1.1694 - val_tp: 41134.0000 - val_fp: 22866.0000 - val_tn: 233134.0000 - val_fn: 22866.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.8214
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-11776000-12032000
[INFO] processing batch 12032000-12288000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.1543 - tp: 123527.0000 - fp: 68473.0000 - tn: 699527.0000 - fn: 68473.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.8955 - val_loss: 1.1368 - val_tp: 41219.0000 - val_fp: 22781.0000 - val_tn: 233219.0000 - val_fn: 22781.0000 - val_accuracy: 0.8576 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-12032000-12288000
[INFO] processing batch 12288000-12544000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.1231 - tp: 123560.0000 - fp: 68440.0000 - tn: 699560.0000 - fn: 68440.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 1.1721 - val_tp: 41268.0000 - val_fp: 22732.0000 - val_tn: 233268.0000 - val_fn: 22732.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.8011
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-12288000-12544000
[INFO] processing batch 12544000-12800000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.1758 - tp: 123588.0000 - fp: 68412.0000 - tn: 699588.0000 - fn: 68412.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.8179 - val_loss: 1.1536 - val_tp: 41269.0000 - val_fp: 22731.0000 - val_tn: 233269.0000 - val_fn: 22731.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.8224
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-12544000-12800000
[INFO] processing batch 12800000-13056000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.1389 - tp: 123531.0000 - fp: 68469.0000 - tn: 699531.0000 - fn: 68469.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.8273 - val_loss: 1.1203 - val_tp: 41181.0000 - val_fp: 22819.0000 - val_tn: 233181.0000 - val_fn: 22819.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.8663
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-12800000-13056000
[INFO] processing batch 13056000-13312000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.1033 - tp: 123615.0000 - fp: 68385.0000 - tn: 699615.0000 - fn: 68385.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.8881 - val_loss: 1.0875 - val_tp: 41192.0000 - val_fp: 22808.0000 - val_tn: 233192.0000 - val_fn: 22808.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-13056000-13312000
[INFO] processing batch 13312000-13568000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.0747 - tp: 123437.0000 - fp: 68563.0000 - tn: 699437.0000 - fn: 68563.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9107 - val_loss: 1.0588 - val_tp: 41179.0000 - val_fp: 22821.0000 - val_tn: 233179.0000 - val_fn: 22821.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-13312000-13568000
[INFO] processing batch 13568000-13824000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.0457 - tp: 123539.0000 - fp: 68461.0000 - tn: 699539.0000 - fn: 68461.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 1.0313 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-13568000-13824000
[INFO] processing batch 13824000-14080000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.0202 - tp: 123556.0000 - fp: 68444.0000 - tn: 699556.0000 - fn: 68444.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 1.0084 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 233173.0000 - val_fn: 22827.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-13824000-14080000
[INFO] processing batch 14080000-14336000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.9958 - tp: 123681.0000 - fp: 68319.0000 - tn: 699681.0000 - fn: 68319.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.9848 - val_tp: 41221.0000 - val_fp: 22779.0000 - val_tn: 233221.0000 - val_fn: 22779.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-14080000-14336000
[INFO] processing batch 14336000-14592000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9760 - tp: 123523.0000 - fp: 68477.0000 - tn: 699523.0000 - fn: 68477.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9109 - val_loss: 0.9649 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 233197.0000 - val_fn: 22803.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-14336000-14592000
[INFO] processing batch 14592000-14848000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9550 - tp: 123652.0000 - fp: 68348.0000 - tn: 699652.0000 - fn: 68348.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9109 - val_loss: 0.9456 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-14592000-14848000
[INFO] processing batch 14848000-15104000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.9373 - tp: 123594.0000 - fp: 68406.0000 - tn: 699594.0000 - fn: 68406.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.9282 - val_tp: 41205.0000 - val_fp: 22795.0000 - val_tn: 233205.0000 - val_fn: 22795.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-14848000-15104000
[INFO] processing batch 15104000-15360000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.9201 - tp: 123629.0000 - fp: 68371.0000 - tn: 699629.0000 - fn: 68371.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.9113 - val_tp: 41234.0000 - val_fp: 22766.0000 - val_tn: 233234.0000 - val_fn: 22766.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-15104000-15360000
[INFO] processing batch 15360000-15616000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9044 - tp: 123632.0000 - fp: 68368.0000 - tn: 699632.0000 - fn: 68368.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.8955 - val_tp: 41266.0000 - val_fp: 22734.0000 - val_tn: 233266.0000 - val_fn: 22734.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-15360000-15616000
[INFO] processing batch 15616000-15872000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.8907 - tp: 123527.0000 - fp: 68473.0000 - tn: 699527.0000 - fn: 68473.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.8831 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 233197.0000 - val_fn: 22803.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-15616000-15872000
[INFO] processing batch 15872000-16128000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8772 - tp: 123531.0000 - fp: 68469.0000 - tn: 699531.0000 - fn: 68469.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.8707 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 233173.0000 - val_fn: 22827.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-15872000-16128000
[INFO] processing batch 16128000-16384000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8629 - tp: 123781.0000 - fp: 68219.0000 - tn: 699781.0000 - fn: 68219.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9112 - val_loss: 0.8583 - val_tp: 41195.0000 - val_fp: 22805.0000 - val_tn: 233195.0000 - val_fn: 22805.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-16128000-16384000
[INFO] processing batch 16384000-16640000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.8526 - tp: 123621.0000 - fp: 68379.0000 - tn: 699621.0000 - fn: 68379.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.8478 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 233165.0000 - val_fn: 22835.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-16384000-16640000
[INFO] processing batch 16640000-16896000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.8432 - tp: 123417.0000 - fp: 68583.0000 - tn: 699417.0000 - fn: 68583.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9107 - val_loss: 0.8363 - val_tp: 41230.0000 - val_fp: 22770.0000 - val_tn: 233230.0000 - val_fn: 22770.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-16640000-16896000
[INFO] processing batch 16896000-17152000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8321 - tp: 123600.0000 - fp: 68400.0000 - tn: 699600.0000 - fn: 68400.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.8274 - val_tp: 41198.0000 - val_fp: 22802.0000 - val_tn: 233198.0000 - val_fn: 22802.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-16896000-17152000
[INFO] processing batch 17152000-17408000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8223 - tp: 123711.0000 - fp: 68289.0000 - tn: 699711.0000 - fn: 68289.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9111 - val_loss: 0.8191 - val_tp: 41168.0000 - val_fp: 22832.0000 - val_tn: 233168.0000 - val_fn: 22832.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-17152000-17408000
[INFO] processing batch 17408000-17664000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.8140 - tp: 123701.0000 - fp: 68299.0000 - tn: 699701.0000 - fn: 68299.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9111 - val_loss: 0.8119 - val_tp: 41118.0000 - val_fp: 22882.0000 - val_tn: 233118.0000 - val_fn: 22882.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-17408000-17664000
[INFO] processing batch 17664000-17920000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.8070 - tp: 123546.0000 - fp: 68454.0000 - tn: 699546.0000 - fn: 68454.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.8048 - val_tp: 41089.0000 - val_fp: 22911.0000 - val_tn: 233089.0000 - val_fn: 22911.0000 - val_accuracy: 0.8568 - val_precision: 0.6420 - val_recall: 0.6420 - val_auc: 0.9105
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-17664000-17920000
[INFO] processing batch 17920000-18176000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7990 - tp: 123681.0000 - fp: 68319.0000 - tn: 699681.0000 - fn: 68319.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.7954 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 233233.0000 - val_fn: 22767.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-17920000-18176000
[INFO] processing batch 18176000-18432000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7926 - tp: 123640.0000 - fp: 68360.0000 - tn: 699640.0000 - fn: 68360.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9109 - val_loss: 0.7880 - val_tp: 41298.0000 - val_fp: 22702.0000 - val_tn: 233298.0000 - val_fn: 22702.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-18176000-18432000
[INFO] processing batch 18432000-18688000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7864 - tp: 123615.0000 - fp: 68385.0000 - tn: 699615.0000 - fn: 68385.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.7830 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 233233.0000 - val_fn: 22767.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-18432000-18688000
[INFO] processing batch 18688000-18944000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7805 - tp: 123645.0000 - fp: 68355.0000 - tn: 699645.0000 - fn: 68355.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.7781 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 233184.0000 - val_fn: 22816.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-18688000-18944000
[INFO] processing batch 18944000-19200000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7740 - tp: 123888.0000 - fp: 68112.0000 - tn: 699888.0000 - fn: 68112.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9113 - val_loss: 0.7732 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 233169.0000 - val_fn: 22831.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-18944000-19200000
[INFO] processing batch 19200000-19456000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7708 - tp: 123500.0000 - fp: 68500.0000 - tn: 699500.0000 - fn: 68500.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.7680 - val_tp: 41189.0000 - val_fp: 22811.0000 - val_tn: 233189.0000 - val_fn: 22811.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-19200000-19456000
[INFO] processing batch 19456000-19712000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7652 - tp: 123689.0000 - fp: 68311.0000 - tn: 699689.0000 - fn: 68311.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.7638 - val_tp: 41166.0000 - val_fp: 22834.0000 - val_tn: 233166.0000 - val_fn: 22834.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-19456000-19712000
[INFO] processing batch 19712000-19968000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7621 - tp: 123402.0000 - fp: 68598.0000 - tn: 699402.0000 - fn: 68598.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9106 - val_loss: 0.7585 - val_tp: 41242.0000 - val_fp: 22758.0000 - val_tn: 233242.0000 - val_fn: 22758.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-19712000-19968000
[INFO] processing batch 19968000-20224000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7573 - tp: 123541.0000 - fp: 68459.0000 - tn: 699541.0000 - fn: 68459.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.7545 - val_tp: 41241.0000 - val_fp: 22759.0000 - val_tn: 233241.0000 - val_fn: 22759.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-19968000-20224000
[INFO] processing batch 20224000-20480000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7530 - tp: 123640.0000 - fp: 68360.0000 - tn: 699640.0000 - fn: 68360.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.7512 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 233209.0000 - val_fn: 22791.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-20224000-20480000
[INFO] processing batch 20480000-20736000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7495 - tp: 123598.0000 - fp: 68402.0000 - tn: 699598.0000 - fn: 68402.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.7473 - val_tp: 41235.0000 - val_fp: 22765.0000 - val_tn: 233235.0000 - val_fn: 22765.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-20480000-20736000
[INFO] processing batch 20736000-20992000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7454 - tp: 123769.0000 - fp: 68231.0000 - tn: 699769.0000 - fn: 68231.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.7442 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-20736000-20992000
[INFO] processing batch 20992000-21248000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7433 - tp: 123459.0000 - fp: 68541.0000 - tn: 699459.0000 - fn: 68541.0000 - accuracy: 0.8572 - precision: 0.6430 - recall: 0.6430 - auc: 0.9107 - val_loss: 0.7411 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 233209.0000 - val_fn: 22791.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-20992000-21248000
[INFO] processing batch 21248000-21504000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7394 - tp: 123683.0000 - fp: 68317.0000 - tn: 699683.0000 - fn: 68317.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.7384 - val_tp: 41183.0000 - val_fp: 22817.0000 - val_tn: 233183.0000 - val_fn: 22817.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-21248000-21504000
[INFO] processing batch 21504000-21760000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7369 - tp: 123564.0000 - fp: 68436.0000 - tn: 699564.0000 - fn: 68436.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.7347 - val_tp: 41254.0000 - val_fp: 22746.0000 - val_tn: 233254.0000 - val_fn: 22746.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-21504000-21760000
[INFO] processing batch 21760000-22016000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7335 - tp: 123717.0000 - fp: 68283.0000 - tn: 699717.0000 - fn: 68283.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9111 - val_loss: 0.7318 - val_tp: 41270.0000 - val_fp: 22730.0000 - val_tn: 233270.0000 - val_fn: 22730.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-21760000-22016000
[INFO] processing batch 22016000-22272000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7309 - tp: 123690.0000 - fp: 68310.0000 - tn: 699690.0000 - fn: 68310.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.7310 - val_tp: 41104.0000 - val_fp: 22896.0000 - val_tn: 233104.0000 - val_fn: 22896.0000 - val_accuracy: 0.8569 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-22016000-22272000
[INFO] processing batch 22272000-22528000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7285 - tp: 123672.0000 - fp: 68328.0000 - tn: 699672.0000 - fn: 68328.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.7270 - val_tp: 41243.0000 - val_fp: 22757.0000 - val_tn: 233243.0000 - val_fn: 22757.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-22272000-22528000
[INFO] processing batch 22528000-22784000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7262 - tp: 123623.0000 - fp: 68377.0000 - tn: 699623.0000 - fn: 68377.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.7241 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 233292.0000 - val_fn: 22708.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-22528000-22784000
[INFO] processing batch 22784000-23040000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7234 - tp: 123759.0000 - fp: 68241.0000 - tn: 699759.0000 - fn: 68241.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.7230 - val_tp: 41180.0000 - val_fp: 22820.0000 - val_tn: 233180.0000 - val_fn: 22820.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-22784000-23040000
[INFO] processing batch 23040000-23296000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7220 - tp: 123507.0000 - fp: 68493.0000 - tn: 699507.0000 - fn: 68493.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.7200 - val_tp: 41255.0000 - val_fp: 22745.0000 - val_tn: 233255.0000 - val_fn: 22745.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-23040000-23296000
[INFO] processing batch 23296000-23552000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7195 - tp: 123601.0000 - fp: 68399.0000 - tn: 699601.0000 - fn: 68399.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.7183 - val_tp: 41213.0000 - val_fp: 22787.0000 - val_tn: 233213.0000 - val_fn: 22787.0000 - val_accuracy: 0.8576 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-23296000-23552000
[INFO] processing batch 23552000-23808000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7169 - tp: 123749.0000 - fp: 68251.0000 - tn: 699749.0000 - fn: 68251.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9111 - val_loss: 0.7155 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 233292.0000 - val_fn: 22708.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-23552000-23808000
[INFO] processing batch 23808000-24064000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7155 - tp: 123603.0000 - fp: 68397.0000 - tn: 699603.0000 - fn: 68397.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.7148 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 233165.0000 - val_fn: 22835.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-23808000-24064000
[INFO] processing batch 24064000-24320000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7136 - tp: 123599.0000 - fp: 68401.0000 - tn: 699599.0000 - fn: 68401.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.7128 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 233184.0000 - val_fn: 22816.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-24064000-24320000
[INFO] processing batch 24320000-24576000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7123 - tp: 123440.0000 - fp: 68560.0000 - tn: 699440.0000 - fn: 68560.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9107 - val_loss: 0.7111 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 233169.0000 - val_fn: 22831.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-24320000-24576000
[INFO] processing batch 24576000-24832000/24819975
[33m[LOSS] 0.7111113691329956[0m
[33m[INFO] epoch 2/10[0m
[33m[INFO] loading file 1-50/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (24819975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
len(df.columns) 108
numFeatures 107
[INFO] columns: Index(['unixtime', 'modbus_function_code', 'modbus_transaction_id', 'service',
       's_port', 'classification', 'orig-192.168.1.48', 'orig-192.168.1.87',
       'orig-192.168.1.88', 'type-alert',
       ...
       'modbus_function_description-Read Tag Service',
       'modbus_function_description-Read Tag Service - Response',
       'modbus_function_description-Unknown Function Code',
       'modbus_function_description-Write Tag Service', 'scada_tag-0',
       'scada_tag-HMI_AIT202', 'scada_tag-HMI_FIT201', 'scada_tag-HMI_LIT101',
       'scada_tag-HMI_LIT301', 'scada_tag-HMI_LIT401'],
      dtype='object', length=108)
[INFO] processing batch 0-256000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 18s - loss: 0.4459 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4058 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-0-256000
[INFO] processing batch 256000-512000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7635 - tp: 112918.0000 - fp: 79082.0000 - tn: 688918.0000 - fn: 79082.0000 - accuracy: 0.8352 - precision: 0.5881 - recall: 0.5881 - auc: 0.8963 - val_loss: 0.8088 - val_tp: 33927.0000 - val_fp: 30073.0000 - val_tn: 225927.0000 - val_fn: 30073.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-256000-512000
[INFO] processing batch 512000-768000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6472 - tp: 138284.0000 - fp: 53716.0000 - tn: 714284.0000 - fn: 53716.0000 - accuracy: 0.8881 - precision: 0.7202 - recall: 0.7202 - auc: 0.9303 - val_loss: 0.4338 - val_tp: 62058.0000 - val_fp: 1942.0000 - val_tn: 254058.0000 - val_fn: 1942.0000 - val_accuracy: 0.9879 - val_precision: 0.9697 - val_recall: 0.9697 - val_auc: 0.9924
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-512000-768000
[INFO] processing batch 768000-1024000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7377 - tp: 117250.0000 - fp: 74750.0000 - tn: 693250.0000 - fn: 74750.0000 - accuracy: 0.8443 - precision: 0.6107 - recall: 0.6107 - auc: 0.9019 - val_loss: 0.5266 - val_tp: 55591.0000 - val_fp: 8409.0000 - val_tn: 247591.0000 - val_fn: 8409.0000 - val_accuracy: 0.9474 - val_precision: 0.8686 - val_recall: 0.8686 - val_auc: 0.9672
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-768000-1024000
[INFO] processing batch 1024000-1280000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6640 - tp: 133967.0000 - fp: 58033.0000 - tn: 709967.0000 - fn: 58033.0000 - accuracy: 0.8791 - precision: 0.6977 - recall: 0.6977 - auc: 0.9244 - val_loss: 0.4186 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-1024000-1280000
[INFO] processing batch 1280000-1536000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.3937 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3627 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-1280000-1536000
[INFO] processing batch 1536000-1792000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.3373 - tp: 191999.0000 - fp: 1.0000 - tn: 767999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3132 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-1536000-1792000
[INFO] processing batch 1792000-2048000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.5805 - tp: 148221.0000 - fp: 43779.0000 - tn: 724221.0000 - fn: 43779.0000 - accuracy: 0.9088 - precision: 0.7720 - recall: 0.7720 - auc: 0.9421 - val_loss: 0.4176 - val_tp: 57941.0000 - val_fp: 6059.0000 - val_tn: 249941.0000 - val_fn: 6059.0000 - val_accuracy: 0.9621 - val_precision: 0.9053 - val_recall: 0.9053 - val_auc: 0.9763
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-1792000-2048000
[INFO] processing batch 2048000-2304000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6204 - tp: 141714.0000 - fp: 50286.0000 - tn: 717714.0000 - fn: 50286.0000 - accuracy: 0.8952 - precision: 0.7381 - recall: 0.7381 - auc: 0.9348 - val_loss: 0.3041 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-2048000-2304000
[INFO] processing batch 2304000-2560000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2917 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2747 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-2304000-2560000
[INFO] processing batch 2560000-2816000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2596 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2449 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-2560000-2816000
[INFO] processing batch 2816000-3072000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.5758 - tp: 148720.0000 - fp: 43280.0000 - tn: 724720.0000 - fn: 43280.0000 - accuracy: 0.9098 - precision: 0.7746 - recall: 0.7746 - auc: 0.9438 - val_loss: 0.7742 - val_tp: 40961.0000 - val_fp: 23039.0000 - val_tn: 232961.0000 - val_fn: 23039.0000 - val_accuracy: 0.8560 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.9100
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-2816000-3072000
[INFO] processing batch 3072000-3328000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7042 - tp: 131495.0000 - fp: 60505.0000 - tn: 707495.0000 - fn: 60505.0000 - accuracy: 0.8739 - precision: 0.6849 - recall: 0.6849 - auc: 0.9215 - val_loss: 0.2547 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-3072000-3328000
[INFO] processing batch 3328000-3584000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2474 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2354 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-3328000-3584000
[INFO] processing batch 3584000-3840000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2240 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2128 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-3584000-3840000
[INFO] processing batch 3840000-4096000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.5044 - tp: 157534.0000 - fp: 34466.0000 - tn: 733534.0000 - fn: 34466.0000 - accuracy: 0.9282 - precision: 0.8205 - recall: 0.8205 - auc: 0.9551 - val_loss: 0.5116 - val_tp: 52219.0000 - val_fp: 11781.0000 - val_tn: 244219.0000 - val_fn: 11781.0000 - val_accuracy: 0.9264 - val_precision: 0.8159 - val_recall: 0.8159 - val_auc: 0.9540
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-3840000-4096000
[INFO] processing batch 4096000-4352000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2187 - tp: 190188.0000 - fp: 1812.0000 - tn: 766188.0000 - fn: 1812.0000 - accuracy: 0.9962 - precision: 0.9906 - recall: 0.9906 - auc: 0.9977 - val_loss: 0.1946 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-4096000-4352000
[INFO] processing batch 4352000-4608000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1866 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1785 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-4352000-4608000
[INFO] processing batch 4608000-4864000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.4691 - tp: 161451.0000 - fp: 30549.0000 - tn: 737451.0000 - fn: 30549.0000 - accuracy: 0.9364 - precision: 0.8409 - recall: 0.8409 - auc: 0.9602 - val_loss: 0.1762 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-4608000-4864000
[INFO] processing batch 4864000-5120000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1714 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1649 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-4864000-5120000
[INFO] processing batch 5120000-5376000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1587 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1526 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-5120000-5376000
[INFO] processing batch 5376000-5632000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1472 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1418 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-5376000-5632000
[INFO] processing batch 5632000-5888000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.5350 - tp: 155809.0000 - fp: 36191.0000 - tn: 731809.0000 - fn: 36191.0000 - accuracy: 0.9246 - precision: 0.8115 - recall: 0.8115 - auc: 0.9529 - val_loss: 0.1441 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-5632000-5888000
[INFO] processing batch 5888000-6144000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1414 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1369 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-5888000-6144000
[INFO] processing batch 6144000-6400000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.3337 - tp: 174156.0000 - fp: 17844.0000 - tn: 750156.0000 - fn: 17844.0000 - accuracy: 0.9628 - precision: 0.9071 - recall: 0.9071 - auc: 0.9769 - val_loss: 0.9026 - val_tp: 41108.0000 - val_fp: 22892.0000 - val_tn: 233108.0000 - val_fn: 22892.0000 - val_accuracy: 0.8569 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-6144000-6400000
[INFO] processing batch 6400000-6656000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7237 - tp: 138766.0000 - fp: 53234.0000 - tn: 714766.0000 - fn: 53234.0000 - accuracy: 0.8891 - precision: 0.7227 - recall: 0.7227 - auc: 0.9307 - val_loss: 0.1434 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-6400000-6656000
[INFO] processing batch 6656000-6912000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1418 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1374 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-6656000-6912000
[INFO] processing batch 6912000-7168000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1328 - tp: 191998.0000 - fp: 2.0000 - tn: 767998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1281 - val_tp: 63999.0000 - val_fp: 1.0000 - val_tn: 255999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-6912000-7168000
[INFO] processing batch 7168000-7424000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1240 - tp: 191999.0000 - fp: 1.0000 - tn: 767999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6342 - val_tp: 44344.0000 - val_fp: 19656.0000 - val_tn: 236344.0000 - val_fn: 19656.0000 - val_accuracy: 0.8772 - val_precision: 0.6929 - val_recall: 0.6929 - val_auc: 0.7697
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-7168000-7424000
[INFO] processing batch 7424000-7680000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.3630 - tp: 102062.0000 - fp: 89938.0000 - tn: 678062.0000 - fn: 89938.0000 - accuracy: 0.8126 - precision: 0.5316 - recall: 0.5316 - auc: 0.6487 - val_loss: 1.1462 - val_tp: 49859.0000 - val_fp: 14141.0000 - val_tn: 241859.0000 - val_fn: 14141.0000 - val_accuracy: 0.9116 - val_precision: 0.7790 - val_recall: 0.7790 - val_auc: 0.8343
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-7424000-7680000
[INFO] processing batch 7680000-7936000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1268 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1235 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-7680000-7936000
[INFO] processing batch 7936000-8192000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1199 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1163 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-7936000-8192000
[INFO] processing batch 8192000-8448000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9063 - tp: 161781.0000 - fp: 30219.0000 - tn: 737781.0000 - fn: 30219.0000 - accuracy: 0.9370 - precision: 0.8426 - recall: 0.8426 - auc: 0.8820 - val_loss: 0.1635 - val_tp: 63369.0000 - val_fp: 631.0000 - val_tn: 255369.0000 - val_fn: 631.0000 - val_accuracy: 0.9961 - val_precision: 0.9901 - val_recall: 0.9901 - val_auc: 0.9926
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-8192000-8448000
[INFO] processing batch 8448000-8704000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.8257 - tp: 123282.0000 - fp: 68718.0000 - tn: 699282.0000 - fn: 68718.0000 - accuracy: 0.8568 - precision: 0.6421 - recall: 0.6421 - auc: 0.7315 - val_loss: 1.8768 - val_tp: 39692.0000 - val_fp: 24308.0000 - val_tn: 231692.0000 - val_fn: 24308.0000 - val_accuracy: 0.8481 - val_precision: 0.6202 - val_recall: 0.6202 - val_auc: 0.7151
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-8448000-8704000
[INFO] processing batch 8704000-8960000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2148 - tp: 188028.0000 - fp: 3972.0000 - tn: 764028.0000 - fn: 3972.0000 - accuracy: 0.9917 - precision: 0.9793 - recall: 0.9793 - auc: 0.9845 - val_loss: 0.1173 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-8704000-8960000
[INFO] processing batch 8960000-9216000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1142 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1110 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-8960000-9216000
[INFO] processing batch 9216000-9472000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.8011 - tp: 120440.0000 - fp: 71560.0000 - tn: 696440.0000 - fn: 71560.0000 - accuracy: 0.8509 - precision: 0.6273 - recall: 0.6273 - auc: 0.7490 - val_loss: 0.1158 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-9216000-9472000
[INFO] processing batch 9472000-9728000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8085 - tp: 161553.0000 - fp: 30447.0000 - tn: 737553.0000 - fn: 30447.0000 - accuracy: 0.9366 - precision: 0.8414 - recall: 0.8414 - auc: 0.9207 - val_loss: 0.8275 - val_tp: 53468.0000 - val_fp: 10532.0000 - val_tn: 245468.0000 - val_fn: 10532.0000 - val_accuracy: 0.9342 - val_precision: 0.8354 - val_recall: 0.8354 - val_auc: 0.9177
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-9472000-9728000
[INFO] processing batch 9728000-9984000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1146 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1116 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-9728000-9984000
[INFO] processing batch 9984000-10240000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1088 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1058 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-9984000-10240000
[INFO] processing batch 10240000-10496000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1638 - tp: 189510.0000 - fp: 2490.0000 - tn: 765510.0000 - fn: 2490.0000 - accuracy: 0.9948 - precision: 0.9870 - recall: 0.9870 - auc: 0.9887 - val_loss: 2.2924 - val_tp: 33975.0000 - val_fp: 30025.0000 - val_tn: 225975.0000 - val_fn: 30025.0000 - val_accuracy: 0.8123 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.5895
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-10240000-10496000
[INFO] processing batch 10496000-10752000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 2.2318 - tp: 101670.0000 - fp: 90330.0000 - tn: 677670.0000 - fn: 90330.0000 - accuracy: 0.8118 - precision: 0.5295 - recall: 0.5295 - auc: 0.6381 - val_loss: 2.1473 - val_tp: 34015.0000 - val_fp: 29985.0000 - val_tn: 226015.0000 - val_fn: 29985.0000 - val_accuracy: 0.8126 - val_precision: 0.5315 - val_recall: 0.5315 - val_auc: 0.7072
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-10496000-10752000
[INFO] processing batch 10752000-11008000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.0949 - tp: 101693.0000 - fp: 90307.0000 - tn: 677693.0000 - fn: 90307.0000 - accuracy: 0.8119 - precision: 0.5297 - recall: 0.5297 - auc: 0.7060 - val_loss: 0.5665 - val_tp: 56989.0000 - val_fp: 7011.0000 - val_tn: 248989.0000 - val_fn: 7011.0000 - val_accuracy: 0.9562 - val_precision: 0.8905 - val_recall: 0.8905 - val_auc: 0.9178
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-10752000-11008000
[INFO] processing batch 11008000-11264000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1196 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1172 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-11008000-11264000
[INFO] processing batch 11264000-11520000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1144 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1116 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-11264000-11520000
[INFO] processing batch 11520000-11776000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1090 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1064 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-11520000-11776000
[INFO] processing batch 11776000-12032000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8661 - tp: 156412.0000 - fp: 35588.0000 - tn: 732412.0000 - fn: 35588.0000 - accuracy: 0.9259 - precision: 0.8146 - recall: 0.8146 - auc: 0.8919 - val_loss: 1.5578 - val_tp: 41134.0000 - val_fp: 22866.0000 - val_tn: 233134.0000 - val_fn: 22866.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.8214
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-11776000-12032000
[INFO] processing batch 12032000-12288000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.5310 - tp: 123527.0000 - fp: 68473.0000 - tn: 699527.0000 - fn: 68473.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.8217 - val_loss: 1.5003 - val_tp: 41219.0000 - val_fp: 22781.0000 - val_tn: 233219.0000 - val_fn: 22781.0000 - val_accuracy: 0.8576 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.8220
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-12032000-12288000
[INFO] processing batch 12288000-12544000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.4761 - tp: 123560.0000 - fp: 68440.0000 - tn: 699560.0000 - fn: 68440.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.8217 - val_loss: 1.1060 - val_tp: 41268.0000 - val_fp: 22732.0000 - val_tn: 233268.0000 - val_fn: 22732.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.8958
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-12288000-12544000
[INFO] processing batch 12544000-12800000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.0196 - tp: 123588.0000 - fp: 68412.0000 - tn: 699588.0000 - fn: 68412.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.9934 - val_tp: 41269.0000 - val_fp: 22731.0000 - val_tn: 233269.0000 - val_fn: 22731.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-12544000-12800000
[INFO] processing batch 12800000-13056000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.9754 - tp: 123531.0000 - fp: 68469.0000 - tn: 699531.0000 - fn: 68469.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9107 - val_loss: 0.9540 - val_tp: 41181.0000 - val_fp: 22819.0000 - val_tn: 233181.0000 - val_fn: 22819.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-12800000-13056000
[INFO] processing batch 13056000-13312000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9350 - tp: 123615.0000 - fp: 68385.0000 - tn: 699615.0000 - fn: 68385.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.9173 - val_tp: 41192.0000 - val_fp: 22808.0000 - val_tn: 233192.0000 - val_fn: 22808.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-13056000-13312000
[INFO] processing batch 13312000-13568000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9032 - tp: 123437.0000 - fp: 68563.0000 - tn: 699437.0000 - fn: 68563.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9107 - val_loss: 0.8865 - val_tp: 41179.0000 - val_fp: 22821.0000 - val_tn: 233179.0000 - val_fn: 22821.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-13312000-13568000
[INFO] processing batch 13568000-13824000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8730 - tp: 123539.0000 - fp: 68461.0000 - tn: 699539.0000 - fn: 68461.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.8586 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-13568000-13824000
[INFO] processing batch 13824000-14080000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8477 - tp: 123556.0000 - fp: 68444.0000 - tn: 699556.0000 - fn: 68444.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.8364 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 233173.0000 - val_fn: 22827.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-13824000-14080000
[INFO] processing batch 14080000-14336000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8250 - tp: 123681.0000 - fp: 68319.0000 - tn: 699681.0000 - fn: 68319.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9109 - val_loss: 0.8151 - val_tp: 41221.0000 - val_fp: 22779.0000 - val_tn: 233221.0000 - val_fn: 22779.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-14080000-14336000
[INFO] processing batch 14336000-14592000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.8076 - tp: 123523.0000 - fp: 68477.0000 - tn: 699523.0000 - fn: 68477.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9109 - val_loss: 0.7984 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 233197.0000 - val_fn: 22803.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-14336000-14592000
[INFO] processing batch 14592000-14848000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7905 - tp: 123652.0000 - fp: 68348.0000 - tn: 699652.0000 - fn: 68348.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.7832 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-14592000-14848000
[INFO] processing batch 14848000-15104000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7771 - tp: 123594.0000 - fp: 68406.0000 - tn: 699594.0000 - fn: 68406.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.7706 - val_tp: 41205.0000 - val_fp: 22795.0000 - val_tn: 233205.0000 - val_fn: 22795.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-14848000-15104000
[INFO] processing batch 15104000-15360000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7650 - tp: 123629.0000 - fp: 68371.0000 - tn: 699629.0000 - fn: 68371.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9111 - val_loss: 0.7591 - val_tp: 41234.0000 - val_fp: 22766.0000 - val_tn: 233234.0000 - val_fn: 22766.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-15104000-15360000
[INFO] processing batch 15360000-15616000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7549 - tp: 123632.0000 - fp: 68368.0000 - tn: 699632.0000 - fn: 68368.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.7492 - val_tp: 41266.0000 - val_fp: 22734.0000 - val_tn: 233266.0000 - val_fn: 22734.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-15360000-15616000
[INFO] processing batch 15616000-15872000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7469 - tp: 123527.0000 - fp: 68473.0000 - tn: 699527.0000 - fn: 68473.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.7425 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 233197.0000 - val_fn: 22803.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-15616000-15872000
[INFO] processing batch 15872000-16128000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7394 - tp: 123531.0000 - fp: 68469.0000 - tn: 699531.0000 - fn: 68469.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.7361 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 233173.0000 - val_fn: 22827.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-15872000-16128000
[INFO] processing batch 16128000-16384000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7318 - tp: 123781.0000 - fp: 68219.0000 - tn: 699781.0000 - fn: 68219.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9112 - val_loss: 0.7300 - val_tp: 41195.0000 - val_fp: 22805.0000 - val_tn: 233195.0000 - val_fn: 22805.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-16128000-16384000
[INFO] processing batch 16384000-16640000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7274 - tp: 123621.0000 - fp: 68379.0000 - tn: 699621.0000 - fn: 68379.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.7256 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 233165.0000 - val_fn: 22835.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-16384000-16640000
[INFO] processing batch 16640000-16896000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7239 - tp: 123417.0000 - fp: 68583.0000 - tn: 699417.0000 - fn: 68583.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9108 - val_loss: 0.7204 - val_tp: 41230.0000 - val_fp: 22770.0000 - val_tn: 233230.0000 - val_fn: 22770.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-16640000-16896000
[INFO] processing batch 16896000-17152000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7191 - tp: 123600.0000 - fp: 68400.0000 - tn: 699600.0000 - fn: 68400.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.7173 - val_tp: 41198.0000 - val_fp: 22802.0000 - val_tn: 233198.0000 - val_fn: 22802.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-16896000-17152000
[INFO] processing batch 17152000-17408000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7152 - tp: 123711.0000 - fp: 68289.0000 - tn: 699711.0000 - fn: 68289.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9111 - val_loss: 0.7147 - val_tp: 41168.0000 - val_fp: 22832.0000 - val_tn: 233168.0000 - val_fn: 22832.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-17152000-17408000
[INFO] processing batch 17408000-17664000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7125 - tp: 123701.0000 - fp: 68299.0000 - tn: 699701.0000 - fn: 68299.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9111 - val_loss: 0.7127 - val_tp: 41118.0000 - val_fp: 22882.0000 - val_tn: 233118.0000 - val_fn: 22882.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-17408000-17664000
[INFO] processing batch 17664000-17920000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7107 - tp: 123546.0000 - fp: 68454.0000 - tn: 699546.0000 - fn: 68454.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.7107 - val_tp: 41089.0000 - val_fp: 22911.0000 - val_tn: 233089.0000 - val_fn: 22911.0000 - val_accuracy: 0.8568 - val_precision: 0.6420 - val_recall: 0.6420 - val_auc: 0.9105
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-17664000-17920000
[INFO] processing batch 17920000-18176000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7080 - tp: 123681.0000 - fp: 68319.0000 - tn: 699681.0000 - fn: 68319.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.7069 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 233233.0000 - val_fn: 22767.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-17920000-18176000
[INFO] processing batch 18176000-18432000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7063 - tp: 123640.0000 - fp: 68360.0000 - tn: 699640.0000 - fn: 68360.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.7044 - val_tp: 41298.0000 - val_fp: 22702.0000 - val_tn: 233298.0000 - val_fn: 22702.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-18176000-18432000
[INFO] processing batch 18432000-18688000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7047 - tp: 123615.0000 - fp: 68385.0000 - tn: 699615.0000 - fn: 68385.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.7035 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 233233.0000 - val_fn: 22767.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-18432000-18688000
[INFO] processing batch 18688000-18944000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7030 - tp: 123645.0000 - fp: 68355.0000 - tn: 699645.0000 - fn: 68355.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.7026 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 233184.0000 - val_fn: 22816.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-18688000-18944000
[INFO] processing batch 18944000-19200000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7007 - tp: 123888.0000 - fp: 68112.0000 - tn: 699888.0000 - fn: 68112.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9113 - val_loss: 0.7015 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 233169.0000 - val_fn: 22831.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-18944000-19200000
[INFO] processing batch 19200000-19456000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7009 - tp: 123500.0000 - fp: 68500.0000 - tn: 699500.0000 - fn: 68500.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9109 - val_loss: 0.7000 - val_tp: 41189.0000 - val_fp: 22811.0000 - val_tn: 233189.0000 - val_fn: 22811.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-19200000-19456000
[INFO] processing batch 19456000-19712000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6990 - tp: 123689.0000 - fp: 68311.0000 - tn: 699689.0000 - fn: 68311.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6991 - val_tp: 41166.0000 - val_fp: 22834.0000 - val_tn: 233166.0000 - val_fn: 22834.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-19456000-19712000
[INFO] processing batch 19712000-19968000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6989 - tp: 123402.0000 - fp: 68598.0000 - tn: 699402.0000 - fn: 68598.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9107 - val_loss: 0.6971 - val_tp: 41242.0000 - val_fp: 22758.0000 - val_tn: 233242.0000 - val_fn: 22758.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-19712000-19968000
[INFO] processing batch 19968000-20224000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6973 - tp: 123541.0000 - fp: 68459.0000 - tn: 699541.0000 - fn: 68459.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.6961 - val_tp: 41241.0000 - val_fp: 22759.0000 - val_tn: 233241.0000 - val_fn: 22759.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-19968000-20224000
[INFO] processing batch 20224000-20480000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6959 - tp: 123640.0000 - fp: 68360.0000 - tn: 699640.0000 - fn: 68360.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6954 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 233209.0000 - val_fn: 22791.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-20224000-20480000
[INFO] processing batch 20480000-20736000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6950 - tp: 123598.0000 - fp: 68402.0000 - tn: 699598.0000 - fn: 68402.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6942 - val_tp: 41235.0000 - val_fp: 22765.0000 - val_tn: 233235.0000 - val_fn: 22765.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-20480000-20736000
[INFO] processing batch 20736000-20992000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6935 - tp: 123769.0000 - fp: 68231.0000 - tn: 699769.0000 - fn: 68231.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.6935 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-20736000-20992000
[INFO] processing batch 20992000-21248000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6936 - tp: 123459.0000 - fp: 68541.0000 - tn: 699459.0000 - fn: 68541.0000 - accuracy: 0.8572 - precision: 0.6430 - recall: 0.6430 - auc: 0.9108 - val_loss: 0.6926 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 233209.0000 - val_fn: 22791.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-20992000-21248000
[INFO] processing batch 21248000-21504000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6920 - tp: 123683.0000 - fp: 68317.0000 - tn: 699683.0000 - fn: 68317.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6919 - val_tp: 41183.0000 - val_fp: 22817.0000 - val_tn: 233183.0000 - val_fn: 22817.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-21248000-21504000
[INFO] processing batch 21504000-21760000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6915 - tp: 123564.0000 - fp: 68436.0000 - tn: 699564.0000 - fn: 68436.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6904 - val_tp: 41254.0000 - val_fp: 22746.0000 - val_tn: 233254.0000 - val_fn: 22746.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-21504000-21760000
[INFO] processing batch 21760000-22016000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6901 - tp: 123717.0000 - fp: 68283.0000 - tn: 699717.0000 - fn: 68283.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9111 - val_loss: 0.6894 - val_tp: 41270.0000 - val_fp: 22730.0000 - val_tn: 233270.0000 - val_fn: 22730.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-21760000-22016000
[INFO] processing batch 22016000-22272000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6893 - tp: 123690.0000 - fp: 68310.0000 - tn: 699690.0000 - fn: 68310.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6902 - val_tp: 41104.0000 - val_fp: 22896.0000 - val_tn: 233104.0000 - val_fn: 22896.0000 - val_accuracy: 0.8569 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-22016000-22272000
[INFO] processing batch 22272000-22528000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6886 - tp: 123672.0000 - fp: 68328.0000 - tn: 699672.0000 - fn: 68328.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6880 - val_tp: 41243.0000 - val_fp: 22757.0000 - val_tn: 233243.0000 - val_fn: 22757.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-22272000-22528000
[INFO] processing batch 22528000-22784000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6879 - tp: 123623.0000 - fp: 68377.0000 - tn: 699623.0000 - fn: 68377.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6867 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 233292.0000 - val_fn: 22708.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-22528000-22784000
[INFO] processing batch 22784000-23040000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6867 - tp: 123759.0000 - fp: 68241.0000 - tn: 699759.0000 - fn: 68241.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.6870 - val_tp: 41180.0000 - val_fp: 22820.0000 - val_tn: 233180.0000 - val_fn: 22820.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-22784000-23040000
[INFO] processing batch 23040000-23296000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6867 - tp: 123507.0000 - fp: 68493.0000 - tn: 699507.0000 - fn: 68493.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6855 - val_tp: 41255.0000 - val_fp: 22745.0000 - val_tn: 233255.0000 - val_fn: 22745.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-23040000-23296000
[INFO] processing batch 23296000-23552000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6857 - tp: 123601.0000 - fp: 68399.0000 - tn: 699601.0000 - fn: 68399.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6852 - val_tp: 41213.0000 - val_fp: 22787.0000 - val_tn: 233213.0000 - val_fn: 22787.0000 - val_accuracy: 0.8576 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-23296000-23552000
[INFO] processing batch 23552000-23808000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6845 - tp: 123749.0000 - fp: 68251.0000 - tn: 699749.0000 - fn: 68251.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9111 - val_loss: 0.6837 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 233292.0000 - val_fn: 22708.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-23552000-23808000
[INFO] processing batch 23808000-24064000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6842 - tp: 123603.0000 - fp: 68397.0000 - tn: 699603.0000 - fn: 68397.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6842 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 233165.0000 - val_fn: 22835.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-23808000-24064000
[INFO] processing batch 24064000-24320000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6835 - tp: 123599.0000 - fp: 68401.0000 - tn: 699599.0000 - fn: 68401.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6833 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 233184.0000 - val_fn: 22816.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-24064000-24320000
[INFO] processing batch 24320000-24576000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6833 - tp: 123440.0000 - fp: 68560.0000 - tn: 699440.0000 - fn: 68560.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9107 - val_loss: 0.6827 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 233169.0000 - val_fn: 22831.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-24320000-24576000
[INFO] processing batch 24576000-24832000/24819975
[33m[LOSS] 0.6827430939674377[0m
[33m[INFO] epoch 3/10[0m
[33m[INFO] loading file 1-50/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (24819975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
len(df.columns) 108
numFeatures 107
[INFO] columns: Index(['unixtime', 'modbus_function_code', 'modbus_transaction_id', 'service',
       's_port', 'classification', 'orig-192.168.1.48', 'orig-192.168.1.87',
       'orig-192.168.1.88', 'type-alert',
       ...
       'modbus_function_description-Read Tag Service',
       'modbus_function_description-Read Tag Service - Response',
       'modbus_function_description-Unknown Function Code',
       'modbus_function_description-Write Tag Service', 'scada_tag-0',
       'scada_tag-HMI_AIT202', 'scada_tag-HMI_FIT201', 'scada_tag-HMI_LIT101',
       'scada_tag-HMI_LIT301', 'scada_tag-HMI_LIT401'],
      dtype='object', length=108)
[INFO] processing batch 0-256000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.4228 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3750 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-0-256000
[INFO] processing batch 256000-512000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7395 - tp: 112918.0000 - fp: 79082.0000 - tn: 688918.0000 - fn: 79082.0000 - accuracy: 0.8352 - precision: 0.5881 - recall: 0.5881 - auc: 0.8973 - val_loss: 0.7845 - val_tp: 33927.0000 - val_fp: 30073.0000 - val_tn: 225927.0000 - val_fn: 30073.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-256000-512000
[INFO] processing batch 512000-768000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6223 - tp: 138284.0000 - fp: 53716.0000 - tn: 714284.0000 - fn: 53716.0000 - accuracy: 0.8881 - precision: 0.7202 - recall: 0.7202 - auc: 0.9300 - val_loss: 0.4088 - val_tp: 62058.0000 - val_fp: 1942.0000 - val_tn: 254058.0000 - val_fn: 1942.0000 - val_accuracy: 0.9879 - val_precision: 0.9697 - val_recall: 0.9697 - val_auc: 0.9924
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-512000-768000
[INFO] processing batch 768000-1024000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7133 - tp: 117250.0000 - fp: 74750.0000 - tn: 693250.0000 - fn: 74750.0000 - accuracy: 0.8443 - precision: 0.6107 - recall: 0.6107 - auc: 0.9020 - val_loss: 0.5048 - val_tp: 55591.0000 - val_fp: 8409.0000 - val_tn: 247591.0000 - val_fn: 8409.0000 - val_accuracy: 0.9474 - val_precision: 0.8686 - val_recall: 0.8686 - val_auc: 0.9672
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-768000-1024000
[INFO] processing batch 1024000-1280000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6408 - tp: 133967.0000 - fp: 58033.0000 - tn: 709967.0000 - fn: 58033.0000 - accuracy: 0.8791 - precision: 0.6977 - recall: 0.6977 - auc: 0.9244 - val_loss: 0.4002 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-1024000-1280000
[INFO] processing batch 1280000-1536000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.3722 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3381 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-1280000-1536000
[INFO] processing batch 1536000-1792000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.3113 - tp: 191999.0000 - fp: 1.0000 - tn: 767999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2864 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-1536000-1792000
[INFO] processing batch 1792000-2048000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.5608 - tp: 148221.0000 - fp: 43779.0000 - tn: 724221.0000 - fn: 43779.0000 - accuracy: 0.9088 - precision: 0.7720 - recall: 0.7720 - auc: 0.9434 - val_loss: 0.3947 - val_tp: 57941.0000 - val_fp: 6059.0000 - val_tn: 249941.0000 - val_fn: 6059.0000 - val_accuracy: 0.9621 - val_precision: 0.9053 - val_recall: 0.9053 - val_auc: 0.9763
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-1792000-2048000
[INFO] processing batch 2048000-2304000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6022 - tp: 141714.0000 - fp: 50286.0000 - tn: 717714.0000 - fn: 50286.0000 - accuracy: 0.8952 - precision: 0.7381 - recall: 0.7381 - auc: 0.9340 - val_loss: 0.2816 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-2048000-2304000
[INFO] processing batch 2304000-2560000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2688 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2515 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-2304000-2560000
[INFO] processing batch 2560000-2816000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.2364 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2219 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-2560000-2816000
[INFO] processing batch 2816000-3072000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.5609 - tp: 148720.0000 - fp: 43280.0000 - tn: 724720.0000 - fn: 43280.0000 - accuracy: 0.9098 - precision: 0.7746 - recall: 0.7746 - auc: 0.9435 - val_loss: 0.7632 - val_tp: 40961.0000 - val_fp: 23039.0000 - val_tn: 232961.0000 - val_fn: 23039.0000 - val_accuracy: 0.8560 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.9100
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-2816000-3072000
[INFO] processing batch 3072000-3328000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6911 - tp: 131495.0000 - fp: 60505.0000 - tn: 707495.0000 - fn: 60505.0000 - accuracy: 0.8739 - precision: 0.6849 - recall: 0.6849 - auc: 0.9207 - val_loss: 0.2356 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-3072000-3328000
[INFO] processing batch 3328000-3584000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2286 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2167 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-3328000-3584000
[INFO] processing batch 3584000-3840000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2054 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1944 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-3584000-3840000
[INFO] processing batch 3840000-4096000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.4908 - tp: 157534.0000 - fp: 34466.0000 - tn: 733534.0000 - fn: 34466.0000 - accuracy: 0.9282 - precision: 0.8205 - recall: 0.8205 - auc: 0.9552 - val_loss: 0.4983 - val_tp: 52219.0000 - val_fp: 11781.0000 - val_tn: 244219.0000 - val_fn: 11781.0000 - val_accuracy: 0.9264 - val_precision: 0.8159 - val_recall: 0.8159 - val_auc: 0.9540
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-3840000-4096000
[INFO] processing batch 4096000-4352000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2020 - tp: 190188.0000 - fp: 1812.0000 - tn: 766188.0000 - fn: 1812.0000 - accuracy: 0.9962 - precision: 0.9906 - recall: 0.9906 - auc: 0.9978 - val_loss: 0.1780 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-4096000-4352000
[INFO] processing batch 4352000-4608000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1702 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1623 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-4352000-4608000
[INFO] processing batch 4608000-4864000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.4574 - tp: 161451.0000 - fp: 30549.0000 - tn: 737451.0000 - fn: 30549.0000 - accuracy: 0.9364 - precision: 0.8409 - recall: 0.8409 - auc: 0.9602 - val_loss: 0.1611 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-4608000-4864000
[INFO] processing batch 4864000-5120000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1565 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1503 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-4864000-5120000
[INFO] processing batch 5120000-5376000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1444 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1385 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-5120000-5376000
[INFO] processing batch 5376000-5632000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1334 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1283 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-5376000-5632000
[INFO] processing batch 5632000-5888000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.5267 - tp: 155809.0000 - fp: 36191.0000 - tn: 731809.0000 - fn: 36191.0000 - accuracy: 0.9246 - precision: 0.8115 - recall: 0.8115 - auc: 0.9524 - val_loss: 0.1313 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-5632000-5888000
[INFO] processing batch 5888000-6144000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1289 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1247 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-5888000-6144000
[INFO] processing batch 6144000-6400000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.3238 - tp: 174156.0000 - fp: 17844.0000 - tn: 750156.0000 - fn: 17844.0000 - accuracy: 0.9628 - precision: 0.9071 - recall: 0.9071 - auc: 0.9768 - val_loss: 0.8980 - val_tp: 41108.0000 - val_fp: 22892.0000 - val_tn: 233108.0000 - val_fn: 22892.0000 - val_accuracy: 0.8569 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-6144000-6400000
[INFO] processing batch 6400000-6656000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7168 - tp: 138766.0000 - fp: 53234.0000 - tn: 714766.0000 - fn: 53234.0000 - accuracy: 0.8891 - precision: 0.7227 - recall: 0.7227 - auc: 0.9307 - val_loss: 0.1326 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-6400000-6656000
[INFO] processing batch 6656000-6912000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1312 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1271 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-6656000-6912000
[INFO] processing batch 6912000-7168000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1226 - tp: 191998.0000 - fp: 2.0000 - tn: 767998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1181 - val_tp: 63999.0000 - val_fp: 1.0000 - val_tn: 255999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-6912000-7168000
[INFO] processing batch 7168000-7424000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1141 - tp: 191999.0000 - fp: 1.0000 - tn: 767999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7986 - val_tp: 44344.0000 - val_fp: 19656.0000 - val_tn: 236344.0000 - val_fn: 19656.0000 - val_accuracy: 0.8772 - val_precision: 0.6929 - val_recall: 0.6929 - val_auc: 0.7313
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-7168000-7424000
[INFO] processing batch 7424000-7680000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.6132 - tp: 102062.0000 - fp: 89938.0000 - tn: 678062.0000 - fn: 89938.0000 - accuracy: 0.8126 - precision: 0.5316 - recall: 0.5316 - auc: 0.5948 - val_loss: 1.2567 - val_tp: 49859.0000 - val_fp: 14141.0000 - val_tn: 241859.0000 - val_fn: 14141.0000 - val_accuracy: 0.9116 - val_precision: 0.7790 - val_recall: 0.7790 - val_auc: 0.8619
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-7424000-7680000
[INFO] processing batch 7680000-7936000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1165 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1134 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-7680000-7936000
[INFO] processing batch 7936000-8192000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1100 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1065 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-7936000-8192000
[INFO] processing batch 8192000-8448000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.0067 - tp: 161781.0000 - fp: 30219.0000 - tn: 737781.0000 - fn: 30219.0000 - accuracy: 0.9370 - precision: 0.8426 - recall: 0.8426 - auc: 0.8426 - val_loss: 0.1602 - val_tp: 63369.0000 - val_fp: 631.0000 - val_tn: 255369.0000 - val_fn: 631.0000 - val_accuracy: 0.9961 - val_precision: 0.9901 - val_recall: 0.9901 - val_auc: 0.9901
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-8192000-8448000
[INFO] processing batch 8448000-8704000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.0563 - tp: 123282.0000 - fp: 68718.0000 - tn: 699282.0000 - fn: 68718.0000 - accuracy: 0.8568 - precision: 0.6421 - recall: 0.6421 - auc: 0.6420 - val_loss: 2.1191 - val_tp: 39692.0000 - val_fp: 24308.0000 - val_tn: 231692.0000 - val_fn: 24308.0000 - val_accuracy: 0.8481 - val_precision: 0.6202 - val_recall: 0.6202 - val_auc: 0.6202
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-8448000-8704000
[INFO] processing batch 8704000-8960000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2177 - tp: 188028.0000 - fp: 3972.0000 - tn: 764028.0000 - fn: 3972.0000 - accuracy: 0.9917 - precision: 0.9793 - recall: 0.9793 - auc: 0.9793 - val_loss: 0.1065 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-8704000-8960000
[INFO] processing batch 8960000-9216000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1036 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1006 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-8960000-9216000
[INFO] processing batch 9216000-9472000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.9825 - tp: 120440.0000 - fp: 71560.0000 - tn: 696440.0000 - fn: 71560.0000 - accuracy: 0.8509 - precision: 0.6273 - recall: 0.6273 - auc: 0.7671 - val_loss: 0.1049 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-9216000-9472000
[INFO] processing batch 9472000-9728000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8779 - tp: 161553.0000 - fp: 30447.0000 - tn: 737553.0000 - fn: 30447.0000 - accuracy: 0.9366 - precision: 0.8414 - recall: 0.8414 - auc: 0.9009 - val_loss: 0.8994 - val_tp: 53468.0000 - val_fp: 10532.0000 - val_tn: 245468.0000 - val_fn: 10532.0000 - val_accuracy: 0.9342 - val_precision: 0.8354 - val_recall: 0.8354 - val_auc: 0.8971
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-9472000-9728000
[INFO] processing batch 9728000-9984000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1035 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1007 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-9728000-9984000
[INFO] processing batch 9984000-10240000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.0981 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0953 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-9984000-10240000
[INFO] processing batch 10240000-10496000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1576 - tp: 189510.0000 - fp: 2490.0000 - tn: 765510.0000 - fn: 2490.0000 - accuracy: 0.9948 - precision: 0.9870 - recall: 0.9870 - auc: 0.9920 - val_loss: 2.4272 - val_tp: 33975.0000 - val_fp: 30025.0000 - val_tn: 225975.0000 - val_fn: 30025.0000 - val_accuracy: 0.8123 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.7068
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-10240000-10496000
[INFO] processing batch 10496000-10752000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.3633 - tp: 101670.0000 - fp: 90330.0000 - tn: 677670.0000 - fn: 90330.0000 - accuracy: 0.8118 - precision: 0.5295 - recall: 0.5295 - auc: 0.7060 - val_loss: 2.2752 - val_tp: 34015.0000 - val_fp: 29985.0000 - val_tn: 226015.0000 - val_fn: 29985.0000 - val_accuracy: 0.8126 - val_precision: 0.5315 - val_recall: 0.5315 - val_auc: 0.6486
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-10496000-10752000
[INFO] processing batch 10752000-11008000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 2.2213 - tp: 101693.0000 - fp: 90307.0000 - tn: 677693.0000 - fn: 90307.0000 - accuracy: 0.8119 - precision: 0.5297 - recall: 0.5297 - auc: 0.7046 - val_loss: 0.5860 - val_tp: 56989.0000 - val_fp: 7011.0000 - val_tn: 248989.0000 - val_fn: 7011.0000 - val_accuracy: 0.9562 - val_precision: 0.8905 - val_recall: 0.8905 - val_auc: 0.9452
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-10752000-11008000
[INFO] processing batch 11008000-11264000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1073 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1051 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-11008000-11264000
[INFO] processing batch 11264000-11520000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1025 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1000 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-11264000-11520000
[INFO] processing batch 11520000-11776000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.0976 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0952 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-11520000-11776000
[INFO] processing batch 11776000-12032000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9062 - tp: 156412.0000 - fp: 35588.0000 - tn: 732412.0000 - fn: 35588.0000 - accuracy: 0.9259 - precision: 0.8146 - recall: 0.8146 - auc: 0.9075 - val_loss: 1.6444 - val_tp: 41134.0000 - val_fp: 22866.0000 - val_tn: 233134.0000 - val_fn: 22866.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.8214
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-11776000-12032000
[INFO] processing batch 12032000-12288000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.6166 - tp: 123527.0000 - fp: 68473.0000 - tn: 699527.0000 - fn: 68473.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.8217 - val_loss: 1.5844 - val_tp: 41219.0000 - val_fp: 22781.0000 - val_tn: 233219.0000 - val_fn: 22781.0000 - val_accuracy: 0.8576 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.8220
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-12032000-12288000
[INFO] processing batch 12288000-12544000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.5592 - tp: 123560.0000 - fp: 68440.0000 - tn: 699560.0000 - fn: 68440.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.8218 - val_loss: 1.1029 - val_tp: 41268.0000 - val_fp: 22732.0000 - val_tn: 233268.0000 - val_fn: 22732.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.8958
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-12288000-12544000
[INFO] processing batch 12544000-12800000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.9981 - tp: 123588.0000 - fp: 68412.0000 - tn: 699588.0000 - fn: 68412.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.9712 - val_tp: 41269.0000 - val_fp: 22731.0000 - val_tn: 233269.0000 - val_fn: 22731.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-12544000-12800000
[INFO] processing batch 12800000-13056000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9528 - tp: 123531.0000 - fp: 68469.0000 - tn: 699531.0000 - fn: 68469.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.9309 - val_tp: 41181.0000 - val_fp: 22819.0000 - val_tn: 233181.0000 - val_fn: 22819.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-12800000-13056000
[INFO] processing batch 13056000-13312000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.9116 - tp: 123615.0000 - fp: 68385.0000 - tn: 699615.0000 - fn: 68385.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.8937 - val_tp: 41192.0000 - val_fp: 22808.0000 - val_tn: 233192.0000 - val_fn: 22808.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-13056000-13312000
[INFO] processing batch 13312000-13568000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.8794 - tp: 123437.0000 - fp: 68563.0000 - tn: 699437.0000 - fn: 68563.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9108 - val_loss: 0.8626 - val_tp: 41179.0000 - val_fp: 22821.0000 - val_tn: 233179.0000 - val_fn: 22821.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-13312000-13568000
[INFO] processing batch 13568000-13824000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8490 - tp: 123539.0000 - fp: 68461.0000 - tn: 699539.0000 - fn: 68461.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.8347 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-13568000-13824000
[INFO] processing batch 13824000-14080000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8238 - tp: 123556.0000 - fp: 68444.0000 - tn: 699556.0000 - fn: 68444.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.8126 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 233173.0000 - val_fn: 22827.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-13824000-14080000
[INFO] processing batch 14080000-14336000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8013 - tp: 123681.0000 - fp: 68319.0000 - tn: 699681.0000 - fn: 68319.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.7917 - val_tp: 41221.0000 - val_fp: 22779.0000 - val_tn: 233221.0000 - val_fn: 22779.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-14080000-14336000
[INFO] processing batch 14336000-14592000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7843 - tp: 123523.0000 - fp: 68477.0000 - tn: 699523.0000 - fn: 68477.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.7754 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 233197.0000 - val_fn: 22803.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-14336000-14592000
[INFO] processing batch 14592000-14848000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7677 - tp: 123652.0000 - fp: 68348.0000 - tn: 699652.0000 - fn: 68348.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.7607 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-14592000-14848000
[INFO] processing batch 14848000-15104000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7549 - tp: 123594.0000 - fp: 68406.0000 - tn: 699594.0000 - fn: 68406.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.7486 - val_tp: 41205.0000 - val_fp: 22795.0000 - val_tn: 233205.0000 - val_fn: 22795.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-14848000-15104000
[INFO] processing batch 15104000-15360000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7434 - tp: 123629.0000 - fp: 68371.0000 - tn: 699629.0000 - fn: 68371.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.7378 - val_tp: 41234.0000 - val_fp: 22766.0000 - val_tn: 233234.0000 - val_fn: 22766.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-15104000-15360000
[INFO] processing batch 15360000-15616000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7339 - tp: 123632.0000 - fp: 68368.0000 - tn: 699632.0000 - fn: 68368.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.7286 - val_tp: 41266.0000 - val_fp: 22734.0000 - val_tn: 233266.0000 - val_fn: 22734.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-15360000-15616000
[INFO] processing batch 15616000-15872000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7266 - tp: 123527.0000 - fp: 68473.0000 - tn: 699527.0000 - fn: 68473.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.7226 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 233197.0000 - val_fn: 22803.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-15616000-15872000
[INFO] processing batch 15872000-16128000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7199 - tp: 123531.0000 - fp: 68469.0000 - tn: 699531.0000 - fn: 68469.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.7169 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 233173.0000 - val_fn: 22827.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-15872000-16128000
[INFO] processing batch 16128000-16384000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7130 - tp: 123781.0000 - fp: 68219.0000 - tn: 699781.0000 - fn: 68219.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9112 - val_loss: 0.7115 - val_tp: 41195.0000 - val_fp: 22805.0000 - val_tn: 233195.0000 - val_fn: 22805.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-16128000-16384000
[INFO] processing batch 16384000-16640000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7092 - tp: 123621.0000 - fp: 68379.0000 - tn: 699621.0000 - fn: 68379.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.7078 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 233165.0000 - val_fn: 22835.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-16384000-16640000
[INFO] processing batch 16640000-16896000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7064 - tp: 123417.0000 - fp: 68583.0000 - tn: 699417.0000 - fn: 68583.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9107 - val_loss: 0.7033 - val_tp: 41230.0000 - val_fp: 22770.0000 - val_tn: 233230.0000 - val_fn: 22770.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-16640000-16896000
[INFO] processing batch 16896000-17152000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7023 - tp: 123600.0000 - fp: 68400.0000 - tn: 699600.0000 - fn: 68400.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.7009 - val_tp: 41198.0000 - val_fp: 22802.0000 - val_tn: 233198.0000 - val_fn: 22802.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-16896000-17152000
[INFO] processing batch 17152000-17408000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6992 - tp: 123711.0000 - fp: 68289.0000 - tn: 699711.0000 - fn: 68289.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9110 - val_loss: 0.6989 - val_tp: 41168.0000 - val_fp: 22832.0000 - val_tn: 233168.0000 - val_fn: 22832.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-17152000-17408000
[INFO] processing batch 17408000-17664000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6970 - tp: 123701.0000 - fp: 68299.0000 - tn: 699701.0000 - fn: 68299.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9111 - val_loss: 0.6975 - val_tp: 41118.0000 - val_fp: 22882.0000 - val_tn: 233118.0000 - val_fn: 22882.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-17408000-17664000
[INFO] processing batch 17664000-17920000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6958 - tp: 123546.0000 - fp: 68454.0000 - tn: 699546.0000 - fn: 68454.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6961 - val_tp: 41089.0000 - val_fp: 22911.0000 - val_tn: 233089.0000 - val_fn: 22911.0000 - val_accuracy: 0.8568 - val_precision: 0.6420 - val_recall: 0.6420 - val_auc: 0.9105
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-17664000-17920000
[INFO] processing batch 17920000-18176000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6937 - tp: 123681.0000 - fp: 68319.0000 - tn: 699681.0000 - fn: 68319.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6929 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 233233.0000 - val_fn: 22767.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-17920000-18176000
[INFO] processing batch 18176000-18432000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6925 - tp: 123640.0000 - fp: 68360.0000 - tn: 699640.0000 - fn: 68360.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6909 - val_tp: 41298.0000 - val_fp: 22702.0000 - val_tn: 233298.0000 - val_fn: 22702.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-18176000-18432000
[INFO] processing batch 18432000-18688000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6915 - tp: 123615.0000 - fp: 68385.0000 - tn: 699615.0000 - fn: 68385.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6906 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 233233.0000 - val_fn: 22767.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-18432000-18688000
[INFO] processing batch 18688000-18944000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6903 - tp: 123645.0000 - fp: 68355.0000 - tn: 699645.0000 - fn: 68355.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6902 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 233184.0000 - val_fn: 22816.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-18688000-18944000
[INFO] processing batch 18944000-19200000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6885 - tp: 123888.0000 - fp: 68112.0000 - tn: 699888.0000 - fn: 68112.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9113 - val_loss: 0.6895 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 233169.0000 - val_fn: 22831.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-18944000-19200000
[INFO] processing batch 19200000-19456000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6891 - tp: 123500.0000 - fp: 68500.0000 - tn: 699500.0000 - fn: 68500.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6885 - val_tp: 41189.0000 - val_fp: 22811.0000 - val_tn: 233189.0000 - val_fn: 22811.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-19200000-19456000
[INFO] processing batch 19456000-19712000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6877 - tp: 123689.0000 - fp: 68311.0000 - tn: 699689.0000 - fn: 68311.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6880 - val_tp: 41166.0000 - val_fp: 22834.0000 - val_tn: 233166.0000 - val_fn: 22834.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-19456000-19712000
[INFO] processing batch 19712000-19968000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6879 - tp: 123402.0000 - fp: 68598.0000 - tn: 699402.0000 - fn: 68598.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9107 - val_loss: 0.6865 - val_tp: 41242.0000 - val_fp: 22758.0000 - val_tn: 233242.0000 - val_fn: 22758.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-19712000-19968000
[INFO] processing batch 19968000-20224000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6868 - tp: 123541.0000 - fp: 68459.0000 - tn: 699541.0000 - fn: 68459.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6858 - val_tp: 41241.0000 - val_fp: 22759.0000 - val_tn: 233241.0000 - val_fn: 22759.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-19968000-20224000
[INFO] processing batch 20224000-20480000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6858 - tp: 123640.0000 - fp: 68360.0000 - tn: 699640.0000 - fn: 68360.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6855 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 233209.0000 - val_fn: 22791.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-20224000-20480000
[INFO] processing batch 20480000-20736000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6853 - tp: 123598.0000 - fp: 68402.0000 - tn: 699598.0000 - fn: 68402.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6846 - val_tp: 41235.0000 - val_fp: 22765.0000 - val_tn: 233235.0000 - val_fn: 22765.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-20480000-20736000
[INFO] processing batch 20736000-20992000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6841 - tp: 123769.0000 - fp: 68231.0000 - tn: 699769.0000 - fn: 68231.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.6843 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-20736000-20992000
[INFO] processing batch 20992000-21248000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6846 - tp: 123459.0000 - fp: 68541.0000 - tn: 699459.0000 - fn: 68541.0000 - accuracy: 0.8572 - precision: 0.6430 - recall: 0.6430 - auc: 0.9108 - val_loss: 0.6837 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 233209.0000 - val_fn: 22791.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-20992000-21248000
[INFO] processing batch 21248000-21504000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6832 - tp: 123683.0000 - fp: 68317.0000 - tn: 699683.0000 - fn: 68317.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6834 - val_tp: 41183.0000 - val_fp: 22817.0000 - val_tn: 233183.0000 - val_fn: 22817.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-21248000-21504000
[INFO] processing batch 21504000-21760000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6831 - tp: 123564.0000 - fp: 68436.0000 - tn: 699564.0000 - fn: 68436.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6821 - val_tp: 41254.0000 - val_fp: 22746.0000 - val_tn: 233254.0000 - val_fn: 22746.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-21504000-21760000
[INFO] processing batch 21760000-22016000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6820 - tp: 123717.0000 - fp: 68283.0000 - tn: 699717.0000 - fn: 68283.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9111 - val_loss: 0.6814 - val_tp: 41270.0000 - val_fp: 22730.0000 - val_tn: 233270.0000 - val_fn: 22730.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-21760000-22016000
[INFO] processing batch 22016000-22272000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6815 - tp: 123690.0000 - fp: 68310.0000 - tn: 699690.0000 - fn: 68310.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6825 - val_tp: 41104.0000 - val_fp: 22896.0000 - val_tn: 233104.0000 - val_fn: 22896.0000 - val_accuracy: 0.8569 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-22016000-22272000
[INFO] processing batch 22272000-22528000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6811 - tp: 123672.0000 - fp: 68328.0000 - tn: 699672.0000 - fn: 68328.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6806 - val_tp: 41243.0000 - val_fp: 22757.0000 - val_tn: 233243.0000 - val_fn: 22757.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-22272000-22528000
[INFO] processing batch 22528000-22784000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6807 - tp: 123623.0000 - fp: 68377.0000 - tn: 699623.0000 - fn: 68377.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6796 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 233292.0000 - val_fn: 22708.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-22528000-22784000
[INFO] processing batch 22784000-23040000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6797 - tp: 123759.0000 - fp: 68241.0000 - tn: 699759.0000 - fn: 68241.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9111 - val_loss: 0.6802 - val_tp: 41180.0000 - val_fp: 22820.0000 - val_tn: 233180.0000 - val_fn: 22820.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-22784000-23040000
[INFO] processing batch 23040000-23296000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6800 - tp: 123507.0000 - fp: 68493.0000 - tn: 699507.0000 - fn: 68493.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6789 - val_tp: 41255.0000 - val_fp: 22745.0000 - val_tn: 233255.0000 - val_fn: 22745.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-23040000-23296000
[INFO] processing batch 23296000-23552000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6792 - tp: 123601.0000 - fp: 68399.0000 - tn: 699601.0000 - fn: 68399.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6788 - val_tp: 41213.0000 - val_fp: 22787.0000 - val_tn: 233213.0000 - val_fn: 22787.0000 - val_accuracy: 0.8576 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-23296000-23552000
[INFO] processing batch 23552000-23808000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6782 - tp: 123749.0000 - fp: 68251.0000 - tn: 699749.0000 - fn: 68251.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9111 - val_loss: 0.6776 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 233292.0000 - val_fn: 22708.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-23552000-23808000
[INFO] processing batch 23808000-24064000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6782 - tp: 123603.0000 - fp: 68397.0000 - tn: 699603.0000 - fn: 68397.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6783 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 233165.0000 - val_fn: 22835.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-23808000-24064000
[INFO] processing batch 24064000-24320000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6777 - tp: 123599.0000 - fp: 68401.0000 - tn: 699599.0000 - fn: 68401.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6776 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 233184.0000 - val_fn: 22816.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-24064000-24320000
[INFO] processing batch 24320000-24576000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6777 - tp: 123440.0000 - fp: 68560.0000 - tn: 699440.0000 - fn: 68560.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9107 - val_loss: 0.6773 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 233169.0000 - val_fn: 22831.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-24320000-24576000
[INFO] processing batch 24576000-24832000/24819975
[33m[LOSS] 0.677280110836029[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.677280110836029  <  0.001
[33m[INFO] epoch 4/10[0m
[33m[INFO] loading file 1-50/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (24819975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
len(df.columns) 108
numFeatures 107
[INFO] columns: Index(['unixtime', 'modbus_function_code', 'modbus_transaction_id', 'service',
       's_port', 'classification', 'orig-192.168.1.48', 'orig-192.168.1.87',
       'orig-192.168.1.88', 'type-alert',
       ...
       'modbus_function_description-Read Tag Service',
       'modbus_function_description-Read Tag Service - Response',
       'modbus_function_description-Unknown Function Code',
       'modbus_function_description-Write Tag Service', 'scada_tag-0',
       'scada_tag-HMI_AIT202', 'scada_tag-HMI_FIT201', 'scada_tag-HMI_LIT101',
       'scada_tag-HMI_LIT301', 'scada_tag-HMI_LIT401'],
      dtype='object', length=108)
[INFO] processing batch 0-256000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.4193 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3711 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-0-256000
[INFO] processing batch 256000-512000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7342 - tp: 112918.0000 - fp: 79082.0000 - tn: 688918.0000 - fn: 79082.0000 - accuracy: 0.8352 - precision: 0.5881 - recall: 0.5881 - auc: 0.8967 - val_loss: 0.7788 - val_tp: 33927.0000 - val_fp: 30073.0000 - val_tn: 225927.0000 - val_fn: 30073.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-256000-512000
[INFO] processing batch 512000-768000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6177 - tp: 138284.0000 - fp: 53716.0000 - tn: 714284.0000 - fn: 53716.0000 - accuracy: 0.8881 - precision: 0.7202 - recall: 0.7202 - auc: 0.9296 - val_loss: 0.4051 - val_tp: 62058.0000 - val_fp: 1942.0000 - val_tn: 254058.0000 - val_fn: 1942.0000 - val_accuracy: 0.9879 - val_precision: 0.9697 - val_recall: 0.9697 - val_auc: 0.9924
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-512000-768000
[INFO] processing batch 768000-1024000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7083 - tp: 117250.0000 - fp: 74750.0000 - tn: 693250.0000 - fn: 74750.0000 - accuracy: 0.8443 - precision: 0.6107 - recall: 0.6107 - auc: 0.9024 - val_loss: 0.5010 - val_tp: 55591.0000 - val_fp: 8409.0000 - val_tn: 247591.0000 - val_fn: 8409.0000 - val_accuracy: 0.9474 - val_precision: 0.8686 - val_recall: 0.8686 - val_auc: 0.9672
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-768000-1024000
[INFO] processing batch 1024000-1280000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6363 - tp: 133967.0000 - fp: 58033.0000 - tn: 709967.0000 - fn: 58033.0000 - accuracy: 0.8791 - precision: 0.6977 - recall: 0.6977 - auc: 0.9244 - val_loss: 0.3972 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-1024000-1280000
[INFO] processing batch 1280000-1536000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.3691 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3349 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-1280000-1536000
[INFO] processing batch 1536000-1792000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.3080 - tp: 191999.0000 - fp: 1.0000 - tn: 767999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2831 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-1536000-1792000
[INFO] processing batch 1792000-2048000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.5571 - tp: 148221.0000 - fp: 43779.0000 - tn: 724221.0000 - fn: 43779.0000 - accuracy: 0.9088 - precision: 0.7720 - recall: 0.7720 - auc: 0.9430 - val_loss: 0.3918 - val_tp: 57941.0000 - val_fp: 6059.0000 - val_tn: 249941.0000 - val_fn: 6059.0000 - val_accuracy: 0.9621 - val_precision: 0.9053 - val_recall: 0.9053 - val_auc: 0.9763
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-1792000-2048000
[INFO] processing batch 2048000-2304000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.5985 - tp: 141714.0000 - fp: 50286.0000 - tn: 717714.0000 - fn: 50286.0000 - accuracy: 0.8952 - precision: 0.7381 - recall: 0.7381 - auc: 0.9346 - val_loss: 0.2782 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-2048000-2304000
[INFO] processing batch 2304000-2560000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2658 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2486 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-2304000-2560000
[INFO] processing batch 2560000-2816000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2336 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2191 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-2560000-2816000
[INFO] processing batch 2816000-3072000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.5578 - tp: 148720.0000 - fp: 43280.0000 - tn: 724720.0000 - fn: 43280.0000 - accuracy: 0.9098 - precision: 0.7746 - recall: 0.7746 - auc: 0.9435 - val_loss: 0.7597 - val_tp: 40961.0000 - val_fp: 23039.0000 - val_tn: 232961.0000 - val_fn: 23039.0000 - val_accuracy: 0.8560 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.9100
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-2816000-3072000
[INFO] processing batch 3072000-3328000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6877 - tp: 131495.0000 - fp: 60505.0000 - tn: 707495.0000 - fn: 60505.0000 - accuracy: 0.8739 - precision: 0.6849 - recall: 0.6849 - auc: 0.9212 - val_loss: 0.2332 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-3072000-3328000
[INFO] processing batch 3328000-3584000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2263 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2144 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-3328000-3584000
[INFO] processing batch 3584000-3840000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2032 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1922 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-3584000-3840000
[INFO] processing batch 3840000-4096000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.4881 - tp: 157534.0000 - fp: 34466.0000 - tn: 733534.0000 - fn: 34466.0000 - accuracy: 0.9282 - precision: 0.8205 - recall: 0.8205 - auc: 0.9551 - val_loss: 0.4956 - val_tp: 52219.0000 - val_fp: 11781.0000 - val_tn: 244219.0000 - val_fn: 11781.0000 - val_accuracy: 0.9264 - val_precision: 0.8159 - val_recall: 0.8159 - val_auc: 0.9540
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-3840000-4096000
[INFO] processing batch 4096000-4352000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2000 - tp: 190188.0000 - fp: 1812.0000 - tn: 766188.0000 - fn: 1812.0000 - accuracy: 0.9962 - precision: 0.9906 - recall: 0.9906 - auc: 0.9976 - val_loss: 0.1759 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-4096000-4352000
[INFO] processing batch 4352000-4608000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1682 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1604 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-4352000-4608000
[INFO] processing batch 4608000-4864000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.4551 - tp: 161451.0000 - fp: 30549.0000 - tn: 737451.0000 - fn: 30549.0000 - accuracy: 0.9364 - precision: 0.8409 - recall: 0.8409 - auc: 0.9602 - val_loss: 0.1592 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-4608000-4864000
[INFO] processing batch 4864000-5120000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1548 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1485 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-4864000-5120000
[INFO] processing batch 5120000-5376000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1427 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1368 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-5120000-5376000
[INFO] processing batch 5376000-5632000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1318 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1267 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-5376000-5632000
[INFO] processing batch 5632000-5888000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.5246 - tp: 155809.0000 - fp: 36191.0000 - tn: 731809.0000 - fn: 36191.0000 - accuracy: 0.9246 - precision: 0.8115 - recall: 0.8115 - auc: 0.9529 - val_loss: 0.1299 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-5632000-5888000
[INFO] processing batch 5888000-6144000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1275 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1232 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-5888000-6144000
[INFO] processing batch 6144000-6400000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.3220 - tp: 174156.0000 - fp: 17844.0000 - tn: 750156.0000 - fn: 17844.0000 - accuracy: 0.9628 - precision: 0.9071 - recall: 0.9071 - auc: 0.9767 - val_loss: 0.8954 - val_tp: 41108.0000 - val_fp: 22892.0000 - val_tn: 233108.0000 - val_fn: 22892.0000 - val_accuracy: 0.8569 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-6144000-6400000
[INFO] processing batch 6400000-6656000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7143 - tp: 138766.0000 - fp: 53234.0000 - tn: 714766.0000 - fn: 53234.0000 - accuracy: 0.8891 - precision: 0.7227 - recall: 0.7227 - auc: 0.9311 - val_loss: 0.1312 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-6400000-6656000
[INFO] processing batch 6656000-6912000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1299 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1258 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-6656000-6912000
[INFO] processing batch 6912000-7168000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1214 - tp: 191998.0000 - fp: 2.0000 - tn: 767998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1169 - val_tp: 63999.0000 - val_fp: 1.0000 - val_tn: 255999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-6912000-7168000
[INFO] processing batch 7168000-7424000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1129 - tp: 191999.0000 - fp: 1.0000 - tn: 767999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8498 - val_tp: 44344.0000 - val_fp: 19656.0000 - val_tn: 236344.0000 - val_fn: 19656.0000 - val_accuracy: 0.8772 - val_precision: 0.6929 - val_recall: 0.6929 - val_auc: 0.7313
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-7168000-7424000
[INFO] processing batch 7424000-7680000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.6914 - tp: 102062.0000 - fp: 89938.0000 - tn: 678062.0000 - fn: 89938.0000 - accuracy: 0.8126 - precision: 0.5316 - recall: 0.5316 - auc: 0.5901 - val_loss: 1.2926 - val_tp: 49859.0000 - val_fp: 14141.0000 - val_tn: 241859.0000 - val_fn: 14141.0000 - val_accuracy: 0.9116 - val_precision: 0.7790 - val_recall: 0.7790 - val_auc: 0.8067
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-7424000-7680000
[INFO] processing batch 7680000-7936000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1151 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1119 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-7680000-7936000
[INFO] processing batch 7936000-8192000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1086 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1051 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-7936000-8192000
[INFO] processing batch 8192000-8448000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.0399 - tp: 161781.0000 - fp: 30219.0000 - tn: 737781.0000 - fn: 30219.0000 - accuracy: 0.9370 - precision: 0.8426 - recall: 0.8426 - auc: 0.8623 - val_loss: 0.1609 - val_tp: 63369.0000 - val_fp: 631.0000 - val_tn: 255369.0000 - val_fn: 631.0000 - val_accuracy: 0.9961 - val_precision: 0.9901 - val_recall: 0.9901 - val_auc: 0.9914
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-8192000-8448000
[INFO] processing batch 8448000-8704000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.1327 - tp: 123282.0000 - fp: 68718.0000 - tn: 699282.0000 - fn: 68718.0000 - accuracy: 0.8568 - precision: 0.6421 - recall: 0.6421 - auc: 0.6868 - val_loss: 2.1999 - val_tp: 39692.0000 - val_fp: 24308.0000 - val_tn: 231692.0000 - val_fn: 24308.0000 - val_accuracy: 0.8481 - val_precision: 0.6202 - val_recall: 0.6202 - val_auc: 0.6677
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-8448000-8704000
[INFO] processing batch 8704000-8960000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.2205 - tp: 188028.0000 - fp: 3972.0000 - tn: 764028.0000 - fn: 3972.0000 - accuracy: 0.9917 - precision: 0.9793 - recall: 0.9793 - auc: 0.9820 - val_loss: 0.1048 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-8704000-8960000
[INFO] processing batch 8960000-9216000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1019 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0989 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-8960000-9216000
[INFO] processing batch 9216000-9472000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.0419 - tp: 120440.0000 - fp: 71560.0000 - tn: 696440.0000 - fn: 71560.0000 - accuracy: 0.8509 - precision: 0.6273 - recall: 0.6273 - auc: 0.7130 - val_loss: 0.1030 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-9216000-9472000
[INFO] processing batch 9472000-9728000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9019 - tp: 161553.0000 - fp: 30447.0000 - tn: 737553.0000 - fn: 30447.0000 - accuracy: 0.9366 - precision: 0.8414 - recall: 0.8414 - auc: 0.9009 - val_loss: 0.9241 - val_tp: 53468.0000 - val_fp: 10532.0000 - val_tn: 245468.0000 - val_fn: 10532.0000 - val_accuracy: 0.9342 - val_precision: 0.8354 - val_recall: 0.8354 - val_auc: 0.8971
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-9472000-9728000
[INFO] processing batch 9728000-9984000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1015 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0987 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-9728000-9984000
[INFO] processing batch 9984000-10240000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.0961 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0935 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-9984000-10240000
[INFO] processing batch 10240000-10496000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1566 - tp: 189510.0000 - fp: 2490.0000 - tn: 765510.0000 - fn: 2490.0000 - accuracy: 0.9948 - precision: 0.9870 - recall: 0.9870 - auc: 0.9919 - val_loss: 2.4545 - val_tp: 33975.0000 - val_fp: 30025.0000 - val_tn: 225975.0000 - val_fn: 30025.0000 - val_accuracy: 0.8123 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.7068
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-10240000-10496000
[INFO] processing batch 10496000-10752000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.3903 - tp: 101670.0000 - fp: 90330.0000 - tn: 677670.0000 - fn: 90330.0000 - accuracy: 0.8118 - precision: 0.5295 - recall: 0.5295 - auc: 0.7059 - val_loss: 2.3017 - val_tp: 34015.0000 - val_fp: 29985.0000 - val_tn: 226015.0000 - val_fn: 29985.0000 - val_accuracy: 0.8126 - val_precision: 0.5315 - val_recall: 0.5315 - val_auc: 0.7072
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-10496000-10752000
[INFO] processing batch 10752000-11008000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.2476 - tp: 101693.0000 - fp: 90307.0000 - tn: 677693.0000 - fn: 90307.0000 - accuracy: 0.8119 - precision: 0.5297 - recall: 0.5297 - auc: 0.7209 - val_loss: 0.5902 - val_tp: 56989.0000 - val_fp: 7011.0000 - val_tn: 248989.0000 - val_fn: 7011.0000 - val_accuracy: 0.9562 - val_precision: 0.8905 - val_recall: 0.8905 - val_auc: 0.9452
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-10752000-11008000
[INFO] processing batch 11008000-11264000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1049 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1027 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-11008000-11264000
[INFO] processing batch 11264000-11520000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1002 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0977 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-11264000-11520000
[INFO] processing batch 11520000-11776000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.0954 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0931 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-11520000-11776000
[INFO] processing batch 11776000-12032000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9147 - tp: 156412.0000 - fp: 35588.0000 - tn: 732412.0000 - fn: 35588.0000 - accuracy: 0.9259 - precision: 0.8146 - recall: 0.8146 - auc: 0.9073 - val_loss: 1.6623 - val_tp: 41134.0000 - val_fp: 22866.0000 - val_tn: 233134.0000 - val_fn: 22866.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.8214
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-11776000-12032000
[INFO] processing batch 12032000-12288000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.6345 - tp: 123527.0000 - fp: 68473.0000 - tn: 699527.0000 - fn: 68473.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.8217 - val_loss: 1.6023 - val_tp: 41219.0000 - val_fp: 22781.0000 - val_tn: 233219.0000 - val_fn: 22781.0000 - val_accuracy: 0.8576 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.8220
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-12032000-12288000
[INFO] processing batch 12288000-12544000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.5768 - tp: 123560.0000 - fp: 68440.0000 - tn: 699560.0000 - fn: 68440.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.8218 - val_loss: 1.1013 - val_tp: 41268.0000 - val_fp: 22732.0000 - val_tn: 233268.0000 - val_fn: 22732.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.8958
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-12288000-12544000
[INFO] processing batch 12544000-12800000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9926 - tp: 123588.0000 - fp: 68412.0000 - tn: 699588.0000 - fn: 68412.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.9656 - val_tp: 41269.0000 - val_fp: 22731.0000 - val_tn: 233269.0000 - val_fn: 22731.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-12544000-12800000
[INFO] processing batch 12800000-13056000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9472 - tp: 123531.0000 - fp: 68469.0000 - tn: 699531.0000 - fn: 68469.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.9253 - val_tp: 41181.0000 - val_fp: 22819.0000 - val_tn: 233181.0000 - val_fn: 22819.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-12800000-13056000
[INFO] processing batch 13056000-13312000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9060 - tp: 123615.0000 - fp: 68385.0000 - tn: 699615.0000 - fn: 68385.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.8881 - val_tp: 41192.0000 - val_fp: 22808.0000 - val_tn: 233192.0000 - val_fn: 22808.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-13056000-13312000
[INFO] processing batch 13312000-13568000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8738 - tp: 123437.0000 - fp: 68563.0000 - tn: 699437.0000 - fn: 68563.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9107 - val_loss: 0.8570 - val_tp: 41179.0000 - val_fp: 22821.0000 - val_tn: 233179.0000 - val_fn: 22821.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-13312000-13568000
[INFO] processing batch 13568000-13824000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8435 - tp: 123539.0000 - fp: 68461.0000 - tn: 699539.0000 - fn: 68461.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.8291 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-13568000-13824000
[INFO] processing batch 13824000-14080000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8183 - tp: 123556.0000 - fp: 68444.0000 - tn: 699556.0000 - fn: 68444.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9110 - val_loss: 0.8072 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 233173.0000 - val_fn: 22827.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-13824000-14080000
[INFO] processing batch 14080000-14336000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7959 - tp: 123681.0000 - fp: 68319.0000 - tn: 699681.0000 - fn: 68319.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.7863 - val_tp: 41221.0000 - val_fp: 22779.0000 - val_tn: 233221.0000 - val_fn: 22779.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-14080000-14336000
[INFO] processing batch 14336000-14592000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7790 - tp: 123523.0000 - fp: 68477.0000 - tn: 699523.0000 - fn: 68477.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.7701 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 233197.0000 - val_fn: 22803.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-14336000-14592000
[INFO] processing batch 14592000-14848000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7625 - tp: 123652.0000 - fp: 68348.0000 - tn: 699652.0000 - fn: 68348.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.7555 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-14592000-14848000
[INFO] processing batch 14848000-15104000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7498 - tp: 123594.0000 - fp: 68406.0000 - tn: 699594.0000 - fn: 68406.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.7436 - val_tp: 41205.0000 - val_fp: 22795.0000 - val_tn: 233205.0000 - val_fn: 22795.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-14848000-15104000
[INFO] processing batch 15104000-15360000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7384 - tp: 123629.0000 - fp: 68371.0000 - tn: 699629.0000 - fn: 68371.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.7329 - val_tp: 41234.0000 - val_fp: 22766.0000 - val_tn: 233234.0000 - val_fn: 22766.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-15104000-15360000
[INFO] processing batch 15360000-15616000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 21s - loss: 0.7291 - tp: 123632.0000 - fp: 68368.0000 - tn: 699632.0000 - fn: 68368.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.7238 - val_tp: 41266.0000 - val_fp: 22734.0000 - val_tn: 233266.0000 - val_fn: 22734.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-15360000-15616000
[INFO] processing batch 15616000-15872000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7219 - tp: 123527.0000 - fp: 68473.0000 - tn: 699527.0000 - fn: 68473.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.7180 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 233197.0000 - val_fn: 22803.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-15616000-15872000
[INFO] processing batch 15872000-16128000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7153 - tp: 123531.0000 - fp: 68469.0000 - tn: 699531.0000 - fn: 68469.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.7124 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 233173.0000 - val_fn: 22827.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-15872000-16128000
[INFO] processing batch 16128000-16384000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7086 - tp: 123781.0000 - fp: 68219.0000 - tn: 699781.0000 - fn: 68219.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9112 - val_loss: 0.7072 - val_tp: 41195.0000 - val_fp: 22805.0000 - val_tn: 233195.0000 - val_fn: 22805.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-16128000-16384000
[INFO] processing batch 16384000-16640000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7050 - tp: 123621.0000 - fp: 68379.0000 - tn: 699621.0000 - fn: 68379.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.7036 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 233165.0000 - val_fn: 22835.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-16384000-16640000
[INFO] processing batch 16640000-16896000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7023 - tp: 123417.0000 - fp: 68583.0000 - tn: 699417.0000 - fn: 68583.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9107 - val_loss: 0.6993 - val_tp: 41230.0000 - val_fp: 22770.0000 - val_tn: 233230.0000 - val_fn: 22770.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-16640000-16896000
[INFO] processing batch 16896000-17152000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6983 - tp: 123600.0000 - fp: 68400.0000 - tn: 699600.0000 - fn: 68400.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6970 - val_tp: 41198.0000 - val_fp: 22802.0000 - val_tn: 233198.0000 - val_fn: 22802.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-16896000-17152000
[INFO] processing batch 17152000-17408000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6953 - tp: 123711.0000 - fp: 68289.0000 - tn: 699711.0000 - fn: 68289.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9111 - val_loss: 0.6951 - val_tp: 41168.0000 - val_fp: 22832.0000 - val_tn: 233168.0000 - val_fn: 22832.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-17152000-17408000
[INFO] processing batch 17408000-17664000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6933 - tp: 123701.0000 - fp: 68299.0000 - tn: 699701.0000 - fn: 68299.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9111 - val_loss: 0.6939 - val_tp: 41118.0000 - val_fp: 22882.0000 - val_tn: 233118.0000 - val_fn: 22882.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-17408000-17664000
[INFO] processing batch 17664000-17920000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6922 - tp: 123546.0000 - fp: 68454.0000 - tn: 699546.0000 - fn: 68454.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6926 - val_tp: 41089.0000 - val_fp: 22911.0000 - val_tn: 233089.0000 - val_fn: 22911.0000 - val_accuracy: 0.8568 - val_precision: 0.6420 - val_recall: 0.6420 - val_auc: 0.9105
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-17664000-17920000
[INFO] processing batch 17920000-18176000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6902 - tp: 123681.0000 - fp: 68319.0000 - tn: 699681.0000 - fn: 68319.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6895 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 233233.0000 - val_fn: 22767.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-17920000-18176000
[INFO] processing batch 18176000-18432000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6892 - tp: 123640.0000 - fp: 68360.0000 - tn: 699640.0000 - fn: 68360.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6876 - val_tp: 41298.0000 - val_fp: 22702.0000 - val_tn: 233298.0000 - val_fn: 22702.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-18176000-18432000
[INFO] processing batch 18432000-18688000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6882 - tp: 123615.0000 - fp: 68385.0000 - tn: 699615.0000 - fn: 68385.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6874 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 233233.0000 - val_fn: 22767.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-18432000-18688000
[INFO] processing batch 18688000-18944000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6872 - tp: 123645.0000 - fp: 68355.0000 - tn: 699645.0000 - fn: 68355.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6871 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 233184.0000 - val_fn: 22816.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-18688000-18944000
[INFO] processing batch 18944000-19200000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6855 - tp: 123888.0000 - fp: 68112.0000 - tn: 699888.0000 - fn: 68112.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9113 - val_loss: 0.6865 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 233169.0000 - val_fn: 22831.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-18944000-19200000
[INFO] processing batch 19200000-19456000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6861 - tp: 123500.0000 - fp: 68500.0000 - tn: 699500.0000 - fn: 68500.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6855 - val_tp: 41189.0000 - val_fp: 22811.0000 - val_tn: 233189.0000 - val_fn: 22811.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-19200000-19456000
[INFO] processing batch 19456000-19712000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6848 - tp: 123689.0000 - fp: 68311.0000 - tn: 699689.0000 - fn: 68311.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6851 - val_tp: 41166.0000 - val_fp: 22834.0000 - val_tn: 233166.0000 - val_fn: 22834.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-19456000-19712000
[INFO] processing batch 19712000-19968000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6852 - tp: 123402.0000 - fp: 68598.0000 - tn: 699402.0000 - fn: 68598.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9107 - val_loss: 0.6837 - val_tp: 41242.0000 - val_fp: 22758.0000 - val_tn: 233242.0000 - val_fn: 22758.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-19712000-19968000
[INFO] processing batch 19968000-20224000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6841 - tp: 123541.0000 - fp: 68459.0000 - tn: 699541.0000 - fn: 68459.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6832 - val_tp: 41241.0000 - val_fp: 22759.0000 - val_tn: 233241.0000 - val_fn: 22759.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-19968000-20224000
[INFO] processing batch 20224000-20480000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6832 - tp: 123640.0000 - fp: 68360.0000 - tn: 699640.0000 - fn: 68360.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6829 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 233209.0000 - val_fn: 22791.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-20224000-20480000
[INFO] processing batch 20480000-20736000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6828 - tp: 123598.0000 - fp: 68402.0000 - tn: 699598.0000 - fn: 68402.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6821 - val_tp: 41235.0000 - val_fp: 22765.0000 - val_tn: 233235.0000 - val_fn: 22765.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-20480000-20736000
[INFO] processing batch 20736000-20992000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6817 - tp: 123769.0000 - fp: 68231.0000 - tn: 699769.0000 - fn: 68231.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.6819 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-20736000-20992000
[INFO] processing batch 20992000-21248000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6822 - tp: 123459.0000 - fp: 68541.0000 - tn: 699459.0000 - fn: 68541.0000 - accuracy: 0.8572 - precision: 0.6430 - recall: 0.6430 - auc: 0.9108 - val_loss: 0.6814 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 233209.0000 - val_fn: 22791.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-20992000-21248000
[INFO] processing batch 21248000-21504000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6810 - tp: 123683.0000 - fp: 68317.0000 - tn: 699683.0000 - fn: 68317.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6811 - val_tp: 41183.0000 - val_fp: 22817.0000 - val_tn: 233183.0000 - val_fn: 22817.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-21248000-21504000
[INFO] processing batch 21504000-21760000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6808 - tp: 123564.0000 - fp: 68436.0000 - tn: 699564.0000 - fn: 68436.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6800 - val_tp: 41254.0000 - val_fp: 22746.0000 - val_tn: 233254.0000 - val_fn: 22746.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-21504000-21760000
[INFO] processing batch 21760000-22016000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6799 - tp: 123717.0000 - fp: 68283.0000 - tn: 699717.0000 - fn: 68283.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9111 - val_loss: 0.6793 - val_tp: 41270.0000 - val_fp: 22730.0000 - val_tn: 233270.0000 - val_fn: 22730.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-21760000-22016000
[INFO] processing batch 22016000-22272000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6795 - tp: 123690.0000 - fp: 68310.0000 - tn: 699690.0000 - fn: 68310.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6804 - val_tp: 41104.0000 - val_fp: 22896.0000 - val_tn: 233104.0000 - val_fn: 22896.0000 - val_accuracy: 0.8569 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-22016000-22272000
[INFO] processing batch 22272000-22528000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6791 - tp: 123672.0000 - fp: 68328.0000 - tn: 699672.0000 - fn: 68328.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6786 - val_tp: 41243.0000 - val_fp: 22757.0000 - val_tn: 233243.0000 - val_fn: 22757.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-22272000-22528000
[INFO] processing batch 22528000-22784000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6787 - tp: 123623.0000 - fp: 68377.0000 - tn: 699623.0000 - fn: 68377.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6777 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 233292.0000 - val_fn: 22708.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-22528000-22784000
[INFO] processing batch 22784000-23040000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6779 - tp: 123759.0000 - fp: 68241.0000 - tn: 699759.0000 - fn: 68241.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9111 - val_loss: 0.6783 - val_tp: 41180.0000 - val_fp: 22820.0000 - val_tn: 233180.0000 - val_fn: 22820.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-22784000-23040000
[INFO] processing batch 23040000-23296000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6782 - tp: 123507.0000 - fp: 68493.0000 - tn: 699507.0000 - fn: 68493.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6771 - val_tp: 41255.0000 - val_fp: 22745.0000 - val_tn: 233255.0000 - val_fn: 22745.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-23040000-23296000
[INFO] processing batch 23296000-23552000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6774 - tp: 123601.0000 - fp: 68399.0000 - tn: 699601.0000 - fn: 68399.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6771 - val_tp: 41213.0000 - val_fp: 22787.0000 - val_tn: 233213.0000 - val_fn: 22787.0000 - val_accuracy: 0.8576 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-23296000-23552000
[INFO] processing batch 23552000-23808000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6765 - tp: 123749.0000 - fp: 68251.0000 - tn: 699749.0000 - fn: 68251.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9111 - val_loss: 0.6759 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 233292.0000 - val_fn: 22708.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-23552000-23808000
[INFO] processing batch 23808000-24064000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6766 - tp: 123603.0000 - fp: 68397.0000 - tn: 699603.0000 - fn: 68397.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6767 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 233165.0000 - val_fn: 22835.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-23808000-24064000
[INFO] processing batch 24064000-24320000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6761 - tp: 123599.0000 - fp: 68401.0000 - tn: 699599.0000 - fn: 68401.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6761 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 233184.0000 - val_fn: 22816.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-24064000-24320000
[INFO] processing batch 24320000-24576000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6762 - tp: 123440.0000 - fp: 68560.0000 - tn: 699440.0000 - fn: 68560.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9107 - val_loss: 0.6758 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 233169.0000 - val_fn: 22831.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-24320000-24576000
[INFO] processing batch 24576000-24832000/24819975
[33m[LOSS] 0.6757676868438721[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6757676868438721  <  0.001
[33m[INFO] epoch 5/10[0m
[33m[INFO] loading file 1-50/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (24819975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
len(df.columns) 108
numFeatures 107
[INFO] columns: Index(['unixtime', 'modbus_function_code', 'modbus_transaction_id', 'service',
       's_port', 'classification', 'orig-192.168.1.48', 'orig-192.168.1.87',
       'orig-192.168.1.88', 'type-alert',
       ...
       'modbus_function_description-Read Tag Service',
       'modbus_function_description-Read Tag Service - Response',
       'modbus_function_description-Unknown Function Code',
       'modbus_function_description-Write Tag Service', 'scada_tag-0',
       'scada_tag-HMI_AIT202', 'scada_tag-HMI_FIT201', 'scada_tag-HMI_LIT101',
       'scada_tag-HMI_LIT301', 'scada_tag-HMI_LIT401'],
      dtype='object', length=108)
[INFO] processing batch 0-256000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.4182 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3700 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-0-256000
[INFO] processing batch 256000-512000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7328 - tp: 112918.0000 - fp: 79082.0000 - tn: 688918.0000 - fn: 79082.0000 - accuracy: 0.8352 - precision: 0.5881 - recall: 0.5881 - auc: 0.8966 - val_loss: 0.7774 - val_tp: 33927.0000 - val_fp: 30073.0000 - val_tn: 225927.0000 - val_fn: 30073.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-256000-512000
[INFO] processing batch 512000-768000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6163 - tp: 138284.0000 - fp: 53716.0000 - tn: 714284.0000 - fn: 53716.0000 - accuracy: 0.8881 - precision: 0.7202 - recall: 0.7202 - auc: 0.9305 - val_loss: 0.4049 - val_tp: 62058.0000 - val_fp: 1942.0000 - val_tn: 254058.0000 - val_fn: 1942.0000 - val_accuracy: 0.9879 - val_precision: 0.9697 - val_recall: 0.9697 - val_auc: 0.9924
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-512000-768000
[INFO] processing batch 768000-1024000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7068 - tp: 117250.0000 - fp: 74750.0000 - tn: 693250.0000 - fn: 74750.0000 - accuracy: 0.8443 - precision: 0.6107 - recall: 0.6107 - auc: 0.9027 - val_loss: 0.5000 - val_tp: 55591.0000 - val_fp: 8409.0000 - val_tn: 247591.0000 - val_fn: 8409.0000 - val_accuracy: 0.9474 - val_precision: 0.8686 - val_recall: 0.8686 - val_auc: 0.9672
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-768000-1024000
[INFO] processing batch 1024000-1280000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6351 - tp: 133967.0000 - fp: 58033.0000 - tn: 709967.0000 - fn: 58033.0000 - accuracy: 0.8791 - precision: 0.6977 - recall: 0.6977 - auc: 0.9243 - val_loss: 0.3968 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-1024000-1280000
[INFO] processing batch 1280000-1536000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.3683 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3340 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-1280000-1536000
[INFO] processing batch 1536000-1792000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.3071 - tp: 191999.0000 - fp: 1.0000 - tn: 767999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2823 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-1536000-1792000
[INFO] processing batch 1792000-2048000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.5560 - tp: 148221.0000 - fp: 43779.0000 - tn: 724221.0000 - fn: 43779.0000 - accuracy: 0.9088 - precision: 0.7720 - recall: 0.7720 - auc: 0.9433 - val_loss: 0.3907 - val_tp: 57941.0000 - val_fp: 6059.0000 - val_tn: 249941.0000 - val_fn: 6059.0000 - val_accuracy: 0.9621 - val_precision: 0.9053 - val_recall: 0.9053 - val_auc: 0.9763
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-1792000-2048000
[INFO] processing batch 2048000-2304000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.5975 - tp: 141714.0000 - fp: 50286.0000 - tn: 717714.0000 - fn: 50286.0000 - accuracy: 0.8952 - precision: 0.7381 - recall: 0.7381 - auc: 0.9347 - val_loss: 0.2776 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-2048000-2304000
[INFO] processing batch 2304000-2560000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2651 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2480 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-2304000-2560000
[INFO] processing batch 2560000-2816000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2330 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2185 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-2560000-2816000
[INFO] processing batch 2816000-3072000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.5568 - tp: 148720.0000 - fp: 43280.0000 - tn: 724720.0000 - fn: 43280.0000 - accuracy: 0.9098 - precision: 0.7746 - recall: 0.7746 - auc: 0.9437 - val_loss: 0.7586 - val_tp: 40961.0000 - val_fp: 23039.0000 - val_tn: 232961.0000 - val_fn: 23039.0000 - val_accuracy: 0.8560 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.9100
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-2816000-3072000
[INFO] processing batch 3072000-3328000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6867 - tp: 131495.0000 - fp: 60505.0000 - tn: 707495.0000 - fn: 60505.0000 - accuracy: 0.8739 - precision: 0.6849 - recall: 0.6849 - auc: 0.9209 - val_loss: 0.2327 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-3072000-3328000
[INFO] processing batch 3328000-3584000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2257 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2138 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-3328000-3584000
[INFO] processing batch 3584000-3840000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.2026 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1917 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-3584000-3840000
[INFO] processing batch 3840000-4096000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.4873 - tp: 157534.0000 - fp: 34466.0000 - tn: 733534.0000 - fn: 34466.0000 - accuracy: 0.9282 - precision: 0.8205 - recall: 0.8205 - auc: 0.9551 - val_loss: 0.4948 - val_tp: 52219.0000 - val_fp: 11781.0000 - val_tn: 244219.0000 - val_fn: 11781.0000 - val_accuracy: 0.9264 - val_precision: 0.8159 - val_recall: 0.8159 - val_auc: 0.9540
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-3840000-4096000
[INFO] processing batch 4096000-4352000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1994 - tp: 190188.0000 - fp: 1812.0000 - tn: 766188.0000 - fn: 1812.0000 - accuracy: 0.9962 - precision: 0.9906 - recall: 0.9906 - auc: 0.9975 - val_loss: 0.1754 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-4096000-4352000
[INFO] processing batch 4352000-4608000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1677 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1600 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-4352000-4608000
[INFO] processing batch 4608000-4864000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.4544 - tp: 161451.0000 - fp: 30549.0000 - tn: 737451.0000 - fn: 30549.0000 - accuracy: 0.9364 - precision: 0.8409 - recall: 0.8409 - auc: 0.9602 - val_loss: 0.1587 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-4608000-4864000
[INFO] processing batch 4864000-5120000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1543 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1481 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-4864000-5120000
[INFO] processing batch 5120000-5376000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1423 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1364 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-5120000-5376000
[INFO] processing batch 5376000-5632000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1314 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1263 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-5376000-5632000
[INFO] processing batch 5632000-5888000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.5239 - tp: 155809.0000 - fp: 36191.0000 - tn: 731809.0000 - fn: 36191.0000 - accuracy: 0.9246 - precision: 0.8115 - recall: 0.8115 - auc: 0.9529 - val_loss: 0.1295 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-5632000-5888000
[INFO] processing batch 5888000-6144000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1271 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1229 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-5888000-6144000
[INFO] processing batch 6144000-6400000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.3215 - tp: 174156.0000 - fp: 17844.0000 - tn: 750156.0000 - fn: 17844.0000 - accuracy: 0.9628 - precision: 0.9071 - recall: 0.9071 - auc: 0.9768 - val_loss: 0.8948 - val_tp: 41108.0000 - val_fp: 22892.0000 - val_tn: 233108.0000 - val_fn: 22892.0000 - val_accuracy: 0.8569 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-6144000-6400000
[INFO] processing batch 6400000-6656000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7136 - tp: 138766.0000 - fp: 53234.0000 - tn: 714766.0000 - fn: 53234.0000 - accuracy: 0.8891 - precision: 0.7227 - recall: 0.7227 - auc: 0.9319 - val_loss: 0.1309 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-6400000-6656000
[INFO] processing batch 6656000-6912000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1296 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1255 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-6656000-6912000
[INFO] processing batch 6912000-7168000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1211 - tp: 191998.0000 - fp: 2.0000 - tn: 767998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1166 - val_tp: 63999.0000 - val_fp: 1.0000 - val_tn: 255999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-6912000-7168000
[INFO] processing batch 7168000-7424000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1127 - tp: 191999.0000 - fp: 1.0000 - tn: 767999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8696 - val_tp: 44344.0000 - val_fp: 19656.0000 - val_tn: 236344.0000 - val_fn: 19656.0000 - val_accuracy: 0.8772 - val_precision: 0.6929 - val_recall: 0.6929 - val_auc: 0.7313
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-7168000-7424000
[INFO] processing batch 7424000-7680000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.7215 - tp: 102062.0000 - fp: 89938.0000 - tn: 678062.0000 - fn: 89938.0000 - accuracy: 0.8126 - precision: 0.5316 - recall: 0.5316 - auc: 0.5902 - val_loss: 1.3066 - val_tp: 49859.0000 - val_fp: 14141.0000 - val_tn: 241859.0000 - val_fn: 14141.0000 - val_accuracy: 0.9116 - val_precision: 0.7790 - val_recall: 0.7790 - val_auc: 0.8067
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-7424000-7680000
[INFO] processing batch 7680000-7936000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1147 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1116 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-7680000-7936000
[INFO] processing batch 7936000-8192000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1082 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1048 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-7936000-8192000
[INFO] processing batch 8192000-8448000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.0535 - tp: 161781.0000 - fp: 30219.0000 - tn: 737781.0000 - fn: 30219.0000 - accuracy: 0.9370 - precision: 0.8426 - recall: 0.8426 - auc: 0.8623 - val_loss: 0.1614 - val_tp: 63369.0000 - val_fp: 631.0000 - val_tn: 255369.0000 - val_fn: 631.0000 - val_accuracy: 0.9961 - val_precision: 0.9901 - val_recall: 0.9901 - val_auc: 0.9914
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-8192000-8448000
[INFO] processing batch 8448000-8704000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.1635 - tp: 123282.0000 - fp: 68718.0000 - tn: 699282.0000 - fn: 68718.0000 - accuracy: 0.8568 - precision: 0.6421 - recall: 0.6421 - auc: 0.6868 - val_loss: 2.2328 - val_tp: 39692.0000 - val_fp: 24308.0000 - val_tn: 231692.0000 - val_fn: 24308.0000 - val_accuracy: 0.8481 - val_precision: 0.6202 - val_recall: 0.6202 - val_auc: 0.6677
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-8448000-8704000
[INFO] processing batch 8704000-8960000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2217 - tp: 188028.0000 - fp: 3972.0000 - tn: 764028.0000 - fn: 3972.0000 - accuracy: 0.9917 - precision: 0.9793 - recall: 0.9793 - auc: 0.9818 - val_loss: 0.1043 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-8704000-8960000
[INFO] processing batch 8960000-9216000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1014 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0985 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-8960000-9216000
[INFO] processing batch 9216000-9472000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.0648 - tp: 120440.0000 - fp: 71560.0000 - tn: 696440.0000 - fn: 71560.0000 - accuracy: 0.8509 - precision: 0.6273 - recall: 0.6273 - auc: 0.6865 - val_loss: 0.1024 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-9216000-9472000
[INFO] processing batch 9472000-9728000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.9112 - tp: 161553.0000 - fp: 30447.0000 - tn: 737553.0000 - fn: 30447.0000 - accuracy: 0.9366 - precision: 0.8414 - recall: 0.8414 - auc: 0.9009 - val_loss: 0.9339 - val_tp: 53468.0000 - val_fp: 10532.0000 - val_tn: 245468.0000 - val_fn: 10532.0000 - val_accuracy: 0.9342 - val_precision: 0.8354 - val_recall: 0.8354 - val_auc: 0.8971
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-9472000-9728000
[INFO] processing batch 9728000-9984000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1009 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0982 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-9728000-9984000
[INFO] processing batch 9984000-10240000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.0956 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0930 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-9984000-10240000
[INFO] processing batch 10240000-10496000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1562 - tp: 189510.0000 - fp: 2490.0000 - tn: 765510.0000 - fn: 2490.0000 - accuracy: 0.9948 - precision: 0.9870 - recall: 0.9870 - auc: 0.9920 - val_loss: 2.4588 - val_tp: 33975.0000 - val_fp: 30025.0000 - val_tn: 225975.0000 - val_fn: 30025.0000 - val_accuracy: 0.8123 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.7068
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-10240000-10496000
[INFO] processing batch 10496000-10752000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.3946 - tp: 101670.0000 - fp: 90330.0000 - tn: 677670.0000 - fn: 90330.0000 - accuracy: 0.8118 - precision: 0.5295 - recall: 0.5295 - auc: 0.7059 - val_loss: 2.3060 - val_tp: 34015.0000 - val_fp: 29985.0000 - val_tn: 226015.0000 - val_fn: 29985.0000 - val_accuracy: 0.8126 - val_precision: 0.5315 - val_recall: 0.5315 - val_auc: 0.7072
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-10496000-10752000
[INFO] processing batch 10752000-11008000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 2.2518 - tp: 101693.0000 - fp: 90307.0000 - tn: 677693.0000 - fn: 90307.0000 - accuracy: 0.8119 - precision: 0.5297 - recall: 0.5297 - auc: 0.7197 - val_loss: 0.5907 - val_tp: 56989.0000 - val_fp: 7011.0000 - val_tn: 248989.0000 - val_fn: 7011.0000 - val_accuracy: 0.9562 - val_precision: 0.8905 - val_recall: 0.8905 - val_auc: 0.9452
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-10752000-11008000
[INFO] processing batch 11008000-11264000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1043 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1021 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-11008000-11264000
[INFO] processing batch 11264000-11520000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.0996 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0971 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-11264000-11520000
[INFO] processing batch 11520000-11776000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.0948 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0925 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-11520000-11776000
[INFO] processing batch 11776000-12032000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9159 - tp: 156412.0000 - fp: 35588.0000 - tn: 732412.0000 - fn: 35588.0000 - accuracy: 0.9259 - precision: 0.8146 - recall: 0.8146 - auc: 0.9073 - val_loss: 1.6656 - val_tp: 41134.0000 - val_fp: 22866.0000 - val_tn: 233134.0000 - val_fn: 22866.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.8214
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-11776000-12032000
[INFO] processing batch 12032000-12288000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.6373 - tp: 123527.0000 - fp: 68473.0000 - tn: 699527.0000 - fn: 68473.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.8217 - val_loss: 1.6049 - val_tp: 41219.0000 - val_fp: 22781.0000 - val_tn: 233219.0000 - val_fn: 22781.0000 - val_accuracy: 0.8576 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.8220
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-12032000-12288000
[INFO] processing batch 12288000-12544000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.5794 - tp: 123560.0000 - fp: 68440.0000 - tn: 699560.0000 - fn: 68440.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.8217 - val_loss: 1.1001 - val_tp: 41268.0000 - val_fp: 22732.0000 - val_tn: 233268.0000 - val_fn: 22732.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.8958
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-12288000-12544000
[INFO] processing batch 12544000-12800000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9905 - tp: 123588.0000 - fp: 68412.0000 - tn: 699588.0000 - fn: 68412.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.9637 - val_tp: 41269.0000 - val_fp: 22731.0000 - val_tn: 233269.0000 - val_fn: 22731.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-12544000-12800000
[INFO] processing batch 12800000-13056000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9452 - tp: 123531.0000 - fp: 68469.0000 - tn: 699531.0000 - fn: 68469.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.9234 - val_tp: 41181.0000 - val_fp: 22819.0000 - val_tn: 233181.0000 - val_fn: 22819.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-12800000-13056000
[INFO] processing batch 13056000-13312000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.9041 - tp: 123615.0000 - fp: 68385.0000 - tn: 699615.0000 - fn: 68385.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.8862 - val_tp: 41192.0000 - val_fp: 22808.0000 - val_tn: 233192.0000 - val_fn: 22808.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-13056000-13312000
[INFO] processing batch 13312000-13568000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8719 - tp: 123437.0000 - fp: 68563.0000 - tn: 699437.0000 - fn: 68563.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9107 - val_loss: 0.8551 - val_tp: 41179.0000 - val_fp: 22821.0000 - val_tn: 233179.0000 - val_fn: 22821.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-13312000-13568000
[INFO] processing batch 13568000-13824000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8416 - tp: 123539.0000 - fp: 68461.0000 - tn: 699539.0000 - fn: 68461.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.8273 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-13568000-13824000
[INFO] processing batch 13824000-14080000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.8165 - tp: 123556.0000 - fp: 68444.0000 - tn: 699556.0000 - fn: 68444.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.8054 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 233173.0000 - val_fn: 22827.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-13824000-14080000
[INFO] processing batch 14080000-14336000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7941 - tp: 123681.0000 - fp: 68319.0000 - tn: 699681.0000 - fn: 68319.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.7846 - val_tp: 41221.0000 - val_fp: 22779.0000 - val_tn: 233221.0000 - val_fn: 22779.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-14080000-14336000
[INFO] processing batch 14336000-14592000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7773 - tp: 123523.0000 - fp: 68477.0000 - tn: 699523.0000 - fn: 68477.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9110 - val_loss: 0.7684 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 233197.0000 - val_fn: 22803.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-14336000-14592000
[INFO] processing batch 14592000-14848000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7608 - tp: 123652.0000 - fp: 68348.0000 - tn: 699652.0000 - fn: 68348.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9109 - val_loss: 0.7539 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-14592000-14848000
[INFO] processing batch 14848000-15104000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7481 - tp: 123594.0000 - fp: 68406.0000 - tn: 699594.0000 - fn: 68406.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.7420 - val_tp: 41205.0000 - val_fp: 22795.0000 - val_tn: 233205.0000 - val_fn: 22795.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-14848000-15104000
[INFO] processing batch 15104000-15360000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7369 - tp: 123629.0000 - fp: 68371.0000 - tn: 699629.0000 - fn: 68371.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.7314 - val_tp: 41234.0000 - val_fp: 22766.0000 - val_tn: 233234.0000 - val_fn: 22766.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-15104000-15360000
[INFO] processing batch 15360000-15616000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7276 - tp: 123632.0000 - fp: 68368.0000 - tn: 699632.0000 - fn: 68368.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.7224 - val_tp: 41266.0000 - val_fp: 22734.0000 - val_tn: 233266.0000 - val_fn: 22734.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-15360000-15616000
[INFO] processing batch 15616000-15872000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7204 - tp: 123527.0000 - fp: 68473.0000 - tn: 699527.0000 - fn: 68473.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.7165 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 233197.0000 - val_fn: 22803.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-15616000-15872000
[INFO] processing batch 15872000-16128000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7139 - tp: 123531.0000 - fp: 68469.0000 - tn: 699531.0000 - fn: 68469.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.7111 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 233173.0000 - val_fn: 22827.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-15872000-16128000
[INFO] processing batch 16128000-16384000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7072 - tp: 123781.0000 - fp: 68219.0000 - tn: 699781.0000 - fn: 68219.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9113 - val_loss: 0.7059 - val_tp: 41195.0000 - val_fp: 22805.0000 - val_tn: 233195.0000 - val_fn: 22805.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-16128000-16384000
[INFO] processing batch 16384000-16640000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7037 - tp: 123621.0000 - fp: 68379.0000 - tn: 699621.0000 - fn: 68379.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.7023 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 233165.0000 - val_fn: 22835.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-16384000-16640000
[INFO] processing batch 16640000-16896000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7010 - tp: 123417.0000 - fp: 68583.0000 - tn: 699417.0000 - fn: 68583.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9107 - val_loss: 0.6980 - val_tp: 41230.0000 - val_fp: 22770.0000 - val_tn: 233230.0000 - val_fn: 22770.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-16640000-16896000
[INFO] processing batch 16896000-17152000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6971 - tp: 123600.0000 - fp: 68400.0000 - tn: 699600.0000 - fn: 68400.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6958 - val_tp: 41198.0000 - val_fp: 22802.0000 - val_tn: 233198.0000 - val_fn: 22802.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-16896000-17152000
[INFO] processing batch 17152000-17408000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6941 - tp: 123711.0000 - fp: 68289.0000 - tn: 699711.0000 - fn: 68289.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9111 - val_loss: 0.6939 - val_tp: 41168.0000 - val_fp: 22832.0000 - val_tn: 233168.0000 - val_fn: 22832.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-17152000-17408000
[INFO] processing batch 17408000-17664000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6922 - tp: 123701.0000 - fp: 68299.0000 - tn: 699701.0000 - fn: 68299.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9111 - val_loss: 0.6927 - val_tp: 41118.0000 - val_fp: 22882.0000 - val_tn: 233118.0000 - val_fn: 22882.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-17408000-17664000
[INFO] processing batch 17664000-17920000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6911 - tp: 123546.0000 - fp: 68454.0000 - tn: 699546.0000 - fn: 68454.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6915 - val_tp: 41089.0000 - val_fp: 22911.0000 - val_tn: 233089.0000 - val_fn: 22911.0000 - val_accuracy: 0.8568 - val_precision: 0.6420 - val_recall: 0.6420 - val_auc: 0.9105
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-17664000-17920000
[INFO] processing batch 17920000-18176000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6892 - tp: 123681.0000 - fp: 68319.0000 - tn: 699681.0000 - fn: 68319.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6884 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 233233.0000 - val_fn: 22767.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-17920000-18176000
[INFO] processing batch 18176000-18432000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6881 - tp: 123640.0000 - fp: 68360.0000 - tn: 699640.0000 - fn: 68360.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6866 - val_tp: 41298.0000 - val_fp: 22702.0000 - val_tn: 233298.0000 - val_fn: 22702.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-18176000-18432000
[INFO] processing batch 18432000-18688000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6872 - tp: 123615.0000 - fp: 68385.0000 - tn: 699615.0000 - fn: 68385.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6864 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 233233.0000 - val_fn: 22767.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-18432000-18688000
[INFO] processing batch 18688000-18944000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6862 - tp: 123645.0000 - fp: 68355.0000 - tn: 699645.0000 - fn: 68355.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6861 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 233184.0000 - val_fn: 22816.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-18688000-18944000
[INFO] processing batch 18944000-19200000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6845 - tp: 123888.0000 - fp: 68112.0000 - tn: 699888.0000 - fn: 68112.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9113 - val_loss: 0.6855 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 233169.0000 - val_fn: 22831.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-18944000-19200000
[INFO] processing batch 19200000-19456000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6852 - tp: 123500.0000 - fp: 68500.0000 - tn: 699500.0000 - fn: 68500.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6846 - val_tp: 41189.0000 - val_fp: 22811.0000 - val_tn: 233189.0000 - val_fn: 22811.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-19200000-19456000
[INFO] processing batch 19456000-19712000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6839 - tp: 123689.0000 - fp: 68311.0000 - tn: 699689.0000 - fn: 68311.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6842 - val_tp: 41166.0000 - val_fp: 22834.0000 - val_tn: 233166.0000 - val_fn: 22834.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-19456000-19712000
[INFO] processing batch 19712000-19968000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6843 - tp: 123402.0000 - fp: 68598.0000 - tn: 699402.0000 - fn: 68598.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9107 - val_loss: 0.6829 - val_tp: 41242.0000 - val_fp: 22758.0000 - val_tn: 233242.0000 - val_fn: 22758.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-19712000-19968000
[INFO] processing batch 19968000-20224000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6832 - tp: 123541.0000 - fp: 68459.0000 - tn: 699541.0000 - fn: 68459.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.6823 - val_tp: 41241.0000 - val_fp: 22759.0000 - val_tn: 233241.0000 - val_fn: 22759.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-19968000-20224000
[INFO] processing batch 20224000-20480000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6824 - tp: 123640.0000 - fp: 68360.0000 - tn: 699640.0000 - fn: 68360.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6821 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 233209.0000 - val_fn: 22791.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-20224000-20480000
[INFO] processing batch 20480000-20736000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6820 - tp: 123598.0000 - fp: 68402.0000 - tn: 699598.0000 - fn: 68402.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6814 - val_tp: 41235.0000 - val_fp: 22765.0000 - val_tn: 233235.0000 - val_fn: 22765.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-20480000-20736000
[INFO] processing batch 20736000-20992000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6809 - tp: 123769.0000 - fp: 68231.0000 - tn: 699769.0000 - fn: 68231.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.6811 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-20736000-20992000
[INFO] processing batch 20992000-21248000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6814 - tp: 123459.0000 - fp: 68541.0000 - tn: 699459.0000 - fn: 68541.0000 - accuracy: 0.8572 - precision: 0.6430 - recall: 0.6430 - auc: 0.9107 - val_loss: 0.6806 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 233209.0000 - val_fn: 22791.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-20992000-21248000
[INFO] processing batch 21248000-21504000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6802 - tp: 123683.0000 - fp: 68317.0000 - tn: 699683.0000 - fn: 68317.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6804 - val_tp: 41183.0000 - val_fp: 22817.0000 - val_tn: 233183.0000 - val_fn: 22817.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-21248000-21504000
[INFO] processing batch 21504000-21760000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6801 - tp: 123564.0000 - fp: 68436.0000 - tn: 699564.0000 - fn: 68436.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6793 - val_tp: 41254.0000 - val_fp: 22746.0000 - val_tn: 233254.0000 - val_fn: 22746.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-21504000-21760000
[INFO] processing batch 21760000-22016000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6792 - tp: 123717.0000 - fp: 68283.0000 - tn: 699717.0000 - fn: 68283.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9111 - val_loss: 0.6786 - val_tp: 41270.0000 - val_fp: 22730.0000 - val_tn: 233270.0000 - val_fn: 22730.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-21760000-22016000
[INFO] processing batch 22016000-22272000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6788 - tp: 123690.0000 - fp: 68310.0000 - tn: 699690.0000 - fn: 68310.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6798 - val_tp: 41104.0000 - val_fp: 22896.0000 - val_tn: 233104.0000 - val_fn: 22896.0000 - val_accuracy: 0.8569 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-22016000-22272000
[INFO] processing batch 22272000-22528000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6784 - tp: 123672.0000 - fp: 68328.0000 - tn: 699672.0000 - fn: 68328.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6780 - val_tp: 41243.0000 - val_fp: 22757.0000 - val_tn: 233243.0000 - val_fn: 22757.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-22272000-22528000
[INFO] processing batch 22528000-22784000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6781 - tp: 123623.0000 - fp: 68377.0000 - tn: 699623.0000 - fn: 68377.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6771 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 233292.0000 - val_fn: 22708.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-22528000-22784000
[INFO] processing batch 22784000-23040000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6772 - tp: 123759.0000 - fp: 68241.0000 - tn: 699759.0000 - fn: 68241.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9111 - val_loss: 0.6777 - val_tp: 41180.0000 - val_fp: 22820.0000 - val_tn: 233180.0000 - val_fn: 22820.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-22784000-23040000
[INFO] processing batch 23040000-23296000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6776 - tp: 123507.0000 - fp: 68493.0000 - tn: 699507.0000 - fn: 68493.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6766 - val_tp: 41255.0000 - val_fp: 22745.0000 - val_tn: 233255.0000 - val_fn: 22745.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-23040000-23296000
[INFO] processing batch 23296000-23552000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6769 - tp: 123601.0000 - fp: 68399.0000 - tn: 699601.0000 - fn: 68399.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6765 - val_tp: 41213.0000 - val_fp: 22787.0000 - val_tn: 233213.0000 - val_fn: 22787.0000 - val_accuracy: 0.8576 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-23296000-23552000
[INFO] processing batch 23552000-23808000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6760 - tp: 123749.0000 - fp: 68251.0000 - tn: 699749.0000 - fn: 68251.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9111 - val_loss: 0.6754 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 233292.0000 - val_fn: 22708.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-23552000-23808000
[INFO] processing batch 23808000-24064000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6760 - tp: 123603.0000 - fp: 68397.0000 - tn: 699603.0000 - fn: 68397.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6761 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 233165.0000 - val_fn: 22835.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-23808000-24064000
[INFO] processing batch 24064000-24320000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6756 - tp: 123599.0000 - fp: 68401.0000 - tn: 699599.0000 - fn: 68401.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6755 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 233184.0000 - val_fn: 22816.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-24064000-24320000
[INFO] processing batch 24320000-24576000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6757 - tp: 123440.0000 - fp: 68560.0000 - tn: 699440.0000 - fn: 68560.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9107 - val_loss: 0.6753 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 233169.0000 - val_fn: 22831.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-24320000-24576000
[INFO] processing batch 24576000-24832000/24819975
[33m[LOSS] 0.6752714872360229[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6752714872360229  <  0.001
[33m[INFO] epoch 6/10[0m
[33m[INFO] loading file 1-50/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (24819975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
len(df.columns) 108
numFeatures 107
[INFO] columns: Index(['unixtime', 'modbus_function_code', 'modbus_transaction_id', 'service',
       's_port', 'classification', 'orig-192.168.1.48', 'orig-192.168.1.87',
       'orig-192.168.1.88', 'type-alert',
       ...
       'modbus_function_description-Read Tag Service',
       'modbus_function_description-Read Tag Service - Response',
       'modbus_function_description-Unknown Function Code',
       'modbus_function_description-Write Tag Service', 'scada_tag-0',
       'scada_tag-HMI_AIT202', 'scada_tag-HMI_FIT201', 'scada_tag-HMI_LIT101',
       'scada_tag-HMI_LIT301', 'scada_tag-HMI_LIT401'],
      dtype='object', length=108)
[INFO] processing batch 0-256000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.4179 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3696 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-0-256000
[INFO] processing batch 256000-512000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7324 - tp: 112918.0000 - fp: 79082.0000 - tn: 688918.0000 - fn: 79082.0000 - accuracy: 0.8352 - precision: 0.5881 - recall: 0.5881 - auc: 0.8970 - val_loss: 0.7770 - val_tp: 33927.0000 - val_fp: 30073.0000 - val_tn: 225927.0000 - val_fn: 30073.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-256000-512000
[INFO] processing batch 512000-768000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6160 - tp: 138284.0000 - fp: 53716.0000 - tn: 714284.0000 - fn: 53716.0000 - accuracy: 0.8881 - precision: 0.7202 - recall: 0.7202 - auc: 0.9297 - val_loss: 0.4045 - val_tp: 62058.0000 - val_fp: 1942.0000 - val_tn: 254058.0000 - val_fn: 1942.0000 - val_accuracy: 0.9879 - val_precision: 0.9697 - val_recall: 0.9697 - val_auc: 0.9924
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-512000-768000
[INFO] processing batch 768000-1024000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7064 - tp: 117250.0000 - fp: 74750.0000 - tn: 693250.0000 - fn: 74750.0000 - accuracy: 0.8443 - precision: 0.6107 - recall: 0.6107 - auc: 0.9031 - val_loss: 0.4995 - val_tp: 55591.0000 - val_fp: 8409.0000 - val_tn: 247591.0000 - val_fn: 8409.0000 - val_accuracy: 0.9474 - val_precision: 0.8686 - val_recall: 0.8686 - val_auc: 0.9672
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-768000-1024000
[INFO] processing batch 1024000-1280000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6347 - tp: 133967.0000 - fp: 58033.0000 - tn: 709967.0000 - fn: 58033.0000 - accuracy: 0.8791 - precision: 0.6977 - recall: 0.6977 - auc: 0.9243 - val_loss: 0.3966 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-1024000-1280000
[INFO] processing batch 1280000-1536000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.3680 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3336 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-1280000-1536000
[INFO] processing batch 1536000-1792000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.3068 - tp: 191999.0000 - fp: 1.0000 - tn: 767999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2819 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-1536000-1792000
[INFO] processing batch 1792000-2048000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.5556 - tp: 148221.0000 - fp: 43779.0000 - tn: 724221.0000 - fn: 43779.0000 - accuracy: 0.9088 - precision: 0.7720 - recall: 0.7720 - auc: 0.9430 - val_loss: 0.3902 - val_tp: 57941.0000 - val_fp: 6059.0000 - val_tn: 249941.0000 - val_fn: 6059.0000 - val_accuracy: 0.9621 - val_precision: 0.9053 - val_recall: 0.9053 - val_auc: 0.9763
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-1792000-2048000
[INFO] processing batch 2048000-2304000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.5971 - tp: 141714.0000 - fp: 50286.0000 - tn: 717714.0000 - fn: 50286.0000 - accuracy: 0.8952 - precision: 0.7381 - recall: 0.7381 - auc: 0.9343 - val_loss: 0.2776 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-2048000-2304000
[INFO] processing batch 2304000-2560000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2649 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2477 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-2304000-2560000
[INFO] processing batch 2560000-2816000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2327 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2183 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-2560000-2816000
[INFO] processing batch 2816000-3072000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.5565 - tp: 148720.0000 - fp: 43280.0000 - tn: 724720.0000 - fn: 43280.0000 - accuracy: 0.9098 - precision: 0.7746 - recall: 0.7746 - auc: 0.9437 - val_loss: 0.7580 - val_tp: 40961.0000 - val_fp: 23039.0000 - val_tn: 232961.0000 - val_fn: 23039.0000 - val_accuracy: 0.8560 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.9100
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-2816000-3072000
[INFO] processing batch 3072000-3328000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6863 - tp: 131495.0000 - fp: 60505.0000 - tn: 707495.0000 - fn: 60505.0000 - accuracy: 0.8739 - precision: 0.6849 - recall: 0.6849 - auc: 0.9209 - val_loss: 0.2323 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-3072000-3328000
[INFO] processing batch 3328000-3584000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.2255 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2136 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-3328000-3584000
[INFO] processing batch 3584000-3840000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2024 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1915 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-3584000-3840000
[INFO] processing batch 3840000-4096000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.4870 - tp: 157534.0000 - fp: 34466.0000 - tn: 733534.0000 - fn: 34466.0000 - accuracy: 0.9282 - precision: 0.8205 - recall: 0.8205 - auc: 0.9551 - val_loss: 0.4945 - val_tp: 52219.0000 - val_fp: 11781.0000 - val_tn: 244219.0000 - val_fn: 11781.0000 - val_accuracy: 0.9264 - val_precision: 0.8159 - val_recall: 0.8159 - val_auc: 0.9540
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-3840000-4096000
[INFO] processing batch 4096000-4352000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1992 - tp: 190188.0000 - fp: 1812.0000 - tn: 766188.0000 - fn: 1812.0000 - accuracy: 0.9962 - precision: 0.9906 - recall: 0.9906 - auc: 0.9978 - val_loss: 0.1753 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-4096000-4352000
[INFO] processing batch 4352000-4608000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1676 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1598 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-4352000-4608000
[INFO] processing batch 4608000-4864000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.4541 - tp: 161451.0000 - fp: 30549.0000 - tn: 737451.0000 - fn: 30549.0000 - accuracy: 0.9364 - precision: 0.8409 - recall: 0.8409 - auc: 0.9602 - val_loss: 0.1586 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-4608000-4864000
[INFO] processing batch 4864000-5120000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1542 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1480 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-4864000-5120000
[INFO] processing batch 5120000-5376000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1421 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1363 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-5120000-5376000
[INFO] processing batch 5376000-5632000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1312 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1262 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-5376000-5632000
[INFO] processing batch 5632000-5888000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.5236 - tp: 155809.0000 - fp: 36191.0000 - tn: 731809.0000 - fn: 36191.0000 - accuracy: 0.9246 - precision: 0.8115 - recall: 0.8115 - auc: 0.9529 - val_loss: 0.1293 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-5632000-5888000
[INFO] processing batch 5888000-6144000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1270 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1228 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-5888000-6144000
[INFO] processing batch 6144000-6400000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.3213 - tp: 174156.0000 - fp: 17844.0000 - tn: 750156.0000 - fn: 17844.0000 - accuracy: 0.9628 - precision: 0.9071 - recall: 0.9071 - auc: 0.9768 - val_loss: 0.8943 - val_tp: 41108.0000 - val_fp: 22892.0000 - val_tn: 233108.0000 - val_fn: 22892.0000 - val_accuracy: 0.8569 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-6144000-6400000
[INFO] processing batch 6400000-6656000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7133 - tp: 138766.0000 - fp: 53234.0000 - tn: 714766.0000 - fn: 53234.0000 - accuracy: 0.8891 - precision: 0.7227 - recall: 0.7227 - auc: 0.9297 - val_loss: 0.1310 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-6400000-6656000
[INFO] processing batch 6656000-6912000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1295 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1253 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-6656000-6912000
[INFO] processing batch 6912000-7168000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1209 - tp: 191998.0000 - fp: 2.0000 - tn: 767998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1165 - val_tp: 63999.0000 - val_fp: 1.0000 - val_tn: 255999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-6912000-7168000
[INFO] processing batch 7168000-7424000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1125 - tp: 191999.0000 - fp: 1.0000 - tn: 767999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8783 - val_tp: 44344.0000 - val_fp: 19656.0000 - val_tn: 236344.0000 - val_fn: 19656.0000 - val_accuracy: 0.8772 - val_precision: 0.6929 - val_recall: 0.6929 - val_auc: 0.7313
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-7168000-7424000
[INFO] processing batch 7424000-7680000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.7348 - tp: 102062.0000 - fp: 89938.0000 - tn: 678062.0000 - fn: 89938.0000 - accuracy: 0.8126 - precision: 0.5316 - recall: 0.5316 - auc: 0.5901 - val_loss: 1.3127 - val_tp: 49859.0000 - val_fp: 14141.0000 - val_tn: 241859.0000 - val_fn: 14141.0000 - val_accuracy: 0.9116 - val_precision: 0.7790 - val_recall: 0.7790 - val_auc: 0.8067
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-7424000-7680000
[INFO] processing batch 7680000-7936000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1145 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1114 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-7680000-7936000
[INFO] processing batch 7936000-8192000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1081 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1046 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-7936000-8192000
[INFO] processing batch 8192000-8448000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.0596 - tp: 161781.0000 - fp: 30219.0000 - tn: 737781.0000 - fn: 30219.0000 - accuracy: 0.9370 - precision: 0.8426 - recall: 0.8426 - auc: 0.8623 - val_loss: 0.1616 - val_tp: 63369.0000 - val_fp: 631.0000 - val_tn: 255369.0000 - val_fn: 631.0000 - val_accuracy: 0.9961 - val_precision: 0.9901 - val_recall: 0.9901 - val_auc: 0.9914
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-8192000-8448000
[INFO] processing batch 8448000-8704000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.1774 - tp: 123282.0000 - fp: 68718.0000 - tn: 699282.0000 - fn: 68718.0000 - accuracy: 0.8568 - precision: 0.6421 - recall: 0.6421 - auc: 0.6869 - val_loss: 2.2474 - val_tp: 39692.0000 - val_fp: 24308.0000 - val_tn: 231692.0000 - val_fn: 24308.0000 - val_accuracy: 0.8481 - val_precision: 0.6202 - val_recall: 0.6202 - val_auc: 0.6677
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-8448000-8704000
[INFO] processing batch 8704000-8960000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2223 - tp: 188028.0000 - fp: 3972.0000 - tn: 764028.0000 - fn: 3972.0000 - accuracy: 0.9917 - precision: 0.9793 - recall: 0.9793 - auc: 0.9819 - val_loss: 0.1041 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-8704000-8960000
[INFO] processing batch 8960000-9216000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1012 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0983 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-8960000-9216000
[INFO] processing batch 9216000-9472000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 2.0751 - tp: 120440.0000 - fp: 71560.0000 - tn: 696440.0000 - fn: 71560.0000 - accuracy: 0.8509 - precision: 0.6273 - recall: 0.6273 - auc: 0.6754 - val_loss: 0.1023 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-9216000-9472000
[INFO] processing batch 9472000-9728000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9153 - tp: 161553.0000 - fp: 30447.0000 - tn: 737553.0000 - fn: 30447.0000 - accuracy: 0.9366 - precision: 0.8414 - recall: 0.8414 - auc: 0.9009 - val_loss: 0.9382 - val_tp: 53468.0000 - val_fp: 10532.0000 - val_tn: 245468.0000 - val_fn: 10532.0000 - val_accuracy: 0.9342 - val_precision: 0.8354 - val_recall: 0.8354 - val_auc: 0.8971
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-9472000-9728000
[INFO] processing batch 9728000-9984000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1007 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0980 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-9728000-9984000
[INFO] processing batch 9984000-10240000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.0954 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0927 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-9984000-10240000
[INFO] processing batch 10240000-10496000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1559 - tp: 189510.0000 - fp: 2490.0000 - tn: 765510.0000 - fn: 2490.0000 - accuracy: 0.9948 - precision: 0.9870 - recall: 0.9870 - auc: 0.9918 - val_loss: 2.4590 - val_tp: 33975.0000 - val_fp: 30025.0000 - val_tn: 225975.0000 - val_fn: 30025.0000 - val_accuracy: 0.8123 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.7068
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-10240000-10496000
[INFO] processing batch 10496000-10752000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.3945 - tp: 101670.0000 - fp: 90330.0000 - tn: 677670.0000 - fn: 90330.0000 - accuracy: 0.8118 - precision: 0.5295 - recall: 0.5295 - auc: 0.7060 - val_loss: 2.3057 - val_tp: 34015.0000 - val_fp: 29985.0000 - val_tn: 226015.0000 - val_fn: 29985.0000 - val_accuracy: 0.8126 - val_precision: 0.5315 - val_recall: 0.5315 - val_auc: 0.7072
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-10496000-10752000
[INFO] processing batch 10752000-11008000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.2515 - tp: 101693.0000 - fp: 90307.0000 - tn: 677693.0000 - fn: 90307.0000 - accuracy: 0.8119 - precision: 0.5297 - recall: 0.5297 - auc: 0.7197 - val_loss: 0.5905 - val_tp: 56989.0000 - val_fp: 7011.0000 - val_tn: 248989.0000 - val_fn: 7011.0000 - val_accuracy: 0.9562 - val_precision: 0.8905 - val_recall: 0.8905 - val_auc: 0.9452
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-10752000-11008000
[INFO] processing batch 11008000-11264000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1040 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1018 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-11008000-11264000
[INFO] processing batch 11264000-11520000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.0994 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0968 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-11264000-11520000
[INFO] processing batch 11520000-11776000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.0946 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0922 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-11520000-11776000
[INFO] processing batch 11776000-12032000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9155 - tp: 156412.0000 - fp: 35588.0000 - tn: 732412.0000 - fn: 35588.0000 - accuracy: 0.9259 - precision: 0.8146 - recall: 0.8146 - auc: 0.9073 - val_loss: 1.6655 - val_tp: 41134.0000 - val_fp: 22866.0000 - val_tn: 233134.0000 - val_fn: 22866.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.8214
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-11776000-12032000
[INFO] processing batch 12032000-12288000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.6370 - tp: 123527.0000 - fp: 68473.0000 - tn: 699527.0000 - fn: 68473.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.8217 - val_loss: 1.6044 - val_tp: 41219.0000 - val_fp: 22781.0000 - val_tn: 233219.0000 - val_fn: 22781.0000 - val_accuracy: 0.8576 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.8220
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-12032000-12288000
[INFO] processing batch 12288000-12544000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.5790 - tp: 123560.0000 - fp: 68440.0000 - tn: 699560.0000 - fn: 68440.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.8217 - val_loss: 1.0995 - val_tp: 41268.0000 - val_fp: 22732.0000 - val_tn: 233268.0000 - val_fn: 22732.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.8958
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-12288000-12544000
[INFO] processing batch 12544000-12800000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9899 - tp: 123588.0000 - fp: 68412.0000 - tn: 699588.0000 - fn: 68412.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.9630 - val_tp: 41269.0000 - val_fp: 22731.0000 - val_tn: 233269.0000 - val_fn: 22731.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-12544000-12800000
[INFO] processing batch 12800000-13056000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9446 - tp: 123531.0000 - fp: 68469.0000 - tn: 699531.0000 - fn: 68469.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.9227 - val_tp: 41181.0000 - val_fp: 22819.0000 - val_tn: 233181.0000 - val_fn: 22819.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-12800000-13056000
[INFO] processing batch 13056000-13312000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9035 - tp: 123615.0000 - fp: 68385.0000 - tn: 699615.0000 - fn: 68385.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.8856 - val_tp: 41192.0000 - val_fp: 22808.0000 - val_tn: 233192.0000 - val_fn: 22808.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-13056000-13312000
[INFO] processing batch 13312000-13568000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8713 - tp: 123437.0000 - fp: 68563.0000 - tn: 699437.0000 - fn: 68563.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9106 - val_loss: 0.8545 - val_tp: 41179.0000 - val_fp: 22821.0000 - val_tn: 233179.0000 - val_fn: 22821.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-13312000-13568000
[INFO] processing batch 13568000-13824000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8410 - tp: 123539.0000 - fp: 68461.0000 - tn: 699539.0000 - fn: 68461.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.8267 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-13568000-13824000
[INFO] processing batch 13824000-14080000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8159 - tp: 123556.0000 - fp: 68444.0000 - tn: 699556.0000 - fn: 68444.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.8048 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 233173.0000 - val_fn: 22827.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-13824000-14080000
[INFO] processing batch 14080000-14336000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7936 - tp: 123681.0000 - fp: 68319.0000 - tn: 699681.0000 - fn: 68319.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9109 - val_loss: 0.7840 - val_tp: 41221.0000 - val_fp: 22779.0000 - val_tn: 233221.0000 - val_fn: 22779.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-14080000-14336000
[INFO] processing batch 14336000-14592000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7767 - tp: 123523.0000 - fp: 68477.0000 - tn: 699523.0000 - fn: 68477.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9109 - val_loss: 0.7679 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 233197.0000 - val_fn: 22803.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-14336000-14592000
[INFO] processing batch 14592000-14848000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7603 - tp: 123652.0000 - fp: 68348.0000 - tn: 699652.0000 - fn: 68348.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9109 - val_loss: 0.7533 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-14592000-14848000
[INFO] processing batch 14848000-15104000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7476 - tp: 123594.0000 - fp: 68406.0000 - tn: 699594.0000 - fn: 68406.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.7415 - val_tp: 41205.0000 - val_fp: 22795.0000 - val_tn: 233205.0000 - val_fn: 22795.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-14848000-15104000
[INFO] processing batch 15104000-15360000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7363 - tp: 123629.0000 - fp: 68371.0000 - tn: 699629.0000 - fn: 68371.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.7309 - val_tp: 41234.0000 - val_fp: 22766.0000 - val_tn: 233234.0000 - val_fn: 22766.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-15104000-15360000
[INFO] processing batch 15360000-15616000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7271 - tp: 123632.0000 - fp: 68368.0000 - tn: 699632.0000 - fn: 68368.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.7219 - val_tp: 41266.0000 - val_fp: 22734.0000 - val_tn: 233266.0000 - val_fn: 22734.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-15360000-15616000
[INFO] processing batch 15616000-15872000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7199 - tp: 123527.0000 - fp: 68473.0000 - tn: 699527.0000 - fn: 68473.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.7161 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 233197.0000 - val_fn: 22803.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-15616000-15872000
[INFO] processing batch 15872000-16128000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7134 - tp: 123531.0000 - fp: 68469.0000 - tn: 699531.0000 - fn: 68469.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9107 - val_loss: 0.7106 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 233173.0000 - val_fn: 22827.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-15872000-16128000
[INFO] processing batch 16128000-16384000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7067 - tp: 123781.0000 - fp: 68219.0000 - tn: 699781.0000 - fn: 68219.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9113 - val_loss: 0.7054 - val_tp: 41195.0000 - val_fp: 22805.0000 - val_tn: 233195.0000 - val_fn: 22805.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-16128000-16384000
[INFO] processing batch 16384000-16640000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7032 - tp: 123621.0000 - fp: 68379.0000 - tn: 699621.0000 - fn: 68379.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.7019 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 233165.0000 - val_fn: 22835.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-16384000-16640000
[INFO] processing batch 16640000-16896000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7006 - tp: 123417.0000 - fp: 68583.0000 - tn: 699417.0000 - fn: 68583.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9107 - val_loss: 0.6976 - val_tp: 41230.0000 - val_fp: 22770.0000 - val_tn: 233230.0000 - val_fn: 22770.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-16640000-16896000
[INFO] processing batch 16896000-17152000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6967 - tp: 123600.0000 - fp: 68400.0000 - tn: 699600.0000 - fn: 68400.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6954 - val_tp: 41198.0000 - val_fp: 22802.0000 - val_tn: 233198.0000 - val_fn: 22802.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-16896000-17152000
[INFO] processing batch 17152000-17408000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6937 - tp: 123711.0000 - fp: 68289.0000 - tn: 699711.0000 - fn: 68289.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9111 - val_loss: 0.6935 - val_tp: 41168.0000 - val_fp: 22832.0000 - val_tn: 233168.0000 - val_fn: 22832.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-17152000-17408000
[INFO] processing batch 17408000-17664000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6918 - tp: 123701.0000 - fp: 68299.0000 - tn: 699701.0000 - fn: 68299.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9110 - val_loss: 0.6923 - val_tp: 41118.0000 - val_fp: 22882.0000 - val_tn: 233118.0000 - val_fn: 22882.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-17408000-17664000
[INFO] processing batch 17664000-17920000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6907 - tp: 123546.0000 - fp: 68454.0000 - tn: 699546.0000 - fn: 68454.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6911 - val_tp: 41089.0000 - val_fp: 22911.0000 - val_tn: 233089.0000 - val_fn: 22911.0000 - val_accuracy: 0.8568 - val_precision: 0.6420 - val_recall: 0.6420 - val_auc: 0.9105
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-17664000-17920000
[INFO] processing batch 17920000-18176000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6888 - tp: 123681.0000 - fp: 68319.0000 - tn: 699681.0000 - fn: 68319.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6881 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 233233.0000 - val_fn: 22767.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-17920000-18176000
[INFO] processing batch 18176000-18432000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6878 - tp: 123640.0000 - fp: 68360.0000 - tn: 699640.0000 - fn: 68360.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6862 - val_tp: 41298.0000 - val_fp: 22702.0000 - val_tn: 233298.0000 - val_fn: 22702.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-18176000-18432000
[INFO] processing batch 18432000-18688000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6868 - tp: 123615.0000 - fp: 68385.0000 - tn: 699615.0000 - fn: 68385.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6860 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 233233.0000 - val_fn: 22767.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-18432000-18688000
[INFO] processing batch 18688000-18944000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6858 - tp: 123645.0000 - fp: 68355.0000 - tn: 699645.0000 - fn: 68355.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6858 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 233184.0000 - val_fn: 22816.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-18688000-18944000
[INFO] processing batch 18944000-19200000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6842 - tp: 123888.0000 - fp: 68112.0000 - tn: 699888.0000 - fn: 68112.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9113 - val_loss: 0.6852 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 233169.0000 - val_fn: 22831.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-18944000-19200000
[INFO] processing batch 19200000-19456000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6849 - tp: 123500.0000 - fp: 68500.0000 - tn: 699500.0000 - fn: 68500.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6843 - val_tp: 41189.0000 - val_fp: 22811.0000 - val_tn: 233189.0000 - val_fn: 22811.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-19200000-19456000
[INFO] processing batch 19456000-19712000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6836 - tp: 123689.0000 - fp: 68311.0000 - tn: 699689.0000 - fn: 68311.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6839 - val_tp: 41166.0000 - val_fp: 22834.0000 - val_tn: 233166.0000 - val_fn: 22834.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-19456000-19712000
[INFO] processing batch 19712000-19968000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6840 - tp: 123402.0000 - fp: 68598.0000 - tn: 699402.0000 - fn: 68598.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9107 - val_loss: 0.6826 - val_tp: 41242.0000 - val_fp: 22758.0000 - val_tn: 233242.0000 - val_fn: 22758.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-19712000-19968000
[INFO] processing batch 19968000-20224000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6829 - tp: 123541.0000 - fp: 68459.0000 - tn: 699541.0000 - fn: 68459.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6820 - val_tp: 41241.0000 - val_fp: 22759.0000 - val_tn: 233241.0000 - val_fn: 22759.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-19968000-20224000
[INFO] processing batch 20224000-20480000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6821 - tp: 123640.0000 - fp: 68360.0000 - tn: 699640.0000 - fn: 68360.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6818 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 233209.0000 - val_fn: 22791.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-20224000-20480000
[INFO] processing batch 20480000-20736000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6817 - tp: 123598.0000 - fp: 68402.0000 - tn: 699598.0000 - fn: 68402.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6811 - val_tp: 41235.0000 - val_fp: 22765.0000 - val_tn: 233235.0000 - val_fn: 22765.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-20480000-20736000
[INFO] processing batch 20736000-20992000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6806 - tp: 123769.0000 - fp: 68231.0000 - tn: 699769.0000 - fn: 68231.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.6808 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-20736000-20992000
[INFO] processing batch 20992000-21248000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6812 - tp: 123459.0000 - fp: 68541.0000 - tn: 699459.0000 - fn: 68541.0000 - accuracy: 0.8572 - precision: 0.6430 - recall: 0.6430 - auc: 0.9107 - val_loss: 0.6804 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 233209.0000 - val_fn: 22791.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-20992000-21248000
[INFO] processing batch 21248000-21504000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6800 - tp: 123683.0000 - fp: 68317.0000 - tn: 699683.0000 - fn: 68317.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6802 - val_tp: 41183.0000 - val_fp: 22817.0000 - val_tn: 233183.0000 - val_fn: 22817.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-21248000-21504000
[INFO] processing batch 21504000-21760000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6799 - tp: 123564.0000 - fp: 68436.0000 - tn: 699564.0000 - fn: 68436.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6790 - val_tp: 41254.0000 - val_fp: 22746.0000 - val_tn: 233254.0000 - val_fn: 22746.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-21504000-21760000
[INFO] processing batch 21760000-22016000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6789 - tp: 123717.0000 - fp: 68283.0000 - tn: 699717.0000 - fn: 68283.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9111 - val_loss: 0.6784 - val_tp: 41270.0000 - val_fp: 22730.0000 - val_tn: 233270.0000 - val_fn: 22730.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-21760000-22016000
[INFO] processing batch 22016000-22272000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6786 - tp: 123690.0000 - fp: 68310.0000 - tn: 699690.0000 - fn: 68310.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6795 - val_tp: 41104.0000 - val_fp: 22896.0000 - val_tn: 233104.0000 - val_fn: 22896.0000 - val_accuracy: 0.8569 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-22016000-22272000
[INFO] processing batch 22272000-22528000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6782 - tp: 123672.0000 - fp: 68328.0000 - tn: 699672.0000 - fn: 68328.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6778 - val_tp: 41243.0000 - val_fp: 22757.0000 - val_tn: 233243.0000 - val_fn: 22757.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-22272000-22528000
[INFO] processing batch 22528000-22784000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6779 - tp: 123623.0000 - fp: 68377.0000 - tn: 699623.0000 - fn: 68377.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6769 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 233292.0000 - val_fn: 22708.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-22528000-22784000
[INFO] processing batch 22784000-23040000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6770 - tp: 123759.0000 - fp: 68241.0000 - tn: 699759.0000 - fn: 68241.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9111 - val_loss: 0.6775 - val_tp: 41180.0000 - val_fp: 22820.0000 - val_tn: 233180.0000 - val_fn: 22820.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-22784000-23040000
[INFO] processing batch 23040000-23296000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6774 - tp: 123507.0000 - fp: 68493.0000 - tn: 699507.0000 - fn: 68493.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6763 - val_tp: 41255.0000 - val_fp: 22745.0000 - val_tn: 233255.0000 - val_fn: 22745.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-23040000-23296000
[INFO] processing batch 23296000-23552000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6767 - tp: 123601.0000 - fp: 68399.0000 - tn: 699601.0000 - fn: 68399.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6763 - val_tp: 41213.0000 - val_fp: 22787.0000 - val_tn: 233213.0000 - val_fn: 22787.0000 - val_accuracy: 0.8576 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-23296000-23552000
[INFO] processing batch 23552000-23808000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6758 - tp: 123749.0000 - fp: 68251.0000 - tn: 699749.0000 - fn: 68251.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9111 - val_loss: 0.6752 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 233292.0000 - val_fn: 22708.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-23552000-23808000
[INFO] processing batch 23808000-24064000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6758 - tp: 123603.0000 - fp: 68397.0000 - tn: 699603.0000 - fn: 68397.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6759 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 233165.0000 - val_fn: 22835.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-23808000-24064000
[INFO] processing batch 24064000-24320000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6754 - tp: 123599.0000 - fp: 68401.0000 - tn: 699599.0000 - fn: 68401.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6754 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 233184.0000 - val_fn: 22816.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-24064000-24320000
[INFO] processing batch 24320000-24576000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6755 - tp: 123440.0000 - fp: 68560.0000 - tn: 699440.0000 - fn: 68560.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9107 - val_loss: 0.6751 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 233169.0000 - val_fn: 22831.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-24320000-24576000
[INFO] processing batch 24576000-24832000/24819975
[33m[LOSS] 0.675088885307312[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.675088885307312  <  0.001
[33m[INFO] epoch 7/10[0m
[33m[INFO] loading file 1-50/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (24819975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
len(df.columns) 108
numFeatures 107
[INFO] columns: Index(['unixtime', 'modbus_function_code', 'modbus_transaction_id', 'service',
       's_port', 'classification', 'orig-192.168.1.48', 'orig-192.168.1.87',
       'orig-192.168.1.88', 'type-alert',
       ...
       'modbus_function_description-Read Tag Service',
       'modbus_function_description-Read Tag Service - Response',
       'modbus_function_description-Unknown Function Code',
       'modbus_function_description-Write Tag Service', 'scada_tag-0',
       'scada_tag-HMI_AIT202', 'scada_tag-HMI_FIT201', 'scada_tag-HMI_LIT101',
       'scada_tag-HMI_LIT301', 'scada_tag-HMI_LIT401'],
      dtype='object', length=108)
[INFO] processing batch 0-256000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.4178 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3695 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-0-256000
[INFO] processing batch 256000-512000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7321 - tp: 112918.0000 - fp: 79082.0000 - tn: 688918.0000 - fn: 79082.0000 - accuracy: 0.8352 - precision: 0.5881 - recall: 0.5881 - auc: 0.8971 - val_loss: 0.7767 - val_tp: 33927.0000 - val_fp: 30073.0000 - val_tn: 225927.0000 - val_fn: 30073.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-256000-512000
[INFO] processing batch 512000-768000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6157 - tp: 138284.0000 - fp: 53716.0000 - tn: 714284.0000 - fn: 53716.0000 - accuracy: 0.8881 - precision: 0.7202 - recall: 0.7202 - auc: 0.9303 - val_loss: 0.4041 - val_tp: 62058.0000 - val_fp: 1942.0000 - val_tn: 254058.0000 - val_fn: 1942.0000 - val_accuracy: 0.9879 - val_precision: 0.9697 - val_recall: 0.9697 - val_auc: 0.9924
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-512000-768000
[INFO] processing batch 768000-1024000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7062 - tp: 117250.0000 - fp: 74750.0000 - tn: 693250.0000 - fn: 74750.0000 - accuracy: 0.8443 - precision: 0.6107 - recall: 0.6107 - auc: 0.9027 - val_loss: 0.4996 - val_tp: 55591.0000 - val_fp: 8409.0000 - val_tn: 247591.0000 - val_fn: 8409.0000 - val_accuracy: 0.9474 - val_precision: 0.8686 - val_recall: 0.8686 - val_auc: 0.9672
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-768000-1024000
[INFO] processing batch 1024000-1280000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6345 - tp: 133967.0000 - fp: 58033.0000 - tn: 709967.0000 - fn: 58033.0000 - accuracy: 0.8791 - precision: 0.6977 - recall: 0.6977 - auc: 0.9239 - val_loss: 0.3958 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-1024000-1280000
[INFO] processing batch 1280000-1536000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.3678 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3336 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-1280000-1536000
[INFO] processing batch 1536000-1792000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.3067 - tp: 191999.0000 - fp: 1.0000 - tn: 767999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2819 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-1536000-1792000
[INFO] processing batch 1792000-2048000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.5556 - tp: 148221.0000 - fp: 43779.0000 - tn: 724221.0000 - fn: 43779.0000 - accuracy: 0.9088 - precision: 0.7720 - recall: 0.7720 - auc: 0.9425 - val_loss: 0.3903 - val_tp: 57941.0000 - val_fp: 6059.0000 - val_tn: 249941.0000 - val_fn: 6059.0000 - val_accuracy: 0.9621 - val_precision: 0.9053 - val_recall: 0.9053 - val_auc: 0.9763
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-1792000-2048000
[INFO] processing batch 2048000-2304000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.5970 - tp: 141714.0000 - fp: 50286.0000 - tn: 717714.0000 - fn: 50286.0000 - accuracy: 0.8952 - precision: 0.7381 - recall: 0.7381 - auc: 0.9344 - val_loss: 0.2772 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-2048000-2304000
[INFO] processing batch 2304000-2560000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2647 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2476 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-2304000-2560000
[INFO] processing batch 2560000-2816000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.2326 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2181 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-2560000-2816000
[INFO] processing batch 2816000-3072000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.5565 - tp: 148720.0000 - fp: 43280.0000 - tn: 724720.0000 - fn: 43280.0000 - accuracy: 0.9098 - precision: 0.7746 - recall: 0.7746 - auc: 0.9436 - val_loss: 0.7581 - val_tp: 40961.0000 - val_fp: 23039.0000 - val_tn: 232961.0000 - val_fn: 23039.0000 - val_accuracy: 0.8560 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.9100
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-2816000-3072000
[INFO] processing batch 3072000-3328000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6863 - tp: 131495.0000 - fp: 60505.0000 - tn: 707495.0000 - fn: 60505.0000 - accuracy: 0.8739 - precision: 0.6849 - recall: 0.6849 - auc: 0.9213 - val_loss: 0.2323 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-3072000-3328000
[INFO] processing batch 3328000-3584000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2254 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2136 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-3328000-3584000
[INFO] processing batch 3584000-3840000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2024 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1914 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-3584000-3840000
[INFO] processing batch 3840000-4096000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.4870 - tp: 157534.0000 - fp: 34466.0000 - tn: 733534.0000 - fn: 34466.0000 - accuracy: 0.9282 - precision: 0.8205 - recall: 0.8205 - auc: 0.9551 - val_loss: 0.4944 - val_tp: 52219.0000 - val_fp: 11781.0000 - val_tn: 244219.0000 - val_fn: 11781.0000 - val_accuracy: 0.9264 - val_precision: 0.8159 - val_recall: 0.8159 - val_auc: 0.9540
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-3840000-4096000
[INFO] processing batch 4096000-4352000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1992 - tp: 190188.0000 - fp: 1812.0000 - tn: 766188.0000 - fn: 1812.0000 - accuracy: 0.9962 - precision: 0.9906 - recall: 0.9906 - auc: 0.9974 - val_loss: 0.1752 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-4096000-4352000
[INFO] processing batch 4352000-4608000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1675 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1597 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-4352000-4608000
[INFO] processing batch 4608000-4864000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.4541 - tp: 161451.0000 - fp: 30549.0000 - tn: 737451.0000 - fn: 30549.0000 - accuracy: 0.9364 - precision: 0.8409 - recall: 0.8409 - auc: 0.9602 - val_loss: 0.1585 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-4608000-4864000
[INFO] processing batch 4864000-5120000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1541 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1479 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-4864000-5120000
[INFO] processing batch 5120000-5376000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1420 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1362 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-5120000-5376000
[INFO] processing batch 5376000-5632000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1311 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1261 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-5376000-5632000
[INFO] processing batch 5632000-5888000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.5235 - tp: 155809.0000 - fp: 36191.0000 - tn: 731809.0000 - fn: 36191.0000 - accuracy: 0.9246 - precision: 0.8115 - recall: 0.8115 - auc: 0.9527 - val_loss: 0.1293 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-5632000-5888000
[INFO] processing batch 5888000-6144000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1269 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1227 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-5888000-6144000
[INFO] processing batch 6144000-6400000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.3212 - tp: 174156.0000 - fp: 17844.0000 - tn: 750156.0000 - fn: 17844.0000 - accuracy: 0.9628 - precision: 0.9071 - recall: 0.9071 - auc: 0.9768 - val_loss: 0.8944 - val_tp: 41108.0000 - val_fp: 22892.0000 - val_tn: 233108.0000 - val_fn: 22892.0000 - val_accuracy: 0.8569 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-6144000-6400000
[INFO] processing batch 6400000-6656000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7132 - tp: 138766.0000 - fp: 53234.0000 - tn: 714766.0000 - fn: 53234.0000 - accuracy: 0.8891 - precision: 0.7227 - recall: 0.7227 - auc: 0.9305 - val_loss: 0.1308 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-6400000-6656000
[INFO] processing batch 6656000-6912000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1295 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1253 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-6656000-6912000
[INFO] processing batch 6912000-7168000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1209 - tp: 191998.0000 - fp: 2.0000 - tn: 767998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1164 - val_tp: 63999.0000 - val_fp: 1.0000 - val_tn: 255999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-6912000-7168000
[INFO] processing batch 7168000-7424000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1125 - tp: 191999.0000 - fp: 1.0000 - tn: 767999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8824 - val_tp: 44344.0000 - val_fp: 19656.0000 - val_tn: 236344.0000 - val_fn: 19656.0000 - val_accuracy: 0.8772 - val_precision: 0.6929 - val_recall: 0.6929 - val_auc: 0.7313
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-7168000-7424000
[INFO] processing batch 7424000-7680000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.7411 - tp: 102062.0000 - fp: 89938.0000 - tn: 678062.0000 - fn: 89938.0000 - accuracy: 0.8126 - precision: 0.5316 - recall: 0.5316 - auc: 0.5901 - val_loss: 1.3157 - val_tp: 49859.0000 - val_fp: 14141.0000 - val_tn: 241859.0000 - val_fn: 14141.0000 - val_accuracy: 0.9116 - val_precision: 0.7790 - val_recall: 0.7790 - val_auc: 0.8067
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-7424000-7680000
[INFO] processing batch 7680000-7936000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1145 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1113 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-7680000-7936000
[INFO] processing batch 7936000-8192000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1080 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1046 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-7936000-8192000
[INFO] processing batch 8192000-8448000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.0623 - tp: 161781.0000 - fp: 30219.0000 - tn: 737781.0000 - fn: 30219.0000 - accuracy: 0.9370 - precision: 0.8426 - recall: 0.8426 - auc: 0.8623 - val_loss: 0.1617 - val_tp: 63369.0000 - val_fp: 631.0000 - val_tn: 255369.0000 - val_fn: 631.0000 - val_accuracy: 0.9961 - val_precision: 0.9901 - val_recall: 0.9901 - val_auc: 0.9914
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-8192000-8448000
[INFO] processing batch 8448000-8704000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 2.1840 - tp: 123282.0000 - fp: 68718.0000 - tn: 699282.0000 - fn: 68718.0000 - accuracy: 0.8568 - precision: 0.6421 - recall: 0.6421 - auc: 0.6869 - val_loss: 2.2544 - val_tp: 39692.0000 - val_fp: 24308.0000 - val_tn: 231692.0000 - val_fn: 24308.0000 - val_accuracy: 0.8481 - val_precision: 0.6202 - val_recall: 0.6202 - val_auc: 0.6677
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-8448000-8704000
[INFO] processing batch 8704000-8960000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2226 - tp: 188028.0000 - fp: 3972.0000 - tn: 764028.0000 - fn: 3972.0000 - accuracy: 0.9917 - precision: 0.9793 - recall: 0.9793 - auc: 0.9822 - val_loss: 0.1040 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-8704000-8960000
[INFO] processing batch 8960000-9216000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1011 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0982 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-8960000-9216000
[INFO] processing batch 9216000-9472000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.0799 - tp: 120440.0000 - fp: 71560.0000 - tn: 696440.0000 - fn: 71560.0000 - accuracy: 0.8509 - precision: 0.6273 - recall: 0.6273 - auc: 0.6737 - val_loss: 0.1021 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-9216000-9472000
[INFO] processing batch 9472000-9728000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9174 - tp: 161553.0000 - fp: 30447.0000 - tn: 737553.0000 - fn: 30447.0000 - accuracy: 0.9366 - precision: 0.8414 - recall: 0.8414 - auc: 0.8992 - val_loss: 0.9403 - val_tp: 53468.0000 - val_fp: 10532.0000 - val_tn: 245468.0000 - val_fn: 10532.0000 - val_accuracy: 0.9342 - val_precision: 0.8354 - val_recall: 0.8354 - val_auc: 0.8971
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-9472000-9728000
[INFO] processing batch 9728000-9984000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1005 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0978 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-9728000-9984000
[INFO] processing batch 9984000-10240000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.0952 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0926 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-9984000-10240000
[INFO] processing batch 10240000-10496000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1558 - tp: 189510.0000 - fp: 2490.0000 - tn: 765510.0000 - fn: 2490.0000 - accuracy: 0.9948 - precision: 0.9870 - recall: 0.9870 - auc: 0.9919 - val_loss: 2.4574 - val_tp: 33975.0000 - val_fp: 30025.0000 - val_tn: 225975.0000 - val_fn: 30025.0000 - val_accuracy: 0.8123 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.7068
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-10240000-10496000
[INFO] processing batch 10496000-10752000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.3931 - tp: 101670.0000 - fp: 90330.0000 - tn: 677670.0000 - fn: 90330.0000 - accuracy: 0.8118 - precision: 0.5295 - recall: 0.5295 - auc: 0.7060 - val_loss: 2.3044 - val_tp: 34015.0000 - val_fp: 29985.0000 - val_tn: 226015.0000 - val_fn: 29985.0000 - val_accuracy: 0.8126 - val_precision: 0.5315 - val_recall: 0.5315 - val_auc: 0.7072
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-10496000-10752000
[INFO] processing batch 10752000-11008000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 2.2502 - tp: 101693.0000 - fp: 90307.0000 - tn: 677693.0000 - fn: 90307.0000 - accuracy: 0.8119 - precision: 0.5297 - recall: 0.5297 - auc: 0.7196 - val_loss: 0.5900 - val_tp: 56989.0000 - val_fp: 7011.0000 - val_tn: 248989.0000 - val_fn: 7011.0000 - val_accuracy: 0.9562 - val_precision: 0.8905 - val_recall: 0.8905 - val_auc: 0.9452
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-10752000-11008000
[INFO] processing batch 11008000-11264000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1039 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1017 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-11008000-11264000
[INFO] processing batch 11264000-11520000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.0992 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0967 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-11264000-11520000
[INFO] processing batch 11520000-11776000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.0944 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0921 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-11520000-11776000
[INFO] processing batch 11776000-12032000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9150 - tp: 156412.0000 - fp: 35588.0000 - tn: 732412.0000 - fn: 35588.0000 - accuracy: 0.9259 - precision: 0.8146 - recall: 0.8146 - auc: 0.9073 - val_loss: 1.6639 - val_tp: 41134.0000 - val_fp: 22866.0000 - val_tn: 233134.0000 - val_fn: 22866.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.8214
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-11776000-12032000
[INFO] processing batch 12032000-12288000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.6358 - tp: 123527.0000 - fp: 68473.0000 - tn: 699527.0000 - fn: 68473.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.8216 - val_loss: 1.6034 - val_tp: 41219.0000 - val_fp: 22781.0000 - val_tn: 233219.0000 - val_fn: 22781.0000 - val_accuracy: 0.8576 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.8220
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-12032000-12288000
[INFO] processing batch 12288000-12544000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.5779 - tp: 123560.0000 - fp: 68440.0000 - tn: 699560.0000 - fn: 68440.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.8218 - val_loss: 1.0992 - val_tp: 41268.0000 - val_fp: 22732.0000 - val_tn: 233268.0000 - val_fn: 22732.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.8958
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-12288000-12544000
[INFO] processing batch 12544000-12800000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9897 - tp: 123588.0000 - fp: 68412.0000 - tn: 699588.0000 - fn: 68412.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.9629 - val_tp: 41269.0000 - val_fp: 22731.0000 - val_tn: 233269.0000 - val_fn: 22731.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-12544000-12800000
[INFO] processing batch 12800000-13056000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9444 - tp: 123531.0000 - fp: 68469.0000 - tn: 699531.0000 - fn: 68469.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.9225 - val_tp: 41181.0000 - val_fp: 22819.0000 - val_tn: 233181.0000 - val_fn: 22819.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-12800000-13056000
[INFO] processing batch 13056000-13312000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9033 - tp: 123615.0000 - fp: 68385.0000 - tn: 699615.0000 - fn: 68385.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.8854 - val_tp: 41192.0000 - val_fp: 22808.0000 - val_tn: 233192.0000 - val_fn: 22808.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-13056000-13312000
[INFO] processing batch 13312000-13568000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.8711 - tp: 123437.0000 - fp: 68563.0000 - tn: 699437.0000 - fn: 68563.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9106 - val_loss: 0.8543 - val_tp: 41179.0000 - val_fp: 22821.0000 - val_tn: 233179.0000 - val_fn: 22821.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-13312000-13568000
[INFO] processing batch 13568000-13824000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8408 - tp: 123539.0000 - fp: 68461.0000 - tn: 699539.0000 - fn: 68461.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.8265 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-13568000-13824000
[INFO] processing batch 13824000-14080000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8157 - tp: 123556.0000 - fp: 68444.0000 - tn: 699556.0000 - fn: 68444.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.8046 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 233173.0000 - val_fn: 22827.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-13824000-14080000
[INFO] processing batch 14080000-14336000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7934 - tp: 123681.0000 - fp: 68319.0000 - tn: 699681.0000 - fn: 68319.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.7838 - val_tp: 41221.0000 - val_fp: 22779.0000 - val_tn: 233221.0000 - val_fn: 22779.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-14080000-14336000
[INFO] processing batch 14336000-14592000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 22s - loss: 0.7765 - tp: 123523.0000 - fp: 68477.0000 - tn: 699523.0000 - fn: 68477.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9109 - val_loss: 0.7676 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 233197.0000 - val_fn: 22803.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-14336000-14592000
[INFO] processing batch 14592000-14848000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7601 - tp: 123652.0000 - fp: 68348.0000 - tn: 699652.0000 - fn: 68348.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.7531 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-14592000-14848000
[INFO] processing batch 14848000-15104000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7474 - tp: 123594.0000 - fp: 68406.0000 - tn: 699594.0000 - fn: 68406.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.7413 - val_tp: 41205.0000 - val_fp: 22795.0000 - val_tn: 233205.0000 - val_fn: 22795.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-14848000-15104000
[INFO] processing batch 15104000-15360000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7361 - tp: 123629.0000 - fp: 68371.0000 - tn: 699629.0000 - fn: 68371.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.7307 - val_tp: 41234.0000 - val_fp: 22766.0000 - val_tn: 233234.0000 - val_fn: 22766.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-15104000-15360000
[INFO] processing batch 15360000-15616000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7269 - tp: 123632.0000 - fp: 68368.0000 - tn: 699632.0000 - fn: 68368.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.7217 - val_tp: 41266.0000 - val_fp: 22734.0000 - val_tn: 233266.0000 - val_fn: 22734.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-15360000-15616000
[INFO] processing batch 15616000-15872000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7198 - tp: 123527.0000 - fp: 68473.0000 - tn: 699527.0000 - fn: 68473.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.7159 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 233197.0000 - val_fn: 22803.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-15616000-15872000
[INFO] processing batch 15872000-16128000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7133 - tp: 123531.0000 - fp: 68469.0000 - tn: 699531.0000 - fn: 68469.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9107 - val_loss: 0.7104 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 233173.0000 - val_fn: 22827.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-15872000-16128000
[INFO] processing batch 16128000-16384000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7066 - tp: 123781.0000 - fp: 68219.0000 - tn: 699781.0000 - fn: 68219.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9112 - val_loss: 0.7052 - val_tp: 41195.0000 - val_fp: 22805.0000 - val_tn: 233195.0000 - val_fn: 22805.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-16128000-16384000
[INFO] processing batch 16384000-16640000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7031 - tp: 123621.0000 - fp: 68379.0000 - tn: 699621.0000 - fn: 68379.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9111 - val_loss: 0.7017 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 233165.0000 - val_fn: 22835.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-16384000-16640000
[INFO] processing batch 16640000-16896000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7004 - tp: 123417.0000 - fp: 68583.0000 - tn: 699417.0000 - fn: 68583.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9107 - val_loss: 0.6974 - val_tp: 41230.0000 - val_fp: 22770.0000 - val_tn: 233230.0000 - val_fn: 22770.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-16640000-16896000
[INFO] processing batch 16896000-17152000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6965 - tp: 123600.0000 - fp: 68400.0000 - tn: 699600.0000 - fn: 68400.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6952 - val_tp: 41198.0000 - val_fp: 22802.0000 - val_tn: 233198.0000 - val_fn: 22802.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-16896000-17152000
[INFO] processing batch 17152000-17408000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6936 - tp: 123711.0000 - fp: 68289.0000 - tn: 699711.0000 - fn: 68289.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9111 - val_loss: 0.6934 - val_tp: 41168.0000 - val_fp: 22832.0000 - val_tn: 233168.0000 - val_fn: 22832.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-17152000-17408000
[INFO] processing batch 17408000-17664000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6916 - tp: 123701.0000 - fp: 68299.0000 - tn: 699701.0000 - fn: 68299.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9111 - val_loss: 0.6922 - val_tp: 41118.0000 - val_fp: 22882.0000 - val_tn: 233118.0000 - val_fn: 22882.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-17408000-17664000
[INFO] processing batch 17664000-17920000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6906 - tp: 123546.0000 - fp: 68454.0000 - tn: 699546.0000 - fn: 68454.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6910 - val_tp: 41089.0000 - val_fp: 22911.0000 - val_tn: 233089.0000 - val_fn: 22911.0000 - val_accuracy: 0.8568 - val_precision: 0.6420 - val_recall: 0.6420 - val_auc: 0.9105
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-17664000-17920000
[INFO] processing batch 17920000-18176000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6886 - tp: 123681.0000 - fp: 68319.0000 - tn: 699681.0000 - fn: 68319.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6879 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 233233.0000 - val_fn: 22767.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-17920000-18176000
[INFO] processing batch 18176000-18432000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6876 - tp: 123640.0000 - fp: 68360.0000 - tn: 699640.0000 - fn: 68360.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6861 - val_tp: 41298.0000 - val_fp: 22702.0000 - val_tn: 233298.0000 - val_fn: 22702.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-18176000-18432000
[INFO] processing batch 18432000-18688000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6867 - tp: 123615.0000 - fp: 68385.0000 - tn: 699615.0000 - fn: 68385.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6859 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 233233.0000 - val_fn: 22767.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-18432000-18688000
[INFO] processing batch 18688000-18944000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6857 - tp: 123645.0000 - fp: 68355.0000 - tn: 699645.0000 - fn: 68355.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6856 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 233184.0000 - val_fn: 22816.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-18688000-18944000
[INFO] processing batch 18944000-19200000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6841 - tp: 123888.0000 - fp: 68112.0000 - tn: 699888.0000 - fn: 68112.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9113 - val_loss: 0.6851 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 233169.0000 - val_fn: 22831.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-18944000-19200000
[INFO] processing batch 19200000-19456000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6848 - tp: 123500.0000 - fp: 68500.0000 - tn: 699500.0000 - fn: 68500.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6842 - val_tp: 41189.0000 - val_fp: 22811.0000 - val_tn: 233189.0000 - val_fn: 22811.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-19200000-19456000
[INFO] processing batch 19456000-19712000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6835 - tp: 123689.0000 - fp: 68311.0000 - tn: 699689.0000 - fn: 68311.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6838 - val_tp: 41166.0000 - val_fp: 22834.0000 - val_tn: 233166.0000 - val_fn: 22834.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-19456000-19712000
[INFO] processing batch 19712000-19968000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6839 - tp: 123402.0000 - fp: 68598.0000 - tn: 699402.0000 - fn: 68598.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9107 - val_loss: 0.6824 - val_tp: 41242.0000 - val_fp: 22758.0000 - val_tn: 233242.0000 - val_fn: 22758.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-19712000-19968000
[INFO] processing batch 19968000-20224000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6828 - tp: 123541.0000 - fp: 68459.0000 - tn: 699541.0000 - fn: 68459.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6819 - val_tp: 41241.0000 - val_fp: 22759.0000 - val_tn: 233241.0000 - val_fn: 22759.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-19968000-20224000
[INFO] processing batch 20224000-20480000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6819 - tp: 123640.0000 - fp: 68360.0000 - tn: 699640.0000 - fn: 68360.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6817 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 233209.0000 - val_fn: 22791.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-20224000-20480000
[INFO] processing batch 20480000-20736000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6816 - tp: 123598.0000 - fp: 68402.0000 - tn: 699598.0000 - fn: 68402.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6810 - val_tp: 41235.0000 - val_fp: 22765.0000 - val_tn: 233235.0000 - val_fn: 22765.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-20480000-20736000
[INFO] processing batch 20736000-20992000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6805 - tp: 123769.0000 - fp: 68231.0000 - tn: 699769.0000 - fn: 68231.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.6807 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-20736000-20992000
[INFO] processing batch 20992000-21248000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6811 - tp: 123459.0000 - fp: 68541.0000 - tn: 699459.0000 - fn: 68541.0000 - accuracy: 0.8572 - precision: 0.6430 - recall: 0.6430 - auc: 0.9107 - val_loss: 0.6803 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 233209.0000 - val_fn: 22791.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-20992000-21248000
[INFO] processing batch 21248000-21504000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6799 - tp: 123683.0000 - fp: 68317.0000 - tn: 699683.0000 - fn: 68317.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6801 - val_tp: 41183.0000 - val_fp: 22817.0000 - val_tn: 233183.0000 - val_fn: 22817.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-21248000-21504000
[INFO] processing batch 21504000-21760000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6798 - tp: 123564.0000 - fp: 68436.0000 - tn: 699564.0000 - fn: 68436.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6789 - val_tp: 41254.0000 - val_fp: 22746.0000 - val_tn: 233254.0000 - val_fn: 22746.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-21504000-21760000
[INFO] processing batch 21760000-22016000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6788 - tp: 123717.0000 - fp: 68283.0000 - tn: 699717.0000 - fn: 68283.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9111 - val_loss: 0.6783 - val_tp: 41270.0000 - val_fp: 22730.0000 - val_tn: 233270.0000 - val_fn: 22730.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-21760000-22016000
[INFO] processing batch 22016000-22272000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6785 - tp: 123690.0000 - fp: 68310.0000 - tn: 699690.0000 - fn: 68310.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6795 - val_tp: 41104.0000 - val_fp: 22896.0000 - val_tn: 233104.0000 - val_fn: 22896.0000 - val_accuracy: 0.8569 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-22016000-22272000
[INFO] processing batch 22272000-22528000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6781 - tp: 123672.0000 - fp: 68328.0000 - tn: 699672.0000 - fn: 68328.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6777 - val_tp: 41243.0000 - val_fp: 22757.0000 - val_tn: 233243.0000 - val_fn: 22757.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-22272000-22528000
[INFO] processing batch 22528000-22784000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6778 - tp: 123623.0000 - fp: 68377.0000 - tn: 699623.0000 - fn: 68377.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6768 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 233292.0000 - val_fn: 22708.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-22528000-22784000
[INFO] processing batch 22784000-23040000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6769 - tp: 123759.0000 - fp: 68241.0000 - tn: 699759.0000 - fn: 68241.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9111 - val_loss: 0.6774 - val_tp: 41180.0000 - val_fp: 22820.0000 - val_tn: 233180.0000 - val_fn: 22820.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-22784000-23040000
[INFO] processing batch 23040000-23296000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6773 - tp: 123507.0000 - fp: 68493.0000 - tn: 699507.0000 - fn: 68493.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6763 - val_tp: 41255.0000 - val_fp: 22745.0000 - val_tn: 233255.0000 - val_fn: 22745.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-23040000-23296000
[INFO] processing batch 23296000-23552000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6766 - tp: 123601.0000 - fp: 68399.0000 - tn: 699601.0000 - fn: 68399.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6762 - val_tp: 41213.0000 - val_fp: 22787.0000 - val_tn: 233213.0000 - val_fn: 22787.0000 - val_accuracy: 0.8576 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-23296000-23552000
[INFO] processing batch 23552000-23808000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6757 - tp: 123749.0000 - fp: 68251.0000 - tn: 699749.0000 - fn: 68251.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9111 - val_loss: 0.6751 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 233292.0000 - val_fn: 22708.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-23552000-23808000
[INFO] processing batch 23808000-24064000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6757 - tp: 123603.0000 - fp: 68397.0000 - tn: 699603.0000 - fn: 68397.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6759 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 233165.0000 - val_fn: 22835.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-23808000-24064000
[INFO] processing batch 24064000-24320000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6753 - tp: 123599.0000 - fp: 68401.0000 - tn: 699599.0000 - fn: 68401.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6753 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 233184.0000 - val_fn: 22816.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-24064000-24320000
[INFO] processing batch 24320000-24576000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6754 - tp: 123440.0000 - fp: 68560.0000 - tn: 699440.0000 - fn: 68560.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9107 - val_loss: 0.6750 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 233169.0000 - val_fn: 22831.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-24320000-24576000
[INFO] processing batch 24576000-24832000/24819975
[33m[LOSS] 0.6750185890197754[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6750185890197754  <  0.001
[33m[INFO] epoch 8/10[0m
[33m[INFO] loading file 1-50/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (24819975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
len(df.columns) 108
numFeatures 107
[INFO] columns: Index(['unixtime', 'modbus_function_code', 'modbus_transaction_id', 'service',
       's_port', 'classification', 'orig-192.168.1.48', 'orig-192.168.1.87',
       'orig-192.168.1.88', 'type-alert',
       ...
       'modbus_function_description-Read Tag Service',
       'modbus_function_description-Read Tag Service - Response',
       'modbus_function_description-Unknown Function Code',
       'modbus_function_description-Write Tag Service', 'scada_tag-0',
       'scada_tag-HMI_AIT202', 'scada_tag-HMI_FIT201', 'scada_tag-HMI_LIT101',
       'scada_tag-HMI_LIT301', 'scada_tag-HMI_LIT401'],
      dtype='object', length=108)
[INFO] processing batch 0-256000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.4177 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3694 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-0-256000
[INFO] processing batch 256000-512000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7321 - tp: 112918.0000 - fp: 79082.0000 - tn: 688918.0000 - fn: 79082.0000 - accuracy: 0.8352 - precision: 0.5881 - recall: 0.5881 - auc: 0.8974 - val_loss: 0.7767 - val_tp: 33927.0000 - val_fp: 30073.0000 - val_tn: 225927.0000 - val_fn: 30073.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-256000-512000
[INFO] processing batch 512000-768000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6157 - tp: 138284.0000 - fp: 53716.0000 - tn: 714284.0000 - fn: 53716.0000 - accuracy: 0.8881 - precision: 0.7202 - recall: 0.7202 - auc: 0.9301 - val_loss: 0.4039 - val_tp: 62058.0000 - val_fp: 1942.0000 - val_tn: 254058.0000 - val_fn: 1942.0000 - val_accuracy: 0.9879 - val_precision: 0.9697 - val_recall: 0.9697 - val_auc: 0.9924
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-512000-768000
[INFO] processing batch 768000-1024000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7061 - tp: 117250.0000 - fp: 74750.0000 - tn: 693250.0000 - fn: 74750.0000 - accuracy: 0.8443 - precision: 0.6107 - recall: 0.6107 - auc: 0.9016 - val_loss: 0.4998 - val_tp: 55591.0000 - val_fp: 8409.0000 - val_tn: 247591.0000 - val_fn: 8409.0000 - val_accuracy: 0.9474 - val_precision: 0.8686 - val_recall: 0.8686 - val_auc: 0.9672
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-768000-1024000
[INFO] processing batch 1024000-1280000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6345 - tp: 133967.0000 - fp: 58033.0000 - tn: 709967.0000 - fn: 58033.0000 - accuracy: 0.8791 - precision: 0.6977 - recall: 0.6977 - auc: 0.9239 - val_loss: 0.3958 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-1024000-1280000
[INFO] processing batch 1280000-1536000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.3677 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3335 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-1280000-1536000
[INFO] processing batch 1536000-1792000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.3067 - tp: 191999.0000 - fp: 1.0000 - tn: 767999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2819 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-1536000-1792000
[INFO] processing batch 1792000-2048000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.5556 - tp: 148221.0000 - fp: 43779.0000 - tn: 724221.0000 - fn: 43779.0000 - accuracy: 0.9088 - precision: 0.7720 - recall: 0.7720 - auc: 0.9416 - val_loss: 0.3901 - val_tp: 57941.0000 - val_fp: 6059.0000 - val_tn: 249941.0000 - val_fn: 6059.0000 - val_accuracy: 0.9621 - val_precision: 0.9053 - val_recall: 0.9053 - val_auc: 0.9763
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-1792000-2048000
[INFO] processing batch 2048000-2304000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.5969 - tp: 141714.0000 - fp: 50286.0000 - tn: 717714.0000 - fn: 50286.0000 - accuracy: 0.8952 - precision: 0.7381 - recall: 0.7381 - auc: 0.9345 - val_loss: 0.2773 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-2048000-2304000
[INFO] processing batch 2304000-2560000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2649 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2477 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-2304000-2560000
[INFO] processing batch 2560000-2816000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2327 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2183 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-2560000-2816000
[INFO] processing batch 2816000-3072000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.5563 - tp: 148720.0000 - fp: 43280.0000 - tn: 724720.0000 - fn: 43280.0000 - accuracy: 0.9098 - precision: 0.7746 - recall: 0.7746 - auc: 0.9437 - val_loss: 0.7580 - val_tp: 40961.0000 - val_fp: 23039.0000 - val_tn: 232961.0000 - val_fn: 23039.0000 - val_accuracy: 0.8560 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.9100
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-2816000-3072000
[INFO] processing batch 3072000-3328000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6861 - tp: 131495.0000 - fp: 60505.0000 - tn: 707495.0000 - fn: 60505.0000 - accuracy: 0.8739 - precision: 0.6849 - recall: 0.6849 - auc: 0.9211 - val_loss: 0.2325 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-3072000-3328000
[INFO] processing batch 3328000-3584000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.2255 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2136 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-3328000-3584000
[INFO] processing batch 3584000-3840000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.2024 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1915 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-3584000-3840000
[INFO] processing batch 3840000-4096000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.4869 - tp: 157534.0000 - fp: 34466.0000 - tn: 733534.0000 - fn: 34466.0000 - accuracy: 0.9282 - precision: 0.8205 - recall: 0.8205 - auc: 0.9551 - val_loss: 0.4944 - val_tp: 52219.0000 - val_fp: 11781.0000 - val_tn: 244219.0000 - val_fn: 11781.0000 - val_accuracy: 0.9264 - val_precision: 0.8159 - val_recall: 0.8159 - val_auc: 0.9540
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-3840000-4096000
[INFO] processing batch 4096000-4352000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1992 - tp: 190188.0000 - fp: 1812.0000 - tn: 766188.0000 - fn: 1812.0000 - accuracy: 0.9962 - precision: 0.9906 - recall: 0.9906 - auc: 0.9977 - val_loss: 0.1752 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-4096000-4352000
[INFO] processing batch 4352000-4608000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1675 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1598 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-4352000-4608000
[INFO] processing batch 4608000-4864000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.4541 - tp: 161451.0000 - fp: 30549.0000 - tn: 737451.0000 - fn: 30549.0000 - accuracy: 0.9364 - precision: 0.8409 - recall: 0.8409 - auc: 0.9602 - val_loss: 0.1585 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-4608000-4864000
[INFO] processing batch 4864000-5120000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1541 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1479 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-4864000-5120000
[INFO] processing batch 5120000-5376000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1421 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1362 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-5120000-5376000
[INFO] processing batch 5376000-5632000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1312 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1261 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-5376000-5632000
[INFO] processing batch 5632000-5888000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.5235 - tp: 155809.0000 - fp: 36191.0000 - tn: 731809.0000 - fn: 36191.0000 - accuracy: 0.9246 - precision: 0.8115 - recall: 0.8115 - auc: 0.9526 - val_loss: 0.1294 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-5632000-5888000
[INFO] processing batch 5888000-6144000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1270 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1227 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-5888000-6144000
[INFO] processing batch 6144000-6400000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.3212 - tp: 174156.0000 - fp: 17844.0000 - tn: 750156.0000 - fn: 17844.0000 - accuracy: 0.9628 - precision: 0.9071 - recall: 0.9071 - auc: 0.9768 - val_loss: 0.8938 - val_tp: 41108.0000 - val_fp: 22892.0000 - val_tn: 233108.0000 - val_fn: 22892.0000 - val_accuracy: 0.8569 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-6144000-6400000
[INFO] processing batch 6400000-6656000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7131 - tp: 138766.0000 - fp: 53234.0000 - tn: 714766.0000 - fn: 53234.0000 - accuracy: 0.8891 - precision: 0.7227 - recall: 0.7227 - auc: 0.9308 - val_loss: 0.1308 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-6400000-6656000
[INFO] processing batch 6656000-6912000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1295 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1253 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-6656000-6912000
[INFO] processing batch 6912000-7168000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1209 - tp: 191998.0000 - fp: 2.0000 - tn: 767998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1164 - val_tp: 63999.0000 - val_fp: 1.0000 - val_tn: 255999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-6912000-7168000
[INFO] processing batch 7168000-7424000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1125 - tp: 191999.0000 - fp: 1.0000 - tn: 767999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8844 - val_tp: 44344.0000 - val_fp: 19656.0000 - val_tn: 236344.0000 - val_fn: 19656.0000 - val_accuracy: 0.8772 - val_precision: 0.6929 - val_recall: 0.6929 - val_auc: 0.7313
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-7168000-7424000
[INFO] processing batch 7424000-7680000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.7440 - tp: 102062.0000 - fp: 89938.0000 - tn: 678062.0000 - fn: 89938.0000 - accuracy: 0.8126 - precision: 0.5316 - recall: 0.5316 - auc: 0.5902 - val_loss: 1.3171 - val_tp: 49859.0000 - val_fp: 14141.0000 - val_tn: 241859.0000 - val_fn: 14141.0000 - val_accuracy: 0.9116 - val_precision: 0.7790 - val_recall: 0.7790 - val_auc: 0.8067
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-7424000-7680000
[INFO] processing batch 7680000-7936000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1145 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1114 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-7680000-7936000
[INFO] processing batch 7936000-8192000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1080 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1046 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-7936000-8192000
[INFO] processing batch 8192000-8448000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.0640 - tp: 161781.0000 - fp: 30219.0000 - tn: 737781.0000 - fn: 30219.0000 - accuracy: 0.9370 - precision: 0.8426 - recall: 0.8426 - auc: 0.8623 - val_loss: 0.1618 - val_tp: 63369.0000 - val_fp: 631.0000 - val_tn: 255369.0000 - val_fn: 631.0000 - val_accuracy: 0.9961 - val_precision: 0.9901 - val_recall: 0.9901 - val_auc: 0.9914
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-8192000-8448000
[INFO] processing batch 8448000-8704000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.1878 - tp: 123282.0000 - fp: 68718.0000 - tn: 699282.0000 - fn: 68718.0000 - accuracy: 0.8568 - precision: 0.6421 - recall: 0.6421 - auc: 0.6869 - val_loss: 2.2583 - val_tp: 39692.0000 - val_fp: 24308.0000 - val_tn: 231692.0000 - val_fn: 24308.0000 - val_accuracy: 0.8481 - val_precision: 0.6202 - val_recall: 0.6202 - val_auc: 0.6677
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-8448000-8704000
[INFO] processing batch 8704000-8960000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2228 - tp: 188028.0000 - fp: 3972.0000 - tn: 764028.0000 - fn: 3972.0000 - accuracy: 0.9917 - precision: 0.9793 - recall: 0.9793 - auc: 0.9820 - val_loss: 0.1040 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-8704000-8960000
[INFO] processing batch 8960000-9216000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1011 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0982 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-8960000-9216000
[INFO] processing batch 9216000-9472000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.0820 - tp: 120440.0000 - fp: 71560.0000 - tn: 696440.0000 - fn: 71560.0000 - accuracy: 0.8509 - precision: 0.6273 - recall: 0.6273 - auc: 0.6739 - val_loss: 0.1021 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-9216000-9472000
[INFO] processing batch 9472000-9728000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9183 - tp: 161553.0000 - fp: 30447.0000 - tn: 737553.0000 - fn: 30447.0000 - accuracy: 0.9366 - precision: 0.8414 - recall: 0.8414 - auc: 0.8976 - val_loss: 0.9413 - val_tp: 53468.0000 - val_fp: 10532.0000 - val_tn: 245468.0000 - val_fn: 10532.0000 - val_accuracy: 0.9342 - val_precision: 0.8354 - val_recall: 0.8354 - val_auc: 0.8971
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-9472000-9728000
[INFO] processing batch 9728000-9984000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1005 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0978 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-9728000-9984000
[INFO] processing batch 9984000-10240000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.0952 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0926 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-9984000-10240000
[INFO] processing batch 10240000-10496000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1558 - tp: 189510.0000 - fp: 2490.0000 - tn: 765510.0000 - fn: 2490.0000 - accuracy: 0.9948 - precision: 0.9870 - recall: 0.9870 - auc: 0.9915 - val_loss: 2.4577 - val_tp: 33975.0000 - val_fp: 30025.0000 - val_tn: 225975.0000 - val_fn: 30025.0000 - val_accuracy: 0.8123 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.7068
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-10240000-10496000
[INFO] processing batch 10496000-10752000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.3929 - tp: 101670.0000 - fp: 90330.0000 - tn: 677670.0000 - fn: 90330.0000 - accuracy: 0.8118 - precision: 0.5295 - recall: 0.5295 - auc: 0.7060 - val_loss: 2.3041 - val_tp: 34015.0000 - val_fp: 29985.0000 - val_tn: 226015.0000 - val_fn: 29985.0000 - val_accuracy: 0.8126 - val_precision: 0.5315 - val_recall: 0.5315 - val_auc: 0.7072
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-10496000-10752000
[INFO] processing batch 10752000-11008000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.2499 - tp: 101693.0000 - fp: 90307.0000 - tn: 677693.0000 - fn: 90307.0000 - accuracy: 0.8119 - precision: 0.5297 - recall: 0.5297 - auc: 0.7197 - val_loss: 0.5900 - val_tp: 56989.0000 - val_fp: 7011.0000 - val_tn: 248989.0000 - val_fn: 7011.0000 - val_accuracy: 0.9562 - val_precision: 0.8905 - val_recall: 0.8905 - val_auc: 0.9452
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-10752000-11008000
[INFO] processing batch 11008000-11264000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1039 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1017 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-11008000-11264000
[INFO] processing batch 11264000-11520000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.0992 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0967 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-11264000-11520000
[INFO] processing batch 11520000-11776000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.0944 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0921 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-11520000-11776000
[INFO] processing batch 11776000-12032000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9148 - tp: 156412.0000 - fp: 35588.0000 - tn: 732412.0000 - fn: 35588.0000 - accuracy: 0.9259 - precision: 0.8146 - recall: 0.8146 - auc: 0.9073 - val_loss: 1.6639 - val_tp: 41134.0000 - val_fp: 22866.0000 - val_tn: 233134.0000 - val_fn: 22866.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.8214
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-11776000-12032000
[INFO] processing batch 12032000-12288000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.6356 - tp: 123527.0000 - fp: 68473.0000 - tn: 699527.0000 - fn: 68473.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.8217 - val_loss: 1.6032 - val_tp: 41219.0000 - val_fp: 22781.0000 - val_tn: 233219.0000 - val_fn: 22781.0000 - val_accuracy: 0.8576 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.8220
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-12032000-12288000
[INFO] processing batch 12288000-12544000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.5777 - tp: 123560.0000 - fp: 68440.0000 - tn: 699560.0000 - fn: 68440.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.8218 - val_loss: 1.0990 - val_tp: 41268.0000 - val_fp: 22732.0000 - val_tn: 233268.0000 - val_fn: 22732.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.8958
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-12288000-12544000
[INFO] processing batch 12544000-12800000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9895 - tp: 123588.0000 - fp: 68412.0000 - tn: 699588.0000 - fn: 68412.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.9627 - val_tp: 41269.0000 - val_fp: 22731.0000 - val_tn: 233269.0000 - val_fn: 22731.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-12544000-12800000
[INFO] processing batch 12800000-13056000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9442 - tp: 123531.0000 - fp: 68469.0000 - tn: 699531.0000 - fn: 68469.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.9224 - val_tp: 41181.0000 - val_fp: 22819.0000 - val_tn: 233181.0000 - val_fn: 22819.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-12800000-13056000
[INFO] processing batch 13056000-13312000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9031 - tp: 123615.0000 - fp: 68385.0000 - tn: 699615.0000 - fn: 68385.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.8852 - val_tp: 41192.0000 - val_fp: 22808.0000 - val_tn: 233192.0000 - val_fn: 22808.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-13056000-13312000
[INFO] processing batch 13312000-13568000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8709 - tp: 123437.0000 - fp: 68563.0000 - tn: 699437.0000 - fn: 68563.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9107 - val_loss: 0.8541 - val_tp: 41179.0000 - val_fp: 22821.0000 - val_tn: 233179.0000 - val_fn: 22821.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-13312000-13568000
[INFO] processing batch 13568000-13824000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.8406 - tp: 123539.0000 - fp: 68461.0000 - tn: 699539.0000 - fn: 68461.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.8263 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-13568000-13824000
[INFO] processing batch 13824000-14080000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8155 - tp: 123556.0000 - fp: 68444.0000 - tn: 699556.0000 - fn: 68444.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.8044 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 233173.0000 - val_fn: 22827.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-13824000-14080000
[INFO] processing batch 14080000-14336000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7932 - tp: 123681.0000 - fp: 68319.0000 - tn: 699681.0000 - fn: 68319.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.7836 - val_tp: 41221.0000 - val_fp: 22779.0000 - val_tn: 233221.0000 - val_fn: 22779.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-14080000-14336000
[INFO] processing batch 14336000-14592000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7764 - tp: 123523.0000 - fp: 68477.0000 - tn: 699523.0000 - fn: 68477.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.7675 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 233197.0000 - val_fn: 22803.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-14336000-14592000
[INFO] processing batch 14592000-14848000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7599 - tp: 123652.0000 - fp: 68348.0000 - tn: 699652.0000 - fn: 68348.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9109 - val_loss: 0.7530 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-14592000-14848000
[INFO] processing batch 14848000-15104000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7473 - tp: 123594.0000 - fp: 68406.0000 - tn: 699594.0000 - fn: 68406.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.7412 - val_tp: 41205.0000 - val_fp: 22795.0000 - val_tn: 233205.0000 - val_fn: 22795.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-14848000-15104000
[INFO] processing batch 15104000-15360000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7360 - tp: 123629.0000 - fp: 68371.0000 - tn: 699629.0000 - fn: 68371.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.7305 - val_tp: 41234.0000 - val_fp: 22766.0000 - val_tn: 233234.0000 - val_fn: 22766.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-15104000-15360000
[INFO] processing batch 15360000-15616000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7267 - tp: 123632.0000 - fp: 68368.0000 - tn: 699632.0000 - fn: 68368.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.7215 - val_tp: 41266.0000 - val_fp: 22734.0000 - val_tn: 233266.0000 - val_fn: 22734.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-15360000-15616000
[INFO] processing batch 15616000-15872000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7196 - tp: 123527.0000 - fp: 68473.0000 - tn: 699527.0000 - fn: 68473.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9110 - val_loss: 0.7158 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 233197.0000 - val_fn: 22803.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-15616000-15872000
[INFO] processing batch 15872000-16128000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7131 - tp: 123531.0000 - fp: 68469.0000 - tn: 699531.0000 - fn: 68469.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.7103 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 233173.0000 - val_fn: 22827.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-15872000-16128000
[INFO] processing batch 16128000-16384000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7065 - tp: 123781.0000 - fp: 68219.0000 - tn: 699781.0000 - fn: 68219.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9111 - val_loss: 0.7051 - val_tp: 41195.0000 - val_fp: 22805.0000 - val_tn: 233195.0000 - val_fn: 22805.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-16128000-16384000
[INFO] processing batch 16384000-16640000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7029 - tp: 123621.0000 - fp: 68379.0000 - tn: 699621.0000 - fn: 68379.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.7016 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 233165.0000 - val_fn: 22835.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-16384000-16640000
[INFO] processing batch 16640000-16896000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7003 - tp: 123417.0000 - fp: 68583.0000 - tn: 699417.0000 - fn: 68583.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9106 - val_loss: 0.6973 - val_tp: 41230.0000 - val_fp: 22770.0000 - val_tn: 233230.0000 - val_fn: 22770.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-16640000-16896000
[INFO] processing batch 16896000-17152000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6964 - tp: 123600.0000 - fp: 68400.0000 - tn: 699600.0000 - fn: 68400.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6951 - val_tp: 41198.0000 - val_fp: 22802.0000 - val_tn: 233198.0000 - val_fn: 22802.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-16896000-17152000
[INFO] processing batch 17152000-17408000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6935 - tp: 123711.0000 - fp: 68289.0000 - tn: 699711.0000 - fn: 68289.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9111 - val_loss: 0.6933 - val_tp: 41168.0000 - val_fp: 22832.0000 - val_tn: 233168.0000 - val_fn: 22832.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-17152000-17408000
[INFO] processing batch 17408000-17664000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6915 - tp: 123701.0000 - fp: 68299.0000 - tn: 699701.0000 - fn: 68299.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9111 - val_loss: 0.6921 - val_tp: 41118.0000 - val_fp: 22882.0000 - val_tn: 233118.0000 - val_fn: 22882.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-17408000-17664000
[INFO] processing batch 17664000-17920000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6905 - tp: 123546.0000 - fp: 68454.0000 - tn: 699546.0000 - fn: 68454.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6909 - val_tp: 41089.0000 - val_fp: 22911.0000 - val_tn: 233089.0000 - val_fn: 22911.0000 - val_accuracy: 0.8568 - val_precision: 0.6420 - val_recall: 0.6420 - val_auc: 0.9105
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-17664000-17920000
[INFO] processing batch 17920000-18176000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6885 - tp: 123681.0000 - fp: 68319.0000 - tn: 699681.0000 - fn: 68319.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6878 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 233233.0000 - val_fn: 22767.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-17920000-18176000
[INFO] processing batch 18176000-18432000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6875 - tp: 123640.0000 - fp: 68360.0000 - tn: 699640.0000 - fn: 68360.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6860 - val_tp: 41298.0000 - val_fp: 22702.0000 - val_tn: 233298.0000 - val_fn: 22702.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-18176000-18432000
[INFO] processing batch 18432000-18688000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6866 - tp: 123615.0000 - fp: 68385.0000 - tn: 699615.0000 - fn: 68385.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6858 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 233233.0000 - val_fn: 22767.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-18432000-18688000
[INFO] processing batch 18688000-18944000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6856 - tp: 123645.0000 - fp: 68355.0000 - tn: 699645.0000 - fn: 68355.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6856 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 233184.0000 - val_fn: 22816.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-18688000-18944000
[INFO] processing batch 18944000-19200000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6840 - tp: 123888.0000 - fp: 68112.0000 - tn: 699888.0000 - fn: 68112.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9113 - val_loss: 0.6850 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 233169.0000 - val_fn: 22831.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-18944000-19200000
[INFO] processing batch 19200000-19456000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6847 - tp: 123500.0000 - fp: 68500.0000 - tn: 699500.0000 - fn: 68500.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6841 - val_tp: 41189.0000 - val_fp: 22811.0000 - val_tn: 233189.0000 - val_fn: 22811.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-19200000-19456000
[INFO] processing batch 19456000-19712000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6834 - tp: 123689.0000 - fp: 68311.0000 - tn: 699689.0000 - fn: 68311.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6837 - val_tp: 41166.0000 - val_fp: 22834.0000 - val_tn: 233166.0000 - val_fn: 22834.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-19456000-19712000
[INFO] processing batch 19712000-19968000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6838 - tp: 123402.0000 - fp: 68598.0000 - tn: 699402.0000 - fn: 68598.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9107 - val_loss: 0.6824 - val_tp: 41242.0000 - val_fp: 22758.0000 - val_tn: 233242.0000 - val_fn: 22758.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-19712000-19968000
[INFO] processing batch 19968000-20224000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6827 - tp: 123541.0000 - fp: 68459.0000 - tn: 699541.0000 - fn: 68459.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6819 - val_tp: 41241.0000 - val_fp: 22759.0000 - val_tn: 233241.0000 - val_fn: 22759.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-19968000-20224000
[INFO] processing batch 20224000-20480000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6819 - tp: 123640.0000 - fp: 68360.0000 - tn: 699640.0000 - fn: 68360.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6817 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 233209.0000 - val_fn: 22791.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-20224000-20480000
[INFO] processing batch 20480000-20736000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6815 - tp: 123598.0000 - fp: 68402.0000 - tn: 699598.0000 - fn: 68402.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6809 - val_tp: 41235.0000 - val_fp: 22765.0000 - val_tn: 233235.0000 - val_fn: 22765.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-20480000-20736000
[INFO] processing batch 20736000-20992000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6805 - tp: 123769.0000 - fp: 68231.0000 - tn: 699769.0000 - fn: 68231.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9111 - val_loss: 0.6806 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-20736000-20992000
[INFO] processing batch 20992000-21248000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6810 - tp: 123459.0000 - fp: 68541.0000 - tn: 699459.0000 - fn: 68541.0000 - accuracy: 0.8572 - precision: 0.6430 - recall: 0.6430 - auc: 0.9108 - val_loss: 0.6802 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 233209.0000 - val_fn: 22791.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-20992000-21248000
[INFO] processing batch 21248000-21504000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6798 - tp: 123683.0000 - fp: 68317.0000 - tn: 699683.0000 - fn: 68317.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6800 - val_tp: 41183.0000 - val_fp: 22817.0000 - val_tn: 233183.0000 - val_fn: 22817.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-21248000-21504000
[INFO] processing batch 21504000-21760000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6797 - tp: 123564.0000 - fp: 68436.0000 - tn: 699564.0000 - fn: 68436.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6788 - val_tp: 41254.0000 - val_fp: 22746.0000 - val_tn: 233254.0000 - val_fn: 22746.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-21504000-21760000
[INFO] processing batch 21760000-22016000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6788 - tp: 123717.0000 - fp: 68283.0000 - tn: 699717.0000 - fn: 68283.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9111 - val_loss: 0.6782 - val_tp: 41270.0000 - val_fp: 22730.0000 - val_tn: 233270.0000 - val_fn: 22730.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-21760000-22016000
[INFO] processing batch 22016000-22272000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6784 - tp: 123690.0000 - fp: 68310.0000 - tn: 699690.0000 - fn: 68310.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6794 - val_tp: 41104.0000 - val_fp: 22896.0000 - val_tn: 233104.0000 - val_fn: 22896.0000 - val_accuracy: 0.8569 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-22016000-22272000
[INFO] processing batch 22272000-22528000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6780 - tp: 123672.0000 - fp: 68328.0000 - tn: 699672.0000 - fn: 68328.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6776 - val_tp: 41243.0000 - val_fp: 22757.0000 - val_tn: 233243.0000 - val_fn: 22757.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-22272000-22528000
[INFO] processing batch 22528000-22784000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6778 - tp: 123623.0000 - fp: 68377.0000 - tn: 699623.0000 - fn: 68377.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6767 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 233292.0000 - val_fn: 22708.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-22528000-22784000
[INFO] processing batch 22784000-23040000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6769 - tp: 123759.0000 - fp: 68241.0000 - tn: 699759.0000 - fn: 68241.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9111 - val_loss: 0.6774 - val_tp: 41180.0000 - val_fp: 22820.0000 - val_tn: 233180.0000 - val_fn: 22820.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-22784000-23040000
[INFO] processing batch 23040000-23296000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6773 - tp: 123507.0000 - fp: 68493.0000 - tn: 699507.0000 - fn: 68493.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6762 - val_tp: 41255.0000 - val_fp: 22745.0000 - val_tn: 233255.0000 - val_fn: 22745.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-23040000-23296000
[INFO] processing batch 23296000-23552000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6765 - tp: 123601.0000 - fp: 68399.0000 - tn: 699601.0000 - fn: 68399.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6762 - val_tp: 41213.0000 - val_fp: 22787.0000 - val_tn: 233213.0000 - val_fn: 22787.0000 - val_accuracy: 0.8576 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-23296000-23552000
[INFO] processing batch 23552000-23808000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6756 - tp: 123749.0000 - fp: 68251.0000 - tn: 699749.0000 - fn: 68251.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9111 - val_loss: 0.6750 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 233292.0000 - val_fn: 22708.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-23552000-23808000
[INFO] processing batch 23808000-24064000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6757 - tp: 123603.0000 - fp: 68397.0000 - tn: 699603.0000 - fn: 68397.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6758 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 233165.0000 - val_fn: 22835.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-23808000-24064000
[INFO] processing batch 24064000-24320000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6753 - tp: 123599.0000 - fp: 68401.0000 - tn: 699599.0000 - fn: 68401.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6752 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 233184.0000 - val_fn: 22816.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-24064000-24320000
[INFO] processing batch 24320000-24576000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6754 - tp: 123440.0000 - fp: 68560.0000 - tn: 699440.0000 - fn: 68560.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9107 - val_loss: 0.6750 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 233169.0000 - val_fn: 22831.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-24320000-24576000
[INFO] processing batch 24576000-24832000/24819975
[33m[LOSS] 0.6749761304855346[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6749761304855346  <  0.001
[33m[INFO] epoch 9/10[0m
[33m[INFO] loading file 1-50/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (24819975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
len(df.columns) 108
numFeatures 107
[INFO] columns: Index(['unixtime', 'modbus_function_code', 'modbus_transaction_id', 'service',
       's_port', 'classification', 'orig-192.168.1.48', 'orig-192.168.1.87',
       'orig-192.168.1.88', 'type-alert',
       ...
       'modbus_function_description-Read Tag Service',
       'modbus_function_description-Read Tag Service - Response',
       'modbus_function_description-Unknown Function Code',
       'modbus_function_description-Write Tag Service', 'scada_tag-0',
       'scada_tag-HMI_AIT202', 'scada_tag-HMI_FIT201', 'scada_tag-HMI_LIT101',
       'scada_tag-HMI_LIT301', 'scada_tag-HMI_LIT401'],
      dtype='object', length=108)
[INFO] processing batch 0-256000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.4177 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3694 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-0-256000
[INFO] processing batch 256000-512000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7320 - tp: 112918.0000 - fp: 79082.0000 - tn: 688918.0000 - fn: 79082.0000 - accuracy: 0.8352 - precision: 0.5881 - recall: 0.5881 - auc: 0.8967 - val_loss: 0.7765 - val_tp: 33927.0000 - val_fp: 30073.0000 - val_tn: 225927.0000 - val_fn: 30073.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-256000-512000
[INFO] processing batch 512000-768000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6157 - tp: 138284.0000 - fp: 53716.0000 - tn: 714284.0000 - fn: 53716.0000 - accuracy: 0.8881 - precision: 0.7202 - recall: 0.7202 - auc: 0.9299 - val_loss: 0.4042 - val_tp: 62058.0000 - val_fp: 1942.0000 - val_tn: 254058.0000 - val_fn: 1942.0000 - val_accuracy: 0.9879 - val_precision: 0.9697 - val_recall: 0.9697 - val_auc: 0.9924
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-512000-768000
[INFO] processing batch 768000-1024000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7061 - tp: 117250.0000 - fp: 74750.0000 - tn: 693250.0000 - fn: 74750.0000 - accuracy: 0.8443 - precision: 0.6107 - recall: 0.6107 - auc: 0.9025 - val_loss: 0.4993 - val_tp: 55591.0000 - val_fp: 8409.0000 - val_tn: 247591.0000 - val_fn: 8409.0000 - val_accuracy: 0.9474 - val_precision: 0.8686 - val_recall: 0.8686 - val_auc: 0.9672
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-768000-1024000
[INFO] processing batch 1024000-1280000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6344 - tp: 133967.0000 - fp: 58033.0000 - tn: 709967.0000 - fn: 58033.0000 - accuracy: 0.8791 - precision: 0.6977 - recall: 0.6977 - auc: 0.9247 - val_loss: 0.3963 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-1024000-1280000
[INFO] processing batch 1280000-1536000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.3677 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3333 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-1280000-1536000
[INFO] processing batch 1536000-1792000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.3065 - tp: 191999.0000 - fp: 1.0000 - tn: 767999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2817 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-1536000-1792000
[INFO] processing batch 1792000-2048000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.5555 - tp: 148221.0000 - fp: 43779.0000 - tn: 724221.0000 - fn: 43779.0000 - accuracy: 0.9088 - precision: 0.7720 - recall: 0.7720 - auc: 0.9429 - val_loss: 0.3901 - val_tp: 57941.0000 - val_fp: 6059.0000 - val_tn: 249941.0000 - val_fn: 6059.0000 - val_accuracy: 0.9621 - val_precision: 0.9053 - val_recall: 0.9053 - val_auc: 0.9763
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-1792000-2048000
[INFO] processing batch 2048000-2304000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.5969 - tp: 141714.0000 - fp: 50286.0000 - tn: 717714.0000 - fn: 50286.0000 - accuracy: 0.8952 - precision: 0.7381 - recall: 0.7381 - auc: 0.9344 - val_loss: 0.2771 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-2048000-2304000
[INFO] processing batch 2304000-2560000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.2646 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2475 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-2304000-2560000
[INFO] processing batch 2560000-2816000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2325 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2181 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-2560000-2816000
[INFO] processing batch 2816000-3072000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.5563 - tp: 148720.0000 - fp: 43280.0000 - tn: 724720.0000 - fn: 43280.0000 - accuracy: 0.9098 - precision: 0.7746 - recall: 0.7746 - auc: 0.9436 - val_loss: 0.7581 - val_tp: 40961.0000 - val_fp: 23039.0000 - val_tn: 232961.0000 - val_fn: 23039.0000 - val_accuracy: 0.8560 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.9100
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-2816000-3072000
[INFO] processing batch 3072000-3328000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6862 - tp: 131495.0000 - fp: 60505.0000 - tn: 707495.0000 - fn: 60505.0000 - accuracy: 0.8739 - precision: 0.6849 - recall: 0.6849 - auc: 0.9213 - val_loss: 0.2322 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-3072000-3328000
[INFO] processing batch 3328000-3584000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.2253 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2135 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-3328000-3584000
[INFO] processing batch 3584000-3840000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.2023 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1914 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-3584000-3840000
[INFO] processing batch 3840000-4096000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.4869 - tp: 157534.0000 - fp: 34466.0000 - tn: 733534.0000 - fn: 34466.0000 - accuracy: 0.9282 - precision: 0.8205 - recall: 0.8205 - auc: 0.9551 - val_loss: 0.4944 - val_tp: 52219.0000 - val_fp: 11781.0000 - val_tn: 244219.0000 - val_fn: 11781.0000 - val_accuracy: 0.9264 - val_precision: 0.8159 - val_recall: 0.8159 - val_auc: 0.9540
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-3840000-4096000
[INFO] processing batch 4096000-4352000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1991 - tp: 190188.0000 - fp: 1812.0000 - tn: 766188.0000 - fn: 1812.0000 - accuracy: 0.9962 - precision: 0.9906 - recall: 0.9906 - auc: 0.9975 - val_loss: 0.1751 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-4096000-4352000
[INFO] processing batch 4352000-4608000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1674 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1597 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-4352000-4608000
[INFO] processing batch 4608000-4864000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.4541 - tp: 161451.0000 - fp: 30549.0000 - tn: 737451.0000 - fn: 30549.0000 - accuracy: 0.9364 - precision: 0.8409 - recall: 0.8409 - auc: 0.9602 - val_loss: 0.1585 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-4608000-4864000
[INFO] processing batch 4864000-5120000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1541 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1479 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-4864000-5120000
[INFO] processing batch 5120000-5376000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1420 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1362 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-5120000-5376000
[INFO] processing batch 5376000-5632000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1311 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1261 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-5376000-5632000
[INFO] processing batch 5632000-5888000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.5235 - tp: 155809.0000 - fp: 36191.0000 - tn: 731809.0000 - fn: 36191.0000 - accuracy: 0.9246 - precision: 0.8115 - recall: 0.8115 - auc: 0.9529 - val_loss: 0.1293 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-5632000-5888000
[INFO] processing batch 5888000-6144000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1269 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1227 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-5888000-6144000
[INFO] processing batch 6144000-6400000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.3212 - tp: 174156.0000 - fp: 17844.0000 - tn: 750156.0000 - fn: 17844.0000 - accuracy: 0.9628 - precision: 0.9071 - recall: 0.9071 - auc: 0.9768 - val_loss: 0.8939 - val_tp: 41108.0000 - val_fp: 22892.0000 - val_tn: 233108.0000 - val_fn: 22892.0000 - val_accuracy: 0.8569 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-6144000-6400000
[INFO] processing batch 6400000-6656000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7132 - tp: 138766.0000 - fp: 53234.0000 - tn: 714766.0000 - fn: 53234.0000 - accuracy: 0.8891 - precision: 0.7227 - recall: 0.7227 - auc: 0.9307 - val_loss: 0.1308 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-6400000-6656000
[INFO] processing batch 6656000-6912000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1294 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1253 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-6656000-6912000
[INFO] processing batch 6912000-7168000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1209 - tp: 191998.0000 - fp: 2.0000 - tn: 767998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1164 - val_tp: 63999.0000 - val_fp: 1.0000 - val_tn: 255999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-6912000-7168000
[INFO] processing batch 7168000-7424000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1124 - tp: 191999.0000 - fp: 1.0000 - tn: 767999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8853 - val_tp: 44344.0000 - val_fp: 19656.0000 - val_tn: 236344.0000 - val_fn: 19656.0000 - val_accuracy: 0.8772 - val_precision: 0.6929 - val_recall: 0.6929 - val_auc: 0.7313
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-7168000-7424000
[INFO] processing batch 7424000-7680000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.7455 - tp: 102062.0000 - fp: 89938.0000 - tn: 678062.0000 - fn: 89938.0000 - accuracy: 0.8126 - precision: 0.5316 - recall: 0.5316 - auc: 0.5901 - val_loss: 1.3177 - val_tp: 49859.0000 - val_fp: 14141.0000 - val_tn: 241859.0000 - val_fn: 14141.0000 - val_accuracy: 0.9116 - val_precision: 0.7790 - val_recall: 0.7790 - val_auc: 0.8067
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-7424000-7680000
[INFO] processing batch 7680000-7936000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1144 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1113 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-7680000-7936000
[INFO] processing batch 7936000-8192000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1080 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1045 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-7936000-8192000
[INFO] processing batch 8192000-8448000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.0647 - tp: 161781.0000 - fp: 30219.0000 - tn: 737781.0000 - fn: 30219.0000 - accuracy: 0.9370 - precision: 0.8426 - recall: 0.8426 - auc: 0.8623 - val_loss: 0.1618 - val_tp: 63369.0000 - val_fp: 631.0000 - val_tn: 255369.0000 - val_fn: 631.0000 - val_accuracy: 0.9961 - val_precision: 0.9901 - val_recall: 0.9901 - val_auc: 0.9914
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-8192000-8448000
[INFO] processing batch 8448000-8704000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 2.1892 - tp: 123282.0000 - fp: 68718.0000 - tn: 699282.0000 - fn: 68718.0000 - accuracy: 0.8568 - precision: 0.6421 - recall: 0.6421 - auc: 0.6868 - val_loss: 2.2596 - val_tp: 39692.0000 - val_fp: 24308.0000 - val_tn: 231692.0000 - val_fn: 24308.0000 - val_accuracy: 0.8481 - val_precision: 0.6202 - val_recall: 0.6202 - val_auc: 0.6677
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-8448000-8704000
[INFO] processing batch 8704000-8960000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2229 - tp: 188028.0000 - fp: 3972.0000 - tn: 764028.0000 - fn: 3972.0000 - accuracy: 0.9917 - precision: 0.9793 - recall: 0.9793 - auc: 0.9820 - val_loss: 0.1039 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-8704000-8960000
[INFO] processing batch 8960000-9216000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1011 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0981 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-8960000-9216000
[INFO] processing batch 9216000-9472000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 2.0835 - tp: 120440.0000 - fp: 71560.0000 - tn: 696440.0000 - fn: 71560.0000 - accuracy: 0.8509 - precision: 0.6273 - recall: 0.6273 - auc: 0.6733 - val_loss: 0.1021 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-9216000-9472000
[INFO] processing batch 9472000-9728000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.9188 - tp: 161553.0000 - fp: 30447.0000 - tn: 737553.0000 - fn: 30447.0000 - accuracy: 0.9366 - precision: 0.8414 - recall: 0.8414 - auc: 0.8976 - val_loss: 0.9418 - val_tp: 53468.0000 - val_fp: 10532.0000 - val_tn: 245468.0000 - val_fn: 10532.0000 - val_accuracy: 0.9342 - val_precision: 0.8354 - val_recall: 0.8354 - val_auc: 0.8971
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-9472000-9728000
[INFO] processing batch 9728000-9984000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1005 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0978 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-9728000-9984000
[INFO] processing batch 9984000-10240000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.0952 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0925 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-9984000-10240000
[INFO] processing batch 10240000-10496000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1557 - tp: 189510.0000 - fp: 2490.0000 - tn: 765510.0000 - fn: 2490.0000 - accuracy: 0.9948 - precision: 0.9870 - recall: 0.9870 - auc: 0.9921 - val_loss: 2.4560 - val_tp: 33975.0000 - val_fp: 30025.0000 - val_tn: 225975.0000 - val_fn: 30025.0000 - val_accuracy: 0.8123 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.7068
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-10240000-10496000
[INFO] processing batch 10496000-10752000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.3919 - tp: 101670.0000 - fp: 90330.0000 - tn: 677670.0000 - fn: 90330.0000 - accuracy: 0.8118 - precision: 0.5295 - recall: 0.5295 - auc: 0.7059 - val_loss: 2.3033 - val_tp: 34015.0000 - val_fp: 29985.0000 - val_tn: 226015.0000 - val_fn: 29985.0000 - val_accuracy: 0.8126 - val_precision: 0.5315 - val_recall: 0.5315 - val_auc: 0.7072
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-10496000-10752000
[INFO] processing batch 10752000-11008000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.2490 - tp: 101693.0000 - fp: 90307.0000 - tn: 677693.0000 - fn: 90307.0000 - accuracy: 0.8119 - precision: 0.5297 - recall: 0.5297 - auc: 0.7209 - val_loss: 0.5897 - val_tp: 56989.0000 - val_fp: 7011.0000 - val_tn: 248989.0000 - val_fn: 7011.0000 - val_accuracy: 0.9562 - val_precision: 0.8905 - val_recall: 0.8905 - val_auc: 0.9452
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-10752000-11008000
[INFO] processing batch 11008000-11264000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1038 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1016 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-11008000-11264000
[INFO] processing batch 11264000-11520000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.0992 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0967 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-11264000-11520000
[INFO] processing batch 11520000-11776000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.0944 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0921 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-11520000-11776000
[INFO] processing batch 11776000-12032000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.9145 - tp: 156412.0000 - fp: 35588.0000 - tn: 732412.0000 - fn: 35588.0000 - accuracy: 0.9259 - precision: 0.8146 - recall: 0.8146 - auc: 0.9073 - val_loss: 1.6630 - val_tp: 41134.0000 - val_fp: 22866.0000 - val_tn: 233134.0000 - val_fn: 22866.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.8214
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-11776000-12032000
[INFO] processing batch 12032000-12288000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.6349 - tp: 123527.0000 - fp: 68473.0000 - tn: 699527.0000 - fn: 68473.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.8217 - val_loss: 1.6025 - val_tp: 41219.0000 - val_fp: 22781.0000 - val_tn: 233219.0000 - val_fn: 22781.0000 - val_accuracy: 0.8576 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.8220
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-12032000-12288000
[INFO] processing batch 12288000-12544000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.5770 - tp: 123560.0000 - fp: 68440.0000 - tn: 699560.0000 - fn: 68440.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.8217 - val_loss: 1.0989 - val_tp: 41268.0000 - val_fp: 22732.0000 - val_tn: 233268.0000 - val_fn: 22732.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.8958
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-12288000-12544000
[INFO] processing batch 12544000-12800000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.9896 - tp: 123588.0000 - fp: 68412.0000 - tn: 699588.0000 - fn: 68412.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.9628 - val_tp: 41269.0000 - val_fp: 22731.0000 - val_tn: 233269.0000 - val_fn: 22731.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-12544000-12800000
[INFO] processing batch 12800000-13056000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.9443 - tp: 123531.0000 - fp: 68469.0000 - tn: 699531.0000 - fn: 68469.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.9224 - val_tp: 41181.0000 - val_fp: 22819.0000 - val_tn: 233181.0000 - val_fn: 22819.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-12800000-13056000
[INFO] processing batch 13056000-13312000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9031 - tp: 123615.0000 - fp: 68385.0000 - tn: 699615.0000 - fn: 68385.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.8852 - val_tp: 41192.0000 - val_fp: 22808.0000 - val_tn: 233192.0000 - val_fn: 22808.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-13056000-13312000
[INFO] processing batch 13312000-13568000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8709 - tp: 123437.0000 - fp: 68563.0000 - tn: 699437.0000 - fn: 68563.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9107 - val_loss: 0.8542 - val_tp: 41179.0000 - val_fp: 22821.0000 - val_tn: 233179.0000 - val_fn: 22821.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-13312000-13568000
[INFO] processing batch 13568000-13824000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8407 - tp: 123539.0000 - fp: 68461.0000 - tn: 699539.0000 - fn: 68461.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.8264 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-13568000-13824000
[INFO] processing batch 13824000-14080000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8156 - tp: 123556.0000 - fp: 68444.0000 - tn: 699556.0000 - fn: 68444.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.8044 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 233173.0000 - val_fn: 22827.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-13824000-14080000
[INFO] processing batch 14080000-14336000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7932 - tp: 123681.0000 - fp: 68319.0000 - tn: 699681.0000 - fn: 68319.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9109 - val_loss: 0.7836 - val_tp: 41221.0000 - val_fp: 22779.0000 - val_tn: 233221.0000 - val_fn: 22779.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-14080000-14336000
[INFO] processing batch 14336000-14592000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7764 - tp: 123523.0000 - fp: 68477.0000 - tn: 699523.0000 - fn: 68477.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9107 - val_loss: 0.7675 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 233197.0000 - val_fn: 22803.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-14336000-14592000
[INFO] processing batch 14592000-14848000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7599 - tp: 123652.0000 - fp: 68348.0000 - tn: 699652.0000 - fn: 68348.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.7530 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-14592000-14848000
[INFO] processing batch 14848000-15104000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7473 - tp: 123594.0000 - fp: 68406.0000 - tn: 699594.0000 - fn: 68406.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.7412 - val_tp: 41205.0000 - val_fp: 22795.0000 - val_tn: 233205.0000 - val_fn: 22795.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-14848000-15104000
[INFO] processing batch 15104000-15360000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7360 - tp: 123629.0000 - fp: 68371.0000 - tn: 699629.0000 - fn: 68371.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.7305 - val_tp: 41234.0000 - val_fp: 22766.0000 - val_tn: 233234.0000 - val_fn: 22766.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-15104000-15360000
[INFO] processing batch 15360000-15616000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7267 - tp: 123632.0000 - fp: 68368.0000 - tn: 699632.0000 - fn: 68368.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.7215 - val_tp: 41266.0000 - val_fp: 22734.0000 - val_tn: 233266.0000 - val_fn: 22734.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-15360000-15616000
[INFO] processing batch 15616000-15872000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7196 - tp: 123527.0000 - fp: 68473.0000 - tn: 699527.0000 - fn: 68473.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.7157 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 233197.0000 - val_fn: 22803.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-15616000-15872000
[INFO] processing batch 15872000-16128000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7131 - tp: 123531.0000 - fp: 68469.0000 - tn: 699531.0000 - fn: 68469.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.7103 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 233173.0000 - val_fn: 22827.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-15872000-16128000
[INFO] processing batch 16128000-16384000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7065 - tp: 123781.0000 - fp: 68219.0000 - tn: 699781.0000 - fn: 68219.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9112 - val_loss: 0.7051 - val_tp: 41195.0000 - val_fp: 22805.0000 - val_tn: 233195.0000 - val_fn: 22805.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-16128000-16384000
[INFO] processing batch 16384000-16640000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7029 - tp: 123621.0000 - fp: 68379.0000 - tn: 699621.0000 - fn: 68379.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.7016 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 233165.0000 - val_fn: 22835.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-16384000-16640000
[INFO] processing batch 16640000-16896000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7003 - tp: 123417.0000 - fp: 68583.0000 - tn: 699417.0000 - fn: 68583.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9107 - val_loss: 0.6973 - val_tp: 41230.0000 - val_fp: 22770.0000 - val_tn: 233230.0000 - val_fn: 22770.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-16640000-16896000
[INFO] processing batch 16896000-17152000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6964 - tp: 123600.0000 - fp: 68400.0000 - tn: 699600.0000 - fn: 68400.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6951 - val_tp: 41198.0000 - val_fp: 22802.0000 - val_tn: 233198.0000 - val_fn: 22802.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-16896000-17152000
[INFO] processing batch 17152000-17408000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6935 - tp: 123711.0000 - fp: 68289.0000 - tn: 699711.0000 - fn: 68289.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9112 - val_loss: 0.6933 - val_tp: 41168.0000 - val_fp: 22832.0000 - val_tn: 233168.0000 - val_fn: 22832.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-17152000-17408000
[INFO] processing batch 17408000-17664000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6915 - tp: 123701.0000 - fp: 68299.0000 - tn: 699701.0000 - fn: 68299.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9111 - val_loss: 0.6921 - val_tp: 41118.0000 - val_fp: 22882.0000 - val_tn: 233118.0000 - val_fn: 22882.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-17408000-17664000
[INFO] processing batch 17664000-17920000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6905 - tp: 123546.0000 - fp: 68454.0000 - tn: 699546.0000 - fn: 68454.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6909 - val_tp: 41089.0000 - val_fp: 22911.0000 - val_tn: 233089.0000 - val_fn: 22911.0000 - val_accuracy: 0.8568 - val_precision: 0.6420 - val_recall: 0.6420 - val_auc: 0.9105
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-17664000-17920000
[INFO] processing batch 17920000-18176000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6885 - tp: 123681.0000 - fp: 68319.0000 - tn: 699681.0000 - fn: 68319.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6878 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 233233.0000 - val_fn: 22767.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-17920000-18176000
[INFO] processing batch 18176000-18432000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6875 - tp: 123640.0000 - fp: 68360.0000 - tn: 699640.0000 - fn: 68360.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6860 - val_tp: 41298.0000 - val_fp: 22702.0000 - val_tn: 233298.0000 - val_fn: 22702.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-18176000-18432000
[INFO] processing batch 18432000-18688000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6866 - tp: 123615.0000 - fp: 68385.0000 - tn: 699615.0000 - fn: 68385.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6858 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 233233.0000 - val_fn: 22767.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-18432000-18688000
[INFO] processing batch 18688000-18944000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6856 - tp: 123645.0000 - fp: 68355.0000 - tn: 699645.0000 - fn: 68355.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6855 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 233184.0000 - val_fn: 22816.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-18688000-18944000
[INFO] processing batch 18944000-19200000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6840 - tp: 123888.0000 - fp: 68112.0000 - tn: 699888.0000 - fn: 68112.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9113 - val_loss: 0.6850 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 233169.0000 - val_fn: 22831.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-18944000-19200000
[INFO] processing batch 19200000-19456000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6847 - tp: 123500.0000 - fp: 68500.0000 - tn: 699500.0000 - fn: 68500.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6841 - val_tp: 41189.0000 - val_fp: 22811.0000 - val_tn: 233189.0000 - val_fn: 22811.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-19200000-19456000
[INFO] processing batch 19456000-19712000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6834 - tp: 123689.0000 - fp: 68311.0000 - tn: 699689.0000 - fn: 68311.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6837 - val_tp: 41166.0000 - val_fp: 22834.0000 - val_tn: 233166.0000 - val_fn: 22834.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-19456000-19712000
[INFO] processing batch 19712000-19968000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6838 - tp: 123402.0000 - fp: 68598.0000 - tn: 699402.0000 - fn: 68598.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9107 - val_loss: 0.6824 - val_tp: 41242.0000 - val_fp: 22758.0000 - val_tn: 233242.0000 - val_fn: 22758.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-19712000-19968000
[INFO] processing batch 19968000-20224000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6827 - tp: 123541.0000 - fp: 68459.0000 - tn: 699541.0000 - fn: 68459.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6818 - val_tp: 41241.0000 - val_fp: 22759.0000 - val_tn: 233241.0000 - val_fn: 22759.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-19968000-20224000
[INFO] processing batch 20224000-20480000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6819 - tp: 123640.0000 - fp: 68360.0000 - tn: 699640.0000 - fn: 68360.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6816 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 233209.0000 - val_fn: 22791.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-20224000-20480000
[INFO] processing batch 20480000-20736000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6815 - tp: 123598.0000 - fp: 68402.0000 - tn: 699598.0000 - fn: 68402.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6809 - val_tp: 41235.0000 - val_fp: 22765.0000 - val_tn: 233235.0000 - val_fn: 22765.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-20480000-20736000
[INFO] processing batch 20736000-20992000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6804 - tp: 123769.0000 - fp: 68231.0000 - tn: 699769.0000 - fn: 68231.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9111 - val_loss: 0.6806 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-20736000-20992000
[INFO] processing batch 20992000-21248000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6810 - tp: 123459.0000 - fp: 68541.0000 - tn: 699459.0000 - fn: 68541.0000 - accuracy: 0.8572 - precision: 0.6430 - recall: 0.6430 - auc: 0.9108 - val_loss: 0.6802 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 233209.0000 - val_fn: 22791.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-20992000-21248000
[INFO] processing batch 21248000-21504000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6798 - tp: 123683.0000 - fp: 68317.0000 - tn: 699683.0000 - fn: 68317.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6800 - val_tp: 41183.0000 - val_fp: 22817.0000 - val_tn: 233183.0000 - val_fn: 22817.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-21248000-21504000
[INFO] processing batch 21504000-21760000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6797 - tp: 123564.0000 - fp: 68436.0000 - tn: 699564.0000 - fn: 68436.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6788 - val_tp: 41254.0000 - val_fp: 22746.0000 - val_tn: 233254.0000 - val_fn: 22746.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-21504000-21760000
[INFO] processing batch 21760000-22016000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6788 - tp: 123717.0000 - fp: 68283.0000 - tn: 699717.0000 - fn: 68283.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9111 - val_loss: 0.6782 - val_tp: 41270.0000 - val_fp: 22730.0000 - val_tn: 233270.0000 - val_fn: 22730.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-21760000-22016000
[INFO] processing batch 22016000-22272000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6784 - tp: 123690.0000 - fp: 68310.0000 - tn: 699690.0000 - fn: 68310.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6794 - val_tp: 41104.0000 - val_fp: 22896.0000 - val_tn: 233104.0000 - val_fn: 22896.0000 - val_accuracy: 0.8569 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-22016000-22272000
[INFO] processing batch 22272000-22528000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6780 - tp: 123672.0000 - fp: 68328.0000 - tn: 699672.0000 - fn: 68328.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6776 - val_tp: 41243.0000 - val_fp: 22757.0000 - val_tn: 233243.0000 - val_fn: 22757.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-22272000-22528000
[INFO] processing batch 22528000-22784000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6777 - tp: 123623.0000 - fp: 68377.0000 - tn: 699623.0000 - fn: 68377.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6767 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 233292.0000 - val_fn: 22708.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-22528000-22784000
[INFO] processing batch 22784000-23040000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6769 - tp: 123759.0000 - fp: 68241.0000 - tn: 699759.0000 - fn: 68241.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9111 - val_loss: 0.6774 - val_tp: 41180.0000 - val_fp: 22820.0000 - val_tn: 233180.0000 - val_fn: 22820.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-22784000-23040000
[INFO] processing batch 23040000-23296000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6772 - tp: 123507.0000 - fp: 68493.0000 - tn: 699507.0000 - fn: 68493.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6762 - val_tp: 41255.0000 - val_fp: 22745.0000 - val_tn: 233255.0000 - val_fn: 22745.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-23040000-23296000
[INFO] processing batch 23296000-23552000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6765 - tp: 123601.0000 - fp: 68399.0000 - tn: 699601.0000 - fn: 68399.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6762 - val_tp: 41213.0000 - val_fp: 22787.0000 - val_tn: 233213.0000 - val_fn: 22787.0000 - val_accuracy: 0.8576 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-23296000-23552000
[INFO] processing batch 23552000-23808000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6756 - tp: 123749.0000 - fp: 68251.0000 - tn: 699749.0000 - fn: 68251.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9111 - val_loss: 0.6750 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 233292.0000 - val_fn: 22708.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-23552000-23808000
[INFO] processing batch 23808000-24064000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6757 - tp: 123603.0000 - fp: 68397.0000 - tn: 699603.0000 - fn: 68397.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6758 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 233165.0000 - val_fn: 22835.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-23808000-24064000
[INFO] processing batch 24064000-24320000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6753 - tp: 123599.0000 - fp: 68401.0000 - tn: 699599.0000 - fn: 68401.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6752 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 233184.0000 - val_fn: 22816.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-24064000-24320000
[INFO] processing batch 24320000-24576000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6754 - tp: 123440.0000 - fp: 68560.0000 - tn: 699440.0000 - fn: 68560.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9107 - val_loss: 0.6750 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 233169.0000 - val_fn: 22831.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-24320000-24576000
[INFO] processing batch 24576000-24832000/24819975
[33m[LOSS] 0.6749686727523804[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6749686727523804  <  0.001
[33m[INFO] epoch 10/10[0m
[33m[INFO] loading file 1-50/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (24819975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
len(df.columns) 108
numFeatures 107
[INFO] columns: Index(['unixtime', 'modbus_function_code', 'modbus_transaction_id', 'service',
       's_port', 'classification', 'orig-192.168.1.48', 'orig-192.168.1.87',
       'orig-192.168.1.88', 'type-alert',
       ...
       'modbus_function_description-Read Tag Service',
       'modbus_function_description-Read Tag Service - Response',
       'modbus_function_description-Unknown Function Code',
       'modbus_function_description-Write Tag Service', 'scada_tag-0',
       'scada_tag-HMI_AIT202', 'scada_tag-HMI_FIT201', 'scada_tag-HMI_LIT101',
       'scada_tag-HMI_LIT301', 'scada_tag-HMI_LIT401'],
      dtype='object', length=108)
[INFO] processing batch 0-256000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.4177 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3694 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-0-256000
[INFO] processing batch 256000-512000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7319 - tp: 112918.0000 - fp: 79082.0000 - tn: 688918.0000 - fn: 79082.0000 - accuracy: 0.8352 - precision: 0.5881 - recall: 0.5881 - auc: 0.8979 - val_loss: 0.7767 - val_tp: 33927.0000 - val_fp: 30073.0000 - val_tn: 225927.0000 - val_fn: 30073.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-256000-512000
[INFO] processing batch 512000-768000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6157 - tp: 138284.0000 - fp: 53716.0000 - tn: 714284.0000 - fn: 53716.0000 - accuracy: 0.8881 - precision: 0.7202 - recall: 0.7202 - auc: 0.9298 - val_loss: 0.4038 - val_tp: 62058.0000 - val_fp: 1942.0000 - val_tn: 254058.0000 - val_fn: 1942.0000 - val_accuracy: 0.9879 - val_precision: 0.9697 - val_recall: 0.9697 - val_auc: 0.9924
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-512000-768000
[INFO] processing batch 768000-1024000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7061 - tp: 117250.0000 - fp: 74750.0000 - tn: 693250.0000 - fn: 74750.0000 - accuracy: 0.8443 - precision: 0.6107 - recall: 0.6107 - auc: 0.9021 - val_loss: 0.4996 - val_tp: 55591.0000 - val_fp: 8409.0000 - val_tn: 247591.0000 - val_fn: 8409.0000 - val_accuracy: 0.9474 - val_precision: 0.8686 - val_recall: 0.8686 - val_auc: 0.9672
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-768000-1024000
[INFO] processing batch 1024000-1280000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6344 - tp: 133967.0000 - fp: 58033.0000 - tn: 709967.0000 - fn: 58033.0000 - accuracy: 0.8791 - precision: 0.6977 - recall: 0.6977 - auc: 0.9245 - val_loss: 0.3962 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-1024000-1280000
[INFO] processing batch 1280000-1536000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.3678 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3335 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-1280000-1536000
[INFO] processing batch 1536000-1792000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.3066 - tp: 191999.0000 - fp: 1.0000 - tn: 767999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2818 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-1536000-1792000
[INFO] processing batch 1792000-2048000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.5554 - tp: 148221.0000 - fp: 43779.0000 - tn: 724221.0000 - fn: 43779.0000 - accuracy: 0.9088 - precision: 0.7720 - recall: 0.7720 - auc: 0.9438 - val_loss: 0.3903 - val_tp: 57941.0000 - val_fp: 6059.0000 - val_tn: 249941.0000 - val_fn: 6059.0000 - val_accuracy: 0.9621 - val_precision: 0.9053 - val_recall: 0.9053 - val_auc: 0.9763
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-1792000-2048000
[INFO] processing batch 2048000-2304000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.5969 - tp: 141714.0000 - fp: 50286.0000 - tn: 717714.0000 - fn: 50286.0000 - accuracy: 0.8952 - precision: 0.7381 - recall: 0.7381 - auc: 0.9343 - val_loss: 0.2772 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-2048000-2304000
[INFO] processing batch 2304000-2560000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.2646 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2475 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-2304000-2560000
[INFO] processing batch 2560000-2816000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2325 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2180 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-2560000-2816000
[INFO] processing batch 2816000-3072000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.5563 - tp: 148720.0000 - fp: 43280.0000 - tn: 724720.0000 - fn: 43280.0000 - accuracy: 0.9098 - precision: 0.7746 - recall: 0.7746 - auc: 0.9436 - val_loss: 0.7580 - val_tp: 40961.0000 - val_fp: 23039.0000 - val_tn: 232961.0000 - val_fn: 23039.0000 - val_accuracy: 0.8560 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.9100
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-2816000-3072000
[INFO] processing batch 3072000-3328000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6862 - tp: 131495.0000 - fp: 60505.0000 - tn: 707495.0000 - fn: 60505.0000 - accuracy: 0.8739 - precision: 0.6849 - recall: 0.6849 - auc: 0.9210 - val_loss: 0.2321 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-3072000-3328000
[INFO] processing batch 3328000-3584000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.2253 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2134 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-3328000-3584000
[INFO] processing batch 3584000-3840000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.2023 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1913 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-3584000-3840000
[INFO] processing batch 3840000-4096000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.4869 - tp: 157534.0000 - fp: 34466.0000 - tn: 733534.0000 - fn: 34466.0000 - accuracy: 0.9282 - precision: 0.8205 - recall: 0.8205 - auc: 0.9551 - val_loss: 0.4944 - val_tp: 52219.0000 - val_fp: 11781.0000 - val_tn: 244219.0000 - val_fn: 11781.0000 - val_accuracy: 0.9264 - val_precision: 0.8159 - val_recall: 0.8159 - val_auc: 0.9540
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-3840000-4096000
[INFO] processing batch 4096000-4352000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1991 - tp: 190188.0000 - fp: 1812.0000 - tn: 766188.0000 - fn: 1812.0000 - accuracy: 0.9962 - precision: 0.9906 - recall: 0.9906 - auc: 0.9979 - val_loss: 0.1751 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-4096000-4352000
[INFO] processing batch 4352000-4608000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1674 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1597 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-4352000-4608000
[INFO] processing batch 4608000-4864000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.4540 - tp: 161451.0000 - fp: 30549.0000 - tn: 737451.0000 - fn: 30549.0000 - accuracy: 0.9364 - precision: 0.8409 - recall: 0.8409 - auc: 0.9602 - val_loss: 0.1584 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-4608000-4864000
[INFO] processing batch 4864000-5120000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1540 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1478 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-4864000-5120000
[INFO] processing batch 5120000-5376000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1420 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1361 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-5120000-5376000
[INFO] processing batch 5376000-5632000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1311 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1261 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-5376000-5632000
[INFO] processing batch 5632000-5888000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.5235 - tp: 155809.0000 - fp: 36191.0000 - tn: 731809.0000 - fn: 36191.0000 - accuracy: 0.9246 - precision: 0.8115 - recall: 0.8115 - auc: 0.9529 - val_loss: 0.1292 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-5632000-5888000
[INFO] processing batch 5888000-6144000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1269 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1226 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-5888000-6144000
[INFO] processing batch 6144000-6400000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.3212 - tp: 174156.0000 - fp: 17844.0000 - tn: 750156.0000 - fn: 17844.0000 - accuracy: 0.9628 - precision: 0.9071 - recall: 0.9071 - auc: 0.9768 - val_loss: 0.8942 - val_tp: 41108.0000 - val_fp: 22892.0000 - val_tn: 233108.0000 - val_fn: 22892.0000 - val_accuracy: 0.8569 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-6144000-6400000
[INFO] processing batch 6400000-6656000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7131 - tp: 138766.0000 - fp: 53234.0000 - tn: 714766.0000 - fn: 53234.0000 - accuracy: 0.8891 - precision: 0.7227 - recall: 0.7227 - auc: 0.9305 - val_loss: 0.1307 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-6400000-6656000
[INFO] processing batch 6656000-6912000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1294 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1253 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-6656000-6912000
[INFO] processing batch 6912000-7168000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1208 - tp: 191998.0000 - fp: 2.0000 - tn: 767998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1164 - val_tp: 63999.0000 - val_fp: 1.0000 - val_tn: 255999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-6912000-7168000
[INFO] processing batch 7168000-7424000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1124 - tp: 191999.0000 - fp: 1.0000 - tn: 767999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8858 - val_tp: 44344.0000 - val_fp: 19656.0000 - val_tn: 236344.0000 - val_fn: 19656.0000 - val_accuracy: 0.8772 - val_precision: 0.6929 - val_recall: 0.6929 - val_auc: 0.7313
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-7168000-7424000
[INFO] processing batch 7424000-7680000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.7462 - tp: 102062.0000 - fp: 89938.0000 - tn: 678062.0000 - fn: 89938.0000 - accuracy: 0.8126 - precision: 0.5316 - recall: 0.5316 - auc: 0.5901 - val_loss: 1.3181 - val_tp: 49859.0000 - val_fp: 14141.0000 - val_tn: 241859.0000 - val_fn: 14141.0000 - val_accuracy: 0.9116 - val_precision: 0.7790 - val_recall: 0.7790 - val_auc: 0.8067
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-7424000-7680000
[INFO] processing batch 7680000-7936000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1144 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1113 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-7680000-7936000
[INFO] processing batch 7936000-8192000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1080 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1045 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-7936000-8192000
[INFO] processing batch 8192000-8448000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.0650 - tp: 161781.0000 - fp: 30219.0000 - tn: 737781.0000 - fn: 30219.0000 - accuracy: 0.9370 - precision: 0.8426 - recall: 0.8426 - auc: 0.8623 - val_loss: 0.1618 - val_tp: 63369.0000 - val_fp: 631.0000 - val_tn: 255369.0000 - val_fn: 631.0000 - val_accuracy: 0.9961 - val_precision: 0.9901 - val_recall: 0.9901 - val_auc: 0.9914
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-8192000-8448000
[INFO] processing batch 8448000-8704000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 2.1901 - tp: 123282.0000 - fp: 68718.0000 - tn: 699282.0000 - fn: 68718.0000 - accuracy: 0.8568 - precision: 0.6421 - recall: 0.6421 - auc: 0.6867 - val_loss: 2.2607 - val_tp: 39692.0000 - val_fp: 24308.0000 - val_tn: 231692.0000 - val_fn: 24308.0000 - val_accuracy: 0.8481 - val_precision: 0.6202 - val_recall: 0.6202 - val_auc: 0.6677
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-8448000-8704000
[INFO] processing batch 8704000-8960000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.2229 - tp: 188028.0000 - fp: 3972.0000 - tn: 764028.0000 - fn: 3972.0000 - accuracy: 0.9917 - precision: 0.9793 - recall: 0.9793 - auc: 0.9818 - val_loss: 0.1039 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-8704000-8960000
[INFO] processing batch 8960000-9216000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1011 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0981 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-8960000-9216000
[INFO] processing batch 9216000-9472000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 2.0837 - tp: 120440.0000 - fp: 71560.0000 - tn: 696440.0000 - fn: 71560.0000 - accuracy: 0.8509 - precision: 0.6273 - recall: 0.6273 - auc: 0.6745 - val_loss: 0.1020 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-9216000-9472000
[INFO] processing batch 9472000-9728000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.9190 - tp: 161553.0000 - fp: 30447.0000 - tn: 737553.0000 - fn: 30447.0000 - accuracy: 0.9366 - precision: 0.8414 - recall: 0.8414 - auc: 0.8966 - val_loss: 0.9419 - val_tp: 53468.0000 - val_fp: 10532.0000 - val_tn: 245468.0000 - val_fn: 10532.0000 - val_accuracy: 0.9342 - val_precision: 0.8354 - val_recall: 0.8354 - val_auc: 0.8971
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-9472000-9728000
[INFO] processing batch 9728000-9984000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1005 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0978 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-9728000-9984000
[INFO] processing batch 9984000-10240000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.0952 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0925 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-9984000-10240000
[INFO] processing batch 10240000-10496000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.1557 - tp: 189510.0000 - fp: 2490.0000 - tn: 765510.0000 - fn: 2490.0000 - accuracy: 0.9948 - precision: 0.9870 - recall: 0.9870 - auc: 0.9922 - val_loss: 2.4547 - val_tp: 33975.0000 - val_fp: 30025.0000 - val_tn: 225975.0000 - val_fn: 30025.0000 - val_accuracy: 0.8123 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.7068
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-10240000-10496000
[INFO] processing batch 10496000-10752000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 2.3910 - tp: 101670.0000 - fp: 90330.0000 - tn: 677670.0000 - fn: 90330.0000 - accuracy: 0.8118 - precision: 0.5295 - recall: 0.5295 - auc: 0.7060 - val_loss: 2.3024 - val_tp: 34015.0000 - val_fp: 29985.0000 - val_tn: 226015.0000 - val_fn: 29985.0000 - val_accuracy: 0.8126 - val_precision: 0.5315 - val_recall: 0.5315 - val_auc: 0.7072
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-10496000-10752000
[INFO] processing batch 10752000-11008000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 2.2481 - tp: 101693.0000 - fp: 90307.0000 - tn: 677693.0000 - fn: 90307.0000 - accuracy: 0.8119 - precision: 0.5297 - recall: 0.5297 - auc: 0.7209 - val_loss: 0.5895 - val_tp: 56989.0000 - val_fp: 7011.0000 - val_tn: 248989.0000 - val_fn: 7011.0000 - val_accuracy: 0.9562 - val_precision: 0.8905 - val_recall: 0.8905 - val_auc: 0.9452
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-10752000-11008000
[INFO] processing batch 11008000-11264000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.1039 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1017 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-11008000-11264000
[INFO] processing batch 11264000-11520000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.0992 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0967 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-11264000-11520000
[INFO] processing batch 11520000-11776000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.0944 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 768000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0921 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 256000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-11520000-11776000
[INFO] processing batch 11776000-12032000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.9142 - tp: 156412.0000 - fp: 35588.0000 - tn: 732412.0000 - fn: 35588.0000 - accuracy: 0.9259 - precision: 0.8146 - recall: 0.8146 - auc: 0.9073 - val_loss: 1.6627 - val_tp: 41134.0000 - val_fp: 22866.0000 - val_tn: 233134.0000 - val_fn: 22866.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.8214
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-11776000-12032000
[INFO] processing batch 12032000-12288000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 1.6343 - tp: 123527.0000 - fp: 68473.0000 - tn: 699527.0000 - fn: 68473.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.8217 - val_loss: 1.6018 - val_tp: 41219.0000 - val_fp: 22781.0000 - val_tn: 233219.0000 - val_fn: 22781.0000 - val_accuracy: 0.8576 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.8220
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-12032000-12288000
[INFO] processing batch 12288000-12544000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 1.5763 - tp: 123560.0000 - fp: 68440.0000 - tn: 699560.0000 - fn: 68440.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.8218 - val_loss: 1.0988 - val_tp: 41268.0000 - val_fp: 22732.0000 - val_tn: 233268.0000 - val_fn: 22732.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.8958
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-12288000-12544000
[INFO] processing batch 12544000-12800000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.9896 - tp: 123588.0000 - fp: 68412.0000 - tn: 699588.0000 - fn: 68412.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.9627 - val_tp: 41269.0000 - val_fp: 22731.0000 - val_tn: 233269.0000 - val_fn: 22731.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-12544000-12800000
[INFO] processing batch 12800000-13056000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.9442 - tp: 123531.0000 - fp: 68469.0000 - tn: 699531.0000 - fn: 68469.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.9224 - val_tp: 41181.0000 - val_fp: 22819.0000 - val_tn: 233181.0000 - val_fn: 22819.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-12800000-13056000
[INFO] processing batch 13056000-13312000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.9031 - tp: 123615.0000 - fp: 68385.0000 - tn: 699615.0000 - fn: 68385.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.8852 - val_tp: 41192.0000 - val_fp: 22808.0000 - val_tn: 233192.0000 - val_fn: 22808.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-13056000-13312000
[INFO] processing batch 13312000-13568000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8709 - tp: 123437.0000 - fp: 68563.0000 - tn: 699437.0000 - fn: 68563.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9107 - val_loss: 0.8542 - val_tp: 41179.0000 - val_fp: 22821.0000 - val_tn: 233179.0000 - val_fn: 22821.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-13312000-13568000
[INFO] processing batch 13568000-13824000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.8407 - tp: 123539.0000 - fp: 68461.0000 - tn: 699539.0000 - fn: 68461.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.8263 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-13568000-13824000
[INFO] processing batch 13824000-14080000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.8156 - tp: 123556.0000 - fp: 68444.0000 - tn: 699556.0000 - fn: 68444.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.8044 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 233173.0000 - val_fn: 22827.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-13824000-14080000
[INFO] processing batch 14080000-14336000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7932 - tp: 123681.0000 - fp: 68319.0000 - tn: 699681.0000 - fn: 68319.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.7836 - val_tp: 41221.0000 - val_fp: 22779.0000 - val_tn: 233221.0000 - val_fn: 22779.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-14080000-14336000
[INFO] processing batch 14336000-14592000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7764 - tp: 123523.0000 - fp: 68477.0000 - tn: 699523.0000 - fn: 68477.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9109 - val_loss: 0.7675 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 233197.0000 - val_fn: 22803.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-14336000-14592000
[INFO] processing batch 14592000-14848000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7599 - tp: 123652.0000 - fp: 68348.0000 - tn: 699652.0000 - fn: 68348.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.7530 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-14592000-14848000
[INFO] processing batch 14848000-15104000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7473 - tp: 123594.0000 - fp: 68406.0000 - tn: 699594.0000 - fn: 68406.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.7412 - val_tp: 41205.0000 - val_fp: 22795.0000 - val_tn: 233205.0000 - val_fn: 22795.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-14848000-15104000
[INFO] processing batch 15104000-15360000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7360 - tp: 123629.0000 - fp: 68371.0000 - tn: 699629.0000 - fn: 68371.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.7305 - val_tp: 41234.0000 - val_fp: 22766.0000 - val_tn: 233234.0000 - val_fn: 22766.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-15104000-15360000
[INFO] processing batch 15360000-15616000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.7267 - tp: 123632.0000 - fp: 68368.0000 - tn: 699632.0000 - fn: 68368.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9111 - val_loss: 0.7216 - val_tp: 41266.0000 - val_fp: 22734.0000 - val_tn: 233266.0000 - val_fn: 22734.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-15360000-15616000
[INFO] processing batch 15616000-15872000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7196 - tp: 123527.0000 - fp: 68473.0000 - tn: 699527.0000 - fn: 68473.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.7158 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 233197.0000 - val_fn: 22803.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-15616000-15872000
[INFO] processing batch 15872000-16128000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7131 - tp: 123531.0000 - fp: 68469.0000 - tn: 699531.0000 - fn: 68469.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.7103 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 233173.0000 - val_fn: 22827.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-15872000-16128000
[INFO] processing batch 16128000-16384000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7065 - tp: 123781.0000 - fp: 68219.0000 - tn: 699781.0000 - fn: 68219.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9112 - val_loss: 0.7051 - val_tp: 41195.0000 - val_fp: 22805.0000 - val_tn: 233195.0000 - val_fn: 22805.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-16128000-16384000
[INFO] processing batch 16384000-16640000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7029 - tp: 123621.0000 - fp: 68379.0000 - tn: 699621.0000 - fn: 68379.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.7016 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 233165.0000 - val_fn: 22835.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-16384000-16640000
[INFO] processing batch 16640000-16896000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.7003 - tp: 123417.0000 - fp: 68583.0000 - tn: 699417.0000 - fn: 68583.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9107 - val_loss: 0.6973 - val_tp: 41230.0000 - val_fp: 22770.0000 - val_tn: 233230.0000 - val_fn: 22770.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-16640000-16896000
[INFO] processing batch 16896000-17152000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6964 - tp: 123600.0000 - fp: 68400.0000 - tn: 699600.0000 - fn: 68400.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6951 - val_tp: 41198.0000 - val_fp: 22802.0000 - val_tn: 233198.0000 - val_fn: 22802.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-16896000-17152000
[INFO] processing batch 17152000-17408000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6935 - tp: 123711.0000 - fp: 68289.0000 - tn: 699711.0000 - fn: 68289.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9111 - val_loss: 0.6933 - val_tp: 41168.0000 - val_fp: 22832.0000 - val_tn: 233168.0000 - val_fn: 22832.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-17152000-17408000
[INFO] processing batch 17408000-17664000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6915 - tp: 123701.0000 - fp: 68299.0000 - tn: 699701.0000 - fn: 68299.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9111 - val_loss: 0.6921 - val_tp: 41118.0000 - val_fp: 22882.0000 - val_tn: 233118.0000 - val_fn: 22882.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-17408000-17664000
[INFO] processing batch 17664000-17920000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6905 - tp: 123546.0000 - fp: 68454.0000 - tn: 699546.0000 - fn: 68454.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6909 - val_tp: 41089.0000 - val_fp: 22911.0000 - val_tn: 233089.0000 - val_fn: 22911.0000 - val_accuracy: 0.8568 - val_precision: 0.6420 - val_recall: 0.6420 - val_auc: 0.9105
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-17664000-17920000
[INFO] processing batch 17920000-18176000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6885 - tp: 123681.0000 - fp: 68319.0000 - tn: 699681.0000 - fn: 68319.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6878 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 233233.0000 - val_fn: 22767.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-17920000-18176000
[INFO] processing batch 18176000-18432000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6875 - tp: 123640.0000 - fp: 68360.0000 - tn: 699640.0000 - fn: 68360.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6860 - val_tp: 41298.0000 - val_fp: 22702.0000 - val_tn: 233298.0000 - val_fn: 22702.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-18176000-18432000
[INFO] processing batch 18432000-18688000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6866 - tp: 123615.0000 - fp: 68385.0000 - tn: 699615.0000 - fn: 68385.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6858 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 233233.0000 - val_fn: 22767.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-18432000-18688000
[INFO] processing batch 18688000-18944000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6856 - tp: 123645.0000 - fp: 68355.0000 - tn: 699645.0000 - fn: 68355.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9109 - val_loss: 0.6856 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 233184.0000 - val_fn: 22816.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-18688000-18944000
[INFO] processing batch 18944000-19200000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6840 - tp: 123888.0000 - fp: 68112.0000 - tn: 699888.0000 - fn: 68112.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9113 - val_loss: 0.6850 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 233169.0000 - val_fn: 22831.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-18944000-19200000
[INFO] processing batch 19200000-19456000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6847 - tp: 123500.0000 - fp: 68500.0000 - tn: 699500.0000 - fn: 68500.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6841 - val_tp: 41189.0000 - val_fp: 22811.0000 - val_tn: 233189.0000 - val_fn: 22811.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-19200000-19456000
[INFO] processing batch 19456000-19712000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6834 - tp: 123689.0000 - fp: 68311.0000 - tn: 699689.0000 - fn: 68311.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6837 - val_tp: 41166.0000 - val_fp: 22834.0000 - val_tn: 233166.0000 - val_fn: 22834.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-19456000-19712000
[INFO] processing batch 19712000-19968000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6838 - tp: 123402.0000 - fp: 68598.0000 - tn: 699402.0000 - fn: 68598.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9107 - val_loss: 0.6824 - val_tp: 41242.0000 - val_fp: 22758.0000 - val_tn: 233242.0000 - val_fn: 22758.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-19712000-19968000
[INFO] processing batch 19968000-20224000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6827 - tp: 123541.0000 - fp: 68459.0000 - tn: 699541.0000 - fn: 68459.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6818 - val_tp: 41241.0000 - val_fp: 22759.0000 - val_tn: 233241.0000 - val_fn: 22759.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-19968000-20224000
[INFO] processing batch 20224000-20480000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6819 - tp: 123640.0000 - fp: 68360.0000 - tn: 699640.0000 - fn: 68360.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6817 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 233209.0000 - val_fn: 22791.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-20224000-20480000
[INFO] processing batch 20480000-20736000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6815 - tp: 123598.0000 - fp: 68402.0000 - tn: 699598.0000 - fn: 68402.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6809 - val_tp: 41235.0000 - val_fp: 22765.0000 - val_tn: 233235.0000 - val_fn: 22765.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-20480000-20736000
[INFO] processing batch 20736000-20992000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6805 - tp: 123769.0000 - fp: 68231.0000 - tn: 699769.0000 - fn: 68231.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.6806 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 233212.0000 - val_fn: 22788.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-20736000-20992000
[INFO] processing batch 20992000-21248000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6810 - tp: 123459.0000 - fp: 68541.0000 - tn: 699459.0000 - fn: 68541.0000 - accuracy: 0.8572 - precision: 0.6430 - recall: 0.6430 - auc: 0.9108 - val_loss: 0.6802 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 233209.0000 - val_fn: 22791.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-20992000-21248000
[INFO] processing batch 21248000-21504000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6798 - tp: 123683.0000 - fp: 68317.0000 - tn: 699683.0000 - fn: 68317.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6800 - val_tp: 41183.0000 - val_fp: 22817.0000 - val_tn: 233183.0000 - val_fn: 22817.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-21248000-21504000
[INFO] processing batch 21504000-21760000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6797 - tp: 123564.0000 - fp: 68436.0000 - tn: 699564.0000 - fn: 68436.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6788 - val_tp: 41254.0000 - val_fp: 22746.0000 - val_tn: 233254.0000 - val_fn: 22746.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-21504000-21760000
[INFO] processing batch 21760000-22016000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6788 - tp: 123717.0000 - fp: 68283.0000 - tn: 699717.0000 - fn: 68283.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9111 - val_loss: 0.6782 - val_tp: 41270.0000 - val_fp: 22730.0000 - val_tn: 233270.0000 - val_fn: 22730.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-21760000-22016000
[INFO] processing batch 22016000-22272000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6784 - tp: 123690.0000 - fp: 68310.0000 - tn: 699690.0000 - fn: 68310.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6794 - val_tp: 41104.0000 - val_fp: 22896.0000 - val_tn: 233104.0000 - val_fn: 22896.0000 - val_accuracy: 0.8569 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-22016000-22272000
[INFO] processing batch 22272000-22528000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6780 - tp: 123672.0000 - fp: 68328.0000 - tn: 699672.0000 - fn: 68328.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6776 - val_tp: 41243.0000 - val_fp: 22757.0000 - val_tn: 233243.0000 - val_fn: 22757.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-22272000-22528000
[INFO] processing batch 22528000-22784000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6778 - tp: 123623.0000 - fp: 68377.0000 - tn: 699623.0000 - fn: 68377.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6767 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 233292.0000 - val_fn: 22708.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-22528000-22784000
[INFO] processing batch 22784000-23040000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 19s - loss: 0.6769 - tp: 123759.0000 - fp: 68241.0000 - tn: 699759.0000 - fn: 68241.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9111 - val_loss: 0.6774 - val_tp: 41180.0000 - val_fp: 22820.0000 - val_tn: 233180.0000 - val_fn: 22820.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-22784000-23040000
[INFO] processing batch 23040000-23296000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6773 - tp: 123507.0000 - fp: 68493.0000 - tn: 699507.0000 - fn: 68493.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6762 - val_tp: 41255.0000 - val_fp: 22745.0000 - val_tn: 233255.0000 - val_fn: 22745.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-23040000-23296000
[INFO] processing batch 23296000-23552000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6765 - tp: 123601.0000 - fp: 68399.0000 - tn: 699601.0000 - fn: 68399.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6762 - val_tp: 41213.0000 - val_fp: 22787.0000 - val_tn: 233213.0000 - val_fn: 22787.0000 - val_accuracy: 0.8576 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-23296000-23552000
[INFO] processing batch 23552000-23808000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6756 - tp: 123749.0000 - fp: 68251.0000 - tn: 699749.0000 - fn: 68251.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9111 - val_loss: 0.6750 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 233292.0000 - val_fn: 22708.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-23552000-23808000
[INFO] processing batch 23808000-24064000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6757 - tp: 123603.0000 - fp: 68397.0000 - tn: 699603.0000 - fn: 68397.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6758 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 233165.0000 - val_fn: 22835.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-23808000-24064000
[INFO] processing batch 24064000-24320000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6753 - tp: 123599.0000 - fp: 68401.0000 - tn: 699599.0000 - fn: 68401.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6752 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 233184.0000 - val_fn: 22816.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-24064000-24320000
[INFO] processing batch 24320000-24576000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model
Train on 1500 samples, validate on 500 samples
Epoch 1/1
 - 20s - loss: 0.6754 - tp: 123440.0000 - fp: 68560.0000 - tn: 699440.0000 - fn: 68560.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9107 - val_loss: 0.6750 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 233169.0000 - val_fn: 22831.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-24320000-24576000
[INFO] processing batch 24576000-24832000/24819975
[33m[LOSS] 0.6749712986946106[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6749712986946106  <  0.001
--- 21162.942186117172 seconds ---
2020-02-09 08:56:35.397189: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-09 08:56:35.411329: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd06461f2d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-09 08:56:35.411371: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow backend.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
=================================================
        SCORING v0.4.4 (multi-class)
=================================================
Date: 2020-02-09 08:56:35.392371
MULTI-CLASS num classes: 5
------------DNN info-------------
wrapLayerSize 8
coreLayerSize 32
numCoreLayers 3
outputLayerActivation softmax
output_dim 5
loss categorical_crossentropy
optimizer adam
------------DNN info-------------
[INFO] input_shape (128, 107)
[INFO] LSTM first and last layer neurons: 8
[INFO] adding core layer 0
[INFO] adding core layer 1
[INFO] adding core layer 2
[INFO] created DNN
loading weights: checkpoints/*
loading file checkpoints/lstm-epoch-010-files-0-50-batch-9984000-10240000
[33m[INFO] model summary:[0m
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 128, 8)            3712      
_________________________________________________________________
dropout_1 (Dropout)          (None, 128, 8)            0         
_________________________________________________________________
lstm_2 (LSTM)                (None, 128, 32)           5248      
_________________________________________________________________
dropout_2 (Dropout)          (None, 128, 32)           0         
_________________________________________________________________
lstm_3 (LSTM)                (None, 128, 32)           8320      
_________________________________________________________________
dropout_3 (Dropout)          (None, 128, 32)           0         
_________________________________________________________________
lstm_4 (LSTM)                (None, 128, 32)           8320      
_________________________________________________________________
dropout_4 (Dropout)          (None, 128, 32)           0         
_________________________________________________________________
lstm_5 (LSTM)                (None, 128, 8)            1312      
_________________________________________________________________
dropout_5 (Dropout)          (None, 128, 8)            0         
_________________________________________________________________
dense_1 (Dense)              (None, 128, 1)            9         
_________________________________________________________________
dropout_6 (Dropout)          (None, 128, 1)            0         
_________________________________________________________________
dense_2 (Dense)              (None, 128, 5)            10        
=================================================================
Total params: 26,931
Trainable params: 26,931
Non-trainable params: 0
_________________________________________________________________
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2015-12-31_130240_112.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2015-12-31_181648_113.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2015-12-31_181648_113.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2015-12-31_233049_114.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-01_151435_117.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-01_151435_117.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-01_151435_117.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-01_203011_118.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-01_203011_118.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-02_014558_119.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-02_121729_121.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-02_121729_121.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-02_121729_121.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-02_172943_122.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-02_172943_122.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-02_172943_122.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (7939824, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (7939824, 17)

[INFO] analyzing data
[INFO] 7939824 rows
[INFO] ** unixtime:21665 (0.27286%)
[INFO] ** orig:[192.168.1.48:99.99797%,192.168.1.88:0.00188%,192.168.1.87:0.00015%]
[INFO] ** type:[log:99.99952%,control:0.00039%,alert:9e-05%]
[INFO] ** i/f_name:[eth1:99.99694%,0:0.00306%]
[INFO] ** i/f_dir:[outbound:99.99708%,inbound:0.00292%]
[INFO] ** src:[192.168.1.60:38.1781%,192.168.1.10:26.08802%,192.168.1.30:18.17053%,192.168.1.20:17.55846%,192.168.1.88:0.00202%,0:0.00118%,192.168.1.19:0.00044%,192.168.1.40:0.00034%,192.168.1.136:0.00031%,192.168.1.49:0.00025%,192.168.1.201:0.00018%,192.168.1.200:0.0001%,192.168.1.199:5e-05%,192.168.1.134:1e-05%]
[INFO] ** dst:[192.168.1.20:43.37809%,192.168.1.10:20.88767%,192.168.1.40:18.17044%,192.168.1.30:17.55826%,0:0.00306%,192.168.1.50:0.00106%,192.168.1.255:0.00039%,192.168.1.60:0.00023%,224.0.0.252:0.0002%,192.168.1.201:0.00015%,224.0.0.251:0.00014%,239.255.255.250:0.0001%,192.168.1.19:8e-05%,192.168.1.49:5e-05%,192.168.1.200:5e-05%,192.168.1.88:4e-05%]
[INFO] ** proto:[tcp:99.99607%,0:0.00306%,udp:0.00087%]
[INFO] ** appi_name:[CIP_read_tag_service:99.99545%,0:0.00306%,NetBIOS Name Service:0.00024%,LLMNR Protocol:0.0002%,NetBIOS Datagram Service:0.00019%,Multicast DNS Protocol (mDNS):0.00014%,SSDP:0.0001%,Unknown Traffic:0.0001%,DCE-RPC Protocol:0.0001%,CIP_gen:9e-05%,Common Industrial Protocol - RMW (Read/Modify/Write):6e-05%,Common Industrial Protocol:6e-05%,EtherNet/IP:6e-05%,Server Message Block (SMB):4e-05%,NetBIOS Session Service:4e-05%,OSIsoft PI:3e-05%,Common Industrial Protocol - success:1e-05%,Simple Object Access Protocol:1e-05%,Web Browsing:1e-05%]
[INFO] ** proxy_src_ip:[192.168.1.60:38.1781%,192.168.1.10:26.08802%,192.168.1.30:18.17053%,192.168.1.20:17.55846%,0:0.00306%,192.168.1.19:0.00044%,192.168.1.40:0.00034%,192.168.1.136:0.00031%,192.168.1.49:0.00025%,192.168.1.201:0.00018%,192.168.1.88:0.00014%,192.168.1.200:0.0001%,192.168.1.199:5e-05%,192.168.1.134:1e-05%]
[INFO] ** modbus_function_code:[0.9743589744:99.99545%,0.0:0.00446%,1.0:9e-05%]
[INFO] ** modbus_function_description:[Read Tag Service - Response:49.99838%,Read Tag Service:49.99708%,0:0.00446%,Forward Close - Response:9e-05%]
[INFO] ** modbus_transaction_id:65536 (0.82541%)
[INFO] ** scada_tag:[HMI_FIT201:26.08708%,HMI_LIT101:20.88743%,HMI_LIT401:18.17008%,HMI_LIT301:17.55785%,HMI_AIT202:17.29042%,0:0.00715%]
[INFO] ** service:[0.7025755984000001:99.99574%,0.0:0.00306%,0.0021476384:0.00024%,0.08394601119999999:0.0002%,0.0021633145999999997:0.00019%,0.08391465880000001:0.00014%,0.0208806885:0.0001%,0.0297847659:0.0001%,0.002116286:0.0001%,0.0021789908:8e-05%,0.08543524949999999:3e-05%,0.0839773636:1e-05%,0.0012540954:1e-05%]
[INFO] ** s_port:[0.834280824:26.08742%,0.8139250565:20.88754%,0.8029830673999999:18.17019%,0.8149336757:17.55806%,0.8137722355:17.29056%,0.0:0.00306%,0.8343113882:0.00034%,0.8059172320999999:0.00034%,0.814841983:0.00031%,0.0020936488:0.00024%,0.8030136315999999:0.00023%,0.0021089309:0.00019%,0.8345253376999999:0.00015%,0.0818051226:0.00014%,0.8030441959000001:0.00013%,0.8344030809:0.00011%,0.8147502904:9e-05%,0.0290360046:6e-05%,0.7431230515:6e-05%,0.696222263:6e-05%,0.8683752063:5e-05%,0.8896631823000001:5e-05%,0.7435203863:5e-05%,0.7081881533:5e-05%,0.7967938137999999:4e-05%,0.9715599976:4e-05%,0.9535729568000001:4e-05%,0.15240846019999998:3e-05%,0.9385047986:3e-05%,0.9137019378:3e-05%,0.7586191087:3e-05%,0.7593068036:3e-05%,0.15243902439999998:3e-05%,0.8411730545999999:3e-05%,0.315972859:3e-05%,0.9310776942:3e-05%,0.9945442875:3e-05%,0.7943945229:1e-05%,0.9228712024:1e-05%,0.7806864723:1e-05%,0.9925728957:1e-05%,0.9406137294:1e-05%,0.8086374473000001:1e-05%,0.1074484993:1e-05%,0.9705208142:1e-05%,0.7840485359999999:1e-05%,0.9882022128:1e-05%,0.7853933615:1e-05%,0.7616602481999999:1e-05%]2020-02-09 08:58:01.903791: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-09 08:58:01.913245: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 08:58:01.917514: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 08:58:01.952261: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-09 08:58:01.954829: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-09 08:58:01.957719: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 08:58:01.960618: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 08:58:01.974261: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.

[INFO] ** classification:[normal:87.56318%,Single Stage Single Point:7.92975%,Multi Stage Multi Point:2.55424%,Single Stage Multi Point:1.3816%,Multi Stage Single Point:0.57123%]
[INFO] columns with count within 2-10 {'orig': 3, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'proto': 3, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'classification': 5}
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
adding missing-0
adding missing-1
adding missing-2
adding missing-3
adding missing-4
adding missing-5
adding missing-6
adding missing-7
adding missing-8
adding missing-9
adding missing-10
adding missing-11
adding missing-12
adding missing-13
adding missing-14
adding missing-15
len(df.columns) 108
numFeatures 107
[INFO] processing batch 0-256000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 1 1 ... 0 1 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.9910369071960449
tp :  164503.0
fp :  91497.0
tn :  932503.0
fn :  91497.0
accuracy :  0.8570374846458435
precision :  0.6425898671150208
recall :  0.6425898671150208
auc :  0.910647451877594

y_eval {0: 164503, 1: 91497}
pred {0: 256000}
[INFO] confusion matrix for file 
[[164503      0      0      0      0]
 [ 91497      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[164503      0      0      0      0]
 [ 91497      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 256000-512000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [1 0 1 ... 2 2 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.3295144600868225
tp :  239293.0
fp :  16707.0
tn :  1007293.0
fn :  16707.0
accuracy :  0.9738954901695251
precision :  0.934738278388977
recall :  0.934738278388977
auc :  0.9732812643051147

y_eval {0: 239293, 1: 9605, 2: 7102}
pred {0: 256000}
[INFO] confusion matrix for file 
[[239293      0      0      0      0]
 [  9605      0      0      0      0]
 [  7102      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[403796      0      0      0      0]
 [101102      0      0      0      0]
 [  7102      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 512000-768000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 2 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.49328000521659854
tp :  236050.0
fp :  19950.0
tn :  1004050.0
fn :  19950.0
accuracy :  0.9688284397125244
precision :  0.922070324420929
recall :  0.922070324420929
auc :  0.9512939453125

y_eval {0: 236050, 2: 19950}
pred {0: 256000}
[INFO] confusion matrix for file 
[[236050      0      0      0      0]
 [     0      0      0      0      0]
 [ 19950      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[639846      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 768000-1024000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 4 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.9276485999822617
tp :  172406.0
fp :  83594.0
tn :  940406.0
fn :  83594.0
accuracy :  0.8693856000900269
precision :  0.6734609603881836
recall :  0.6734609603881836
auc :  0.6734609603881836

y_eval {0: 172406, 4: 83594}
pred {0: 256000}
[INFO] confusion matrix for file 
[[172406      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [ 83594      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[812252      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [ 83594      0      0      0      0]]
[INFO] processing batch 1024000-1280000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [4 0 4 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.709474277615547
tp :  136792.0
fp :  119208.0
tn :  904792.0
fn :  119208.0
accuracy :  0.8137394189834595
precision :  0.5343437790870667
recall :  0.5343437790870667
auc :  0.5343437790870667

y_eval {0: 136792, 4: 119208}
pred {0: 256000}
[INFO] confusion matrix for file 
[[136792      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [119208      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[949044      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [202802      0      0      0      0]]
[INFO] processing batch 1280000-1536000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09252930438518524
tp :  256000.0
fp :  0.0
tn :  1024000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 256000}
pred {0: 256000}
[INFO] confusion matrix for file 
[[256000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1205044       0       0       0       0]
 [ 101102       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 1536000-1792000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 1 1 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.15077208495140076
tp :  250069.0
fp :  5931.0
tn :  1018069.0
fn :  5931.0
accuracy :  0.9907329678535461
precision :  0.9768320322036743
recall :  0.9768320322036743
auc :  0.9942079782485962

y_eval {0: 250069, 1: 5931}
pred {0: 256000}
[INFO] confusion matrix for file 
[[250069      0      0      0      0]
 [  5931      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1455113       0       0       0       0]
 [ 107033       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 1792000-2048000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 1] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.38042417919635774
tp :  226683.0
fp :  29317.0
tn :  994683.0
fn :  29317.0
accuracy :  0.9541926980018616
precision :  0.8854804635047913
recall :  0.8854804635047913
auc :  0.9713701009750366

y_eval {0: 226683, 1: 29317}
pred {0: 256000}
[INFO] confusion matrix for file 
[[226683      0      0      0      0]
 [ 29317      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1681796       0       0       0       0]
 [ 136350       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 2048000-2304000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [1 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.7628772373199463
tp :  187737.0
fp :  68263.0
tn :  955737.0
fn :  68263.0
accuracy :  0.8933401107788086
precision :  0.7333476543426514
recall :  0.7333476543426514
auc :  0.9333369135856628

y_eval {0: 187737, 1: 68263}
pred {0: 256000}
[INFO] confusion matrix for file 
[[187737      0      0      0      0]
 [ 68263      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1869533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 2304000-2560000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09252930438518524
tp :  256000.0
fp :  0.0
tn :  1024000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 256000}
pred {0: 256000}
[INFO] confusion matrix for file 
[[256000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2125533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 2560000-2816000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09252930438518524
tp :  256000.0
fp :  0.0
tn :  1024000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 256000}
pred {0: 256000}
[INFO] confusion matrix for file 
[[256000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2381533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 2816000-3072000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 1 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.5635386492013932
tp :  208036.0
fp :  47964.0
tn :  976036.0
fn :  47964.0
accuracy :  0.9250568151473999
precision :  0.8126406073570251
recall :  0.8126406073570251
auc :  0.9531601667404175

y_eval {0: 208036, 1: 47964}
pred {0: 256000}
[INFO] confusion matrix for file 
[[208036      0      0      0      0]
 [ 47964      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2589569       0       0       0       0]
 [ 252577       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 3072000-3328000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.372214448928833
tp :  227519.0
fp :  28481.0
tn :  995519.0
fn :  28481.0
accuracy :  0.9554988741874695
precision :  0.8887460827827454
recall :  0.8887460827827454
auc :  0.9721865057945251

y_eval {0: 227519, 1: 28481}
pred {0: 256000}
[INFO] confusion matrix for file 
[[227519      0      0      0      0]
 [ 28481      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2817088       0       0       0       0]
 [ 281058       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 3328000-3584000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09252930438518524
tp :  256000.0
fp :  0.0
tn :  1024000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 256000}
pred {0: 256000}
[INFO] confusion matrix for file 
[[256000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3073088       0       0       0       0]
 [ 281058       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 3584000-3840000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.26299572360515594
tp :  238641.0
fp :  17359.0
tn :  1006641.0
fn :  17359.0
accuracy :  0.972876787185669
precision :  0.9321914315223694
recall :  0.9321914315223694
auc :  0.9830478429794312

y_eval {0: 238641, 1: 17359}
pred {0: 256000}
[INFO] confusion matrix for file 
[[238641      0      0      0      0]
 [ 17359      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3311729       0       0       0       0]
 [ 298417       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 3840000-4096000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 2 2 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.5746046323776246
tp :  182220.0
fp :  73780.0
tn :  950220.0
fn :  73780.0
accuracy :  0.884719729423523
precision :  0.7117968797683716
recall :  0.7117968797683716
auc :  0.819873034954071

y_eval {0: 182220, 2: 73780}
pred {0: 256000}
[INFO] confusion matrix for file 
[[182220      0      0      0      0]
 [     0      0      0      0      0]
 [ 73780      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3493949       0       0       0       0]
 [ 298417       0       0       0       0]
 [ 100832       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 4096000-4352000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 2 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.270567191362381
tp :  247137.0
fp :  8863.0
tn :  1015137.0
fn :  8863.0
accuracy :  0.9861516952514648
precision :  0.9653788805007935
recall :  0.9653788805007935
auc :  0.9783617854118347

y_eval {0: 247137, 2: 8863}
pred {0: 256000}
[INFO] confusion matrix for file 
[[247137      0      0      0      0]
 [     0      0      0      0      0]
 [  8863      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3741086       0       0       0       0]
 [ 298417       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 4352000-4608000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 1 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.4495375760793686
tp :  219645.0
fp :  36355.0
tn :  987645.0
fn :  36355.0
accuracy :  0.943195641040802
precision :  0.8579882979393005
recall :  0.8579882979393005
auc :  0.9644970893859863

y_eval {0: 219645, 1: 36355}
pred {0: 256000}
[INFO] confusion matrix for file 
[[219645      0      0      0      0]
 [ 36355      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3960731       0       0       0       0]
 [ 334772       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 4608000-4864000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 1 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.6482955704927444
tp :  199405.0
fp :  56595.0
tn :  967405.0
fn :  56595.0
accuracy :  0.9115711450576782
precision :  0.7789257764816284
recall :  0.7789257764816284
auc :  0.9447314143180847

y_eval {0: 199405, 1: 56595}
pred {0: 256000}
[INFO] confusion matrix for file 
[[199405      0      0      0      0]
 [ 56595      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4160136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 4864000-5120000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09252930438518524
tp :  256000.0
fp :  0.0
tn :  1024000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 256000}
pred {0: 256000}
[INFO] confusion matrix for file 
[[256000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4416136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 5120000-5376000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09252930438518524
tp :  256000.0
fp :  0.0
tn :  1024000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 256000}
pred {0: 256000}
[INFO] confusion matrix for file 
[[256000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4672136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 5376000-5632000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09256948006153107
tp :  255998.0
fp :  2.0
tn :  1023998.0
fn :  2.0
accuracy :  0.9999969005584717
precision :  0.9999921917915344
recall :  0.9999921917915344
auc :  0.9999951124191284

y_eval {0: 255998, 2: 2}
pred {0: 256000}
[INFO] confusion matrix for file 
[[255998      0      0      0      0]
 [     0      0      0      0      0]
 [     2      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4928134       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109697       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 5632000-5888000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.4626473699808121
tp :  237169.0
fp :  18831.0
tn :  1005169.0
fn :  18831.0
accuracy :  0.9705768823623657
precision :  0.9264414310455322
recall :  0.9264414310455322
auc :  0.9540258646011353

y_eval {0: 237169, 3: 18831}
pred {0: 256000}
[INFO] confusion matrix for file 
[[237169      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [ 18831      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5165303       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109697       0       0       0       0]
 [  18831       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 5888000-6144000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.7283825231790543
tp :  217813.0
fp :  38187.0
tn :  985813.0
fn :  38187.0
accuracy :  0.9403335452079773
precision :  0.8508320450782776
recall :  0.8508320450782776
auc :  0.9238544702529907

y_eval {0: 217813, 1: 11663, 3: 26524}
pred {0: 256000}
[INFO] confusion matrix for file 
[[217813      0      0      0      0]
 [ 11663      0      0      0      0]
 [     0      0      0      0      0]
 [ 26524      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5383116       0       0       0       0]
 [ 403030       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 6144000-6400000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [1 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.17186557483673096
tp :  247921.0
fp :  8079.0
tn :  1015921.0
fn :  8079.0
accuracy :  0.9873766899108887
precision :  0.9684414267539978
recall :  0.9684414267539978
auc :  0.9921103715896606

y_eval {0: 247921, 1: 8079}
pred {0: 256000}
[INFO] confusion matrix for file 
[[247921      0      0      0      0]
 [  8079      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5631037       0       0       0       0]
 [ 411109       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 6400000-6656000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09252930438518524
tp :  256000.0
fp :  0.0
tn :  1024000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 256000}
pred {0: 256000}
[INFO] confusion matrix for file 
[[256000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5887037       0       0       0       0]
 [ 411109       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 6656000-6912000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 1 0 1] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.24518239104747772
tp :  240455.0
fp :  15545.0
tn :  1008455.0
fn :  15545.0
accuracy :  0.9757110476493835
precision :  0.9392773509025574
recall :  0.9392773509025574
auc :  0.9848193526268005

y_eval {0: 240455, 1: 15545}
pred {0: 256000}
[INFO] confusion matrix for file 
[[240455      0      0      0      0]
 [ 15545      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[6127492       0       0       0       0]
 [ 426654       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 6912000-7168000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 1] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.9843200025558472
tp :  165187.0
fp :  90813.0
tn :  933187.0
fn :  90813.0
accuracy :  0.858106255531311
precision :  0.6452617049217224
recall :  0.6452617049217224
auc :  0.9113154411315918

y_eval {0: 165187, 1: 90813}
pred {0: 256000}
[INFO] confusion matrix for file 
[[165187      0      0      0      0]
 [ 90813      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[6292679       0       0       0       0]
 [ 517467       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 7168000-7424000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 1 ... 0 1 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.9916555852890014
tp :  164440.0
fp :  91560.0
tn :  932440.0
fn :  91560.0
accuracy :  0.856938898563385
precision :  0.6423437595367432
recall :  0.6423437595367432
auc :  0.9105859398841858

y_eval {0: 164440, 1: 91560}
pred {0: 256000}
[INFO] confusion matrix for file 
[[164440      0      0      0      0]
 [ 91560      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[6457119       0       0       0       0]
 [ 609027       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 7424000-7680000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [1 0 1 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.2946363182067871
tp :  235419.0
fp :  20581.0
tn :  1003419.0
fn :  20581.0
accuracy :  0.9678425192832947
precision :  0.9196054935455322
recall :  0.9196054935455322
auc :  0.9799013733863831

y_eval {0: 235419, 1: 20581}
pred {0: 256000}
[INFO] confusion matrix for file 
[[235419      0      0      0      0]
 [ 20581      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[6692538       0       0       0       0]
 [ 629608       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 7680000-7936000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09252930438518524
tp :  256000.0
fp :  0.0
tn :  1024000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 256000}
pred {0: 256000}
[INFO] confusion matrix for file 
[[256000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[6948538       0       0       0       0]
 [ 629608       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 7936000-8192000/7939824
--- 400.54495906829834 seconds ---
