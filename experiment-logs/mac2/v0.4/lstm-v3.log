2020-02-06 02:55:00.005685: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-06 02:55:00.018799: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff013140400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-06 02:55:00.018833: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow backend.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
2020-02-06 02:55:04.313470: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-06 02:55:04.343472: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-06 02:55:04.355359: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-06 02:55:04.461797: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-06 02:55:04.469072: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-06 02:55:04.477694: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-06 02:55:04.485919: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-06 02:55:04.524594: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-06 02:55:09.753058: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-06 02:55:09.760514: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-06 02:55:09.764118: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-06 02:55:09.793435: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-06 02:55:09.795592: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-06 02:55:09.798048: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-06 02:55:09.800585: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-06 02:55:09.813804: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
=============================
        TRAINING v0.4
=============================
Date: 2020-02-06 02:55:00.001564
[INFO] input_shape (10, 16)
[INFO] LSTM first and last layer neurons: 8
[INFO] adding core layer 0
[INFO] created DNN
[33m[INFO] epoch 1/10[0m
[33m[INFO] loading file 1-1/1 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 7s - loss: 0.8168 - tp: 33040.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 46960.0000 - accuracy: 0.8826 - precision: 1.0000 - recall: 0.4130 - auc: 0.9999 - val_loss: 0.3223 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-1-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 0.2602 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1193 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-1-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 0.1628 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9983 - val_loss: 1.8912 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.8101
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-1-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 1.2788 - tp: 42447.0000 - fp: 37553.0000 - tn: 282447.0000 - fn: 37553.0000 - accuracy: 0.8122 - precision: 0.5306 - recall: 0.5306 - auc: 0.8296 - val_loss: 0.9116 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8825
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-1-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 0.8724 - tp: 38574.0000 - fp: 34301.0000 - tn: 285699.0000 - fn: 41426.0000 - accuracy: 0.8107 - precision: 0.5293 - recall: 0.4822 - auc: 0.8824 - val_loss: 0.7912 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8824
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-1-batch-400000-500000
[33m[LOSS] 0.7911619253158569[0m
[33m[INFO] epoch 2/10[0m
[33m[INFO] loading file 1-1/1 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 0.2971 - tp: 79735.0000 - fp: 54.0000 - tn: 319946.0000 - fn: 265.0000 - accuracy: 0.9992 - precision: 0.9993 - recall: 0.9967 - auc: 1.0000 - val_loss: 0.1320 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-1-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 0.1346 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0681 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-1-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 0.1035 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9987 - val_loss: 1.6968 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.8829
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-1-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 1.0750 - tp: 42341.0000 - fp: 37508.0000 - tn: 282492.0000 - fn: 37659.0000 - accuracy: 0.8121 - precision: 0.5303 - recall: 0.5293 - auc: 0.8727 - val_loss: 0.7779 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8823
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-1-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 0.8096 - tp: 39533.0000 - fp: 36229.0000 - tn: 283771.0000 - fn: 40467.0000 - accuracy: 0.8083 - precision: 0.5218 - recall: 0.4942 - auc: 0.8815 - val_loss: 0.7416 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8824
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-1-batch-400000-500000
[33m[LOSS] 0.7416375818252563[0m
[33m[INFO] epoch 3/10[0m
[33m[INFO] loading file 1-1/1 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 0.2442 - tp: 79836.0000 - fp: 108.0000 - tn: 319892.0000 - fn: 164.0000 - accuracy: 0.9993 - precision: 0.9986 - recall: 0.9980 - auc: 1.0000 - val_loss: 0.1054 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-1-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 0.1122 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0559 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-1-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 0.0898 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9987 - val_loss: 1.6800 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.8824
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-1-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 1.0290 - tp: 42356.0000 - fp: 37503.0000 - tn: 282497.0000 - fn: 37644.0000 - accuracy: 0.8121 - precision: 0.5304 - recall: 0.5294 - auc: 0.8772 - val_loss: 0.7536 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8822
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-1-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 0.7849 - tp: 40536.0000 - fp: 36993.0000 - tn: 283007.0000 - fn: 39464.0000 - accuracy: 0.8089 - precision: 0.5228 - recall: 0.5067 - auc: 0.8816 - val_loss: 0.7256 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8823
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-1-batch-400000-500000
[33m[LOSS] 0.725628568649292[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.725628568649292  <  0.001
[33m[INFO] epoch 4/10[0m
[33m[INFO] loading file 1-1/1 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 0.2297 - tp: 79910.0000 - fp: 67.0000 - tn: 319933.0000 - fn: 90.0000 - accuracy: 0.9996 - precision: 0.9992 - recall: 0.9989 - auc: 1.0000 - val_loss: 0.0976 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-1-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 0.1048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0517 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-1-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 0.0848 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9990 - val_loss: 1.6756 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.8831
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-1-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 1.0031 - tp: 42355.0000 - fp: 37534.0000 - tn: 282466.0000 - fn: 37645.0000 - accuracy: 0.8121 - precision: 0.5302 - recall: 0.5294 - auc: 0.8794 - val_loss: 0.7414 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8820
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-1-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 0.7705 - tp: 41048.0000 - fp: 37235.0000 - tn: 282765.0000 - fn: 38952.0000 - accuracy: 0.8095 - precision: 0.5244 - recall: 0.5131 - auc: 0.8817 - val_loss: 0.7184 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8823
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-1-batch-400000-500000
[33m[LOSS] 0.7184354887008667[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.7184354887008667  <  0.001
[33m[INFO] epoch 5/10[0m
[33m[INFO] loading file 1-1/1 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 0.2224 - tp: 79947.0000 - fp: 42.0000 - tn: 319958.0000 - fn: 53.0000 - accuracy: 0.9998 - precision: 0.9995 - recall: 0.9993 - auc: 1.0000 - val_loss: 0.0938 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-1-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 0.1013 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0496 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-1-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 0.0818 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9990 - val_loss: 1.6728 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.8826
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-1-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 0.9896 - tp: 42369.0000 - fp: 37543.0000 - tn: 282457.0000 - fn: 37631.0000 - accuracy: 0.8121 - precision: 0.5302 - recall: 0.5296 - auc: 0.8809 - val_loss: 0.7357 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8822
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-1-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 0.7616 - tp: 41270.0000 - fp: 37446.0000 - tn: 282554.0000 - fn: 38730.0000 - accuracy: 0.8096 - precision: 0.5243 - recall: 0.5159 - auc: 0.8819 - val_loss: 0.7142 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8822
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-1-batch-400000-500000
[33m[LOSS] 0.7142198781967163[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.7142198781967163  <  0.001
[33m[INFO] epoch 6/10[0m
[33m[INFO] loading file 1-1/1 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 0.2183 - tp: 79961.0000 - fp: 35.0000 - tn: 319965.0000 - fn: 39.0000 - accuracy: 0.9998 - precision: 0.9996 - recall: 0.9995 - auc: 1.0000 - val_loss: 0.0918 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-1-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 0.0989 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0484 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-1-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 0.0800 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9992 - val_loss: 1.6713 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.8828
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-1-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 0.9814 - tp: 42399.0000 - fp: 37538.0000 - tn: 282462.0000 - fn: 37601.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5300 - auc: 0.8812 - val_loss: 0.7309 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8823
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-1-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 0.7547 - tp: 41325.0000 - fp: 37583.0000 - tn: 282417.0000 - fn: 38675.0000 - accuracy: 0.8094 - precision: 0.5237 - recall: 0.5166 - auc: 0.8818 - val_loss: 0.7109 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8830
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-1-batch-400000-500000
[33m[LOSS] 0.7108830871582031[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.7108830871582031  <  0.001
[33m[INFO] epoch 7/10[0m
[33m[INFO] loading file 1-1/1 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 0.2166 - tp: 79961.0000 - fp: 33.0000 - tn: 319967.0000 - fn: 39.0000 - accuracy: 0.9998 - precision: 0.9996 - recall: 0.9995 - auc: 1.0000 - val_loss: 0.0906 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-1-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 0.0977 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0477 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-1-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 0.0784 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9993 - val_loss: 1.6702 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.8829
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-1-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 0.9747 - tp: 42323.0000 - fp: 37612.0000 - tn: 282388.0000 - fn: 37677.0000 - accuracy: 0.8118 - precision: 0.5295 - recall: 0.5290 - auc: 0.8818 - val_loss: 0.7297 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8821
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-1-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 0.7527 - tp: 41665.0000 - fp: 37636.0000 - tn: 282364.0000 - fn: 38335.0000 - accuracy: 0.8101 - precision: 0.5254 - recall: 0.5208 - auc: 0.8816 - val_loss: 0.7093 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8826
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-1-batch-400000-500000
[33m[LOSS] 0.7093084769248963[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.7093084769248963  <  0.001
[33m[INFO] epoch 8/10[0m
[33m[INFO] loading file 1-1/1 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 0.2141 - tp: 79968.0000 - fp: 28.0000 - tn: 319972.0000 - fn: 32.0000 - accuracy: 0.9998 - precision: 0.9997 - recall: 0.9996 - auc: 1.0000 - val_loss: 0.0896 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-1-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 0.0966 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0471 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-1-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 0.0782 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9992 - val_loss: 1.6682 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.8829
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-1-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 0.9694 - tp: 42404.0000 - fp: 37550.0000 - tn: 282450.0000 - fn: 37596.0000 - accuracy: 0.8121 - precision: 0.5304 - recall: 0.5300 - auc: 0.8824 - val_loss: 0.7276 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8822
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-1-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 0.7496 - tp: 41670.0000 - fp: 37700.0000 - tn: 282300.0000 - fn: 38330.0000 - accuracy: 0.8099 - precision: 0.5250 - recall: 0.5209 - auc: 0.8817 - val_loss: 0.7081 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8823
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-1-batch-400000-500000
[33m[LOSS] 0.708133599281311[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.708133599281311  <  0.001
[33m[INFO] epoch 9/10[0m
[33m[INFO] loading file 1-1/1 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 0.2129 - tp: 79979.0000 - fp: 19.0000 - tn: 319981.0000 - fn: 21.0000 - accuracy: 0.9999 - precision: 0.9998 - recall: 0.9997 - auc: 1.0000 - val_loss: 0.0890 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-1-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 0.0950 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0467 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-1-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 0.0767 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9992 - val_loss: 1.6681 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.8829
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-1-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 0.9687 - tp: 42428.0000 - fp: 37547.0000 - tn: 282453.0000 - fn: 37572.0000 - accuracy: 0.8122 - precision: 0.5305 - recall: 0.5304 - auc: 0.8820 - val_loss: 0.7274 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8820
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-1-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 0.7447 - tp: 41743.0000 - fp: 37601.0000 - tn: 282399.0000 - fn: 38257.0000 - accuracy: 0.8104 - precision: 0.5261 - recall: 0.5218 - auc: 0.8823 - val_loss: 0.7066 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8824
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-1-batch-400000-500000
[33m[LOSS] 0.7066158642768859[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.7066158642768859  <  0.001
[33m[INFO] epoch 10/10[0m
[33m[INFO] loading file 1-1/1 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 6s - loss: 0.2116 - tp: 79977.0000 - fp: 21.0000 - tn: 319979.0000 - fn: 23.0000 - accuracy: 0.9999 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - val_loss: 0.0885 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-1-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 0.0944 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0464 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-1-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 0.0762 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9993 - val_loss: 1.6677 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.8828
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-1-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 0.9655 - tp: 42444.0000 - fp: 37539.0000 - tn: 282461.0000 - fn: 37556.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5306 - auc: 0.8822 - val_loss: 0.7261 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8818
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-1-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 0.7426 - tp: 41751.0000 - fp: 37630.0000 - tn: 282370.0000 - fn: 38249.0000 - accuracy: 0.8103 - precision: 0.5260 - recall: 0.5219 - auc: 0.8823 - val_loss: 0.7052 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8824
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-1-batch-400000-500000
[33m[LOSS] 0.7051864066123963[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.7051864066123963  <  0.001
--- 297.8286690711975 seconds ---
2020-02-06 03:00:00.383168: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-06 03:00:00.396240: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe6fb6c9680 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-06 03:00:00.396272: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow backend.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
2020-02-06 03:00:04.634290: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-06 03:00:04.642404: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-06 03:00:04.645533: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-06 03:00:04.671986: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-06 03:00:04.673938: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-06 03:00:04.676135: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-06 03:00:04.678408: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-06 03:00:04.689091: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
=============================
        SCORING v0.4
=============================
Date: 2020-02-06 03:00:00.378510
[INFO] input_shape (10, 16)
[INFO] LSTM first and last layer neurons: 8
[INFO] adding core layer 0
[INFO] created DNN
loading weights: checkpoints/*
loading file checkpoints/lstm-epoch-010-files-0-1-batch-400000-500000
[33m[INFO] model summary:[0m
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 10, 8)             800       
_________________________________________________________________
dropout_1 (Dropout)          (None, 10, 8)             0         
_________________________________________________________________
lstm_2 (LSTM)                (None, 10, 32)            5248      
_________________________________________________________________
dropout_2 (Dropout)          (None, 10, 32)            0         
_________________________________________________________________
lstm_3 (LSTM)                (None, 10, 8)             1312      
_________________________________________________________________
dropout_3 (Dropout)          (None, 10, 8)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 10, 1)             9         
_________________________________________________________________
dropout_4 (Dropout)          (None, 10, 1)             0         
_________________________________________________________________
dense_2 (Dense)              (None, 10, 5)             10        
=================================================================
Total params: 7,379
Trainable params: 7,379
Non-trainable params: 0
_________________________________________________________________
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1359 (0.2718%)
[INFO] ** orig:[0.5:100.0%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[0.0:99.9996%,0.5:0.0004%]
[INFO] ** i/f_dir:[0.0:99.9996%,1.0:0.0004%]
[INFO] ** src:[0.0666666667:38.3832%,0.9333333333:25.9606%,0.6666666667:18.1352%,0.3333333333:17.52%,0.1333333333:0.0004%,1.0:0.0004%,0.5333333333:0.0002%]
[INFO] ** dst:[0.1764705882:43.3108%,0.9411764706:21.0326%,0.8823529412000001:18.135%,0.5294117647:17.5198%,0.0:0.0008%,0.2941176471:0.0004%,0.4117647059:0.0004%,0.23529411760000002:0.0002%]
[INFO] ** proto:[0.5:99.9996%,0.0:0.0004%]
[INFO] ** appi_name:[0.0:99.9992%,0.0384615385:0.0004%,0.5384615385:0.0002%,0.7307692308:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.3832%,0.0:25.9606%,0.9333333333:18.1352%,0.4:17.52%,0.5333333333:0.0004%,0.7333333333:0.0004%,0.6:0.0002%]
[INFO] ** modbus_function_code:[0.9743589744:99.9992%,0.0:0.0008%]
[INFO] ** modbus_function_description:[0.2:50.0%,0.0:49.9992%,0.4:0.0008%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:25.9596%,0.6:21.0326%,0.8:18.1348%,0.0:17.5194%,0.4:17.3504%,0.2:0.0032%]
[INFO] ** service:[0.7025755984000001:99.9992%,0.0:0.0004%,0.0012540954:0.0002%,0.002116286:0.0002%]
[INFO] ** s_port:[0.834280824:25.96%,0.8139250565:21.0326%,0.8029830673999999:18.1348%,0.8149336757:17.5196%,0.8137722355:17.3506%,0.8343113882:0.0004%,0.0:0.0004%,0.8059172320999999:0.0002%,0.8030136315999999:0.0002%,0.8147502904:0.0002%,0.8030441959000001:0.0002%,0.814841983:0.0002%,0.9621003729000001:0.0002%,0.8345253376999999:0.0002%,0.7788831836:0.0002%]
[INFO] ** classification:[normal:72.7902%,Single Stage Single Point:27.2098%]
[INFO] columns with count within 2-10 {'i/f_name': 2, 'i/f_dir': 2, 'src': 7, 'dst': 8, 'proto': 2, 'appi_name': 4, 'proxy_src_ip': 7, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 4, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 1 ... 0 1 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.7051534363746643
tp :  53024.0
fp :  46976.0
tn :  353024.0
fn :  46976.0
accuracy :  0.8120962381362915
precision :  0.530239999294281
recall :  0.530239999294281
auc :  0.882418155670166

y_eval {0: 53024, 1: 46976}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53024     0     0     0     0]
 [46976     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[53024     0     0     0     0]
 [46976     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.571269018650055
tp :  87619.0
fp :  12381.0
tn :  387619.0
fn :  12381.0
accuracy :  0.9504759907722473
precision :  0.8761900067329407
recall :  0.8761900067329407
auc :  0.9689949750900269

y_eval {0: 87619, 1: 12381}
pred {0: 100000}
[INFO] confusion matrix for file 
[[87619     0     0     0     0]
 [12381     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[140643      0      0      0      0]
 [ 59357      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 1 0 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.5890480159759521
tp :  83025.0
fp :  16975.0
tn :  383025.0
fn :  16975.0
accuracy :  0.9320994019508362
precision :  0.8302500247955322
recall :  0.8302500247955322
auc :  0.9574993848800659

y_eval {0: 83025, 1: 16975}
pred {0: 100000}
[INFO] confusion matrix for file 
[[83025     0     0     0     0]
 [16975     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[223668      0      0      0      0]
 [ 76332      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 0 ... 1 1 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.7055298572540283
tp :  52923.0
fp :  47077.0
tn :  352923.0
fn :  47077.0
accuracy :  0.8116917014122009
precision :  0.529229998588562
recall :  0.529229998588562
auc :  0.882240891456604

y_eval {0: 52923, 1: 47077}
pred {0: 100000}
[INFO] confusion matrix for file 
[[52923     0     0     0     0]
 [47077     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[276591      0      0      0      0]
 [123409      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.572266236114502
tp :  87360.0
fp :  12640.0
tn :  387360.0
fn :  12640.0
accuracy :  0.9494400024414062
precision :  0.8736000061035156
recall :  0.8736000061035156
auc :  0.9686198234558105

y_eval {0: 87360, 1: 12640}
pred {0: 100000}
[INFO] confusion matrix for file 
[[87360     0     0     0     0]
 [12640     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[363951      0      0      0      0]
 [136049      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
--- 19.09857201576233 seconds ---
