2020-02-08 11:18:16.479014: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-08 11:18:16.489213: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc9108c4110 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-08 11:18:16.489241: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow backend.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
2020-02-08 11:18:22.614915: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-08 11:18:22.645961: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 11:18:22.664731: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 11:18:22.793157: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-08 11:18:22.802461: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-08 11:18:22.812757: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 11:18:22.822260: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 11:18:22.865753: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-08 11:18:28.722009: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-08 11:18:28.730292: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 11:18:28.734435: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 11:18:28.764003: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-08 11:18:28.766384: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-08 11:18:28.768909: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 11:18:28.771453: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 11:18:28.786590: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
=================================================
        TRAINING v0.4.2 (binaryClasses)
=================================================
Date: 2020-02-08 11:18:16.474882
[INFO] input_shape (32, 16)
[INFO] LSTM first and last layer neurons: 16
[INFO] adding core layer 0
[INFO] adding core layer 1
[INFO] adding core layer 2
wrapLayerSize 16
coreLayerSize 64
numCoreLayers 3
outputLayerActivation sigmoid
output_dim 2
loss binary_crossentropy
optimizer sgd
[INFO] created DNN
[33m[INFO] epoch 1/3[0m
[33m[INFO] loading file 1-2/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: 0.6479 - tp: 78828.0000 - fp: 373.0000 - tn: 79627.0000 - fn: 1172.0000 - accuracy: 0.9903 - precision: 0.9953 - recall: 0.9854 - auc: 0.9978 - val_loss: 0.6035 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-2-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.5663 - tp: 79995.0000 - fp: 5.0000 - tn: 79995.0000 - fn: 5.0000 - accuracy: 0.9999 - precision: 0.9999 - recall: 0.9999 - auc: 0.9999 - val_loss: 0.5297 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-2-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 5s - loss: 0.5005 - tp: 79766.0000 - fp: 234.0000 - tn: 79766.0000 - fn: 234.0000 - accuracy: 0.9971 - precision: 0.9971 - recall: 0.9971 - auc: 0.9970 - val_loss: 0.7101 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 10606.0000 - val_fn: 9394.0000 - val_accuracy: 0.5303 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.5303
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-2-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 5s - loss: 0.7083 - tp: 42447.0000 - fp: 37553.0000 - tn: 42447.0000 - fn: 37553.0000 - accuracy: 0.5306 - precision: 0.5306 - recall: 0.5306 - auc: 0.5302 - val_loss: 0.7064 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 10626.0000 - val_fn: 9374.0000 - val_accuracy: 0.5313 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.5313
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-2-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.7054 - tp: 42438.0000 - fp: 37562.0000 - tn: 42438.0000 - fn: 37562.0000 - accuracy: 0.5305 - precision: 0.5305 - recall: 0.5305 - auc: 0.5302 - val_loss: 0.7042 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 10603.0000 - val_fn: 9397.0000 - val_accuracy: 0.5301 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-2-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 5s - loss: 0.7030 - tp: 42435.0000 - fp: 37565.0000 - tn: 42435.0000 - fn: 37565.0000 - accuracy: 0.5304 - precision: 0.5304 - recall: 0.5304 - auc: 0.5302 - val_loss: 0.7023 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 10589.0000 - val_fn: 9411.0000 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.5294
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-2-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.5606 - tp: 67619.0000 - fp: 12381.0000 - tn: 67619.0000 - fn: 12381.0000 - accuracy: 0.8452 - precision: 0.8452 - recall: 0.8452 - auc: 0.8442 - val_loss: 0.4718 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-2-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.5052 - tp: 72432.0000 - fp: 7568.0000 - tn: 72432.0000 - fn: 7568.0000 - accuracy: 0.9054 - precision: 0.9054 - recall: 0.9054 - auc: 0.9032 - val_loss: 0.7212 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 10593.0000 - val_fn: 9407.0000 - val_accuracy: 0.5296 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.5296
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-2-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.7190 - tp: 42321.0000 - fp: 37679.0000 - tn: 42321.0000 - fn: 37679.0000 - accuracy: 0.5290 - precision: 0.5290 - recall: 0.5290 - auc: 0.5288 - val_loss: 0.7158 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 10602.0000 - val_fn: 9398.0000 - val_accuracy: 0.5301 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-2-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.5312 - tp: 67360.0000 - fp: 12640.0000 - tn: 67360.0000 - fn: 12640.0000 - accuracy: 0.8420 - precision: 0.8420 - recall: 0.8420 - auc: 0.8400 - val_loss: 0.4222 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-2-batch-900000-1000000
[33m[INFO] loading file 3-4/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 5s - loss: 0.7005 - tp: 45236.0000 - fp: 34764.0000 - tn: 45236.0000 - fn: 34764.0000 - accuracy: 0.5655 - precision: 0.5655 - recall: 0.5655 - auc: 0.5665 - val_loss: 0.7215 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 10571.0000 - val_fn: 9429.0000 - val_accuracy: 0.5286 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.5286
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-4-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6026 - tp: 57751.0000 - fp: 22249.0000 - tn: 57751.0000 - fn: 22249.0000 - accuracy: 0.7219 - precision: 0.7219 - recall: 0.7219 - auc: 0.7231 - val_loss: 0.4244 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-4-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.4026 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3811 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-4-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.3627 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3446 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-4-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.3290 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3136 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-4-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.3003 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2870 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-4-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.2756 - tp: 79999.0000 - fp: 1.0000 - tn: 79999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2641 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-4-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 5s - loss: 0.2542 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2442 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-4-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.3781 - tp: 71528.0000 - fp: 8472.0000 - tn: 71528.0000 - fn: 8472.0000 - accuracy: 0.8941 - precision: 0.8941 - recall: 0.8941 - auc: 0.8940 - val_loss: 1.0444 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 7806.0000 - val_fn: 12194.0000 - val_accuracy: 0.3903 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.3903
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-4-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6175 - tp: 56887.0000 - fp: 23113.0000 - tn: 56887.0000 - fn: 23113.0000 - accuracy: 0.7111 - precision: 0.7111 - recall: 0.7111 - auc: 0.7137 - val_loss: 0.2416 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-4-batch-900000-1000000
[33m[INFO] loading file 5-6/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 5s - loss: 0.5263 - tp: 62445.0000 - fp: 17555.0000 - tn: 62445.0000 - fn: 17555.0000 - accuracy: 0.7806 - precision: 0.7806 - recall: 0.7806 - auc: 0.7806 - val_loss: 0.7056 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 12842.0000 - val_fn: 7158.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6421
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-6-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.7026 - tp: 51316.0000 - fp: 28684.0000 - tn: 51316.0000 - fn: 28684.0000 - accuracy: 0.6414 - precision: 0.6414 - recall: 0.6414 - auc: 0.6417 - val_loss: 0.4369 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 17052.0000 - val_fn: 2948.0000 - val_accuracy: 0.8526 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.8526
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-6-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.2448 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2355 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-6-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.2274 - tp: 79998.0000 - fp: 2.0000 - tn: 79998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2191 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-6-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.2120 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2047 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-6-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1984 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1920 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-6-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1863 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1806 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-6-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1755 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1703 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-6-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1658 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5420 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 15632.0000 - val_fn: 4368.0000 - val_accuracy: 0.7816 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.7816
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-6-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.7807 - tp: 51195.0000 - fp: 28805.0000 - tn: 51195.0000 - fn: 28805.0000 - accuracy: 0.6399 - precision: 0.6399 - recall: 0.6399 - auc: 0.6405 - val_loss: 0.7748 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 12768.0000 - val_fn: 7232.0000 - val_accuracy: 0.6384 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.6384
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-6-batch-900000-1000000
[33m[INFO] loading file 7-8/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.7645 - tp: 51210.0000 - fp: 28790.0000 - tn: 51210.0000 - fn: 28790.0000 - accuracy: 0.6401 - precision: 0.6401 - recall: 0.6401 - auc: 0.6400 - val_loss: 0.7568 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 12803.0000 - val_fn: 7197.0000 - val_accuracy: 0.6402 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.6402
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-8-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.7478 - tp: 51338.0000 - fp: 28662.0000 - tn: 51338.0000 - fn: 28662.0000 - accuracy: 0.6417 - precision: 0.6417 - recall: 0.6417 - auc: 0.6415 - val_loss: 0.7392 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 12860.0000 - val_fn: 7140.0000 - val_accuracy: 0.6430 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.6430
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-8-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.4757 - tp: 65370.0000 - fp: 14630.0000 - tn: 65370.0000 - fn: 14630.0000 - accuracy: 0.8171 - precision: 0.8171 - recall: 0.8171 - auc: 0.8171 - val_loss: 0.1994 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-8-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1933 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1872 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-8-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1818 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1763 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-8-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1714 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1665 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-8-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1621 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1577 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-8-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1537 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1496 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-8-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.3049 - tp: 73166.0000 - fp: 6834.0000 - tn: 73166.0000 - fn: 6834.0000 - accuracy: 0.9146 - precision: 0.9146 - recall: 0.9146 - auc: 0.9146 - val_loss: 0.4817 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 16368.0000 - val_fn: 3632.0000 - val_accuracy: 0.8184 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.8184
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-8-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.4806 - tp: 65505.0000 - fp: 14495.0000 - tn: 65505.0000 - fn: 14495.0000 - accuracy: 0.8188 - precision: 0.8188 - recall: 0.8188 - auc: 0.8188 - val_loss: 0.4796 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 16383.0000 - val_fn: 3617.0000 - val_accuracy: 0.8191 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.8191
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-8-batch-900000-1000000
[33m[INFO] loading file 9-10/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.4845 - tp: 65300.0000 - fp: 14700.0000 - tn: 65300.0000 - fn: 14700.0000 - accuracy: 0.8163 - precision: 0.8163 - recall: 0.8163 - auc: 0.8163 - val_loss: 0.4879 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 16283.0000 - val_fn: 3717.0000 - val_accuracy: 0.8141 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.8141
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-10-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1726 - tp: 78936.0000 - fp: 1064.0000 - tn: 78936.0000 - fn: 1064.0000 - accuracy: 0.9867 - precision: 0.9867 - recall: 0.9867 - auc: 0.9866 - val_loss: 0.1448 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-10-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1414 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1380 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-10-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1349 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1317 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-10-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1288 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1259 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-10-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1233 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1206 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-10-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1199 - tp: 79936.0000 - fp: 64.0000 - tn: 79936.0000 - fn: 64.0000 - accuracy: 0.9992 - precision: 0.9992 - recall: 0.9992 - auc: 0.9990 - val_loss: 0.8665 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 12843.0000 - val_fn: 7157.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6422
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-10-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.7213 - tp: 56672.0000 - fp: 23328.0000 - tn: 56672.0000 - fn: 23328.0000 - accuracy: 0.7084 - precision: 0.7084 - recall: 0.7084 - auc: 0.7077 - val_loss: 0.1237 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-10-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1212 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1186 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-10-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1162 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1138 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-10-batch-900000-1000000
[33m[INFO] loading file 11-12/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1116 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1094 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-12-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1074 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1053 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-12-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1034 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-12-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.0998 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0980 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-12-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.0963 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0946 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-12-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.0931 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0915 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-12-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.0901 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4825 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 16689.0000 - val_fn: 3311.0000 - val_accuracy: 0.8345 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8345
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-12-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.9272 - tp: 51328.0000 - fp: 28672.0000 - tn: 51328.0000 - fn: 28672.0000 - accuracy: 0.6416 - precision: 0.6416 - recall: 0.6416 - auc: 0.6419 - val_loss: 0.5762 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 15792.0000 - val_fn: 4208.0000 - val_accuracy: 0.7896 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.7896
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-12-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.0964 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0947 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-12-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.0932 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0916 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-12-batch-900000-1000000
[33m[INFO] loading file 13-14/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.0902 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0887 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-14-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.0874 - tp: 79998.0000 - fp: 2.0000 - tn: 79998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0859 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-14-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.0846 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6850 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 15075.0000 - val_fn: 4925.0000 - val_accuracy: 0.7538 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.7537
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-14-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.9447 - tp: 51313.0000 - fp: 28687.0000 - tn: 51313.0000 - fn: 28687.0000 - accuracy: 0.6414 - precision: 0.6414 - recall: 0.6414 - auc: 0.6415 - val_loss: 0.9241 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 12876.0000 - val_fn: 7124.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-14-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.9146 - tp: 51356.0000 - fp: 28644.0000 - tn: 51356.0000 - fn: 28644.0000 - accuracy: 0.6420 - precision: 0.6420 - recall: 0.6420 - auc: 0.6422 - val_loss: 0.8974 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 12867.0000 - val_fn: 7133.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-14-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.5860 - tp: 62543.0000 - fp: 17457.0000 - tn: 62543.0000 - fn: 17457.0000 - accuracy: 0.7818 - precision: 0.7818 - recall: 0.7818 - auc: 0.7843 - val_loss: 0.1068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-14-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1028 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-14-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1010 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0992 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-14-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.0975 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0958 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-14-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.0942 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0926 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-14-batch-900000-1000000
[33m[INFO] loading file 15-16/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (939690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.0912 - tp: 79998.0000 - fp: 2.0000 - tn: 79998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0896 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-16-batch-0-100000
[INFO] processing batch 100000-200000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.0883 - tp: 79998.0000 - fp: 2.0000 - tn: 79998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0868 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-16-batch-100000-200000
[INFO] processing batch 200000-300000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.0855 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0841 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-16-batch-200000-300000
[INFO] processing batch 300000-400000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.0829 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1184 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 11586.0000 - val_fn: 8414.0000 - val_accuracy: 0.5793 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.5793
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-16-batch-300000-400000
[INFO] processing batch 400000-500000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 1.2062 - tp: 42561.0000 - fp: 37439.0000 - tn: 42561.0000 - fn: 37439.0000 - accuracy: 0.5320 - precision: 0.5320 - recall: 0.5320 - auc: 0.5315 - val_loss: 1.1783 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 10627.0000 - val_fn: 9373.0000 - val_accuracy: 0.5314 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.5314
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-16-batch-400000-500000
[INFO] processing batch 500000-600000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 1.1516 - tp: 42492.0000 - fp: 37508.0000 - tn: 42492.0000 - fn: 37508.0000 - accuracy: 0.5311 - precision: 0.5311 - recall: 0.5311 - auc: 0.5313 - val_loss: 1.1244 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 10618.0000 - val_fn: 9382.0000 - val_accuracy: 0.5309 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.5309
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-16-batch-500000-600000
[INFO] processing batch 600000-700000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6885 - tp: 58381.0000 - fp: 21619.0000 - tn: 58381.0000 - fn: 21619.0000 - accuracy: 0.7298 - precision: 0.7298 - recall: 0.7298 - auc: 0.7303 - val_loss: 0.1156 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-16-batch-600000-700000
[INFO] processing batch 700000-800000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1133 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1110 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-16-batch-700000-800000
[INFO] processing batch 800000-900000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1090 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-16-batch-800000-900000
[INFO] processing batch 900000-1000000/939690
[33m[INFO] loading file 17-18/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1049 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-18-batch-0-100000
[INFO] processing batch 100000-200000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1012 - tp: 79999.0000 - fp: 1.0000 - tn: 79999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0993 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-18-batch-100000-200000
[INFO] processing batch 200000-300000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.0976 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0958 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-18-batch-200000-300000
[INFO] processing batch 300000-400000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.4224 - tp: 68607.0000 - fp: 11393.0000 - tn: 68607.0000 - fn: 11393.0000 - accuracy: 0.8576 - precision: 0.8576 - recall: 0.8576 - auc: 0.8576 - val_loss: 0.5110 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 16369.0000 - val_fn: 3631.0000 - val_accuracy: 0.8184 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.8184
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-18-batch-300000-400000
[INFO] processing batch 400000-500000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.5082 - tp: 65526.0000 - fp: 14474.0000 - tn: 65526.0000 - fn: 14474.0000 - accuracy: 0.8191 - precision: 0.8191 - recall: 0.8191 - auc: 0.8190 - val_loss: 0.2525 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 18648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9324 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9324
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-18-batch-400000-500000
[INFO] processing batch 500000-600000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.3216 - tp: 72129.0000 - fp: 7871.0000 - tn: 72129.0000 - fn: 7871.0000 - accuracy: 0.9016 - precision: 0.9016 - recall: 0.9016 - auc: 0.9016 - val_loss: 0.9563 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 12369.0000 - val_fn: 7631.0000 - val_accuracy: 0.6184 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.6184
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-18-batch-500000-600000
[INFO] processing batch 600000-700000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.9352 - tp: 49698.0000 - fp: 30302.0000 - tn: 49698.0000 - fn: 30302.0000 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - auc: 0.6208 - val_loss: 0.9268 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 12357.0000 - val_fn: 7643.0000 - val_accuracy: 0.6179 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.6179
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-18-batch-600000-700000
[INFO] processing batch 700000-800000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.9096 - tp: 49541.0000 - fp: 30459.0000 - tn: 49541.0000 - fn: 30459.0000 - accuracy: 0.6193 - precision: 0.6193 - recall: 0.6193 - auc: 0.6196 - val_loss: 0.8939 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 12397.0000 - val_fn: 7603.0000 - val_accuracy: 0.6198 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.6199
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-18-batch-700000-800000
[INFO] processing batch 800000-900000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.2625 - tp: 74509.0000 - fp: 5491.0000 - tn: 74509.0000 - fn: 5491.0000 - accuracy: 0.9314 - precision: 0.9314 - recall: 0.9314 - auc: 0.9291 - val_loss: 0.1218 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-18-batch-800000-900000
[INFO] processing batch 900000-1000000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1193 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1168 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-18-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039690
[33m[INFO] loading file 19-20/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1145 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1122 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-20-batch-0-100000
[INFO] processing batch 100000-200000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1101 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1079 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-20-batch-100000-200000
[INFO] processing batch 200000-300000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1060 - tp: 79999.0000 - fp: 1.0000 - tn: 79999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1039 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-20-batch-200000-300000
[INFO] processing batch 300000-400000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.3989 - tp: 69321.0000 - fp: 10679.0000 - tn: 69321.0000 - fn: 10679.0000 - accuracy: 0.8665 - precision: 0.8665 - recall: 0.8665 - auc: 0.8665 - val_loss: 1.4368 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 7882.0000 - val_fn: 12118.0000 - val_accuracy: 0.3941 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.3941
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-20-batch-300000-400000
[INFO] processing batch 400000-500000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 1.3959 - tp: 31237.0000 - fp: 48763.0000 - tn: 31237.0000 - fn: 48763.0000 - accuracy: 0.3905 - precision: 0.3905 - recall: 0.3905 - auc: 0.3914 - val_loss: 0.1269 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-20-batch-400000-500000
[INFO] processing batch 500000-600000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1243 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1736 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 19491.0000 - val_fn: 509.0000 - val_accuracy: 0.9746 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9746
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-20-batch-500000-600000
[INFO] processing batch 600000-700000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.4934 - tp: 65427.0000 - fp: 14573.0000 - tn: 65427.0000 - fn: 14573.0000 - accuracy: 0.8178 - precision: 0.8178 - recall: 0.8178 - auc: 0.8181 - val_loss: 0.4925 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 16357.0000 - val_fn: 3643.0000 - val_accuracy: 0.8178 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.8178
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-20-batch-600000-700000
[INFO] processing batch 700000-800000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.4936 - tp: 65351.0000 - fp: 14649.0000 - tn: 65351.0000 - fn: 14649.0000 - accuracy: 0.8169 - precision: 0.8169 - recall: 0.8169 - auc: 0.8169 - val_loss: 0.4895 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 16371.0000 - val_fn: 3629.0000 - val_accuracy: 0.8185 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.8185
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-20-batch-700000-800000
[INFO] processing batch 800000-900000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.2258 - tp: 76022.0000 - fp: 3978.0000 - tn: 76022.0000 - fn: 3978.0000 - accuracy: 0.9503 - precision: 0.9503 - recall: 0.9503 - auc: 0.9503 - val_loss: 0.1244 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-20-batch-800000-900000
[INFO] processing batch 900000-1000000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1218 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1192 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-20-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039690
[33m[INFO] loading file 21-22/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1168 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1144 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-22-batch-0-100000
[INFO] processing batch 100000-200000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1122 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1099 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-22-batch-100000-200000
[INFO] processing batch 200000-300000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1079 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1058 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-22-batch-200000-300000
[INFO] processing batch 300000-400000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1039 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-22-batch-300000-400000
[INFO] processing batch 400000-500000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1002 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0984 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-22-batch-400000-500000
[INFO] processing batch 500000-600000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.7984 - tp: 55006.0000 - fp: 24994.0000 - tn: 55006.0000 - fn: 24994.0000 - accuracy: 0.6876 - precision: 0.6876 - recall: 0.6876 - auc: 0.6911 - val_loss: 1.1320 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 10612.0000 - val_fn: 9388.0000 - val_accuracy: 0.5306 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.5306
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-22-batch-500000-600000
[INFO] processing batch 600000-700000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 1.1077 - tp: 42398.0000 - fp: 37602.0000 - tn: 42398.0000 - fn: 37602.0000 - accuracy: 0.5300 - precision: 0.5300 - recall: 0.5300 - auc: 0.5296 - val_loss: 1.0889 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 10527.0000 - val_fn: 9473.0000 - val_accuracy: 0.5264 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.5264
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-22-batch-600000-700000
[INFO] processing batch 700000-800000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 1.0586 - tp: 42367.0000 - fp: 37631.0000 - tn: 42369.0000 - fn: 37633.0000 - accuracy: 0.5296 - precision: 0.5296 - recall: 0.5296 - auc: 0.5297 - val_loss: 1.0315 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 10623.0000 - val_fn: 9377.0000 - val_accuracy: 0.5311 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.5311
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-22-batch-700000-800000
[INFO] processing batch 800000-900000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 1.0108 - tp: 42452.0000 - fp: 37548.0000 - tn: 42452.0000 - fn: 37548.0000 - accuracy: 0.5307 - precision: 0.5307 - recall: 0.5307 - auc: 0.5306 - val_loss: 0.9899 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 10601.0000 - val_fn: 9399.0000 - val_accuracy: 0.5300 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-22-batch-800000-900000
[INFO] processing batch 900000-1000000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.9707 - tp: 42382.0000 - fp: 37618.0000 - tn: 42382.0000 - fn: 37618.0000 - accuracy: 0.5298 - precision: 0.5298 - recall: 0.5298 - auc: 0.5298 - val_loss: 0.9494 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 10612.0000 - val_fn: 9388.0000 - val_accuracy: 0.5306 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.5306
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-22-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039687
[33m[INFO] loading file 23-24/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.7407 - tp: 52270.0000 - fp: 27730.0000 - tn: 52270.0000 - fn: 27730.0000 - accuracy: 0.6534 - precision: 0.6534 - recall: 0.6534 - auc: 0.6529 - val_loss: 0.1880 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-24-batch-0-100000
[INFO] processing batch 100000-200000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1826 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1770 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-24-batch-100000-200000
[INFO] processing batch 200000-300000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1721 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1672 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-24-batch-200000-300000
[INFO] processing batch 300000-400000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1628 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1583 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-24-batch-300000-400000
[INFO] processing batch 400000-500000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1543 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1502 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-24-batch-400000-500000
[INFO] processing batch 500000-600000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1466 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1429 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-24-batch-500000-600000
[INFO] processing batch 600000-700000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1395 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1362 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-24-batch-600000-700000
[INFO] processing batch 700000-800000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1331 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1300 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-24-batch-700000-800000
[INFO] processing batch 800000-900000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.1273 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1244 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-24-batch-800000-900000
[INFO] processing batch 900000-1000000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.2324 - tp: 75698.0000 - fp: 4302.0000 - tn: 75698.0000 - fn: 4302.0000 - accuracy: 0.9462 - precision: 0.9462 - recall: 0.9462 - auc: 0.9474 - val_loss: 0.8465 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 12912.0000 - val_fn: 7088.0000 - val_accuracy: 0.6456 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.6456
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-24-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039687
[33m[INFO] loading file 25-26/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.8392 - tp: 51502.0000 - fp: 28498.0000 - tn: 51502.0000 - fn: 28498.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6444 - val_loss: 0.8313 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 12842.0000 - val_fn: 7158.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6421
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-26-batch-0-100000
[INFO] processing batch 100000-200000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.8185 - tp: 51479.0000 - fp: 28521.0000 - tn: 51479.0000 - fn: 28521.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6429 - val_loss: 0.8060 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 12894.0000 - val_fn: 7106.0000 - val_accuracy: 0.6447 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.6447
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-26-batch-100000-200000
[INFO] processing batch 200000-300000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.7992 - tp: 51470.0000 - fp: 28530.0000 - tn: 51470.0000 - fn: 28530.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6438 - val_loss: 0.7914 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 12850.0000 - val_fn: 7150.0000 - val_accuracy: 0.6425 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.6425
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-26-batch-200000-300000
[INFO] processing batch 300000-400000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.7808 - tp: 51503.0000 - fp: 28497.0000 - tn: 51503.0000 - fn: 28497.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6430 - val_loss: 0.7751 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 12843.0000 - val_fn: 7157.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6422
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-26-batch-300000-400000
[INFO] processing batch 400000-500000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.7655 - tp: 51468.0000 - fp: 28532.0000 - tn: 51468.0000 - fn: 28532.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6438 - val_loss: 0.7577 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 12868.0000 - val_fn: 7132.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-26-batch-400000-500000
[INFO] processing batch 500000-600000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.7500 - tp: 51523.0000 - fp: 28477.0000 - tn: 51523.0000 - fn: 28477.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6444 - val_loss: 0.7442 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 12867.0000 - val_fn: 7133.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-26-batch-500000-600000
[INFO] processing batch 600000-700000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.7361 - tp: 51579.0000 - fp: 28421.0000 - tn: 51579.0000 - fn: 28421.0000 - accuracy: 0.6447 - precision: 0.6447 - recall: 0.6447 - auc: 0.6439 - val_loss: 0.7323 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 12864.0000 - val_fn: 7136.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-26-batch-600000-700000
[INFO] processing batch 700000-800000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.7268 - tp: 51461.0000 - fp: 28538.0000 - tn: 51462.0000 - fn: 28539.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6427 - val_loss: 0.7182 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 12911.0000 - val_fn: 7089.0000 - val_accuracy: 0.6456 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.6456
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-26-batch-700000-800000
[INFO] processing batch 800000-900000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.7159 - tp: 51506.0000 - fp: 28494.0000 - tn: 51506.0000 - fn: 28494.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6437 - val_loss: 0.7071 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 12936.0000 - val_fn: 7064.0000 - val_accuracy: 0.6468 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.6468
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-26-batch-800000-900000
[INFO] processing batch 900000-1000000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.7075 - tp: 51474.0000 - fp: 28526.0000 - tn: 51474.0000 - fn: 28526.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6433 - val_loss: 0.6984 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 12945.0000 - val_fn: 7055.0000 - val_accuracy: 0.6472 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.6472
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-26-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039687
[33m[INFO] loading file 27-28/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (979817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.7005 - tp: 51419.0000 - fp: 28581.0000 - tn: 51419.0000 - fn: 28581.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6433 - val_loss: 0.6984 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 12829.0000 - val_fn: 7171.0000 - val_accuracy: 0.6414 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.6414
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-28-batch-0-100000
[INFO] processing batch 100000-200000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6926 - tp: 51484.0000 - fp: 28514.0000 - tn: 51486.0000 - fn: 28516.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6435 - auc: 0.6441 - val_loss: 0.6866 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 12918.0000 - val_fn: 7082.0000 - val_accuracy: 0.6459 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.6459
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-28-batch-100000-200000
[INFO] processing batch 200000-300000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6852 - tp: 51583.0000 - fp: 28417.0000 - tn: 51583.0000 - fn: 28417.0000 - accuracy: 0.6448 - precision: 0.6448 - recall: 0.6448 - auc: 0.6445 - val_loss: 0.6843 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 12863.0000 - val_fn: 7137.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6431
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-28-batch-200000-300000
[INFO] processing batch 300000-400000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6827 - tp: 51396.0000 - fp: 28604.0000 - tn: 51396.0000 - fn: 28604.0000 - accuracy: 0.6424 - precision: 0.6424 - recall: 0.6424 - auc: 0.6428 - val_loss: 0.6801 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 12851.0000 - val_fn: 7149.0000 - val_accuracy: 0.6425 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.6425
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-28-batch-300000-400000
[INFO] processing batch 400000-500000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6770 - tp: 51479.0000 - fp: 28521.0000 - tn: 51479.0000 - fn: 28521.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6432 - val_loss: 0.6749 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 12871.0000 - val_fn: 7129.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-28-batch-400000-500000
[INFO] processing batch 500000-600000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6742 - tp: 51397.0000 - fp: 28603.0000 - tn: 51397.0000 - fn: 28603.0000 - accuracy: 0.6425 - precision: 0.6425 - recall: 0.6425 - auc: 0.6432 - val_loss: 0.6718 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 12861.0000 - val_fn: 7139.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6430
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-28-batch-500000-600000
[INFO] processing batch 600000-700000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6702 - tp: 51457.0000 - fp: 28543.0000 - tn: 51457.0000 - fn: 28543.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6430 - val_loss: 0.6684 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 12868.0000 - val_fn: 7132.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-28-batch-600000-700000
[INFO] processing batch 700000-800000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6673 - tp: 51459.0000 - fp: 28541.0000 - tn: 51459.0000 - fn: 28541.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6433 - val_loss: 0.6641 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 12903.0000 - val_fn: 7097.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6451
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-28-batch-700000-800000
[INFO] processing batch 800000-900000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6641 - tp: 51525.0000 - fp: 28475.0000 - tn: 51525.0000 - fn: 28475.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6439 - val_loss: 0.6642 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 12854.0000 - val_fn: 7146.0000 - val_accuracy: 0.6427 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.6427
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-28-batch-800000-900000
[INFO] processing batch 900000-1000000/979817
[33m[INFO] loading file 29-30/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 5s - loss: 0.6628 - tp: 51460.0000 - fp: 28540.0000 - tn: 51460.0000 - fn: 28540.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6427 - val_loss: 0.6622 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-30-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6603 - tp: 51527.0000 - fp: 28473.0000 - tn: 51527.0000 - fn: 28473.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6445 - val_loss: 0.6609 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 12849.0000 - val_fn: 7151.0000 - val_accuracy: 0.6424 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.6424
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-30-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6593 - tp: 51484.0000 - fp: 28516.0000 - tn: 51484.0000 - fn: 28516.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6437 - val_loss: 0.6561 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 12931.0000 - val_fn: 7069.0000 - val_accuracy: 0.6465 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.6465
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-30-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6573 - tp: 51556.0000 - fp: 28444.0000 - tn: 51556.0000 - fn: 28444.0000 - accuracy: 0.6445 - precision: 0.6445 - recall: 0.6445 - auc: 0.6447 - val_loss: 0.6581 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-30-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6570 - tp: 51488.0000 - fp: 28511.0000 - tn: 51489.0000 - fn: 28512.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6429 - val_loss: 0.6564 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 12875.0000 - val_fn: 7125.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-30-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6557 - tp: 51529.0000 - fp: 28471.0000 - tn: 51529.0000 - fn: 28471.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6435 - val_loss: 0.6561 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 12860.0000 - val_fn: 7140.0000 - val_accuracy: 0.6430 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.6430
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-30-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6557 - tp: 51449.0000 - fp: 28549.0000 - tn: 51451.0000 - fn: 28551.0000 - accuracy: 0.6431 - precision: 0.6431 - recall: 0.6431 - auc: 0.6431 - val_loss: 0.6556 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 12855.0000 - val_fn: 7145.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-30-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6547 - tp: 51488.0000 - fp: 28512.0000 - tn: 51488.0000 - fn: 28512.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6432 - val_loss: 0.6550 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 12856.0000 - val_fn: 7144.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-30-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6537 - tp: 51529.0000 - fp: 28471.0000 - tn: 51529.0000 - fn: 28471.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6443 - val_loss: 0.6537 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 12877.0000 - val_fn: 7123.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-30-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6531 - tp: 51550.0000 - fp: 28450.0000 - tn: 51550.0000 - fn: 28450.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6443 - val_loss: 0.6536 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 12870.0000 - val_fn: 7130.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-30-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 31-32/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6533 - tp: 51494.0000 - fp: 28506.0000 - tn: 51494.0000 - fn: 28506.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6436 - val_loss: 0.6514 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 12921.0000 - val_fn: 7079.0000 - val_accuracy: 0.6460 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.6460
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-32-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6527 - tp: 51524.0000 - fp: 28476.0000 - tn: 51524.0000 - fn: 28476.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6440 - val_loss: 0.6518 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 12902.0000 - val_fn: 7098.0000 - val_accuracy: 0.6451 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.6451
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-32-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6532 - tp: 51428.0000 - fp: 28572.0000 - tn: 51428.0000 - fn: 28572.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6429 - val_loss: 0.6525 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 12874.0000 - val_fn: 7126.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-32-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6526 - tp: 51479.0000 - fp: 28521.0000 - tn: 51479.0000 - fn: 28521.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6519 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 12886.0000 - val_fn: 7114.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-32-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6521 - tp: 51508.0000 - fp: 28492.0000 - tn: 51508.0000 - fn: 28492.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6515 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 12893.0000 - val_fn: 7107.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-32-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6522 - tp: 51484.0000 - fp: 28516.0000 - tn: 51484.0000 - fn: 28516.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6434 - val_loss: 0.6515 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 12889.0000 - val_fn: 7111.0000 - val_accuracy: 0.6445 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.6445
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-32-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6516 - tp: 51531.0000 - fp: 28469.0000 - tn: 51531.0000 - fn: 28469.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6441 - val_loss: 0.6518 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 12875.0000 - val_fn: 7125.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-32-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6512 - tp: 51576.0000 - fp: 28424.0000 - tn: 51576.0000 - fn: 28424.0000 - accuracy: 0.6447 - precision: 0.6447 - recall: 0.6447 - auc: 0.6447 - val_loss: 0.6513 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 12890.0000 - val_fn: 7110.0000 - val_accuracy: 0.6445 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.6445
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-32-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6519 - tp: 51487.0000 - fp: 28511.0000 - tn: 51489.0000 - fn: 28513.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6431 - val_loss: 0.6520 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 12864.0000 - val_fn: 7136.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-32-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6520 - tp: 51448.0000 - fp: 28551.0000 - tn: 51449.0000 - fn: 28552.0000 - accuracy: 0.6431 - precision: 0.6431 - recall: 0.6431 - auc: 0.6431 - val_loss: 0.6518 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 12867.0000 - val_fn: 7133.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-32-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 33-34/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 5s - loss: 0.6515 - tp: 51508.0000 - fp: 28492.0000 - tn: 51508.0000 - fn: 28492.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6515 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 12875.0000 - val_fn: 7125.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-34-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6514 - tp: 51518.0000 - fp: 28482.0000 - tn: 51518.0000 - fn: 28482.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6440 - val_loss: 0.6518 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 12864.0000 - val_fn: 7136.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-34-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6522 - tp: 51404.0000 - fp: 28596.0000 - tn: 51404.0000 - fn: 28596.0000 - accuracy: 0.6425 - precision: 0.6425 - recall: 0.6425 - auc: 0.6426 - val_loss: 0.6518 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 12862.0000 - val_fn: 7138.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6431
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-34-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6510 - tp: 51551.0000 - fp: 28448.0000 - tn: 51552.0000 - fn: 28449.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6446 - val_loss: 0.6511 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 12886.0000 - val_fn: 7114.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-34-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6507 - tp: 51593.0000 - fp: 28406.0000 - tn: 51594.0000 - fn: 28407.0000 - accuracy: 0.6449 - precision: 0.6449 - recall: 0.6449 - auc: 0.6449 - val_loss: 0.6497 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 12929.0000 - val_fn: 7071.0000 - val_accuracy: 0.6464 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.6465
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-34-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6513 - tp: 51505.0000 - fp: 28495.0000 - tn: 51505.0000 - fn: 28495.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6438 - val_loss: 0.6524 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 12842.0000 - val_fn: 7158.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6421
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-34-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6516 - tp: 51470.0000 - fp: 28530.0000 - tn: 51470.0000 - fn: 28530.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6434 - val_loss: 0.6516 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 12865.0000 - val_fn: 7135.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-34-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6509 - tp: 51584.0000 - fp: 28416.0000 - tn: 51584.0000 - fn: 28416.0000 - accuracy: 0.6448 - precision: 0.6448 - recall: 0.6448 - auc: 0.6447 - val_loss: 0.6513 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 12876.0000 - val_fn: 7124.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-34-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6520 - tp: 51408.0000 - fp: 28592.0000 - tn: 51408.0000 - fn: 28592.0000 - accuracy: 0.6426 - precision: 0.6426 - recall: 0.6426 - auc: 0.6426 - val_loss: 0.6526 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 12834.0000 - val_fn: 7166.0000 - val_accuracy: 0.6417 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.6417
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-34-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6519 - tp: 51422.0000 - fp: 28578.0000 - tn: 51422.0000 - fn: 28578.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6428 - val_loss: 0.6512 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 12877.0000 - val_fn: 7123.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-34-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 35-36/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6511 - tp: 51520.0000 - fp: 28480.0000 - tn: 51520.0000 - fn: 28480.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6440 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-36-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6514 - tp: 51486.0000 - fp: 28514.0000 - tn: 51486.0000 - fn: 28514.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6431 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 12876.0000 - val_fn: 7124.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-36-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6513 - tp: 51495.0000 - fp: 28504.0000 - tn: 51496.0000 - fn: 28505.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 12892.0000 - val_fn: 7108.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-36-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6511 - tp: 51521.0000 - fp: 28479.0000 - tn: 51521.0000 - fn: 28479.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6440 - val_loss: 0.6519 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 12855.0000 - val_fn: 7145.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-36-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6507 - tp: 51570.0000 - fp: 28430.0000 - tn: 51570.0000 - fn: 28430.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6513 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 12872.0000 - val_fn: 7128.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-36-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 51498.0000 - fn: 28502.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6513 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 12874.0000 - val_fn: 7126.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-36-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6502 - tp: 51644.0000 - fp: 28356.0000 - tn: 51644.0000 - fn: 28356.0000 - accuracy: 0.6456 - precision: 0.6456 - recall: 0.6456 - auc: 0.6455 - val_loss: 0.6506 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 12895.0000 - val_fn: 7105.0000 - val_accuracy: 0.6447 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.6447
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-36-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: 0.6520 - tp: 51397.0000 - fp: 28603.0000 - tn: 51397.0000 - fn: 28603.0000 - accuracy: 0.6425 - precision: 0.6425 - recall: 0.6425 - auc: 0.6425 - val_loss: 0.6495 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 12933.0000 - val_fn: 7067.0000 - val_accuracy: 0.6467 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.6467
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-36-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: 0.6519 - tp: 51415.0000 - fp: 28585.0000 - tn: 51415.0000 - fn: 28585.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6427 - val_loss: 0.6512 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 12878.0000 - val_fn: 7122.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-36-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: 0.6512 - tp: 51500.0000 - fp: 28500.0000 - tn: 51500.0000 - fn: 28500.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6437 - val_loss: 0.6518 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 12856.0000 - val_fn: 7144.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-36-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 37-38/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6519 - tp: 51413.0000 - fp: 28587.0000 - tn: 51413.0000 - fn: 28587.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6427 - val_loss: 0.6519 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 12854.0000 - val_fn: 7146.0000 - val_accuracy: 0.6427 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.6427
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-38-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6516 - tp: 51456.0000 - fp: 28544.0000 - tn: 51456.0000 - fn: 28544.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6432 - val_loss: 0.6504 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 12903.0000 - val_fn: 7097.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6451
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-38-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6508 - tp: 51565.0000 - fp: 28435.0000 - tn: 51565.0000 - fn: 28435.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6445 - val_loss: 0.6514 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 12871.0000 - val_fn: 7129.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-38-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6511 - tp: 51512.0000 - fp: 28488.0000 - tn: 51512.0000 - fn: 28488.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6508 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 12888.0000 - val_fn: 7112.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-38-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6510 - tp: 51528.0000 - fp: 28472.0000 - tn: 51528.0000 - fn: 28472.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6441 - val_loss: 0.6505 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 12899.0000 - val_fn: 7101.0000 - val_accuracy: 0.6449 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.6449
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-38-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6511 - tp: 51512.0000 - fp: 28487.0000 - tn: 51513.0000 - fn: 28488.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6496 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 12931.0000 - val_fn: 7069.0000 - val_accuracy: 0.6465 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.6465
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-38-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6506 - tp: 51589.0000 - fp: 28411.0000 - tn: 51589.0000 - fn: 28411.0000 - accuracy: 0.6449 - precision: 0.6449 - recall: 0.6449 - auc: 0.6449 - val_loss: 0.6522 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 12842.0000 - val_fn: 7158.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6421
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-38-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6514 - tp: 51481.0000 - fp: 28519.0000 - tn: 51481.0000 - fn: 28519.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-38-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6509 - tp: 51549.0000 - fp: 28451.0000 - tn: 51549.0000 - fn: 28451.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6444 - val_loss: 0.6505 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 12898.0000 - val_fn: 7102.0000 - val_accuracy: 0.6449 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.6449
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-38-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 51550.0000 - fn: 28450.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6444 - val_loss: 0.6515 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 12866.0000 - val_fn: 7134.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-38-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 39-40/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6513 - tp: 51486.0000 - fp: 28514.0000 - tn: 51486.0000 - fn: 28514.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6521 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 12847.0000 - val_fn: 7153.0000 - val_accuracy: 0.6424 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-40-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6505 - tp: 51597.0000 - fp: 28403.0000 - tn: 51597.0000 - fn: 28403.0000 - accuracy: 0.6450 - precision: 0.6450 - recall: 0.6450 - auc: 0.6450 - val_loss: 0.6502 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 12910.0000 - val_fn: 7090.0000 - val_accuracy: 0.6455 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.6455
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-40-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6503 - tp: 51631.0000 - fp: 28369.0000 - tn: 51631.0000 - fn: 28369.0000 - accuracy: 0.6454 - precision: 0.6454 - recall: 0.6454 - auc: 0.6454 - val_loss: 0.6507 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 12894.0000 - val_fn: 7106.0000 - val_accuracy: 0.6447 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.6447
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-40-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 51493.0000 - fn: 28507.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 12869.0000 - val_fn: 7131.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-40-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6513 - tp: 51488.0000 - fp: 28512.0000 - tn: 51488.0000 - fn: 28512.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 12875.0000 - val_fn: 7125.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-40-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6518 - tp: 51418.0000 - fp: 28582.0000 - tn: 51418.0000 - fn: 28582.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6427 - val_loss: 0.6522 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 12843.0000 - val_fn: 7157.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6422
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-40-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6513 - tp: 51491.0000 - fp: 28509.0000 - tn: 51491.0000 - fn: 28509.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 12862.0000 - val_fn: 7138.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6431
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-40-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6508 - tp: 51556.0000 - fp: 28444.0000 - tn: 51556.0000 - fn: 28444.0000 - accuracy: 0.6445 - precision: 0.6445 - recall: 0.6445 - auc: 0.6445 - val_loss: 0.6500 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 12916.0000 - val_fn: 7084.0000 - val_accuracy: 0.6458 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.6458
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-40-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6512 - tp: 51505.0000 - fp: 28495.0000 - tn: 51505.0000 - fn: 28495.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6438 - val_loss: 0.6523 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 12838.0000 - val_fn: 7162.0000 - val_accuracy: 0.6419 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.6419
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-40-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6517 - tp: 51432.0000 - fp: 28568.0000 - tn: 51432.0000 - fn: 28568.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6429 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 12850.0000 - val_fn: 7150.0000 - val_accuracy: 0.6425 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.6425
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-40-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 41-42/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 5s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 51427.0000 - fn: 28573.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6428 - val_loss: 0.6516 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 12861.0000 - val_fn: 7139.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6430
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-42-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 5s - loss: 0.6511 - tp: 51515.0000 - fp: 28485.0000 - tn: 51515.0000 - fn: 28485.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6514 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 12868.0000 - val_fn: 7132.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-42-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 51452.0000 - fn: 28548.0000 - accuracy: 0.6431 - precision: 0.6431 - recall: 0.6431 - auc: 0.6431 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 12876.0000 - val_fn: 7124.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-42-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6506 - tp: 51584.0000 - fp: 28414.0000 - tn: 51586.0000 - fn: 28416.0000 - accuracy: 0.6448 - precision: 0.6448 - recall: 0.6448 - auc: 0.6448 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 12860.0000 - val_fn: 7140.0000 - val_accuracy: 0.6430 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.6430
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-42-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6507 - tp: 51566.0000 - fp: 28434.0000 - tn: 51566.0000 - fn: 28434.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6494 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 12937.0000 - val_fn: 7063.0000 - val_accuracy: 0.6468 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.6468
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-42-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6515 - tp: 51460.0000 - fp: 28540.0000 - tn: 51460.0000 - fn: 28540.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6432 - val_loss: 0.6527 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 12826.0000 - val_fn: 7174.0000 - val_accuracy: 0.6413 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.6413
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-42-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6513 - tp: 51507.0000 - fp: 28490.0000 - tn: 51510.0000 - fn: 28493.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6438 - auc: 0.6439 - val_loss: 0.6510 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 12882.0000 - val_fn: 7118.0000 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.6441
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-42-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6512 - tp: 51499.0000 - fp: 28501.0000 - tn: 51499.0000 - fn: 28501.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6519 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 12853.0000 - val_fn: 7147.0000 - val_accuracy: 0.6427 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.6427
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-42-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: 0.6513 - tp: 51492.0000 - fp: 28507.0000 - tn: 51493.0000 - fn: 28508.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6436 - auc: 0.6437 - val_loss: 0.6500 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 12917.0000 - val_fn: 7083.0000 - val_accuracy: 0.6459 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.6459
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-42-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: 0.6506 - tp: 51584.0000 - fp: 28416.0000 - tn: 51584.0000 - fn: 28416.0000 - accuracy: 0.6448 - precision: 0.6448 - recall: 0.6448 - auc: 0.6448 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 12875.0000 - val_fn: 7125.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-42-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 43-44/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 51591.0000 - fn: 28409.0000 - accuracy: 0.6449 - precision: 0.6449 - recall: 0.6449 - auc: 0.6449 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 12873.0000 - val_fn: 7127.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-44-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6510 - tp: 51529.0000 - fp: 28471.0000 - tn: 51529.0000 - fn: 28471.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6441 - val_loss: 0.6527 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 12824.0000 - val_fn: 7176.0000 - val_accuracy: 0.6412 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.6412
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-44-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6521 - tp: 51387.0000 - fp: 28613.0000 - tn: 51387.0000 - fn: 28613.0000 - accuracy: 0.6423 - precision: 0.6423 - recall: 0.6423 - auc: 0.6423 - val_loss: 0.6506 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 12896.0000 - val_fn: 7104.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-44-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6511 - tp: 51518.0000 - fp: 28482.0000 - tn: 51518.0000 - fn: 28482.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6439 - val_loss: 0.6521 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 12844.0000 - val_fn: 7156.0000 - val_accuracy: 0.6422 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.6422
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-44-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 51591.0000 - fn: 28409.0000 - accuracy: 0.6449 - precision: 0.6449 - recall: 0.6449 - auc: 0.6449 - val_loss: 0.6489 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 12952.0000 - val_fn: 7048.0000 - val_accuracy: 0.6476 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.6476
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-44-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 51452.0000 - fn: 28548.0000 - accuracy: 0.6431 - precision: 0.6431 - recall: 0.6431 - auc: 0.6431 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 12855.0000 - val_fn: 7145.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-44-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6512 - tp: 51498.0000 - fp: 28501.0000 - tn: 51499.0000 - fn: 28502.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-44-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6509 - tp: 51543.0000 - fp: 28457.0000 - tn: 51543.0000 - fn: 28457.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6443 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-44-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 51427.0000 - fn: 28573.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6428 - val_loss: 0.6508 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 12891.0000 - val_fn: 7109.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-44-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6510 - tp: 51537.0000 - fp: 28463.0000 - tn: 51537.0000 - fn: 28463.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 12863.0000 - val_fn: 7137.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6431
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-44-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 45-46/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6503 - tp: 51620.0000 - fp: 28380.0000 - tn: 51620.0000 - fn: 28380.0000 - accuracy: 0.6453 - precision: 0.6453 - recall: 0.6453 - auc: 0.6452 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 12869.0000 - val_fn: 7131.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-46-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6509 - tp: 51538.0000 - fp: 28462.0000 - tn: 51538.0000 - fn: 28462.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6509 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 12885.0000 - val_fn: 7115.0000 - val_accuracy: 0.6442 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.6442
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-46-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6508 - tp: 51564.0000 - fp: 28436.0000 - tn: 51564.0000 - fn: 28436.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6445 - val_loss: 0.6504 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 12904.0000 - val_fn: 7096.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-46-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6506 - tp: 51590.0000 - fp: 28410.0000 - tn: 51590.0000 - fn: 28410.0000 - accuracy: 0.6449 - precision: 0.6449 - recall: 0.6449 - auc: 0.6449 - val_loss: 0.6521 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 12844.0000 - val_fn: 7156.0000 - val_accuracy: 0.6422 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.6422
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-46-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6520 - tp: 51395.0000 - fp: 28605.0000 - tn: 51395.0000 - fn: 28605.0000 - accuracy: 0.6424 - precision: 0.6424 - recall: 0.6424 - auc: 0.6425 - val_loss: 0.6506 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 12896.0000 - val_fn: 7104.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-46-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6511 - tp: 51524.0000 - fp: 28476.0000 - tn: 51524.0000 - fn: 28476.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6440 - val_loss: 0.6501 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 12913.0000 - val_fn: 7087.0000 - val_accuracy: 0.6457 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.6457
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-46-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6515 - tp: 51461.0000 - fp: 28539.0000 - tn: 51461.0000 - fn: 28539.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6433 - val_loss: 0.6510 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 12883.0000 - val_fn: 7117.0000 - val_accuracy: 0.6442 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.6442
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-46-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6510 - tp: 51532.0000 - fp: 28468.0000 - tn: 51532.0000 - fn: 28468.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6509 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 12885.0000 - val_fn: 7115.0000 - val_accuracy: 0.6442 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.6442
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-46-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6512 - tp: 51502.0000 - fp: 28498.0000 - tn: 51502.0000 - fn: 28498.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6438 - val_loss: 0.6496 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 12929.0000 - val_fn: 7071.0000 - val_accuracy: 0.6464 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.6465
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-46-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6507 - tp: 51569.0000 - fp: 28431.0000 - tn: 51569.0000 - fn: 28431.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 12873.0000 - val_fn: 7127.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-46-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 47-48/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 5s - loss: 0.6505 - tp: 51601.0000 - fp: 28399.0000 - tn: 51601.0000 - fn: 28399.0000 - accuracy: 0.6450 - precision: 0.6450 - recall: 0.6450 - auc: 0.6450 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 12892.0000 - val_fn: 7108.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-48-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6508 - tp: 51559.0000 - fp: 28441.0000 - tn: 51559.0000 - fn: 28441.0000 - accuracy: 0.6445 - precision: 0.6445 - recall: 0.6445 - auc: 0.6445 - val_loss: 0.6513 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 12871.0000 - val_fn: 7129.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-48-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 51468.0000 - fn: 28532.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6433 - val_loss: 0.6528 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 12822.0000 - val_fn: 7178.0000 - val_accuracy: 0.6411 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.6411
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-48-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 51493.0000 - fn: 28507.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6511 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 12881.0000 - val_fn: 7119.0000 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.6441
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-48-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6513 - tp: 51492.0000 - fp: 28508.0000 - tn: 51492.0000 - fn: 28508.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6502 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 12909.0000 - val_fn: 7091.0000 - val_accuracy: 0.6454 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.6454
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-48-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6510 - tp: 51525.0000 - fp: 28475.0000 - tn: 51525.0000 - fn: 28475.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6440 - val_loss: 0.6526 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 12830.0000 - val_fn: 7170.0000 - val_accuracy: 0.6415 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.6415
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-48-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 51497.0000 - fn: 28503.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6511 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 12879.0000 - val_fn: 7121.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-48-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6509 - tp: 51546.0000 - fp: 28454.0000 - tn: 51546.0000 - fn: 28454.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6443 - val_loss: 0.6502 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 12911.0000 - val_fn: 7089.0000 - val_accuracy: 0.6456 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.6456
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-48-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6507 - tp: 51566.0000 - fp: 28434.0000 - tn: 51566.0000 - fn: 28434.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 12863.0000 - val_fn: 7137.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6431
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-48-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6504 - tp: 51606.0000 - fp: 28394.0000 - tn: 51606.0000 - fn: 28394.0000 - accuracy: 0.6451 - precision: 0.6451 - recall: 0.6451 - auc: 0.6451 - val_loss: 0.6503 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 12905.0000 - val_fn: 7095.0000 - val_accuracy: 0.6453 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.6453
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-48-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 49-50/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6510 - tp: 51532.0000 - fp: 28468.0000 - tn: 51532.0000 - fn: 28468.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6441 - val_loss: 0.6515 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 12865.0000 - val_fn: 7135.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-50-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6517 - tp: 51430.0000 - fp: 28570.0000 - tn: 51430.0000 - fn: 28570.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6429 - val_loss: 0.6498 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 12924.0000 - val_fn: 7076.0000 - val_accuracy: 0.6462 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.6462
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-50-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6515 - tp: 51469.0000 - fp: 28531.0000 - tn: 51469.0000 - fn: 28531.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6434 - val_loss: 0.6526 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 12829.0000 - val_fn: 7171.0000 - val_accuracy: 0.6414 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.6414
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-50-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6513 - tp: 51489.0000 - fp: 28510.0000 - tn: 51490.0000 - fn: 28511.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6498 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 12922.0000 - val_fn: 7078.0000 - val_accuracy: 0.6461 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.6461
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-50-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6513 - tp: 51495.0000 - fp: 28505.0000 - tn: 51495.0000 - fn: 28505.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6508 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 12890.0000 - val_fn: 7110.0000 - val_accuracy: 0.6445 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.6445
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-50-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6518 - tp: 51422.0000 - fp: 28578.0000 - tn: 51422.0000 - fn: 28578.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6428 - val_loss: 0.6528 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 12823.0000 - val_fn: 7177.0000 - val_accuracy: 0.6411 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.6411
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-50-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6514 - tp: 51483.0000 - fp: 28517.0000 - tn: 51483.0000 - fn: 28517.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 12892.0000 - val_fn: 7108.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-50-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6517 - tp: 51432.0000 - fp: 28568.0000 - tn: 51432.0000 - fn: 28568.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6429 - val_loss: 0.6520 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 12849.0000 - val_fn: 7151.0000 - val_accuracy: 0.6424 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.6424
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-50-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6515 - tp: 51461.0000 - fp: 28539.0000 - tn: 51461.0000 - fn: 28539.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6433 - val_loss: 0.6508 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 12889.0000 - val_fn: 7111.0000 - val_accuracy: 0.6445 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.6445
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-50-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.6515 - tp: 51467.0000 - fp: 28533.0000 - tn: 51467.0000 - fn: 28533.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6433 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-50-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[LOSS] 0.6517624092102051[0m
[33m[INFO] epoch 2/3[0m
[33m[INFO] loading file 1-2/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.4175 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3947 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-2-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.3754 - tp: 79993.0000 - fp: 6.0000 - tn: 79994.0000 - fn: 7.0000 - accuracy: 0.9999 - precision: 0.9999 - recall: 0.9999 - auc: 0.9999 - val_loss: 0.3560 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-2-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.3425 - tp: 79761.0000 - fp: 237.0000 - tn: 79763.0000 - fn: 239.0000 - accuracy: 0.9970 - precision: 0.9970 - recall: 0.9970 - auc: 0.9963 - val_loss: 0.7755 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 10606.0000 - val_fn: 9394.0000 - val_accuracy: 0.5303 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.5303
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-2-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.7685 - tp: 42442.0000 - fp: 37557.0000 - tn: 42443.0000 - fn: 37558.0000 - accuracy: 0.5305 - precision: 0.5305 - recall: 0.5305 - auc: 0.5307 - val_loss: 0.7610 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 10626.0000 - val_fn: 9374.0000 - val_accuracy: 0.5313 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.5312
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-2-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.7560 - tp: 42437.0000 - fp: 37563.0000 - tn: 42437.0000 - fn: 37563.0000 - accuracy: 0.5305 - precision: 0.5305 - recall: 0.5305 - auc: 0.5298 - val_loss: 0.7504 - val_tp: 10602.0000 - val_fp: 9397.0000 - val_tn: 10603.0000 - val_fn: 9398.0000 - val_accuracy: 0.5301 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-2-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.7453 - tp: 42434.0000 - fp: 37566.0000 - tn: 42434.0000 - fn: 37566.0000 - accuracy: 0.5304 - precision: 0.5304 - recall: 0.5304 - auc: 0.5307 - val_loss: 0.7411 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 10589.0000 - val_fn: 9411.0000 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.5294
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-2-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.4966 - tp: 67619.0000 - fp: 12381.0000 - tn: 67619.0000 - fn: 12381.0000 - accuracy: 0.8452 - precision: 0.8452 - recall: 0.8452 - auc: 0.8428 - val_loss: 0.3647 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-2-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.4342 - tp: 72432.0000 - fp: 7568.0000 - tn: 72432.0000 - fn: 7568.0000 - accuracy: 0.9054 - precision: 0.9054 - recall: 0.9054 - auc: 0.9067 - val_loss: 0.7646 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 10593.0000 - val_fn: 9407.0000 - val_accuracy: 0.5296 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.5296
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-2-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.7591 - tp: 42321.0000 - fp: 37679.0000 - tn: 42321.0000 - fn: 37679.0000 - accuracy: 0.5290 - precision: 0.5290 - recall: 0.5290 - auc: 0.5286 - val_loss: 0.7522 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 10602.0000 - val_fn: 9398.0000 - val_accuracy: 0.5301 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-2-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.4890 - tp: 67360.0000 - fp: 12640.0000 - tn: 67360.0000 - fn: 12640.0000 - accuracy: 0.8420 - precision: 0.8420 - recall: 0.8420 - auc: 0.8421 - val_loss: 0.3450 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-2-batch-900000-1000000
[33m[INFO] loading file 3-4/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.7268 - tp: 45228.0000 - fp: 34768.0000 - tn: 45232.0000 - fn: 34772.0000 - accuracy: 0.5654 - precision: 0.5654 - recall: 0.5653 - auc: 0.5658 - val_loss: 0.7537 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 10571.0000 - val_fn: 9429.0000 - val_accuracy: 0.5286 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.5286
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-4-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.5935 - tp: 57742.0000 - fp: 22258.0000 - tn: 57742.0000 - fn: 22258.0000 - accuracy: 0.7218 - precision: 0.7218 - recall: 0.7218 - auc: 0.7208 - val_loss: 0.3583 - val_tp: 19996.0000 - val_fp: 4.0000 - val_tn: 19996.0000 - val_fn: 4.0000 - val_accuracy: 0.9998 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 0.9997
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-4-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.3415 - tp: 79999.0000 - fp: 1.0000 - tn: 79999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3250 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-4-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: 0.3110 - tp: 79996.0000 - fp: 4.0000 - tn: 79996.0000 - fn: 4.0000 - accuracy: 0.9999 - precision: 0.9999 - recall: 0.9999 - auc: 1.0000 - val_loss: 0.2973 - val_tp: 19995.0000 - val_fp: 5.0000 - val_tn: 19995.0000 - val_fn: 5.0000 - val_accuracy: 0.9998 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 0.9997
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-4-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 11141.0000 - fp: 123.0000 - tn: 79877.0000 - fn: 68859.0000 - accuracy: 0.1393 - precision: 0.9891 - recall: 0.1393 - auc: 0.0194 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-4-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-4-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-4-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-4-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-4-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-4-batch-900000-1000000
[33m[INFO] loading file 5-6/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-6-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-6-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-6-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-6-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-6-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-6-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-6-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-6-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-6-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-6-batch-900000-1000000
[33m[INFO] loading file 7-8/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 5s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-8-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-8-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-8-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-8-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-8-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-8-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-8-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-8-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-8-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-8-batch-900000-1000000
[33m[INFO] loading file 9-10/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-10-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-10-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-10-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-10-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-10-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-10-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-10-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-10-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-10-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-10-batch-900000-1000000
[33m[INFO] loading file 11-12/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-12-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-12-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-12-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-12-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-12-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-12-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-12-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-12-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-12-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-12-batch-900000-1000000
[33m[INFO] loading file 13-14/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-14-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-14-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-14-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-14-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-14-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-14-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-14-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-14-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-14-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-14-batch-900000-1000000
[33m[INFO] loading file 15-16/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (939690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-16-batch-0-100000
[INFO] processing batch 100000-200000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-16-batch-100000-200000
[INFO] processing batch 200000-300000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-16-batch-200000-300000
[INFO] processing batch 300000-400000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-16-batch-300000-400000
[INFO] processing batch 400000-500000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-16-batch-400000-500000
[INFO] processing batch 500000-600000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-16-batch-500000-600000
[INFO] processing batch 600000-700000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-16-batch-600000-700000
[INFO] processing batch 700000-800000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-16-batch-700000-800000
[INFO] processing batch 800000-900000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-16-batch-800000-900000
[INFO] processing batch 900000-1000000/939690
[33m[INFO] loading file 17-18/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-18-batch-0-100000
[INFO] processing batch 100000-200000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-18-batch-100000-200000
[INFO] processing batch 200000-300000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-18-batch-200000-300000
[INFO] processing batch 300000-400000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-18-batch-300000-400000
[INFO] processing batch 400000-500000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-18-batch-400000-500000
[INFO] processing batch 500000-600000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-18-batch-500000-600000
[INFO] processing batch 600000-700000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-18-batch-600000-700000
[INFO] processing batch 700000-800000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-18-batch-700000-800000
[INFO] processing batch 800000-900000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-18-batch-800000-900000
[INFO] processing batch 900000-1000000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-18-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039690
[33m[INFO] loading file 19-20/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-20-batch-0-100000
[INFO] processing batch 100000-200000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-20-batch-100000-200000
[INFO] processing batch 200000-300000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-20-batch-200000-300000
[INFO] processing batch 300000-400000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-20-batch-300000-400000
[INFO] processing batch 400000-500000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-20-batch-400000-500000
[INFO] processing batch 500000-600000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-20-batch-500000-600000
[INFO] processing batch 600000-700000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-20-batch-600000-700000
[INFO] processing batch 700000-800000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-20-batch-700000-800000
[INFO] processing batch 800000-900000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-20-batch-800000-900000
[INFO] processing batch 900000-1000000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-20-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039690
[33m[INFO] loading file 21-22/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-22-batch-0-100000
[INFO] processing batch 100000-200000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-22-batch-100000-200000
[INFO] processing batch 200000-300000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-22-batch-200000-300000
[INFO] processing batch 300000-400000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-22-batch-300000-400000
[INFO] processing batch 400000-500000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-22-batch-400000-500000
[INFO] processing batch 500000-600000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-22-batch-500000-600000
[INFO] processing batch 600000-700000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-22-batch-600000-700000
[INFO] processing batch 700000-800000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-22-batch-700000-800000
[INFO] processing batch 800000-900000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-22-batch-800000-900000
[INFO] processing batch 900000-1000000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-22-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039687
[33m[INFO] loading file 23-24/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-24-batch-0-100000
[INFO] processing batch 100000-200000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 5s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-24-batch-100000-200000
[INFO] processing batch 200000-300000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-24-batch-200000-300000
[INFO] processing batch 300000-400000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-24-batch-300000-400000
[INFO] processing batch 400000-500000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-24-batch-400000-500000
[INFO] processing batch 500000-600000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-24-batch-500000-600000
[INFO] processing batch 600000-700000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-24-batch-600000-700000
[INFO] processing batch 700000-800000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-24-batch-700000-800000
[INFO] processing batch 800000-900000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-24-batch-800000-900000
[INFO] processing batch 900000-1000000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-24-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039687
[33m[INFO] loading file 25-26/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-26-batch-0-100000
[INFO] processing batch 100000-200000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-26-batch-100000-200000
[INFO] processing batch 200000-300000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-26-batch-200000-300000
[INFO] processing batch 300000-400000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-26-batch-300000-400000
[INFO] processing batch 400000-500000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-26-batch-400000-500000
[INFO] processing batch 500000-600000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-26-batch-500000-600000
[INFO] processing batch 600000-700000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-26-batch-600000-700000
[INFO] processing batch 700000-800000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-26-batch-700000-800000
[INFO] processing batch 800000-900000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-26-batch-800000-900000
[INFO] processing batch 900000-1000000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-26-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039687
[33m[INFO] loading file 27-28/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (979817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-28-batch-0-100000
[INFO] processing batch 100000-200000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-28-batch-100000-200000
[INFO] processing batch 200000-300000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-28-batch-200000-300000
[INFO] processing batch 300000-400000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-28-batch-300000-400000
[INFO] processing batch 400000-500000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-28-batch-400000-500000
[INFO] processing batch 500000-600000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-28-batch-500000-600000
[INFO] processing batch 600000-700000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-28-batch-600000-700000
[INFO] processing batch 700000-800000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-28-batch-700000-800000
[INFO] processing batch 800000-900000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-28-batch-800000-900000
[INFO] processing batch 900000-1000000/979817
[33m[INFO] loading file 29-30/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-30-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-30-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-30-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-30-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-30-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-30-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-30-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-30-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-30-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-30-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 31-32/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-32-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-32-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-32-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-32-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-32-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-32-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-32-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-32-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-32-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-32-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 33-34/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-34-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-34-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-34-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-34-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-34-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-34-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-34-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-34-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-34-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-34-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 35-36/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-36-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-36-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-36-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-36-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-36-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-36-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-36-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-36-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-36-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-36-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 37-38/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-38-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-38-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-38-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-38-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-38-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-38-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-38-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-38-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-38-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-38-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 39-40/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-40-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-40-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-40-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-40-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-40-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-40-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-40-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-40-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-40-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-40-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 41-42/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-42-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-42-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-42-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-42-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-42-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-42-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-42-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-42-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-42-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-42-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 43-44/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-44-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-44-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-44-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-44-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-44-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-44-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-44-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-44-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-44-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-44-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 45-46/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-46-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-46-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-46-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-46-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-46-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-46-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-46-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-46-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-46-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-46-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 47-48/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-48-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-48-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-48-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-48-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-48-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-48-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-48-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-48-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-48-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-48-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 49-50/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-50-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-50-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-50-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-50-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-50-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-50-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-50-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-50-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-50-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-50-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[LOSS] nan[0m
[33m[INFO] epoch 3/3[0m
[33m[INFO] loading file 1-2/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-2-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-2-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-2-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-2-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-2-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-2-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-2-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-2-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-2-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-2-batch-900000-1000000
[33m[INFO] loading file 3-4/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-4-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-4-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-4-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-4-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-4-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-4-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-4-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-4-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-4-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-4-batch-900000-1000000
[33m[INFO] loading file 5-6/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-6-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-6-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-6-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-6-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-6-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-6-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-6-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-6-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-6-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-6-batch-900000-1000000
[33m[INFO] loading file 7-8/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-8-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-8-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-8-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-8-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-8-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-8-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-8-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-8-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-8-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-8-batch-900000-1000000
[33m[INFO] loading file 9-10/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-10-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-10-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 5s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-10-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-10-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-10-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-10-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-10-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-10-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-10-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-10-batch-900000-1000000
[33m[INFO] loading file 11-12/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-12-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-12-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-12-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-12-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-12-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-12-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-12-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-12-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-12-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-12-batch-900000-1000000
[33m[INFO] loading file 13-14/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-14-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-14-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-14-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-14-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-14-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-14-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-14-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-14-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-14-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-14-batch-900000-1000000
[33m[INFO] loading file 15-16/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (939690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-16-batch-0-100000
[INFO] processing batch 100000-200000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-16-batch-100000-200000
[INFO] processing batch 200000-300000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-16-batch-200000-300000
[INFO] processing batch 300000-400000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-16-batch-300000-400000
[INFO] processing batch 400000-500000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-16-batch-400000-500000
[INFO] processing batch 500000-600000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-16-batch-500000-600000
[INFO] processing batch 600000-700000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 9s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-16-batch-600000-700000
[INFO] processing batch 700000-800000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 9s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-16-batch-700000-800000
[INFO] processing batch 800000-900000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-16-batch-800000-900000
[INFO] processing batch 900000-1000000/939690
[33m[INFO] loading file 17-18/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-18-batch-0-100000
[INFO] processing batch 100000-200000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-18-batch-100000-200000
[INFO] processing batch 200000-300000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-18-batch-200000-300000
[INFO] processing batch 300000-400000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-18-batch-300000-400000
[INFO] processing batch 400000-500000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-18-batch-400000-500000
[INFO] processing batch 500000-600000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-18-batch-500000-600000
[INFO] processing batch 600000-700000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-18-batch-600000-700000
[INFO] processing batch 700000-800000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-18-batch-700000-800000
[INFO] processing batch 800000-900000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-18-batch-800000-900000
[INFO] processing batch 900000-1000000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-18-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039690
[33m[INFO] loading file 19-20/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-20-batch-0-100000
[INFO] processing batch 100000-200000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-20-batch-100000-200000
[INFO] processing batch 200000-300000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-20-batch-200000-300000
[INFO] processing batch 300000-400000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-20-batch-300000-400000
[INFO] processing batch 400000-500000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-20-batch-400000-500000
[INFO] processing batch 500000-600000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-20-batch-500000-600000
[INFO] processing batch 600000-700000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-20-batch-600000-700000
[INFO] processing batch 700000-800000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-20-batch-700000-800000
[INFO] processing batch 800000-900000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-20-batch-800000-900000
[INFO] processing batch 900000-1000000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-20-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039690
[33m[INFO] loading file 21-22/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-22-batch-0-100000
[INFO] processing batch 100000-200000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-22-batch-100000-200000
[INFO] processing batch 200000-300000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-22-batch-200000-300000
[INFO] processing batch 300000-400000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-22-batch-300000-400000
[INFO] processing batch 400000-500000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-22-batch-400000-500000
[INFO] processing batch 500000-600000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-22-batch-500000-600000
[INFO] processing batch 600000-700000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-22-batch-600000-700000
[INFO] processing batch 700000-800000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-22-batch-700000-800000
[INFO] processing batch 800000-900000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-22-batch-800000-900000
[INFO] processing batch 900000-1000000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-22-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039687
[33m[INFO] loading file 23-24/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-24-batch-0-100000
[INFO] processing batch 100000-200000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-24-batch-100000-200000
[INFO] processing batch 200000-300000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-24-batch-200000-300000
[INFO] processing batch 300000-400000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-24-batch-300000-400000
[INFO] processing batch 400000-500000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-24-batch-400000-500000
[INFO] processing batch 500000-600000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-24-batch-500000-600000
[INFO] processing batch 600000-700000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-24-batch-600000-700000
[INFO] processing batch 700000-800000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-24-batch-700000-800000
[INFO] processing batch 800000-900000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-24-batch-800000-900000
[INFO] processing batch 900000-1000000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-24-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039687
[33m[INFO] loading file 25-26/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-26-batch-0-100000
[INFO] processing batch 100000-200000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-26-batch-100000-200000
[INFO] processing batch 200000-300000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-26-batch-200000-300000
[INFO] processing batch 300000-400000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-26-batch-300000-400000
[INFO] processing batch 400000-500000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-26-batch-400000-500000
[INFO] processing batch 500000-600000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-26-batch-500000-600000
[INFO] processing batch 600000-700000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-26-batch-600000-700000
[INFO] processing batch 700000-800000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-26-batch-700000-800000
[INFO] processing batch 800000-900000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-26-batch-800000-900000
[INFO] processing batch 900000-1000000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-26-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039687
[33m[INFO] loading file 27-28/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (979817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-28-batch-0-100000
[INFO] processing batch 100000-200000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-28-batch-100000-200000
[INFO] processing batch 200000-300000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-28-batch-200000-300000
[INFO] processing batch 300000-400000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-28-batch-300000-400000
[INFO] processing batch 400000-500000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-28-batch-400000-500000
[INFO] processing batch 500000-600000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-28-batch-500000-600000
[INFO] processing batch 600000-700000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-28-batch-600000-700000
[INFO] processing batch 700000-800000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-28-batch-700000-800000
[INFO] processing batch 800000-900000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-28-batch-800000-900000
[INFO] processing batch 900000-1000000/979817
[33m[INFO] loading file 29-30/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-30-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-30-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-30-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 9s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-30-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-30-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-30-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-30-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-30-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-30-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-30-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 31-32/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-32-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-32-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-32-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 9s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-32-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-32-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-32-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-32-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-32-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-32-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-32-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 33-34/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-34-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 9s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-34-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 9s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-34-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 9s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-34-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 9s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-34-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 9s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-34-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-34-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-34-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-34-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-34-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 35-36/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-36-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-36-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-36-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-36-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-36-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-36-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-36-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-36-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 9s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-36-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 9s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-36-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 37-38/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-38-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-38-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-38-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-38-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-38-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-38-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-38-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-38-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-38-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-38-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 39-40/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-40-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-40-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-40-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-40-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-40-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-40-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-40-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-40-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-40-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-40-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 41-42/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-42-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-42-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-42-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-42-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-42-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-42-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-42-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-42-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-42-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-42-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 43-44/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-44-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-44-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-44-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-44-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-44-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-44-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-44-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-44-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-44-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-44-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 45-46/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-46-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-46-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-46-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-46-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-46-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-46-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-46-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-46-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-46-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-46-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 47-48/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-48-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-48-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-48-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 6s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-48-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-48-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-48-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-48-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-48-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-48-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-48-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 49-50/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-50-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-50-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-50-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-50-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-50-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-50-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-50-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 7s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-50-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-50-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 8s - loss: nan - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 80000.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: nan - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 20000.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
train.py:189: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version
of pandas will change to not sort by default.

To accept the future behavior, pass 'sort=False'.

To retain the current behavior and silence the warning, pass 'sort=True'.

  df = pd.concat(df_from_each_file, ignore_index=True)
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-50-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[LOSS] nan[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => nan  <  0.001
--- 4991.364769935608 seconds ---
2020-02-08 12:41:32.324885: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-08 12:41:32.339601: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8bfc539e50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-08 12:41:32.339634: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow backend.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
2020-02-08 12:41:37.273092: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-08 12:41:37.283600: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 12:41:37.288604: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 12:41:37.331350: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-08 12:41:37.334601: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-08 12:41:37.338076: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 12:41:37.341230: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 12:41:37.355535: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
=================================================
        SCORING v0.4.2 (binaryClasses)
=================================================
Date: 2020-02-08 12:41:32.320554
wrapLayerSize 16
coreLayerSize 64
numCoreLayers 3
outputLayerActivation sigmoid
output_dim 2
loss binary_crossentropy
optimizer sgd
[INFO] input_shape (32, 16)
[INFO] LSTM first and last layer neurons: 16
[INFO] adding core layer 0
[INFO] adding core layer 1
[INFO] adding core layer 2
[INFO] created DNN
loading weights: checkpoints/*
loading file checkpoints/lstm-epoch-003-files-8-10-batch-900000-1000000
[33m[INFO] model summary:[0m
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 32, 16)            2112      
_________________________________________________________________
dropout_1 (Dropout)          (None, 32, 16)            0         
_________________________________________________________________
lstm_2 (LSTM)                (None, 32, 64)            20736     
_________________________________________________________________
dropout_2 (Dropout)          (None, 32, 64)            0         
_________________________________________________________________
lstm_3 (LSTM)                (None, 32, 64)            33024     
_________________________________________________________________
dropout_3 (Dropout)          (None, 32, 64)            0         
_________________________________________________________________
lstm_4 (LSTM)                (None, 32, 64)            33024     
_________________________________________________________________
dropout_4 (Dropout)          (None, 32, 64)            0         
_________________________________________________________________
lstm_5 (LSTM)                (None, 32, 16)            5184      
_________________________________________________________________
dropout_5 (Dropout)          (None, 32, 16)            0         
_________________________________________________________________
dense_1 (Dense)              (None, 32, 1)             17        
_________________________________________________________________
dropout_6 (Dropout)          (None, 32, 1)             0         
_________________________________________________________________
dense_2 (Dense)              (None, 32, 2)             4         
=================================================================
Total params: 94,101
Trainable params: 94,101
Non-trainable params: 0
_________________________________________________________________
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2015-12-31_130240_112.log.part10_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1364 (0.2728%)
[INFO] ** orig:[0.0:99.9992%,-1.0:0.0008%]
[INFO] ** type:[1.0:99.9984%,0.0:0.0014%,-1.0:0.0002%]
[INFO] ** i/f_name:[-1.0:99.9984%,0.0:0.0016%]
[INFO] ** i/f_dir:[-0.7071067812:99.9986%,0.7071067812:0.0014%]
[INFO] ** src:[-1.3652730819:38.114%,1.3652730819:26.0964%,0.5251050315:18.2424%,-0.5251050315:17.543%,-1.1552310693:0.0016%,-1.5753150944999998:0.0012%,-0.9451890567:0.001%,0.10502100630000001:0.0004%]
[INFO] ** dst:[-1.0302443927:43.3686%,1.4048787174000001:20.8412%,1.2175615551:18.2422%,0.0936585812:17.5434%,-0.6556100681:0.0016%,-1.5921958797:0.0014%,-0.4682929058:0.0006%,0.28097574350000004:0.0004%,-0.0936585812:0.0002%,-0.8429272304000001:0.0002%,-1.4048787174000001:0.0002%]
[INFO] ** proto:[0.0:99.997%,-1.0:0.0016%,1.0:0.0014%]
[INFO] ** appi_name:[-1.6378460497:99.9962%,-1.5118578919999999:0.0016%,1.3858697344:0.0004%,-1.3858697344:0.0004%,0.37796447299999997:0.0002%,-0.5039526307:0.0002%,-0.25197631530000003:0.0002%,-0.6299407883:0.0002%,0.25197631530000003:0.0002%,1.5118578919999999:0.0002%,-0.37796447299999997:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.114%,-1.5753150944999998:26.0964%,1.3652730819:18.2424%,-0.3150630189:17.543%,0.10502100630000001:0.0016%,-1.1552310693:0.0012%,-1.3652730819:0.001%,0.3150630189:0.0004%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9962%,-176.7993450566:0.0036%,4.6584169229:0.0002%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.9988%,-1.3363062096:49.9974%,-0.2672612419:0.0036%,0.2672612419:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:26.0954%,0.2672612419:20.841%,0.8017837256999999:18.242%,-1.3363062096:17.5424%,-0.2672612419:17.2726%,-0.8017837256999999:0.0066%]
[INFO] ** service:[0.0054950911:99.997%,-185.27759935790002:0.0016%,-184.7070904767:0.0004%,-163.1476425417:0.0004%,-163.13937429709998:0.0002%,-184.7112245991:0.0002%,-177.4227669367:0.0002%]
[INFO] ** s_port:[1.4631574735:26.0956%,-0.2976951931:20.8412%,-1.2442195994:18.242%,-0.2104457366:17.5424%,-0.3109148077:17.2728%,-70.70536262659999:0.0016%,-9.4443465444:0.0008%,-0.2183775054:0.0006%,-70.522931945:0.0004%,-0.9904029989:0.0004%,-63.6289029238:0.0004%,1.4658013963999998:0.0004%,-1.2389317536:0.0002%,-68.19363585:0.0002%,-3.1729613716000005:0.0002%,-70.5242539064:0.0002%,-1.2415756765000001:0.0002%,1.4843088569:0.0002%,1.4737331652:0.0002%]
[INFO] ** classification:[normal:79.7796%,Single Stage Single Point:20.2204%]
[INFO] columns with count within 2-10 {'orig': 2, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'src': 8, 'proto': 3, 'proxy_src_ip': 8, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 7, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 1 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 64261, 1: 35739}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64261     0]
 [35739     0]]
[INFO] confusion matrix after adding it to total:
[[64261     0]
 [35739     0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 1 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 64231, 1: 35769}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64231     0]
 [35769     0]]
[INFO] confusion matrix after adding it to total:
[[128492      0]
 [ 71508      0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 70406, 1: 29594}
pred {0: 100000}
[INFO] confusion matrix for file 
[[70406     0]
 [29594     0]]
[INFO] confusion matrix after adding it to total:
[[198898      0]
 [101102      0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[298898      0]
 [101102      0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[398898      0]
 [101102      0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2015-12-31_181648_113.log.part08_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1370 (0.274%)
[INFO] ** orig:[0.0:99.9948%,1.0:0.0052%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[-1.0:99.9948%,0.0:0.0052%]
[INFO] ** i/f_dir:[-0.7071067812:99.9948%,0.7071067812:0.0052%]
[INFO] ** src:[-1.3652730819:38.4402%,1.3652730819:25.9738%,0.5251050315:18.1202%,-0.5251050315:17.4598%,0.9451890567:0.0052%,-0.7351470441:0.0004%,0.10502100630000001:0.0002%,-1.5753150944999998:0.0002%]
[INFO] ** dst:[-1.0302443927:43.345%,1.4048787174000001:21.0682%,1.2175615551:18.1202%,0.0936585812:17.4594%,-0.6556100681:0.0052%,-1.5921958797:0.0012%,0.8429272304000001:0.0004%,-0.8429272304000001:0.0002%,1.5921958797:0.0002%]
[INFO] ** proto:[0.0:99.9946%,-1.0:0.0052%,1.0:0.0002%]
[INFO] ** appi_name:[-1.6378460497:99.9942%,-1.5118578919999999:0.0052%,-0.1259881577:0.0002%,-0.25197631530000003:0.0002%,-1.133893419:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.4402%,-1.5753150944999998:25.9738%,1.3652730819:18.1202%,-0.3150630189:17.4598%,0.10502100630000001:0.0052%,0.9451890567:0.0004%,-1.1552310693:0.0002%,0.3150630189:0.0002%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9942%,-176.7993450566:0.0058%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.998%,-1.3363062096:49.9962%,-0.2672612419:0.0058%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:25.9726%,0.2672612419:21.0682%,0.8017837256999999:18.1198%,-1.3363062096:17.459%,-0.2672612419:17.3718%,-0.8017837256999999:0.0086%]
[INFO] ** service:[0.0054950911:99.9942%,-185.27759935790002:0.0052%,-184.7029563544:0.0004%,-184.7112245991:0.0002%]
[INFO] ** s_port:[1.4631574735:25.973%,-0.2976951931:21.0682%,-1.2442195994:18.12%,-0.2104457366:17.4592%,-0.3109148077:17.372%,-70.70536262659999:0.0052%,-0.2183775054:0.0006%,8.3333911883:0.0004%,1.4658013963999998:0.0004%,-0.9904029989:0.0002%,-1.2415756765000001:0.0002%,-70.5242539064:0.0002%,1.4843088569:0.0002%,1.4737331652:0.0002%]
[INFO] ** classification:[normal:80.1196%,Multi Stage Multi Point:14.47%,Single Stage Multi Point:5.4104%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 8, 'dst': 9, 'proto': 3, 'appi_name': 5, 'proxy_src_ip': 8, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 4, 'classification': 3}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 72948, 1: 27052}
pred {0: 100000}
[INFO] confusion matrix for file 
[[72948     0]
 [27052     0]]
[INFO] confusion matrix after adding it to total:
[[471846      0]
 [128154      0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[571846      0]
 [128154      0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[671846      0]
 [128154      0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 74770, 1: 25230}
pred {0: 100000}
[INFO] confusion matrix for file 
[[74770     0]
 [25230     0]]
[INFO] confusion matrix after adding it to total:
[[746616      0]
 [153384      0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 52880, 1: 47120}
pred {0: 100000}
[INFO] confusion matrix for file 
[[52880     0]
 [47120     0]]
[INFO] confusion matrix after adding it to total:
[[799496      0]
 [200504      0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2015-12-31_181648_113.log.part09_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1359 (0.2718%)
[INFO] ** orig:[0.0:99.9966%,1.0:0.0034%]
[INFO] ** type:[1.0:99.9996%,0.0:0.0004%]
[INFO] ** i/f_name:[-1.0:99.9938%,0.0:0.0062%]
[INFO] ** i/f_dir:[-0.7071067812:99.9942%,0.7071067812:0.0058%]
[INFO] ** src:[-1.3652730819:38.4204%,1.3652730819:25.9634%,0.5251050315:18.123%,-0.5251050315:17.486%,0.9451890567:0.0034%,-1.1552310693:0.0028%,0.10502100630000001:0.0006%,-0.7351470441:0.0004%]
[INFO] ** dst:[-1.0302443927:43.3316%,1.4048787174000001:21.0518%,1.2175615551:18.123%,0.0936585812:17.486%,-0.6556100681:0.0062%,-1.5921958797:0.0008%,-0.0936585812:0.0002%,-0.8429272304000001:0.0002%,-1.4048787174000001:0.0002%]
[INFO] ** proto:[0.0:99.9934%,-1.0:0.0062%,1.0:0.0004%]
[INFO] ** appi_name:[-1.6378460497:99.9934%,-1.5118578919999999:0.0062%,-0.6299407883:0.0002%,1.5118578919999999:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.4204%,-1.5753150944999998:25.9634%,1.3652730819:18.123%,-0.3150630189:17.486%,0.10502100630000001:0.0062%,0.3150630189:0.0006%,0.9451890567:0.0004%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9934%,-176.7993450566:0.0066%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.9972%,-1.3363062096:49.9962%,-0.2672612419:0.0066%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:25.9624%,0.2672612419:21.0518%,0.8017837256999999:18.1226%,-1.3363062096:17.4856%,-0.2672612419:17.3686%,-0.8017837256999999:0.009%]
[INFO] ** service:[0.0054950911:99.9934%,-185.27759935790002:0.0062%,-163.13937429709998:0.0002%,-177.4227669367:0.0002%]
[INFO] ** s_port:[1.4631574735:25.9628%,-0.2976951931:21.0518%,-1.2442195994:18.1226%,-0.2104457366:17.4858%,-0.3109148077:17.3686%,-70.70536262659999:0.0062%,-0.9904029989:0.0006%,13.3383372811:0.0002%,-1.2415756765000001:0.0002%,-1.2389317536:0.0002%,-0.22630927420000002:0.0002%,1.4843088569:0.0002%,11.782388641099999:0.0002%,1.4737331652:0.0002%,1.4658013963999998:0.0002%]
[INFO] ** classification:[normal:73.9096%,Multi Stage Multi Point:26.0904%]
[INFO] columns with count within 2-10 {'orig': 2, 'type': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 8, 'dst': 9, 'proto': 3, 'appi_name': 4, 'proxy_src_ip': 7, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 4, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 1 1 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 52975, 1: 47025}
pred {0: 100000}
[INFO] confusion matrix for file 
[[52975     0]
 [47025     0]]
[INFO] confusion matrix after adding it to total:
[[852471      0]
 [247529      0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 1 ... 0 1 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 53029, 1: 46971}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53029     0]
 [46971     0]]
[INFO] confusion matrix after adding it to total:
[[905500      0]
 [294500      0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 1 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 63544, 1: 36456}
pred {0: 100000}
[INFO] confusion matrix for file 
[[63544     0]
 [36456     0]]
[INFO] confusion matrix after adding it to total:
[[969044      0]
 [330956      0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[1069044       0]
 [ 330956       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[1169044       0]
 [ 330956       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2015-12-31_233049_114.log.part11_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1361 (0.2722%)
[INFO] ** orig:[0.0:99.9996%,1.0:0.0004%]
[INFO] ** type:[1.0:99.9994%,0.0:0.0004%,-1.0:0.0002%]
[INFO] ** i/f_name:[-1.0:99.9968%,0.0:0.0032%]
[INFO] ** i/f_dir:[-0.7071067812:99.9972%,0.7071067812:0.0028%]
[INFO] ** src:[-1.3652730819:38.4512%,1.3652730819:25.9642%,0.5251050315:18.089%,-0.5251050315:17.4908%,-1.1552310693:0.0028%,-1.5753150944999998:0.0008%,0.10502100630000001:0.0004%,-0.7351470441:0.0004%,0.9451890567:0.0004%]
[INFO] ** dst:[-1.0302443927:43.3436%,1.4048787174000001:21.0714%,1.2175615551:18.0896%,0.0936585812:17.4906%,-0.6556100681:0.0032%,-1.5921958797:0.001%,-0.0936585812:0.0002%,-0.8429272304000001:0.0002%,-1.4048787174000001:0.0002%]
[INFO] ** proto:[0.0:99.9964%,-1.0:0.0032%,1.0:0.0004%]
[INFO] ** appi_name:[-1.6378460497:99.9956%,-1.5118578919999999:0.0032%,-0.37796447299999997:0.0002%,-0.5039526307:0.0002%,0.25197631530000003:0.0002%,0.37796447299999997:0.0002%,-0.6299407883:0.0002%,1.5118578919999999:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.4512%,-1.5753150944999998:25.9642%,1.3652730819:18.089%,-0.3150630189:17.4908%,0.10502100630000001:0.0032%,-1.1552310693:0.0008%,0.3150630189:0.0004%,0.9451890567:0.0004%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9956%,-176.7993450566:0.0042%,4.6584169229:0.0002%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.999%,-1.3363062096:49.9966%,-0.2672612419:0.0042%,0.2672612419:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:25.9632%,0.2672612419:21.0714%,0.8017837256999999:18.0886%,-1.3363062096:17.4902%,-0.2672612419:17.3796%,-0.8017837256999999:0.007%]
[INFO] ** service:[0.0054950911:99.9964%,-185.27759935790002:0.0032%,-163.13937429709998:0.0002%,-177.4227669367:0.0002%]
[INFO] ** s_port:[1.4631574735:25.9636%,-0.2976951931:21.0714%,-1.2442195994:18.0886%,-0.2104457366:17.4904%,-0.3109148077:17.3798%,-70.70536262659999:0.0032%,6.2539458095:0.0008%,-0.9904029989:0.0004%,1.4658013963999998:0.0004%,13.3383372811:0.0002%,-1.2415756765000001:0.0002%,-0.2183775054:0.0002%,-1.2389317536:0.0002%,-0.22630927420000002:0.0002%,1.4843088569:0.0002%,11.782388641099999:0.0002%]
[INFO] ** classification:[normal:95.0874%,Single Stage Single Point:4.9126%]
[INFO] columns with count within 2-10 {'orig': 2, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'src': 9, 'dst': 9, 'proto': 3, 'appi_name': 8, 'proxy_src_ip': 8, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 4, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[1269044       0]
 [ 330956       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[1369044       0]
 [ 330956       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 92639, 1: 7361}
pred {0: 100000}
[INFO] confusion matrix for file 
[[92639     0]
 [ 7361     0]]
[INFO] confusion matrix after adding it to total:
[[1461683       0]
 [ 338317       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 82798, 1: 17202}
pred {0: 100000}
[INFO] confusion matrix for file 
[[82798     0]
 [17202     0]]
[INFO] confusion matrix after adding it to total:
[[1544481       0]
 [ 355519       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[1644481       0]
 [ 355519       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-01_151435_117.log.part03_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1365 (0.273%)
[INFO] ** orig:[0.0:99.9976%,1.0:0.0024%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[-1.0:99.9966%,0.0:0.0034%]
[INFO] ** i/f_dir:[-0.7071067812:99.9966%,0.7071067812:0.0034%]
[INFO] ** src:[-1.3652730819:38.1462%,1.3652730819:26.099%,0.5251050315:18.1904%,-0.5251050315:17.5592%,0.9451890567:0.0028%,-1.1552310693:0.001%,1.5753150944999998:0.0006%,0.10502100630000001:0.0004%,-0.7351470441:0.0004%]
[INFO] ** dst:[-1.0302443927:43.376%,1.4048787174000001:20.8688%,1.2175615551:18.1902%,0.0936585812:17.5592%,-0.6556100681:0.0034%,-1.5921958797:0.0008%,-0.0936585812:0.0004%,0.4682929058:0.0004%,-0.4682929058:0.0004%,-0.8429272304000001:0.0002%,-0.28097574350000004:0.0002%]
[INFO] ** proto:[0.0:99.9958%,-1.0:0.0034%,1.0:0.0008%]
[INFO] ** appi_name:[-1.6378460497:99.9952%,-1.5118578919999999:0.0034%,0.1259881577:0.0006%,-0.6299407883:0.0004%,-1.3858697344:0.0002%,-0.25197631530000003:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.1462%,-1.5753150944999998:26.099%,1.3652730819:18.1904%,-0.3150630189:17.5592%,0.10502100630000001:0.0034%,0.7351470441:0.0006%,-0.10502100630000001:0.0004%,0.3150630189:0.0004%,0.9451890567:0.0004%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9952%,-176.7993450566:0.0048%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.9978%,-1.3363062096:49.9974%,-0.2672612419:0.0048%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:26.0982%,0.2672612419:20.8688%,0.8017837256999999:18.19%,-1.3363062096:17.5588%,-0.2672612419:17.2772%,-0.8017837256999999:0.007%]
[INFO] ** service:[0.0054950911:99.9952%,-185.27759935790002:0.0034%,-184.71949284369998:0.0006%,-163.13937429709998:0.0004%,-184.7070904767:0.0002%,-184.7112245991:0.0002%]
[INFO] ** s_port:[1.4631574735:26.0986%,-0.2976951931:20.8688%,-1.2442195994:18.1902%,-0.2104457366:17.559%,-0.3109148077:17.2774%,-70.70536262659999:0.0034%,-0.9904029989:0.0004%,1.4843088569:0.0002%,-0.7550938587:0.0002%,9.1265680651:0.0002%,-70.522931945:0.0002%,-70.5242539064:0.0002%,-2.8821298501:0.0002%,-4.818803391:0.0002%,-0.2183775054:0.0002%,-1.2415756765000001:0.0002%,4.4124534938:0.0002%,1.4658013963999998:0.0002%]
[INFO] ** classification:[normal:84.2104%,Single Stage Single Point:15.7896%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 9, 'proto': 3, 'appi_name': 6, 'proxy_src_ip': 9, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 6, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 70708, 1: 29292}
pred {0: 100000}
[INFO] confusion matrix for file 
[[70708     0]
 [29292     0]]
[INFO] confusion matrix after adding it to total:
[[1715189       0]
 [ 384811       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 1 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 64215, 1: 35785}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64215     0]
 [35785     0]]
[INFO] confusion matrix after adding it to total:
[[1779404       0]
 [ 420596       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 86129, 1: 13871}
pred {0: 100000}
[INFO] confusion matrix for file 
[[86129     0]
 [13871     0]]
[INFO] confusion matrix after adding it to total:
[[1865533       0]
 [ 434467       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[1965533       0]
 [ 434467       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[2065533       0]
 [ 434467       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-01_151435_117.log.part12_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1377 (0.2754%)
[INFO] ** orig:[0.0:99.9964%,1.0:0.0036%]
[INFO] ** type:[1.0:99.9994%,0.0:0.0004%,-1.0:0.0002%]
[INFO] ** i/f_name:[-1.0:99.996%,0.0:0.004%]
[INFO] ** i/f_dir:[-0.7071067812:99.9964%,0.7071067812:0.0036%]
[INFO] ** src:[-1.3652730819:38.049%,1.3652730819:26.1306%,0.5251050315:18.2264%,-0.5251050315:17.587%,0.9451890567:0.0036%,-1.5753150944999998:0.0014%,-0.9451890567:0.001%,-1.1552310693:0.0004%,0.10502100630000001:0.0002%,0.3150630189:0.0002%,-0.3150630189:0.0002%]
[INFO] ** dst:[-1.0302443927:43.355%,1.4048787174000001:20.8256%,1.2175615551:18.226%,0.0936585812:17.5868%,-0.6556100681:0.004%,-0.4682929058:0.001%,-1.5921958797:0.0006%,0.28097574350000004:0.0004%,-0.0936585812:0.0002%,-0.8429272304000001:0.0002%,-1.4048787174000001:0.0002%]
[INFO] ** proto:[0.0:99.9942%,-1.0:0.004%,1.0:0.0018%]
[INFO] ** appi_name:[-1.6378460497:99.9932%,-1.5118578919999999:0.004%,-0.25197631530000003:0.0006%,-1.3858697344:0.0004%,1.3858697344:0.0004%,0.37796447299999997:0.0002%,-1.0079052614:0.0002%,-0.6299407883:0.0002%,0.25197631530000003:0.0002%,1.5118578919999999:0.0002%,-0.37796447299999997:0.0002%,-0.5039526307:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.049%,-1.5753150944999998:26.1306%,1.3652730819:18.2264%,-0.3150630189:17.587%,0.10502100630000001:0.004%,-1.1552310693:0.0014%,-1.3652730819:0.001%,0.3150630189:0.0002%,1.5753150944999998:0.0002%,-0.5251050315:0.0002%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9932%,-176.7993450566:0.0066%,4.6584169229:0.0002%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.9974%,-1.3363062096:49.9958%,-0.2672612419:0.0066%,0.2672612419:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:26.13%,0.2672612419:20.8244%,0.8017837256999999:18.2258%,-1.3363062096:17.5864%,-0.2672612419:17.2242%,-0.8017837256999999:0.0092%]
[INFO] ** service:[0.0054950911:99.9942%,-185.27759935790002:0.004%,-184.7112245991:0.0006%,-184.7070904767:0.0004%,-163.1476425417:0.0004%,-163.13937429709998:0.0002%,-177.4227669367:0.0002%]
[INFO] ** s_port:[1.4631574735:26.1304%,-0.2976951931:20.8246%,-1.2442195994:18.226%,-0.2104457366:17.5866%,-0.3109148077:17.2244%,-70.70536262659999:0.004%,-6.4223426437:0.0008%,-70.5242539064:0.0006%,-0.2183775054:0.0004%,-63.6289029238:0.0004%,-70.522931945:0.0004%,-1.2415756765000001:0.0002%,-61.4106515916:0.0002%,-1.2389317536:0.0002%,-68.19363585:0.0002%,-1.7796139913:0.0002%,1.4843088569:0.0002%,-0.9904029989:0.0002%]
[INFO] ** classification:[normal:97.1716%,Single Stage Single Point:2.8284%]
[INFO] columns with count within 2-10 {'orig': 2, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'proto': 3, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 7, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[2165533       0]
 [ 434467       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[2265533       0]
 [ 434467       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[2365533       0]
 [ 434467       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[2465533       0]
 [ 434467       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 1 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 85858, 1: 14142}
pred {0: 100000}
[INFO] confusion matrix for file 
[[85858     0]
 [14142     0]]
[INFO] confusion matrix after adding it to total:
[[2551391       0]
 [ 448609       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-01_151435_117.log.part13_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1365 (0.273%)
[INFO] ** orig:[0.0:99.9986%,1.0:0.0014%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[-1.0:99.998%,0.0:0.002%]
[INFO] ** i/f_dir:[-0.7071067812:99.998%,0.7071067812:0.002%]
[INFO] ** src:[-1.3652730819:38.1186%,1.3652730819:26.0918%,0.5251050315:18.2288%,-0.5251050315:17.558%,0.9451890567:0.0018%,-1.1552310693:0.0006%,0.10502100630000001:0.0004%]
[INFO] ** dst:[-1.0302443927:43.3702%,1.4048787174000001:20.8392%,1.2175615551:18.2288%,0.0936585812:17.5578%,-0.6556100681:0.002%,-1.5921958797:0.0012%,-0.8429272304000001:0.0004%,-0.0936585812:0.0002%,-0.4682929058:0.0002%]
[INFO] ** proto:[0.0:99.9976%,-1.0:0.002%,1.0:0.0004%]
[INFO] ** appi_name:[-1.6378460497:99.9976%,-1.5118578919999999:0.002%,-0.25197631530000003:0.0002%,-0.6299407883:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.1186%,-1.5753150944999998:26.0918%,1.3652730819:18.2288%,-0.3150630189:17.558%,0.10502100630000001:0.002%,-0.10502100630000001:0.0004%,0.3150630189:0.0004%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9976%,-176.7993450566:0.0024%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.9998%,-1.3363062096:49.9978%,-0.2672612419:0.0024%]
[INFO] ** modbus_transaction_id:65534 (13.1068%)
[INFO] ** scada_tag:[1.3363062096:26.0906%,0.2672612419:20.839%,0.8017837256999999:18.2282%,-1.3363062096:17.5572%,-0.2672612419:17.2792%,-0.8017837256999999:0.0058%]
[INFO] ** service:[0.0054950911:99.9976%,-185.27759935790002:0.002%,-163.13937429709998:0.0002%,-184.7112245991:0.0002%]
[INFO] ** s_port:[1.4631574735:26.0908%,-0.2976951931:20.8392%,-1.2442195994:18.2284%,-0.2104457366:17.5576%,-0.3109148077:17.2794%,-70.70536262659999:0.002%,1.4658013963999998:0.0006%,-0.9904029989:0.0004%,-1.2415756765000001:0.0004%,4.4124534938:0.0002%,-0.2183775054:0.0002%,-0.22630927420000002:0.0002%,-70.5242539064:0.0002%,1.4843088569:0.0002%,1.4737331652:0.0002%]
[INFO] ** classification:[normal:87.5394%,Single Stage Single Point:12.4606%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 7, 'dst': 9, 'proto': 3, 'appi_name': 4, 'proxy_src_ip': 7, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 4, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 1 0 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 53028, 1: 46972}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53028     0]
 [46972     0]]
[INFO] confusion matrix after adding it to total:
[[2604419       0]
 [ 495581       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 84669, 1: 15331}
pred {0: 100000}
[INFO] confusion matrix for file 
[[84669     0]
 [15331     0]]
[INFO] confusion matrix after adding it to total:
[[2689088       0]
 [ 510912       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[2789088       0]
 [ 510912       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[2889088       0]
 [ 510912       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[2989088       0]
 [ 510912       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-01_203011_118.log.part06_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1366 (0.2732%)
[INFO] ** orig:[0.0:99.9988%,1.0:0.0008%,-1.0:0.0004%]
[INFO] ** type:[1.0:99.9986%,0.0:0.001%,-1.0:0.0004%]
[INFO] ** i/f_name:[-1.0:99.998%,0.0:0.002%]
[INFO] ** i/f_dir:[-0.7071067812:99.9982%,0.7071067812:0.0018%]
[INFO] ** src:[-1.3652730819:38.138%,1.3652730819:26.0904%,0.5251050315:18.1762%,-0.5251050315:17.5892%,-0.9451890567:0.0018%,-1.5753150944999998:0.0016%,-1.1552310693:0.0012%,0.9451890567:0.0008%,0.10502100630000001:0.0006%,-0.3150630189:0.0002%]
[INFO] ** dst:[-1.0302443927:43.3838%,1.4048787174000001:20.845%,1.2175615551:18.1758%,0.0936585812:17.589%,-0.6556100681:0.002%,-1.5921958797:0.0014%,-0.4682929058:0.0014%,-0.0936585812:0.0004%,-0.8429272304000001:0.0004%,-1.4048787174000001:0.0004%,0.28097574350000004:0.0004%]
[INFO] ** proto:[0.0:99.9954%,1.0:0.0026%,-1.0:0.002%]
[INFO] ** appi_name:[-1.6378460497:99.9944%,-1.5118578919999999:0.002%,-1.3858697344:0.0008%,-0.25197631530000003:0.0006%,-0.5039526307:0.0004%,-0.6299407883:0.0004%,1.3858697344:0.0004%,1.5118578919999999:0.0004%,0.37796447299999997:0.0002%,0.25197631530000003:0.0002%,-0.37796447299999997:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.138%,-1.5753150944999998:26.0904%,1.3652730819:18.1762%,-0.3150630189:17.5892%,0.10502100630000001:0.002%,-1.3652730819:0.0018%,-1.1552310693:0.0016%,0.3150630189:0.0006%,1.5753150944999998:0.0002%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9944%,-176.7993450566:0.0052%,4.6584169229:0.0004%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.998%,-1.3363062096:49.9964%,-0.2672612419:0.0052%,0.2672612419:0.0004%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:26.0894%,0.2672612419:20.8438%,0.8017837256999999:18.1758%,-1.3363062096:17.5888%,-0.2672612419:17.294%,-0.8017837256999999:0.0082%]
[INFO] ** service:[0.0054950911:99.9954%,-185.27759935790002:0.002%,-184.7070904767:0.0008%,-184.7112245991:0.0006%,-163.13937429709998:0.0004%,-163.1476425417:0.0004%,-177.4227669367:0.0004%]
[INFO] ** s_port:[1.4631574735:26.0898%,-0.2976951931:20.844%,-1.2442195994:18.1758%,-0.2104457366:17.589%,-0.3109148077:17.294%,-70.70536262659999:0.002%,-6.3879716457:0.0008%,-70.522931945:0.0008%,-70.5242539064:0.0006%,-0.9904029989:0.0006%,1.4658013963999998:0.0006%,-1.2415756765000001:0.0004%,-68.19363585:0.0004%,-63.6289029238:0.0004%,-1.7796139913:0.0004%,-0.2183775054:0.0002%,-6.4223426437:0.0002%]
[INFO] ** classification:[normal:90.7904%,Single Stage Multi Point:5.7378%,Single Stage Single Point:3.4718%]
[INFO] columns with count within 2-10 {'orig': 3, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'proto': 3, 'proxy_src_ip': 9, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 7, 'classification': 3}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[3089088       0]
 [ 510912       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[3189088       0]
 [ 510912       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[3289088       0]
 [ 510912       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 82641, 1: 17359}
pred {0: 100000}
[INFO] confusion matrix for file 
[[82641     0]
 [17359     0]]
[INFO] confusion matrix after adding it to total:
[[3371729       0]
 [ 528271       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 1 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 71311, 1: 28689}
pred {0: 100000}
[INFO] confusion matrix for file 
[[71311     0]
 [28689     0]]
[INFO] confusion matrix after adding it to total:
[[3443040       0]
 [ 556960       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-01_203011_118.log.part07_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1366 (0.2732%)
[INFO] ** orig:[0.0:99.9996%,1.0:0.0004%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[-1.0:99.9994%,0.0:0.0006%]
[INFO] ** i/f_dir:[-0.7071067812:99.9994%,0.7071067812:0.0006%]
[INFO] ** src:[-1.3652730819:38.0718%,1.3652730819:26.1174%,0.5251050315:18.2344%,-0.5251050315:17.5754%,0.9451890567:0.0008%,-1.1552310693:0.0002%]
[INFO] ** dst:[-1.0302443927:43.3758%,1.4048787174000001:20.813%,1.2175615551:18.2342%,0.0936585812:17.5754%,-0.6556100681:0.0006%,-1.5921958797:0.0004%,-0.0936585812:0.0002%,-0.8429272304000001:0.0002%,-0.4682929058:0.0002%]
[INFO] ** proto:[0.0:99.999%,-1.0:0.0006%,1.0:0.0004%]
[INFO] ** appi_name:[-1.6378460497:99.999%,-1.5118578919999999:0.0006%,-0.25197631530000003:0.0002%,-0.6299407883:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.0718%,-1.5753150944999998:26.1174%,1.3652730819:18.2344%,-0.3150630189:17.5754%,0.10502100630000001:0.0006%,-0.10502100630000001:0.0004%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.999%,-176.7993450566:0.001%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.9996%,-1.3363062096:49.9994%,-0.2672612419:0.001%]
[INFO] ** modbus_transaction_id:65301 (13.0602%)
[INFO] ** scada_tag:[1.3363062096:26.1164%,0.2672612419:20.813%,0.8017837256999999:18.2338%,-1.3363062096:17.575%,-0.2672612419:17.2586%,-0.8017837256999999:0.0032%]
[INFO] ** service:[0.0054950911:99.999%,-185.27759935790002:0.0006%,-163.13937429709998:0.0002%,-184.7112245991:0.0002%]
[INFO] ** s_port:[1.4631574735:26.1168%,-0.2976951931:20.813%,-1.2442195994:18.234%,-0.2104457366:17.5752%,-0.3109148077:17.2588%,-70.70536262659999:0.0006%,4.4124534938:0.0002%,-1.2415756765000001:0.0002%,-0.2183775054:0.0002%,-1.2389317536:0.0002%,-70.5242539064:0.0002%,1.4843088569:0.0002%,1.4737331652:0.0002%,1.4658013963999998:0.0002%]
[INFO] ** classification:[normal:89.2092%,Single Stage Multi Point:10.7908%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 6, 'dst': 9, 'proto': 3, 'appi_name': 4, 'proxy_src_ip': 6, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 4, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 0 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 53027, 1: 46973}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53027     0]
 [46973     0]]
[INFO] confusion matrix after adding it to total:
[[3496067       0]
 [ 603933       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 93019, 1: 6981}
pred {0: 100000}
[INFO] confusion matrix for file 
[[93019     0]
 [ 6981     0]]
[INFO] confusion matrix after adding it to total:
[[3589086       0]
 [ 610914       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[3689086       0]
 [ 610914       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[3789086       0]
 [ 610914       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[3889086       0]
 [ 610914       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-02_014558_119.log.part06_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1366 (0.2732%)
[INFO] ** orig:[0.0:99.997%,1.0:0.003%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[-1.0:99.9964%,0.0:0.0036%]
[INFO] ** i/f_dir:[-0.7071067812:99.9964%,0.7071067812:0.0036%]
[INFO] ** src:[-1.3652730819:38.0288%,1.3652730819:26.1242%,0.5251050315:18.2114%,-0.5251050315:17.6294%,0.9451890567:0.003%,-0.7351470441:0.0008%,-1.1552310693:0.0006%,1.5753150944999998:0.0006%,0.10502100630000001:0.0004%,-0.3150630189:0.0004%,-1.5753150944999998:0.0002%,0.3150630189:0.0002%]
[INFO] ** dst:[-1.0302443927:43.357%,1.4048787174000001:20.7952%,1.2175615551:18.2116%,0.0936585812:17.629%,-0.6556100681:0.0036%,-1.5921958797:0.0012%,0.4682929058:0.0008%,0.6556100681:0.0004%,0.8429272304000001:0.0004%,-0.4682929058:0.0004%,-0.8429272304000001:0.0002%,1.5921958797:0.0002%]
[INFO] ** proto:[0.0:99.9958%,-1.0:0.0036%,1.0:0.0006%]
[INFO] ** appi_name:[-1.6378460497:99.9942%,-1.5118578919999999:0.0036%,0.8819171037000001:0.0008%,-0.25197631530000003:0.0004%,-0.1259881577:0.0002%,-1.3858697344:0.0002%,-1.2598815767:0.0002%,-1.133893419:0.0002%,0.1259881577:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.0288%,-1.5753150944999998:26.1242%,1.3652730819:18.2114%,-0.3150630189:17.6294%,0.10502100630000001:0.0036%,0.9451890567:0.0008%,0.7351470441:0.0006%,0.3150630189:0.0004%,1.5753150944999998:0.0004%,-1.1552310693:0.0002%,-0.5251050315:0.0002%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9942%,-176.7993450566:0.0058%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.9974%,-1.3363062096:49.9968%,-0.2672612419:0.0058%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:26.123%,0.2672612419:20.7952%,0.8017837256999999:18.211%,-1.3363062096:17.6288%,-0.2672612419:17.2336%,-0.8017837256999999:0.0084%]
[INFO] ** service:[0.0054950911:99.9942%,-185.27759935790002:0.0036%,-179.7709484184:0.0008%,-184.7112245991:0.0004%,-184.7029563544:0.0004%,-184.71949284369998:0.0002%,-162.746632676:0.0002%,-184.7070904767:0.0002%]
[INFO] ** s_port:[1.4631574735:26.1234%,-0.2976951931:20.7952%,-1.2442195994:18.2112%,-0.2104457366:17.629%,-0.3109148077:17.2336%,-70.70536262659999:0.0036%,1.4658013963999998:0.0006%,9.8364613699:0.0004%,-0.9904029989:0.0004%,-70.5242539064:0.0004%,-5.0223854561:0.0002%,-57.521440972200004:0.0002%,-1.2415756765000001:0.0002%,-0.2183775054:0.0002%,-0.22630927420000002:0.0002%,-57.518797049300005:0.0002%,-70.522931945:0.0002%,2.0593620926:0.0002%,-5.0818737219:0.0002%,1.4737331652:0.0002%,-43.372487451000005:0.0002%]
[INFO] ** classification:[normal:81.41%,Single Stage Single Point:18.59%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'proto': 3, 'appi_name': 9, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 8, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 1 0 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 67398, 1: 32602}
pred {0: 100000}
[INFO] confusion matrix for file 
[[67398     0]
 [32602     0]]
[INFO] confusion matrix after adding it to total:
[[3956484       0]
 [ 643516       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 1 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 53052, 1: 46948}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53052     0]
 [46948     0]]
[INFO] confusion matrix after adding it to total:
[[4009536       0]
 [ 690464       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 86600, 1: 13400}
pred {0: 100000}
[INFO] confusion matrix for file 
[[86600     0]
 [13400     0]]
[INFO] confusion matrix after adding it to total:
[[4096136       0]
 [ 703864       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[4196136       0]
 [ 703864       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[4296136       0]
 [ 703864       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-02_121729_121.log.part12_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1368 (0.2736%)
[INFO] ** orig:[0.0:99.9986%,-1.0:0.0008%,1.0:0.0006%]
[INFO] ** type:[1.0:99.9984%,0.0:0.0014%,-1.0:0.0002%]
[INFO] ** i/f_name:[-1.0:99.9978%,0.0:0.0022%]
[INFO] ** i/f_dir:[-0.7071067812:99.998%,0.7071067812:0.002%]
[INFO] ** src:[-1.3652730819:38.1136%,1.3652730819:26.1176%,0.5251050315:18.2158%,-0.5251050315:17.5472%,-1.1552310693:0.0016%,-1.5753150944999998:0.0014%,-0.9451890567:0.001%,0.9451890567:0.0006%,0.10502100630000001:0.0004%,-0.7351470441:0.0004%,1.5753150944999998:0.0002%,-0.3150630189:0.0002%]
[INFO] ** dst:[-1.0302443927:43.4022%,1.4048787174000001:20.8284%,1.2175615551:18.2156%,0.0936585812:17.547%,-0.6556100681:0.0022%,-1.5921958797:0.002%,-0.4682929058:0.0008%,0.8429272304000001:0.0004%,1.5921958797:0.0004%,0.28097574350000004:0.0004%,-0.0936585812:0.0002%,-1.4048787174000001:0.0002%,-0.8429272304000001:0.0002%]
[INFO] ** proto:[0.0:99.996%,-1.0:0.0022%,1.0:0.0018%]
[INFO] ** appi_name:[-1.6378460497:99.9946%,-1.5118578919999999:0.0022%,-0.25197631530000003:0.0006%,1.3858697344:0.0004%,-1.3858697344:0.0004%,0.37796447299999997:0.0002%,-0.1259881577:0.0002%,-0.5039526307:0.0002%,-0.6299407883:0.0002%,0.25197631530000003:0.0002%,1.6378460497:0.0002%,-1.133893419:0.0002%,1.5118578919999999:0.0002%,-0.37796447299999997:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.1136%,-1.5753150944999998:26.1176%,1.3652730819:18.2158%,-0.3150630189:17.5472%,0.10502100630000001:0.0022%,-1.1552310693:0.0014%,-1.3652730819:0.001%,0.3150630189:0.0004%,0.9451890567:0.0004%,0.7351470441:0.0002%,1.5753150944999998:0.0002%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9946%,-176.7993450566:0.0052%,4.6584169229:0.0002%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.9984%,-1.3363062096:49.9962%,-0.2672612419:0.0052%,0.2672612419:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:26.1164%,0.2672612419:20.8284%,0.8017837256999999:18.2154%,-1.3363062096:17.5466%,-0.2672612419:17.285%,-0.8017837256999999:0.0082%]
[INFO] ** service:[0.0054950911:99.9954%,-185.27759935790002:0.0022%,-184.7112245991:0.0006%,-184.7070904767:0.0004%,-163.1476425417:0.0004%,-184.7029563544:0.0004%,-163.13110605239999:0.0002%,-163.13937429709998:0.0002%,-177.4227669367:0.0002%]
[INFO] ** s_port:[1.4631574735:26.1168%,-0.2976951931:20.8284%,-1.2442195994:18.2154%,-0.2104457366:17.5468%,-0.3109148077:17.2852%,-70.70536262659999:0.0022%,-10.479442368700001:0.0008%,-70.5242539064:0.0006%,-63.6289029238:0.0004%,-0.2183775054:0.0004%,-70.522931945:0.0004%,-0.9904029989:0.0004%,1.4658013963999998:0.0004%,10.4789346401:0.0004%,-68.19363585:0.0002%,-1.2389317536:0.0002%,13.2484439018:0.0002%,1.4843088569:0.0002%,15.1560342905:0.0002%,-1.2415756765000001:0.0002%,1.4737331652:0.0002%]
[INFO] ** classification:[normal:99.9996%,Single Stage Multi Point:0.0004%]
[INFO] columns with count within 2-10 {'orig': 3, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'proto': 3, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 9, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[4396136       0]
 [ 703864       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[4496136       0]
 [ 703864       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[4596136       0]
 [ 703864       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[4696136       0]
 [ 703864       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 99998, 1: 2}
pred {0: 100000}
[INFO] confusion matrix for file 
[[99998     0]
 [    2     0]]
[INFO] confusion matrix after adding it to total:
[[4796134       0]
 [ 703866       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-02_121729_121.log.part13_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1368 (0.2736%)
[INFO] ** orig:[0.0:99.9996%,1.0:0.0004%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[-1.0:99.9994%,0.0:0.0006%]
[INFO] ** i/f_dir:[-0.7071067812:99.9994%,0.7071067812:0.0006%]
[INFO] ** src:[-1.3652730819:38.162%,1.3652730819:26.1664%,0.5251050315:18.0742%,-0.5251050315:17.5958%,0.9451890567:0.0008%,0.10502100630000001:0.0002%,-1.1552310693:0.0002%,0.7351470441:0.0002%,0.3150630189:0.0002%]
[INFO] ** dst:[-1.0302443927:43.4352%,1.4048787174000001:20.8932%,1.2175615551:18.0744%,0.0936585812:17.5952%,-0.0936585812:0.0006%,-1.5921958797:0.0006%,-0.6556100681:0.0006%,-0.4682929058:0.0002%]
[INFO] ** proto:[0.0:99.9986%,1.0:0.0008%,-1.0:0.0006%]
[INFO] ** appi_name:[-1.6378460497:99.9986%,-1.5118578919999999:0.0006%,-0.6299407883:0.0006%,-0.25197631530000003:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.162%,-1.5753150944999998:26.1664%,1.3652730819:18.0742%,-0.3150630189:17.5958%,0.10502100630000001:0.0006%,-0.10502100630000001:0.0004%,0.3150630189:0.0002%,-0.7351470441:0.0002%,-0.5251050315:0.0002%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9986%,-176.7993450566:0.0014%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.9998%,-1.3363062096:49.9988%,-0.2672612419:0.0014%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:26.166%,0.2672612419:20.893%,0.8017837256999999:18.0738%,-1.3363062096:17.5948%,-0.2672612419:17.2688%,-0.8017837256999999:0.0036%]
[INFO] ** service:[0.0054950911:99.9986%,-185.27759935790002:0.0006%,-163.13937429709998:0.0006%,-184.7112245991:0.0002%]
[INFO] ** s_port:[1.4631574735:26.1662%,-0.2976951931:20.8932%,-1.2442195994:18.074%,-0.2104457366:17.5952%,-0.3109148077:17.2688%,-70.70536262659999:0.0006%,-0.2183775054:0.0004%,15.3265673191:0.0004%,-0.9904029989:0.0002%,4.4124534938:0.0002%,-1.2389317536:0.0002%,-0.22630927420000002:0.0002%,-70.5242539064:0.0002%,1.4737331652:0.0002%]
[INFO] ** classification:[normal:92.8338%,Multi Stage Single Point:7.1662%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 9, 'dst': 8, 'proto': 3, 'appi_name': 4, 'proxy_src_ip': 9, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 4, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[4896134       0]
 [ 703866       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 88734, 1: 11266}
pred {0: 100000}
[INFO] confusion matrix for file 
[[88734     0]
 [11266     0]]
[INFO] confusion matrix after adding it to total:
[[4984868       0]
 [ 715132       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 92435, 1: 7565}
pred {0: 100000}
[INFO] confusion matrix for file 
[[92435     0]
 [ 7565     0]]
[INFO] confusion matrix after adding it to total:
[[5077303       0]
 [ 722697       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[5177303       0]
 [ 722697       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 83000, 1: 17000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[83000     0]
 [17000     0]]
[INFO] confusion matrix after adding it to total:
[[5260303       0]
 [ 739697       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-02_121729_121.log.part14_sorted-labeled.csv
[INFO] process dataset, shape: (439824, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (439824, 17)

[INFO] analyzing data
[INFO] 439824 rows
[INFO] ** unixtime:1201 (0.27306%)
[INFO] ** orig:[0.0:99.99955%,1.0:0.00045%]
[INFO] ** type:[1.0:99.99977%,0.0:0.00023%]
[INFO] ** i/f_name:[-1.0:99.99864%,0.0:0.00136%]
[INFO] ** i/f_dir:[-0.7071067812:99.99886%,0.7071067812:0.00114%]
[INFO] ** src:[-1.3652730819:38.09456%,1.3652730819:26.09703%,0.5251050315:18.22161%,-0.5251050315:17.58408%,-1.1552310693:0.00091%,0.10502100630000001:0.00068%,0.9451890567:0.00068%,1.5753150944999998:0.00023%,-0.3150630189:0.00023%]
[INFO] ** dst:[-1.0302443927:43.35416%,1.4048787174000001:20.83674%,1.2175615551:18.22115%,0.0936585812:17.58385%,-1.5921958797:0.00159%,-0.6556100681:0.00136%,-0.8429272304000001:0.00045%,-0.28097574350000004:0.00023%,-0.4682929058:0.00023%,0.28097574350000004:0.00023%]
[INFO] ** proto:[0.0:99.99818%,-1.0:0.00136%,1.0:0.00045%]
[INFO] ** appi_name:[-1.6378460497:99.99795%,-1.5118578919999999:0.00136%,-1.3858697344:0.00023%,1.3858697344:0.00023%,0.7559289459999999:0.00023%]
[INFO] ** proxy_src_ip:[0.5251050315:38.09456%,-1.5753150944999998:26.09703%,1.3652730819:18.22161%,-0.3150630189:17.58408%,0.10502100630000001:0.00136%,0.3150630189:0.00068%,-0.10502100630000001:0.00023%,0.7351470441:0.00023%,1.5753150944999998:0.00023%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.99795%,-176.7993450566:0.00205%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.99955%,-1.3363062096:49.99841%,-0.2672612419:0.00205%]
[INFO] ** modbus_transaction_id:65536 (14.90051%)
[INFO] ** scada_tag:[1.3363062096:26.09612%,0.2672612419:20.83652%,0.8017837256999999:18.22092%,-1.3363062096:17.5834%,-0.2672612419:17.25758%,-0.8017837256999999:0.00546%]
[INFO] ** service:[0.0054950911:99.99795%,-185.27759935790002:0.00136%,-184.94686957169998:0.00023%,-184.7070904767:0.00023%,-163.1476425417:0.00023%]
[INFO] ** s_port:[1.4631574735:26.09635%,-0.2976951931:20.83674%,-1.2442195994:18.22115%,-0.2104457366:17.58362%,-0.3109148077:17.25781%,-70.70536262659999:0.00136%,-0.9904029989:0.00068%,-1.2415756765000001:0.00045%,-0.2183775054:0.00045%,1.4658013963999998:0.00045%,-63.6289029238:0.00023%,-1.2389317536:0.00023%,1.4843088569:0.00023%,-70.522931945:0.00023%]
[INFO] ** classification:[normal:93.34597%,Single Stage Single Point:4.48861%,Multi Stage Single Point:2.16541%]
[INFO] columns with count within 2-10 {'orig': 2, 'type': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 9, 'proto': 3, 'appi_name': 5, 'proxy_src_ip': 9, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 5, 'classification': 3}
[INFO] processing batch 0-100000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 0 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 86777, 1: 13223}
pred {0: 100000}
[INFO] confusion matrix for file 
[[86777     0]
 [13223     0]]
[INFO] confusion matrix after adding it to total:
[[5347080       0]
 [ 752920       0]]
[INFO] processing batch 100000-200000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 83957, 1: 16043}
pred {0: 100000}
[INFO] confusion matrix for file 
[[83957     0]
 [16043     0]]
[INFO] confusion matrix after adding it to total:
[[5431037       0]
 [ 768963       0]]
[INFO] processing batch 200000-300000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[5531037       0]
 [ 768963       0]]
[INFO] processing batch 300000-400000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[5631037       0]
 [ 768963       0]]
[INFO] processing batch 400000-500000/439824
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-02_172943_122.log.part03_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1376 (0.2752%)
[INFO] ** orig:[0.0:99.9976%,1.0:0.002%,-1.0:0.0004%]
[INFO] ** type:[1.0:99.9988%,0.0:0.001%,-1.0:0.0002%]
[INFO] ** i/f_name:[-1.0:99.9944%,0.0:0.0056%]
[INFO] ** i/f_dir:[-0.7071067812:99.9946%,0.7071067812:0.0054%]
[INFO] ** src:[-1.3652730819:38.2234%,1.3652730819:26.124%,0.5251050315:18.075%,-0.5251050315:17.571%,-1.1552310693:0.0036%,0.9451890567:0.0022%,-0.7351470441:0.0004%,-1.5753150944999998:0.0002%,-0.9451890567:0.0002%]
[INFO] ** dst:[-1.0302443927:43.4342%,1.4048787174000001:20.913%,1.2175615551:18.0748%,0.0936585812:17.5708%,-0.6556100681:0.0056%,-1.5921958797:0.0006%,0.28097574350000004:0.0004%,-0.0936585812:0.0002%,-0.8429272304000001:0.0002%,-1.4048787174000001:0.0002%]
[INFO] ** proto:[0.0:99.9936%,-1.0:0.0056%,1.0:0.0008%]
[INFO] ** appi_name:[-1.6378460497:99.9934%,-1.5118578919999999:0.0056%,1.3858697344:0.0004%,-0.5039526307:0.0002%,-0.6299407883:0.0002%,1.5118578919999999:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.2234%,-1.5753150944999998:26.124%,1.3652730819:18.075%,-0.3150630189:17.571%,0.10502100630000001:0.0056%,0.9451890567:0.0004%,-1.1552310693:0.0002%,-0.10502100630000001:0.0002%,-1.3652730819:0.0002%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9934%,-176.7993450566:0.0064%,4.6584169229:0.0002%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.997%,-1.3363062096:49.9964%,-0.2672612419:0.0064%,0.2672612419:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:26.1234%,0.2672612419:20.9128%,0.8017837256999999:18.0748%,-1.3363062096:17.5704%,-0.2672612419:17.3102%,-0.8017837256999999:0.0084%]
[INFO] ** service:[0.0054950911:99.9936%,-185.27759935790002:0.0056%,-163.1476425417:0.0004%,-163.13937429709998:0.0002%,-177.4227669367:0.0002%]
[INFO] ** s_port:[1.4631574735:26.1238%,-0.2976951931:20.913%,-1.2442195994:18.0748%,-0.2104457366:17.5706%,-0.3109148077:17.3104%,-70.70536262659999:0.0056%,-63.6289029238:0.0004%,-0.2183775054:0.0004%,13.3383372811:0.0002%,-1.2415756765000001:0.0002%,1.4843088569:0.0002%,11.782388641099999:0.0002%,-10.479442368700001:0.0002%]
[INFO] ** classification:[normal:94.9296%,Single Stage Single Point:5.0704%]
[INFO] columns with count within 2-10 {'orig': 3, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'src': 9, 'proto': 3, 'appi_name': 6, 'proxy_src_ip': 9, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 5, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[5731037       0]
 [ 768963       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[5831037       0]
 [ 768963       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[5931037       0]
 [ 768963       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[6031037       0]
 [ 768963       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 74648, 1: 25352}
pred {0: 100000}
[INFO] confusion matrix for file 
[[74648     0]
 [25352     0]]
[INFO] confusion matrix after adding it to total:
[[6105685       0]
 [ 794315       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-02_172943_122.log.part04_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1377 (0.2754%)
[INFO] ** orig:[0.0:99.995%,1.0:0.005%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[-1.0:99.9944%,0.0:0.0056%]
[INFO] ** i/f_dir:[-0.7071067812:99.9944%,0.7071067812:0.0056%]
[INFO] ** src:[-1.3652730819:38.203%,1.3652730819:26.1368%,0.5251050315:18.1014%,-0.5251050315:17.5508%,0.9451890567:0.005%,1.5753150944999998:0.0008%,0.10502100630000001:0.0006%,-1.1552310693:0.0006%,-0.7351470441:0.0004%,-0.3150630189:0.0004%,0.3150630189:0.0002%]
[INFO] ** dst:[-1.0302443927:43.4462%,1.4048787174000001:20.893%,1.2175615551:18.1012%,0.0936585812:17.5504%,-0.6556100681:0.0056%,-1.5921958797:0.0016%,0.4682929058:0.0008%,-0.4682929058:0.0006%,0.6556100681:0.0004%,-0.8429272304000001:0.0002%]
[INFO] ** proto:[0.0:99.9938%,-1.0:0.0056%,1.0:0.0006%]
[INFO] ** appi_name:[-1.6378460497:99.9926%,-1.5118578919999999:0.0056%,0.8819171037000001:0.0008%,-1.3858697344:0.0004%,0.1259881577:0.0002%,-0.25197631530000003:0.0002%,-1.2598815767:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.203%,-1.5753150944999998:26.1368%,1.3652730819:18.1014%,-0.3150630189:17.5508%,0.10502100630000001:0.0056%,0.7351470441:0.0008%,0.3150630189:0.0006%,1.5753150944999998:0.0004%,0.9451890567:0.0004%,-0.5251050315:0.0002%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9926%,-176.7993450566:0.0074%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.9972%,-1.3363062096:49.9954%,-0.2672612419:0.0074%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:26.1358%,0.2672612419:20.8928%,0.8017837256999999:18.1008%,-1.3363062096:17.55%,-0.2672612419:17.31%,-0.8017837256999999:0.0106%]
[INFO] ** service:[0.0054950911:99.9926%,-185.27759935790002:0.0056%,-179.7709484184:0.0008%,-184.7070904767:0.0004%,-184.71949284369998:0.0002%,-162.746632676:0.0002%,-184.7112245991:0.0002%]
[INFO] ** s_port:[1.4631574735:26.136%,-0.2976951931:20.893%,-1.2442195994:18.101%,-0.2104457366:17.5502%,-0.3109148077:17.31%,-70.70536262659999:0.0056%,-0.9904029989:0.0006%,1.4658013963999998:0.0006%,-0.2183775054:0.0004%,-70.522931945:0.0004%,-5.0223854561:0.0002%,-57.521440972200004:0.0002%,-1.2415756765000001:0.0002%,-1.2389317536:0.0002%,-0.22630927420000002:0.0002%,-70.5242539064:0.0002%,-57.518797049300005:0.0002%,1.4843088569:0.0002%,2.0593620926:0.0002%,-5.0818737219:0.0002%,-43.372487451000005:0.0002%]
[INFO] ** classification:[normal:64.3482%,Single Stage Single Point:35.6518%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'proto': 3, 'appi_name': 7, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 7, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 64457, 1: 35543}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64457     0]
 [35543     0]]
[INFO] confusion matrix after adding it to total:
[[6170142       0]
 [ 829858       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 64588, 1: 35412}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64588     0]
 [35412     0]]
[INFO] confusion matrix after adding it to total:
[[6234730       0]
 [ 865270       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 64276, 1: 35724}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64276     0]
 [35724     0]]
[INFO] confusion matrix after adding it to total:
[[6299006       0]
 [ 900994       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 1 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 64281, 1: 35719}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64281     0]
 [35719     0]]
[INFO] confusion matrix after adding it to total:
[[6363287       0]
 [ 936713       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 0 ... 1 1 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 64139, 1: 35861}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64139     0]
 [35861     0]]
[INFO] confusion matrix after adding it to total:
[[6427426       0]
 [ 972574       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-02_172943_122.log.part05_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1367 (0.2734%)
[INFO] ** orig:[0.0:99.9992%,1.0:0.0008%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[-1.0:99.9984%,0.0:0.0016%]
[INFO] ** i/f_dir:[-0.7071067812:99.9984%,0.7071067812:0.0016%]
[INFO] ** src:[-1.3652730819:38.0648%,1.3652730819:26.1164%,0.5251050315:18.2044%,-0.5251050315:17.6118%,0.9451890567:0.001%,-1.1552310693:0.0008%,1.5753150944999998:0.0004%,-0.7351470441:0.0004%]
[INFO] ** dst:[-1.0302443927:43.368%,1.4048787174000001:20.8128%,1.2175615551:18.2044%,0.0936585812:17.6114%,-0.6556100681:0.0016%,-1.5921958797:0.0006%,0.4682929058:0.0004%,-0.0936585812:0.0002%,-0.8429272304000001:0.0002%,-0.4682929058:0.0002%,-0.28097574350000004:0.0002%]
[INFO] ** proto:[0.0:99.998%,-1.0:0.0016%,1.0:0.0004%]
[INFO] ** appi_name:[-1.6378460497:99.9974%,-1.5118578919999999:0.0016%,0.1259881577:0.0006%,-0.25197631530000003:0.0002%,-0.6299407883:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.0648%,-1.5753150944999998:26.1164%,1.3652730819:18.2044%,-0.3150630189:17.6118%,0.10502100630000001:0.0016%,0.7351470441:0.0004%,0.9451890567:0.0004%,-0.10502100630000001:0.0002%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9974%,-176.7993450566:0.0026%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.9992%,-1.3363062096:49.9982%,-0.2672612419:0.0026%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:26.1154%,0.2672612419:20.8126%,0.8017837256999999:18.204%,-1.3363062096:17.6112%,-0.2672612419:17.2518%,-0.8017837256999999:0.005%]
[INFO] ** service:[0.0054950911:99.9974%,-185.27759935790002:0.0016%,-184.71949284369998:0.0006%,-163.13937429709998:0.0002%,-184.7112245991:0.0002%]
[INFO] ** s_port:[1.4631574735:26.1158%,-0.2976951931:20.8128%,-1.2442195994:18.204%,-0.2104457366:17.6114%,-0.3109148077:17.252%,-70.70536262659999:0.0016%,1.4658013963999998:0.0004%,10.6613653218:0.0002%,-2.7657972414999996:0.0002%,-1.9871619406999999:0.0002%,-70.5242539064:0.0002%,-1.2389317536:0.0002%,-0.2183775054:0.0002%,-1.2415756765000001:0.0002%,1.4737331652:0.0002%,14.7779533126:0.0002%,-0.22630927420000002:0.0002%]
[INFO] ** classification:[normal:97.0224%,Single Stage Single Point:2.9776%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 8, 'proto': 3, 'appi_name': 5, 'proxy_src_ip': 8, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 5, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 85112, 1: 14888}
pred {0: 100000}
[INFO] confusion matrix for file 
[[85112     0]
 [14888     0]]
[INFO] confusion matrix after adding it to total:
[[6512538       0]
 [ 987462       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[6612538       0]
 [ 987462       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[6712538       0]
 [ 987462       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[6812538       0]
 [ 987462       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  nan
tp :  0.0
fp :  0.0
tn :  100000.0
fn :  100000.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[6912538       0]
 [ 987462       0]]
--- 377.4690980911255 seconds ---
