2020-02-03 08:00:44.833778: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-02-03 08:00:44.833936: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-02-03 08:00:44.833952: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-02-03 08:00:45.636610: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-02-03 08:00:45.636642: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-02-03 08:00:45.636672: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (***REMOVED***): /proc/driver/nvidia/version does not exist
2020-02-03 08:00:45.636871: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-03 08:00:45.646414: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2112050000 Hz
2020-02-03 08:00:45.648054: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5a34050 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-03 08:00:45.648089: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-02-03 08:00:49.391863: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-03 08:00:49.409402: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 08:00:49.417086: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 08:00:49.481053: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-03 08:00:49.484957: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-03 08:00:49.490525: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 08:00:49.496060: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 08:00:49.509663: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-03 08:00:53.280364: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-03 08:00:53.284419: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 08:00:53.286263: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 08:00:53.300380: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-03 08:00:53.301335: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-03 08:00:53.302700: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 08:00:53.304070: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 08:00:53.308051: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
=============================
        TRAINING v0.3
=============================
Date: 2020-02-03 08:00:45.630930
[INFO] input_shape (10, 16)
[INFO] LSTM first and last layer neurons: 5
adding core layer 0
[INFO] created DNN
[33m[INFO] epoch 1/10[0m
[33m[INFO] loading file 1-1/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 1.1607 - tp: 9563.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 70437.0000 - accuracy: 0.8239 - precision: 1.0000 - recall: 0.1195 - auc: 0.9347 - val_loss: 0.5832 - val_tp: 16000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 4000.0000 - val_accuracy: 0.9600 - val_precision: 1.0000 - val_recall: 0.8000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-1-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.3527 - tp: 69076.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 10924.0000 - accuracy: 0.9727 - precision: 1.0000 - recall: 0.8634 - auc: 1.0000 - val_loss: 0.1264 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-1-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1573 - tp: 79728.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 272.0000 - accuracy: 0.9987 - precision: 0.9971 - recall: 0.9966 - auc: 0.9977 - val_loss: 3.4797 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.5932
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-1-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.8171 - tp: 30541.0000 - fp: 26415.0000 - tn: 293585.0000 - fn: 49459.0000 - accuracy: 0.8103 - precision: 0.5362 - recall: 0.3818 - auc: 0.7287 - val_loss: 1.1030 - val_tp: 2055.0000 - val_fp: 221.0000 - val_tn: 79779.0000 - val_fn: 17945.0000 - val_accuracy: 0.8183 - val_precision: 0.9029 - val_recall: 0.1028 - val_auc: 0.9088
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-1-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.9417 - tp: 21723.0000 - fp: 1679.0000 - tn: 318321.0000 - fn: 58277.0000 - accuracy: 0.8501 - precision: 0.9283 - recall: 0.2715 - auc: 0.9239 - val_loss: 0.7694 - val_tp: 7127.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 12873.0000 - val_accuracy: 0.8713 - val_precision: 1.0000 - val_recall: 0.3564 - val_auc: 0.9770
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-1-batch-400000-500000
[33m[INFO] loading file 2-2/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.7048 - tp: 31695.0000 - fp: 1511.0000 - tn: 318489.0000 - fn: 48305.0000 - accuracy: 0.8755 - precision: 0.9545 - recall: 0.3962 - auc: 0.9629 - val_loss: 0.5536 - val_tp: 10170.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 9830.0000 - val_accuracy: 0.9017 - val_precision: 1.0000 - val_recall: 0.5085 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-1-2-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4878 - tp: 66210.0000 - fp: 11894.0000 - tn: 308106.0000 - fn: 13790.0000 - accuracy: 0.9358 - precision: 0.8477 - recall: 0.8276 - auc: 0.9745 - val_loss: 0.2427 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-1-2-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.3460 - tp: 72432.0000 - fp: 7568.0000 - tn: 312432.0000 - fn: 7568.0000 - accuracy: 0.9622 - precision: 0.9054 - recall: 0.9054 - auc: 0.9845 - val_loss: 1.0691 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 70593.0000 - val_fn: 9407.0000 - val_accuracy: 0.8119 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.9430
[INFO] saving weights to checkpoints/lstm-epoch-001-files-1-2-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.5481 - tp: 49180.0000 - fp: 11918.0000 - tn: 308082.0000 - fn: 30820.0000 - accuracy: 0.8932 - precision: 0.8049 - recall: 0.6148 - auc: 0.9648 - val_loss: 0.3509 - val_tp: 19445.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 555.0000 - val_accuracy: 0.9945 - val_precision: 1.0000 - val_recall: 0.9722 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-1-2-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4033 - tp: 66804.0000 - fp: 12685.0000 - tn: 307315.0000 - fn: 13196.0000 - accuracy: 0.9353 - precision: 0.8404 - recall: 0.8350 - auc: 0.9784 - val_loss: 0.1871 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-1-2-batch-400000-500000
[33m[INFO] loading file 3-3/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4135 - tp: 67009.0000 - fp: 11650.0000 - tn: 308350.0000 - fn: 12991.0000 - accuracy: 0.9384 - precision: 0.8519 - recall: 0.8376 - auc: 0.9822 - val_loss: 0.2585 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-3-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4332 - tp: 58130.0000 - fp: 15401.0000 - tn: 304599.0000 - fn: 21870.0000 - accuracy: 0.9068 - precision: 0.7906 - recall: 0.7266 - auc: 0.9718 - val_loss: 0.3997 - val_tp: 13072.0000 - val_fp: 3412.0000 - val_tn: 76588.0000 - val_fn: 6928.0000 - val_accuracy: 0.8966 - val_precision: 0.7930 - val_recall: 0.6536 - val_auc: 0.9668
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-3-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0526 - tp: 79818.0000 - fp: 104.0000 - tn: 319896.0000 - fn: 182.0000 - accuracy: 0.9993 - precision: 0.9987 - recall: 0.9977 - auc: 1.0000 - val_loss: 0.0028 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-3-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0262 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0013 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-3-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0172 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.2186e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-3-batch-400000-500000
[33m[INFO] loading file 4-4/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0116 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4447e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-3-4-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0088 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.8987e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-3-4-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0066 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.9719e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-3-4-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4863 - tp: 71516.0000 - fp: 8474.0000 - tn: 311526.0000 - fn: 8484.0000 - accuracy: 0.9576 - precision: 0.8941 - recall: 0.8939 - auc: 0.9641 - val_loss: 1.2435 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 67806.0000 - val_fn: 12194.0000 - val_accuracy: 0.7561 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.9057
[INFO] saving weights to checkpoints/lstm-epoch-001-files-3-4-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.5355 - tp: 54805.0000 - fp: 22148.0000 - tn: 297852.0000 - fn: 25195.0000 - accuracy: 0.8816 - precision: 0.7122 - recall: 0.6851 - auc: 0.9539 - val_loss: 0.3469 - val_tp: 17951.0000 - val_fp: 1601.0000 - val_tn: 78399.0000 - val_fn: 2049.0000 - val_accuracy: 0.9635 - val_precision: 0.9181 - val_recall: 0.8975 - val_auc: 0.9925
[INFO] saving weights to checkpoints/lstm-epoch-001-files-3-4-batch-400000-500000
[33m[INFO] loading file 5-5/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.3711 - tp: 65229.0000 - fp: 13409.0000 - tn: 306591.0000 - fn: 14771.0000 - accuracy: 0.9296 - precision: 0.8295 - recall: 0.8154 - auc: 0.9801 - val_loss: 0.1964 - val_tp: 19974.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 26.0000 - val_accuracy: 0.9997 - val_precision: 1.0000 - val_recall: 0.9987 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-5-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.2285 - tp: 72915.0000 - fp: 7066.0000 - tn: 312934.0000 - fn: 7085.0000 - accuracy: 0.9646 - precision: 0.9117 - recall: 0.9114 - auc: 0.9964 - val_loss: 0.4245 - val_tp: 15795.0000 - val_fp: 4205.0000 - val_tn: 75795.0000 - val_fn: 4205.0000 - val_accuracy: 0.9159 - val_precision: 0.7897 - val_recall: 0.7897 - val_auc: 0.9811
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-5-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1593 - tp: 74322.0000 - fp: 5654.0000 - tn: 314346.0000 - fn: 5678.0000 - accuracy: 0.9717 - precision: 0.9293 - recall: 0.9290 - auc: 0.9969 - val_loss: 0.0020 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-5-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0148 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.8090e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-5-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0093 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9656e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-5-batch-400000-500000
[33m[INFO] loading file 6-6/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0064 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.1701e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-5-6-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0047 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3606e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-5-6-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0036 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.1114e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-5-6-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0027 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.1795 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 75632.0000 - val_fn: 4368.0000 - val_accuracy: 0.9126 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.8635
[INFO] saving weights to checkpoints/lstm-epoch-001-files-5-6-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4924 - tp: 69266.0000 - fp: 10601.0000 - tn: 309399.0000 - fn: 10734.0000 - accuracy: 0.9467 - precision: 0.8673 - recall: 0.8658 - auc: 0.9681 - val_loss: 0.0861 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-5-6-batch-400000-500000
[33m[INFO] loading file 7-7/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1721 - tp: 72865.0000 - fp: 7110.0000 - tn: 312890.0000 - fn: 7135.0000 - accuracy: 0.9644 - precision: 0.9111 - recall: 0.9108 - auc: 0.9975 - val_loss: 0.0612 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-7-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1453 - tp: 75199.0000 - fp: 3987.0000 - tn: 316013.0000 - fn: 4801.0000 - accuracy: 0.9780 - precision: 0.9497 - recall: 0.9400 - auc: 0.9986 - val_loss: 0.0460 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-7-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.3471 - tp: 65430.0000 - fp: 14360.0000 - tn: 305640.0000 - fn: 14570.0000 - accuracy: 0.9277 - precision: 0.8200 - recall: 0.8179 - auc: 0.9810 - val_loss: 0.2649 - val_tp: 18611.0000 - val_fp: 1389.0000 - val_tn: 78611.0000 - val_fn: 1389.0000 - val_accuracy: 0.9722 - val_precision: 0.9305 - val_recall: 0.9305 - val_auc: 0.9904
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-7-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0607 - tp: 79399.0000 - fp: 594.0000 - tn: 319406.0000 - fn: 601.0000 - accuracy: 0.9970 - precision: 0.9926 - recall: 0.9925 - auc: 0.9996 - val_loss: 0.0025 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-7-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0131 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.4753e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-7-batch-400000-500000
[33m[INFO] loading file 8-8/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0083 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.4997e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-7-8-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0059 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.0335e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-7-8-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0044 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3076e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-7-8-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.2749 - tp: 73148.0000 - fp: 6849.0000 - tn: 313151.0000 - fn: 6852.0000 - accuracy: 0.9657 - precision: 0.9144 - recall: 0.9143 - auc: 0.9874 - val_loss: 0.3394 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 76368.0000 - val_fn: 3632.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9837
[INFO] saving weights to checkpoints/lstm-epoch-001-files-7-8-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1603 - tp: 73482.0000 - fp: 6438.0000 - tn: 313562.0000 - fn: 6518.0000 - accuracy: 0.9676 - precision: 0.9194 - recall: 0.9185 - auc: 0.9969 - val_loss: 0.0262 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-7-8-batch-400000-500000
[33m[INFO] loading file 9-9/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0909 - tp: 76262.0000 - fp: 3738.0000 - tn: 316262.0000 - fn: 3738.0000 - accuracy: 0.9813 - precision: 0.9533 - recall: 0.9533 - auc: 0.9994 - val_loss: 0.0202 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-9-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1258 - tp: 78194.0000 - fp: 1806.0000 - tn: 318194.0000 - fn: 1806.0000 - accuracy: 0.9910 - precision: 0.9774 - recall: 0.9774 - auc: 0.9945 - val_loss: 0.0226 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-9-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0130 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.8064e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-9-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8814e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-9-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0036 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.7957e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-9-batch-400000-500000
[33m[INFO] loading file 10-10/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0026 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.8022e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-9-10-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0101 - tp: 79936.0000 - fp: 64.0000 - tn: 319936.0000 - fn: 64.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 0.9995 - val_loss: 3.2568 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.7763
[INFO] saving weights to checkpoints/lstm-epoch-001-files-9-10-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4129 - tp: 69300.0000 - fp: 10698.0000 - tn: 309302.0000 - fn: 10700.0000 - accuracy: 0.9465 - precision: 0.8663 - recall: 0.8662 - auc: 0.9780 - val_loss: 0.7791 - val_tp: 12813.0000 - val_fp: 7187.0000 - val_tn: 72813.0000 - val_fn: 7187.0000 - val_accuracy: 0.8563 - val_precision: 0.6406 - val_recall: 0.6406 - val_auc: 0.9671
[INFO] saving weights to checkpoints/lstm-epoch-001-files-9-10-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1004 - tp: 77308.0000 - fp: 2686.0000 - tn: 317314.0000 - fn: 2692.0000 - accuracy: 0.9866 - precision: 0.9664 - recall: 0.9664 - auc: 0.9992 - val_loss: 0.0142 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-9-10-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0114 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0061 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-9-10-batch-400000-500000
[33m[INFO] loading file 11-11/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0055 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0013 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-11-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.5123e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-11-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0016 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.4835e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-11-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0013 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4622e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-11-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0010 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.4294e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-11-batch-400000-500000
[33m[INFO] loading file 12-12/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.4517e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.4957e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-11-12-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.8438e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6441 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 76689.0000 - val_fn: 3311.0000 - val_accuracy: 0.9338 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8965
[INFO] saving weights to checkpoints/lstm-epoch-001-files-11-12-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.5455 - tp: 67845.0000 - fp: 12146.0000 - tn: 307854.0000 - fn: 12155.0000 - accuracy: 0.9392 - precision: 0.8482 - recall: 0.8481 - auc: 0.9655 - val_loss: 0.3830 - val_tp: 17100.0000 - val_fp: 2900.0000 - val_tn: 77100.0000 - val_fn: 2900.0000 - val_accuracy: 0.9420 - val_precision: 0.8550 - val_recall: 0.8550 - val_auc: 0.9735
[INFO] saving weights to checkpoints/lstm-epoch-001-files-11-12-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1390 - tp: 76241.0000 - fp: 3753.0000 - tn: 316247.0000 - fn: 3759.0000 - accuracy: 0.9812 - precision: 0.9531 - recall: 0.9530 - auc: 0.9978 - val_loss: 0.0175 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-11-12-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0165 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0087 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-11-12-batch-400000-500000
[33m[INFO] loading file 13-13/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0097 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0049 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-13-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0056 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0021 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-13-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0034 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.5865 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 75075.0000 - val_fn: 4925.0000 - val_accuracy: 0.9015 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.8682
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-13-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4718 - tp: 66888.0000 - fp: 13112.0000 - tn: 306888.0000 - fn: 13112.0000 - accuracy: 0.9344 - precision: 0.8361 - recall: 0.8361 - auc: 0.9729 - val_loss: 0.0414 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-13-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1373 - tp: 72843.0000 - fp: 7152.0000 - tn: 312848.0000 - fn: 7157.0000 - accuracy: 0.9642 - precision: 0.9106 - recall: 0.9105 - auc: 0.9977 - val_loss: 0.0290 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-13-batch-400000-500000
[33m[INFO] loading file 14-14/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.3529 - tp: 65735.0000 - fp: 14259.0000 - tn: 305741.0000 - fn: 14265.0000 - accuracy: 0.9287 - precision: 0.8217 - recall: 0.8217 - auc: 0.9825 - val_loss: 0.4743 - val_tp: 15371.0000 - val_fp: 4615.0000 - val_tn: 75385.0000 - val_fn: 4629.0000 - val_accuracy: 0.9076 - val_precision: 0.7691 - val_recall: 0.7685 - val_auc: 0.9754
[INFO] saving weights to checkpoints/lstm-epoch-001-files-13-14-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0678 - tp: 78939.0000 - fp: 1060.0000 - tn: 318940.0000 - fn: 1061.0000 - accuracy: 0.9947 - precision: 0.9867 - recall: 0.9867 - auc: 0.9992 - val_loss: 3.5761e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-13-14-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0134 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6896e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-13-14-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0096 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.3965e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-13-14-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0071 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.7391e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-13-14-batch-400000-500000
[33m[INFO] loading file 15-15/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0058 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.7582e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-15-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0045 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.5344e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-15-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0035 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8732e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-15-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0028 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.7809 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 71586.0000 - val_fn: 8414.0000 - val_accuracy: 0.8317 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.7371
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-15-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.3237 - tp: 40314.0000 - fp: 39449.0000 - tn: 280551.0000 - fn: 39686.0000 - accuracy: 0.8022 - precision: 0.5054 - recall: 0.5039 - auc: 0.6600 - val_loss: 2.9342 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 70627.0000 - val_fn: 9373.0000 - val_accuracy: 0.8125 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.6491
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-15-batch-400000-500000
[33m[INFO] loading file 16-16/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.5547 - tp: 41307.0000 - fp: 38256.0000 - tn: 281744.0000 - fn: 38693.0000 - accuracy: 0.8076 - precision: 0.5192 - recall: 0.5163 - auc: 0.7419 - val_loss: 2.1867 - val_tp: 10618.0000 - val_fp: 9224.0000 - val_tn: 70776.0000 - val_fn: 9382.0000 - val_accuracy: 0.8139 - val_precision: 0.5351 - val_recall: 0.5309 - val_auc: 0.8125
[INFO] saving weights to checkpoints/lstm-epoch-001-files-15-16-batch-0-100000
[INFO] processing batch 100000-200000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.3021 - tp: 58073.0000 - fp: 21810.0000 - tn: 298190.0000 - fn: 21927.0000 - accuracy: 0.8907 - precision: 0.7270 - recall: 0.7259 - auc: 0.8922 - val_loss: 0.1724 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-15-16-batch-100000-200000
[INFO] processing batch 200000-300000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0452 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-15-16-batch-200000-300000
[INFO] processing batch 300000-400000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0158 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-15-16-batch-300000-400000
[INFO] processing batch 400000-500000/439690
[33m[INFO] loading file 17-17/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0107 - tp: 79991.0000 - fp: 8.0000 - tn: 319992.0000 - fn: 9.0000 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-17-batch-0-100000
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0051 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.8245e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-17-batch-100000-200000
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0040 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.5220e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-17-batch-200000-300000
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.5037 - tp: 68607.0000 - fp: 11393.0000 - tn: 308607.0000 - fn: 11393.0000 - accuracy: 0.9430 - precision: 0.8576 - recall: 0.8576 - auc: 0.8848 - val_loss: 1.4174 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 76369.0000 - val_fn: 3631.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.8518
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-17-batch-300000-400000
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.1451 - tp: 64585.0000 - fp: 15100.0000 - tn: 304900.0000 - fn: 15415.0000 - accuracy: 0.9237 - precision: 0.8105 - recall: 0.8073 - auc: 0.8792 - val_loss: 0.4826 - val_tp: 16390.0000 - val_fp: 3610.0000 - val_tn: 76390.0000 - val_fn: 3610.0000 - val_accuracy: 0.9278 - val_precision: 0.8195 - val_recall: 0.8195 - val_auc: 0.9622
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-17-batch-400000-500000
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 18-18/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.7284 - tp: 71505.0000 - fp: 8491.0000 - tn: 311509.0000 - fn: 8495.0000 - accuracy: 0.9575 - precision: 0.8939 - recall: 0.8938 - auc: 0.9160 - val_loss: 2.3023 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 72369.0000 - val_fn: 7631.0000 - val_accuracy: 0.8474 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.6774
[INFO] saving weights to checkpoints/lstm-epoch-001-files-17-18-batch-0-100000
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.6641 - tp: 49689.0000 - fp: 30160.0000 - tn: 289840.0000 - fn: 30311.0000 - accuracy: 0.8488 - precision: 0.6223 - recall: 0.6211 - auc: 0.7930 - val_loss: 1.2939 - val_tp: 12356.0000 - val_fp: 7644.0000 - val_tn: 72356.0000 - val_fn: 7644.0000 - val_accuracy: 0.8471 - val_precision: 0.6178 - val_recall: 0.6178 - val_auc: 0.8898
[INFO] saving weights to checkpoints/lstm-epoch-001-files-17-18-batch-100000-200000
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.2038 - tp: 49541.0000 - fp: 30408.0000 - tn: 289592.0000 - fn: 30459.0000 - accuracy: 0.8478 - precision: 0.6197 - recall: 0.6193 - auc: 0.8898 - val_loss: 1.0009 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 72397.0000 - val_fn: 7603.0000 - val_accuracy: 0.8479 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.9277
[INFO] saving weights to checkpoints/lstm-epoch-001-files-17-18-batch-200000-300000
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4050 - tp: 72394.0000 - fp: 7528.0000 - tn: 312472.0000 - fn: 7606.0000 - accuracy: 0.9622 - precision: 0.9058 - recall: 0.9049 - auc: 0.9687 - val_loss: 0.0646 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-17-18-batch-300000-400000
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0309 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0062 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-17-18-batch-400000-500000
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 19-19/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0137 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0028 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-19-batch-0-100000
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0088 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0016 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-19-batch-100000-200000
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0062 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0011 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-19-batch-200000-300000
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.5844 - tp: 69321.0000 - fp: 10679.0000 - tn: 309321.0000 - fn: 10679.0000 - accuracy: 0.9466 - precision: 0.8665 - recall: 0.8665 - auc: 0.9436 - val_loss: 1.8822 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 67882.0000 - val_fn: 12118.0000 - val_accuracy: 0.7576 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.8518
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-19-batch-300000-400000
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.2457 - tp: 31223.0000 - fp: 47380.0000 - tn: 272620.0000 - fn: 48777.0000 - accuracy: 0.7596 - precision: 0.3972 - recall: 0.3903 - auc: 0.8319 - val_loss: 0.4806 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-19-batch-400000-500000
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 20-20/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1703 - tp: 79998.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1235 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 79491.0000 - val_fn: 509.0000 - val_accuracy: 0.9898 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9936
[INFO] saving weights to checkpoints/lstm-epoch-001-files-19-20-batch-0-100000
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.5183 - tp: 65427.0000 - fp: 14573.0000 - tn: 305427.0000 - fn: 14573.0000 - accuracy: 0.9271 - precision: 0.8178 - recall: 0.8178 - auc: 0.9542 - val_loss: 0.4909 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 76357.0000 - val_fn: 3643.0000 - val_accuracy: 0.9271 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.9536
[INFO] saving weights to checkpoints/lstm-epoch-001-files-19-20-batch-100000-200000
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4905 - tp: 65351.0000 - fp: 14649.0000 - tn: 305351.0000 - fn: 14649.0000 - accuracy: 0.9268 - precision: 0.8169 - recall: 0.8169 - auc: 0.9548 - val_loss: 0.4833 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 76371.0000 - val_fn: 3629.0000 - val_accuracy: 0.9274 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.9607
[INFO] saving weights to checkpoints/lstm-epoch-001-files-19-20-batch-200000-300000
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.2251 - tp: 76024.0000 - fp: 3976.0000 - tn: 316024.0000 - fn: 3976.0000 - accuracy: 0.9801 - precision: 0.9503 - recall: 0.9503 - auc: 0.9876 - val_loss: 0.0617 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-19-20-batch-300000-400000
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0328 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0125 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-19-20-batch-400000-500000
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 21-21/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539688, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0140 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0054 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-21-batch-0-100000
[INFO] processing batch 100000-200000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0090 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0030 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-21-batch-100000-200000
[INFO] processing batch 200000-300000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0064 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0018 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-21-batch-200000-300000
[INFO] processing batch 300000-400000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0049 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0012 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-21-batch-300000-400000
[INFO] processing batch 400000-500000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0038 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.8517e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-21-batch-400000-500000
[INFO] processing batch 500000-600000/539688
[33m[INFO] loading file 22-22/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (308729, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/308729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.2065 - tp: 42934.0000 - fp: 20889.0000 - tn: 299111.0000 - fn: 37066.0000 - accuracy: 0.8551 - precision: 0.6727 - recall: 0.5367 - auc: 0.7543 - val_loss: 3.2011 - val_tp: 5180.0000 - val_fp: 4820.0000 - val_tn: 75180.0000 - val_fn: 14820.0000 - val_accuracy: 0.8036 - val_precision: 0.5180 - val_recall: 0.2590 - val_auc: 0.5298
[INFO] saving weights to checkpoints/lstm-epoch-001-files-21-22-batch-0-100000
[INFO] processing batch 100000-200000/308729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.9146 - tp: 20382.0000 - fp: 17722.0000 - tn: 302278.0000 - fn: 59618.0000 - accuracy: 0.8066 - precision: 0.5349 - recall: 0.2548 - auc: 0.5293 - val_loss: 2.4786 - val_tp: 4313.0000 - val_fp: 3028.0000 - val_tn: 76972.0000 - val_fn: 15687.0000 - val_accuracy: 0.8128 - val_precision: 0.5875 - val_recall: 0.2157 - val_auc: 0.5334
[INFO] saving weights to checkpoints/lstm-epoch-001-files-21-22-batch-100000-200000
[INFO] processing batch 200000-300000/308729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.2225 - tp: 26392.0000 - fp: 21321.0000 - tn: 298679.0000 - fn: 53608.0000 - accuracy: 0.8127 - precision: 0.5531 - recall: 0.3299 - auc: 0.5330 - val_loss: 1.9030 - val_tp: 10324.0000 - val_fp: 6125.0000 - val_tn: 73875.0000 - val_fn: 9676.0000 - val_accuracy: 0.8420 - val_precision: 0.6276 - val_recall: 0.5162 - val_auc: 0.5641
[INFO] saving weights to checkpoints/lstm-epoch-001-files-21-22-batch-200000-300000
[INFO] processing batch 300000-400000/308729
[33m[INFO] loading file 23-23/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (508729, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.9072 - tp: 63450.0000 - fp: 11657.0000 - tn: 308343.0000 - fn: 16550.0000 - accuracy: 0.9295 - precision: 0.8448 - recall: 0.7931 - auc: 0.8630 - val_loss: 0.2459 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-23-batch-0-100000
[INFO] processing batch 100000-200000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0657 - tp: 79864.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 136.0000 - accuracy: 0.9997 - precision: 1.0000 - recall: 0.9983 - auc: 1.0000 - val_loss: 0.0156 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-23-batch-100000-200000
[INFO] processing batch 200000-300000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0231 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0060 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-23-batch-200000-300000
[INFO] processing batch 300000-400000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0116 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0024 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-23-batch-300000-400000
[INFO] processing batch 400000-500000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0072 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0013 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-23-batch-400000-500000
[INFO] processing batch 500000-600000/508729
[33m[INFO] loading file 24-24/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (508729, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0055 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.0713e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-23-24-batch-0-100000
[INFO] processing batch 100000-200000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0046 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.5844e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-23-24-batch-100000-200000
[INFO] processing batch 200000-300000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0039 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.0108e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-23-24-batch-200000-300000
[INFO] processing batch 300000-400000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0033 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.9490e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-23-24-batch-300000-400000
[INFO] processing batch 400000-500000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.2604 - tp: 64722.0000 - fp: 15278.0000 - tn: 304722.0000 - fn: 15278.0000 - accuracy: 0.9236 - precision: 0.8090 - recall: 0.8090 - auc: 0.8605 - val_loss: 1.3167 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 72899.0000 - val_fn: 7101.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.7854
[INFO] saving weights to checkpoints/lstm-epoch-001-files-23-24-batch-400000-500000
[INFO] processing batch 500000-600000/508729
[33m[INFO] loading file 25-25/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (508729, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.1424 - tp: 44505.0000 - fp: 23285.0000 - tn: 296715.0000 - fn: 35495.0000 - accuracy: 0.8530 - precision: 0.6565 - recall: 0.5563 - auc: 0.8209 - val_loss: 0.9116 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9511
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-25-batch-0-100000
[INFO] processing batch 100000-200000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.6959 - tp: 55806.0000 - fp: 19517.0000 - tn: 300483.0000 - fn: 24194.0000 - accuracy: 0.8907 - precision: 0.7409 - recall: 0.6976 - auc: 0.9395 - val_loss: 0.4038 - val_tp: 12860.0000 - val_fp: 2383.0000 - val_tn: 77617.0000 - val_fn: 7140.0000 - val_accuracy: 0.9048 - val_precision: 0.8437 - val_recall: 0.6430 - val_auc: 0.9698
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-25-batch-100000-200000
[INFO] processing batch 200000-300000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4180 - tp: 63709.0000 - fp: 8118.0000 - tn: 311882.0000 - fn: 16291.0000 - accuracy: 0.9390 - precision: 0.8870 - recall: 0.7964 - auc: 0.9802 - val_loss: 0.2028 - val_tp: 19316.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 684.0000 - val_accuracy: 0.9932 - val_precision: 0.9999 - val_recall: 0.9658 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-25-batch-200000-300000
[INFO] processing batch 300000-400000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.3178 - tp: 72478.0000 - fp: 7158.0000 - tn: 312842.0000 - fn: 7522.0000 - accuracy: 0.9633 - precision: 0.9101 - recall: 0.9060 - auc: 0.9886 - val_loss: 0.1221 - val_tp: 19999.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-25-batch-300000-400000
[INFO] processing batch 400000-500000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.2572 - tp: 72737.0000 - fp: 7263.0000 - tn: 312737.0000 - fn: 7263.0000 - accuracy: 0.9637 - precision: 0.9092 - recall: 0.9092 - auc: 0.9953 - val_loss: 0.0826 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-25-batch-400000-500000
[INFO] processing batch 500000-600000/508729
[33m[INFO] loading file 26-26/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (508729, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.5010 - tp: 64471.0000 - fp: 14198.0000 - tn: 305802.0000 - fn: 15529.0000 - accuracy: 0.9257 - precision: 0.8195 - recall: 0.8059 - auc: 0.9700 - val_loss: 0.8514 - val_tp: 12898.0000 - val_fp: 7026.0000 - val_tn: 72974.0000 - val_fn: 7102.0000 - val_accuracy: 0.8587 - val_precision: 0.6474 - val_recall: 0.6449 - val_auc: 0.9370
[INFO] saving weights to checkpoints/lstm-epoch-001-files-25-26-batch-0-100000
[INFO] processing batch 100000-200000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.6605 - tp: 51488.0000 - fp: 13333.0000 - tn: 306667.0000 - fn: 28512.0000 - accuracy: 0.8954 - precision: 0.7943 - recall: 0.6436 - auc: 0.9372 - val_loss: 0.4878 - val_tp: 12872.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 7128.0000 - val_accuracy: 0.9287 - val_precision: 0.9999 - val_recall: 0.6436 - val_auc: 0.9370
[INFO] saving weights to checkpoints/lstm-epoch-001-files-25-26-batch-100000-200000
[INFO] processing batch 200000-300000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4361 - tp: 50061.0000 - fp: 878.0000 - tn: 319122.0000 - fn: 29939.0000 - accuracy: 0.9230 - precision: 0.9828 - recall: 0.6258 - auc: 0.9696 - val_loss: 0.3268 - val_tp: 12881.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 7119.0000 - val_accuracy: 0.9288 - val_precision: 0.9999 - val_recall: 0.6441 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-25-26-batch-200000-300000
[INFO] processing batch 300000-400000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.3071 - tp: 55880.0000 - fp: 286.0000 - tn: 319714.0000 - fn: 24120.0000 - accuracy: 0.9390 - precision: 0.9949 - recall: 0.6985 - auc: 0.9974 - val_loss: 0.2259 - val_tp: 19997.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 3.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9998 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-25-26-batch-300000-400000
[INFO] processing batch 400000-500000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.2276 - tp: 74495.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 5505.0000 - accuracy: 0.9862 - precision: 1.0000 - recall: 0.9312 - auc: 0.9998 - val_loss: 0.1590 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-25-26-batch-400000-500000
[INFO] processing batch 500000-600000/508729
[33m[INFO] loading file 27-27/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (448859, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/448859
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.2026 - tp: 76462.0000 - fp: 1099.0000 - tn: 318901.0000 - fn: 3538.0000 - accuracy: 0.9884 - precision: 0.9858 - recall: 0.9558 - auc: 0.9994 - val_loss: 0.1187 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-27-batch-0-100000
[INFO] processing batch 100000-200000/448859
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1418 - tp: 77493.0000 - fp: 4.0000 - tn: 319996.0000 - fn: 2507.0000 - accuracy: 0.9937 - precision: 0.9999 - recall: 0.9687 - auc: 0.9998 - val_loss: 0.0852 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-27-batch-100000-200000
[INFO] processing batch 200000-300000/448859
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1149 - tp: 77493.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 2507.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9687 - auc: 0.9998 - val_loss: 0.0637 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-27-batch-200000-300000
[INFO] processing batch 300000-400000/448859
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0963 - tp: 77484.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 2516.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9686 - auc: 0.9998 - val_loss: 0.0475 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-27-batch-300000-400000
[INFO] processing batch 400000-500000/448859
[33m[INFO] loading file 28-28/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (382775, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/382775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0817 - tp: 77501.0000 - fp: 14.0000 - tn: 319986.0000 - fn: 2499.0000 - accuracy: 0.9937 - precision: 0.9998 - recall: 0.9688 - auc: 0.9998 - val_loss: 0.0370 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-27-28-batch-0-100000
[INFO] processing batch 100000-200000/382775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0705 - tp: 77559.0000 - fp: 50.0000 - tn: 319950.0000 - fn: 2441.0000 - accuracy: 0.9938 - precision: 0.9994 - recall: 0.9695 - auc: 0.9998 - val_loss: 0.0292 - val_tp: 19994.0000 - val_fp: 6.0000 - val_tn: 79994.0000 - val_fn: 6.0000 - val_accuracy: 0.9999 - val_precision: 0.9997 - val_recall: 0.9997 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-27-28-batch-100000-200000
[INFO] processing batch 200000-300000/382775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0629 - tp: 77428.0000 - fp: 9.0000 - tn: 319991.0000 - fn: 2572.0000 - accuracy: 0.9935 - precision: 0.9999 - recall: 0.9679 - auc: 0.9998 - val_loss: 0.0229 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-27-28-batch-200000-300000
[INFO] processing batch 300000-400000/382775
[33m[INFO] loading file 29-29/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582775, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0557 - tp: 77491.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 2509.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9686 - auc: 0.9999 - val_loss: 0.0175 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-29-batch-0-100000
[INFO] processing batch 100000-200000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0500 - tp: 77877.0000 - fp: 168.0000 - tn: 319832.0000 - fn: 2123.0000 - accuracy: 0.9943 - precision: 0.9978 - recall: 0.9735 - auc: 0.9999 - val_loss: 0.0142 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-29-batch-100000-200000
[INFO] processing batch 200000-300000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0463 - tp: 78244.0000 - fp: 415.0000 - tn: 319585.0000 - fn: 1756.0000 - accuracy: 0.9946 - precision: 0.9947 - recall: 0.9780 - auc: 0.9999 - val_loss: 0.0114 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-29-batch-200000-300000
[INFO] processing batch 300000-400000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0424 - tp: 78878.0000 - fp: 724.0000 - tn: 319276.0000 - fn: 1122.0000 - accuracy: 0.9954 - precision: 0.9909 - recall: 0.9860 - auc: 0.9999 - val_loss: 0.0095 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-29-batch-300000-400000
[INFO] processing batch 400000-500000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0400 - tp: 79112.0000 - fp: 888.0000 - tn: 319112.0000 - fn: 888.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 0.0082 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-29-batch-400000-500000
[INFO] processing batch 500000-600000/582775
[33m[INFO] loading file 30-30/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582775, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0371 - tp: 79140.0000 - fp: 860.0000 - tn: 319140.0000 - fn: 860.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9999 - val_loss: 0.0072 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-001-files-29-30-batch-0-100000
[INFO] processing batch 100000-200000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0354 - tp: 79109.0000 - fp: 891.0000 - tn: 319109.0000 - fn: 891.0000 - accuracy: 0.9955 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 0.0055 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-29-30-batch-100000-200000
[INFO] processing batch 200000-300000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0336 - tp: 79109.0000 - fp: 891.0000 - tn: 319109.0000 - fn: 891.0000 - accuracy: 0.9955 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 0.0046 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-29-30-batch-200000-300000
[INFO] processing batch 300000-400000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0319 - tp: 79144.0000 - fp: 856.0000 - tn: 319144.0000 - fn: 856.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9999 - val_loss: 0.0039 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-29-30-batch-300000-400000
[INFO] processing batch 400000-500000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0303 - tp: 79128.0000 - fp: 872.0000 - tn: 319128.0000 - fn: 872.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 0.0049 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-001-files-29-30-batch-400000-500000
[INFO] processing batch 500000-600000/582775
[33m[INFO] loading file 31-31/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582775, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0318 - tp: 79040.0000 - fp: 957.0000 - tn: 319043.0000 - fn: 960.0000 - accuracy: 0.9952 - precision: 0.9880 - recall: 0.9880 - auc: 0.9999 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-31-batch-0-100000
[INFO] processing batch 100000-200000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0291 - tp: 79085.0000 - fp: 915.0000 - tn: 319085.0000 - fn: 915.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 0.0024 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-31-batch-100000-200000
[INFO] processing batch 200000-300000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0282 - tp: 79083.0000 - fp: 917.0000 - tn: 319083.0000 - fn: 917.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9999 - val_loss: 0.0021 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-31-batch-200000-300000
[INFO] processing batch 300000-400000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0261 - tp: 79165.0000 - fp: 835.0000 - tn: 319165.0000 - fn: 835.0000 - accuracy: 0.9958 - precision: 0.9896 - recall: 0.9896 - auc: 0.9999 - val_loss: 0.0018 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-31-batch-300000-400000
[INFO] processing batch 400000-500000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0266 - tp: 79082.0000 - fp: 918.0000 - tn: 319082.0000 - fn: 918.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9999 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-31-batch-400000-500000
[INFO] processing batch 500000-600000/582775
[33m[INFO] loading file 32-32/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582775, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0262 - tp: 79083.0000 - fp: 917.0000 - tn: 319083.0000 - fn: 917.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9999 - val_loss: 0.0013 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-31-32-batch-0-100000
[INFO] processing batch 100000-200000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0248 - tp: 79099.0000 - fp: 901.0000 - tn: 319099.0000 - fn: 901.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 0.0019 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-31-32-batch-100000-200000
[INFO] processing batch 200000-300000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0250 - tp: 79047.0000 - fp: 953.0000 - tn: 319047.0000 - fn: 953.0000 - accuracy: 0.9952 - precision: 0.9881 - recall: 0.9881 - auc: 0.9999 - val_loss: 0.0011 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-31-32-batch-200000-300000
[INFO] processing batch 300000-400000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0238 - tp: 79147.0000 - fp: 853.0000 - tn: 319147.0000 - fn: 853.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9999 - val_loss: 0.0062 - val_tp: 19988.0000 - val_fp: 12.0000 - val_tn: 79988.0000 - val_fn: 12.0000 - val_accuracy: 0.9998 - val_precision: 0.9994 - val_recall: 0.9994 - val_auc: 0.9996
[INFO] saving weights to checkpoints/lstm-epoch-001-files-31-32-batch-300000-400000
[INFO] processing batch 400000-500000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0238 - tp: 79122.0000 - fp: 878.0000 - tn: 319122.0000 - fn: 878.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 7.1732e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-31-32-batch-400000-500000
[INFO] processing batch 500000-600000/582775
[33m[INFO] loading file 33-33/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582775, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0231 - tp: 79129.0000 - fp: 871.0000 - tn: 319129.0000 - fn: 871.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 6.2310e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-33-batch-0-100000
[INFO] processing batch 100000-200000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0228 - tp: 79128.0000 - fp: 872.0000 - tn: 319128.0000 - fn: 872.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 0.0013 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-33-batch-100000-200000
[INFO] processing batch 200000-300000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0239 - tp: 79046.0000 - fp: 954.0000 - tn: 319046.0000 - fn: 954.0000 - accuracy: 0.9952 - precision: 0.9881 - recall: 0.9881 - auc: 0.9999 - val_loss: 4.6977e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-33-batch-200000-300000
[INFO] processing batch 300000-400000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0229 - tp: 79108.0000 - fp: 892.0000 - tn: 319108.0000 - fn: 892.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 0.0023 - val_tp: 19996.0000 - val_fp: 4.0000 - val_tn: 79996.0000 - val_fn: 4.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-33-batch-300000-400000
[INFO] processing batch 400000-500000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0227 - tp: 79102.0000 - fp: 898.0000 - tn: 319102.0000 - fn: 898.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 3.7054e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-33-batch-400000-500000
[INFO] processing batch 500000-600000/582775
[33m[INFO] loading file 34-34/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (424208, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/424208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0223 - tp: 79103.0000 - fp: 897.0000 - tn: 319103.0000 - fn: 897.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 3.3081e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-33-34-batch-0-100000
[INFO] processing batch 100000-200000/424208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0213 - tp: 79143.0000 - fp: 857.0000 - tn: 319143.0000 - fn: 857.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9999 - val_loss: 7.9707e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-33-34-batch-100000-200000
[INFO] processing batch 200000-300000/424208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0230 - tp: 79067.0000 - fp: 933.0000 - tn: 319067.0000 - fn: 933.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9999 - val_loss: 0.0013 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-001-files-33-34-batch-200000-300000
[INFO] processing batch 300000-400000/424208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0222 - tp: 79074.0000 - fp: 926.0000 - tn: 319074.0000 - fn: 926.0000 - accuracy: 0.9954 - precision: 0.9884 - recall: 0.9884 - auc: 0.9999 - val_loss: 2.3092e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-33-34-batch-300000-400000
[INFO] processing batch 400000-500000/424208
[33m[INFO] loading file 35-35/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524208, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0227 - tp: 79099.0000 - fp: 901.0000 - tn: 319099.0000 - fn: 901.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 2.2466e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-35-batch-0-100000
[INFO] processing batch 100000-200000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0224 - tp: 79081.0000 - fp: 919.0000 - tn: 319081.0000 - fn: 919.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9999 - val_loss: 0.0012 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-35-batch-100000-200000
[INFO] processing batch 200000-300000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0228 - tp: 79068.0000 - fp: 932.0000 - tn: 319068.0000 - fn: 932.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9999 - val_loss: 1.7420e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-35-batch-200000-300000
[INFO] processing batch 300000-400000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0217 - tp: 79087.0000 - fp: 913.0000 - tn: 319087.0000 - fn: 913.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 1.5339e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-35-batch-300000-400000
[INFO] processing batch 400000-500000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0217 - tp: 79084.0000 - fp: 916.0000 - tn: 319084.0000 - fn: 916.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 1.3487e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-35-batch-400000-500000
[INFO] processing batch 500000-600000/524208
[33m[INFO] loading file 36-36/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524208, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0212 - tp: 79116.0000 - fp: 884.0000 - tn: 319116.0000 - fn: 884.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 9.3051e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-35-36-batch-0-100000
[INFO] processing batch 100000-200000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0219 - tp: 79096.0000 - fp: 904.0000 - tn: 319096.0000 - fn: 904.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 9.1635e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-35-36-batch-100000-200000
[INFO] processing batch 200000-300000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0218 - tp: 79083.0000 - fp: 917.0000 - tn: 319083.0000 - fn: 917.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9999 - val_loss: 9.8241e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-35-36-batch-200000-300000
[INFO] processing batch 300000-400000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0215 - tp: 79104.0000 - fp: 896.0000 - tn: 319104.0000 - fn: 896.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 8.8819e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-35-36-batch-300000-400000
[INFO] processing batch 400000-500000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0216 - tp: 79074.0000 - fp: 926.0000 - tn: 319074.0000 - fn: 926.0000 - accuracy: 0.9954 - precision: 0.9884 - recall: 0.9884 - auc: 0.9999 - val_loss: 8.9223e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-35-36-batch-400000-500000
[INFO] processing batch 500000-600000/524208
[33m[INFO] loading file 37-37/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524208, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0215 - tp: 79073.0000 - fp: 927.0000 - tn: 319073.0000 - fn: 927.0000 - accuracy: 0.9954 - precision: 0.9884 - recall: 0.9884 - auc: 0.9999 - val_loss: 7.5887e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-37-batch-0-100000
[INFO] processing batch 100000-200000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0201 - tp: 79153.0000 - fp: 847.0000 - tn: 319153.0000 - fn: 847.0000 - accuracy: 0.9958 - precision: 0.9894 - recall: 0.9894 - auc: 0.9999 - val_loss: 6.2967e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-37-batch-100000-200000
[INFO] processing batch 200000-300000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0219 - tp: 79063.0000 - fp: 937.0000 - tn: 319063.0000 - fn: 937.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9999 - val_loss: 5.9164e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-37-batch-200000-300000
[INFO] processing batch 300000-400000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0222 - tp: 79040.0000 - fp: 960.0000 - tn: 319040.0000 - fn: 960.0000 - accuracy: 0.9952 - precision: 0.9880 - recall: 0.9880 - auc: 0.9999 - val_loss: 0.0015 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-37-batch-300000-400000
[INFO] processing batch 400000-500000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79160.0000 - fp: 840.0000 - tn: 319160.0000 - fn: 840.0000 - accuracy: 0.9958 - precision: 0.9895 - recall: 0.9895 - auc: 0.9999 - val_loss: 4.7636e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-37-batch-400000-500000
[INFO] processing batch 500000-600000/524208
[33m[INFO] loading file 38-38/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524208, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0216 - tp: 79097.0000 - fp: 903.0000 - tn: 319097.0000 - fn: 903.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 0.0012 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-001-files-37-38-batch-0-100000
[INFO] processing batch 100000-200000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0212 - tp: 79080.0000 - fp: 920.0000 - tn: 319080.0000 - fn: 920.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9999 - val_loss: 3.8399e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-37-38-batch-100000-200000
[INFO] processing batch 200000-300000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79124.0000 - fp: 876.0000 - tn: 319124.0000 - fn: 876.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 3.4201e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-37-38-batch-200000-300000
[INFO] processing batch 300000-400000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0213 - tp: 79115.0000 - fp: 885.0000 - tn: 319115.0000 - fn: 885.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 3.1007e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-37-38-batch-300000-400000
[INFO] processing batch 400000-500000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0215 - tp: 79093.0000 - fp: 907.0000 - tn: 319093.0000 - fn: 907.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 2.8220e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-37-38-batch-400000-500000
[INFO] processing batch 500000-600000/524208
[33m[INFO] loading file 39-39/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524208, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0214 - tp: 79107.0000 - fp: 893.0000 - tn: 319107.0000 - fn: 893.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 2.5789e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-39-batch-0-100000
[INFO] processing batch 100000-200000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79107.0000 - fp: 893.0000 - tn: 319107.0000 - fn: 893.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 2.3163e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-39-batch-100000-200000
[INFO] processing batch 200000-300000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0202 - tp: 79149.0000 - fp: 851.0000 - tn: 319149.0000 - fn: 851.0000 - accuracy: 0.9957 - precision: 0.9894 - recall: 0.9894 - auc: 0.9999 - val_loss: 2.0936e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-39-batch-200000-300000
[INFO] processing batch 300000-400000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0210 - tp: 79102.0000 - fp: 898.0000 - tn: 319102.0000 - fn: 898.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 1.8621e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-39-batch-300000-400000
[INFO] processing batch 400000-500000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79094.0000 - fp: 906.0000 - tn: 319094.0000 - fn: 906.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 1.6940e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-39-batch-400000-500000
[INFO] processing batch 500000-600000/524208
[33m[INFO] loading file 40-40/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524208, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79120.0000 - fp: 880.0000 - tn: 319120.0000 - fn: 880.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 1.9078e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-39-40-batch-0-100000
[INFO] processing batch 100000-200000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79120.0000 - fp: 880.0000 - tn: 319120.0000 - fn: 880.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 1.5528e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-39-40-batch-100000-200000
[INFO] processing batch 200000-300000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0213 - tp: 79087.0000 - fp: 913.0000 - tn: 319087.0000 - fn: 913.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 6.3116e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-39-40-batch-200000-300000
[INFO] processing batch 300000-400000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0224 - tp: 79113.0000 - fp: 887.0000 - tn: 319113.0000 - fn: 887.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9998 - val_loss: 1.4514e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-39-40-batch-300000-400000
[INFO] processing batch 400000-500000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0211 - tp: 79108.0000 - fp: 892.0000 - tn: 319108.0000 - fn: 892.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 1.2333e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-39-40-batch-400000-500000
[INFO] processing batch 500000-600000/524208
[33m[INFO] loading file 41-41/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (464366, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/464366
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0211 - tp: 79149.0000 - fp: 851.0000 - tn: 319149.0000 - fn: 851.0000 - accuracy: 0.9957 - precision: 0.9894 - recall: 0.9894 - auc: 0.9999 - val_loss: 1.1684e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-41-batch-0-100000
[INFO] processing batch 100000-200000/464366
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79133.0000 - fp: 867.0000 - tn: 319133.0000 - fn: 867.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 0.0021 - val_tp: 19997.0000 - val_fp: 3.0000 - val_tn: 79997.0000 - val_fn: 3.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-41-batch-100000-200000
[INFO] processing batch 200000-300000/464366
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0209 - tp: 79093.0000 - fp: 907.0000 - tn: 319093.0000 - fn: 907.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 1.3546e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-41-batch-200000-300000
[INFO] processing batch 300000-400000/464366
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0222 - tp: 79116.0000 - fp: 884.0000 - tn: 319116.0000 - fn: 884.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9998 - val_loss: 9.4436e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-41-batch-300000-400000
[INFO] processing batch 400000-500000/464366
[33m[INFO] loading file 42-42/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (407880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/407880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0216 - tp: 79105.0000 - fp: 895.0000 - tn: 319105.0000 - fn: 895.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 0.0018 - val_tp: 19997.0000 - val_fp: 3.0000 - val_tn: 79997.0000 - val_fn: 3.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-001-files-41-42-batch-0-100000
[INFO] processing batch 100000-200000/407880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0221 - tp: 79129.0000 - fp: 871.0000 - tn: 319129.0000 - fn: 871.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9998 - val_loss: 0.0017 - val_tp: 19997.0000 - val_fp: 3.0000 - val_tn: 79997.0000 - val_fn: 3.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-001-files-41-42-batch-100000-200000
[INFO] processing batch 200000-300000/407880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0209 - tp: 79095.0000 - fp: 905.0000 - tn: 319095.0000 - fn: 905.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 2.8073e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-41-42-batch-200000-300000
[INFO] processing batch 300000-400000/407880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0219 - tp: 79090.0000 - fp: 910.0000 - tn: 319090.0000 - fn: 910.0000 - accuracy: 0.9955 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 2.5229e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-41-42-batch-300000-400000
[INFO] processing batch 400000-500000/407880
[33m[INFO] loading file 43-43/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (507880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0293 - tp: 78983.0000 - fp: 1017.0000 - tn: 318983.0000 - fn: 1017.0000 - accuracy: 0.9949 - precision: 0.9873 - recall: 0.9873 - auc: 0.9994 - val_loss: 1.7838e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-43-batch-0-100000
[INFO] processing batch 100000-200000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0212 - tp: 79119.0000 - fp: 881.0000 - tn: 319119.0000 - fn: 881.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 8.2212e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-43-batch-100000-200000
[INFO] processing batch 200000-300000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0203 - tp: 79119.0000 - fp: 881.0000 - tn: 319119.0000 - fn: 881.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 1.4980e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-43-batch-200000-300000
[INFO] processing batch 300000-400000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0206 - tp: 79095.0000 - fp: 905.0000 - tn: 319095.0000 - fn: 905.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 1.2252e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-43-batch-300000-400000
[INFO] processing batch 400000-500000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0218 - tp: 79036.0000 - fp: 964.0000 - tn: 319036.0000 - fn: 964.0000 - accuracy: 0.9952 - precision: 0.9880 - recall: 0.9880 - auc: 0.9999 - val_loss: 1.0855e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-43-batch-400000-500000
[INFO] processing batch 500000-600000/507880
[33m[INFO] loading file 44-44/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (507880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0209 - tp: 79100.0000 - fp: 900.0000 - tn: 319100.0000 - fn: 900.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 0.0011 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-001-files-43-44-batch-0-100000
[INFO] processing batch 100000-200000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79124.0000 - fp: 876.0000 - tn: 319124.0000 - fn: 876.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 1.7398e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-43-44-batch-100000-200000
[INFO] processing batch 200000-300000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0209 - tp: 79101.0000 - fp: 899.0000 - tn: 319101.0000 - fn: 899.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 1.3711e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-43-44-batch-200000-300000
[INFO] processing batch 300000-400000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0213 - tp: 79070.0000 - fp: 930.0000 - tn: 319070.0000 - fn: 930.0000 - accuracy: 0.9953 - precision: 0.9884 - recall: 0.9884 - auc: 0.9999 - val_loss: 8.1614e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-43-44-batch-300000-400000
[INFO] processing batch 400000-500000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0213 - tp: 79096.0000 - fp: 904.0000 - tn: 319096.0000 - fn: 904.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 8.3052e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-43-44-batch-400000-500000
[INFO] processing batch 500000-600000/507880
[33m[INFO] loading file 45-45/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (507880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79116.0000 - fp: 884.0000 - tn: 319116.0000 - fn: 884.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 1.3854e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-45-batch-0-100000
[INFO] processing batch 100000-200000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0212 - tp: 79084.0000 - fp: 916.0000 - tn: 319084.0000 - fn: 916.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 1.0019e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-45-batch-100000-200000
[INFO] processing batch 200000-300000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79117.0000 - fp: 883.0000 - tn: 319117.0000 - fn: 883.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 5.3263e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-45-batch-200000-300000
[INFO] processing batch 300000-400000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0210 - tp: 79081.0000 - fp: 919.0000 - tn: 319081.0000 - fn: 919.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9999 - val_loss: 8.2462e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-45-batch-300000-400000
[INFO] processing batch 400000-500000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0213 - tp: 79092.0000 - fp: 908.0000 - tn: 319092.0000 - fn: 908.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 5.8248e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-45-batch-400000-500000
[INFO] processing batch 500000-600000/507880
[33m[INFO] loading file 46-46/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (507880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0213 - tp: 79098.0000 - fp: 902.0000 - tn: 319098.0000 - fn: 902.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 6.4285e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-45-46-batch-0-100000
[INFO] processing batch 100000-200000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0212 - tp: 79128.0000 - fp: 872.0000 - tn: 319128.0000 - fn: 872.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 8.1148e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-45-46-batch-100000-200000
[INFO] processing batch 200000-300000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79115.0000 - fp: 885.0000 - tn: 319115.0000 - fn: 885.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 4.6700e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-45-46-batch-200000-300000
[INFO] processing batch 300000-400000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0203 - tp: 79141.0000 - fp: 859.0000 - tn: 319141.0000 - fn: 859.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9999 - val_loss: 3.8367e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-45-46-batch-300000-400000
[INFO] processing batch 400000-500000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0201 - tp: 79128.0000 - fp: 872.0000 - tn: 319128.0000 - fn: 872.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 9.8514e-04 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-001-files-45-46-batch-400000-500000
[INFO] processing batch 500000-600000/507880
[33m[INFO] loading file 47-47/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (507880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79129.0000 - fp: 871.0000 - tn: 319129.0000 - fn: 871.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 5.9032e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-47-batch-0-100000
[INFO] processing batch 100000-200000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0195 - tp: 79181.0000 - fp: 819.0000 - tn: 319181.0000 - fn: 819.0000 - accuracy: 0.9959 - precision: 0.9898 - recall: 0.9898 - auc: 0.9999 - val_loss: 4.1406e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-47-batch-100000-200000
[INFO] processing batch 200000-300000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79102.0000 - fp: 898.0000 - tn: 319102.0000 - fn: 898.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 8.0937e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-47-batch-200000-300000
[INFO] processing batch 300000-400000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0213 - tp: 79083.0000 - fp: 917.0000 - tn: 319083.0000 - fn: 917.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9999 - val_loss: 2.8048e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-47-batch-300000-400000
[INFO] processing batch 400000-500000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0202 - tp: 79152.0000 - fp: 848.0000 - tn: 319152.0000 - fn: 848.0000 - accuracy: 0.9958 - precision: 0.9894 - recall: 0.9894 - auc: 0.9999 - val_loss: 6.6873e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-47-batch-400000-500000
[INFO] processing batch 500000-600000/507880
[33m[INFO] loading file 48-48/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (507880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0212 - tp: 79086.0000 - fp: 914.0000 - tn: 319086.0000 - fn: 914.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 2.1795e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-47-48-batch-0-100000
[INFO] processing batch 100000-200000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79111.0000 - fp: 889.0000 - tn: 319111.0000 - fn: 889.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 1.4959e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-47-48-batch-100000-200000
[INFO] processing batch 200000-300000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0214 - tp: 79077.0000 - fp: 923.0000 - tn: 319077.0000 - fn: 923.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9999 - val_loss: 1.4219e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-47-48-batch-200000-300000
[INFO] processing batch 300000-400000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0228 - tp: 79060.0000 - fp: 940.0000 - tn: 319060.0000 - fn: 940.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9998 - val_loss: 6.8902e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-47-48-batch-300000-400000
[INFO] processing batch 400000-500000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79125.0000 - fp: 875.0000 - tn: 319125.0000 - fn: 875.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 8.1344e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-47-48-batch-400000-500000
[INFO] processing batch 500000-600000/507880
[33m[INFO] loading file 49-49/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (507880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79109.0000 - fp: 891.0000 - tn: 319109.0000 - fn: 891.0000 - accuracy: 0.9955 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 1.3575e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-49-batch-0-100000
[INFO] processing batch 100000-200000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0211 - tp: 79121.0000 - fp: 879.0000 - tn: 319121.0000 - fn: 879.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 1.4225e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-49-batch-100000-200000
[INFO] processing batch 200000-300000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0201 - tp: 79125.0000 - fp: 875.0000 - tn: 319125.0000 - fn: 875.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 1.3796e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-49-batch-200000-300000
[INFO] processing batch 300000-400000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0210 - tp: 79132.0000 - fp: 868.0000 - tn: 319132.0000 - fn: 868.0000 - accuracy: 0.9957 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 0.0011 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-49-batch-300000-400000
[INFO] processing batch 400000-500000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0212 - tp: 79071.0000 - fp: 929.0000 - tn: 319071.0000 - fn: 929.0000 - accuracy: 0.9954 - precision: 0.9884 - recall: 0.9884 - auc: 0.9999 - val_loss: 6.0566e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-49-batch-400000-500000
[INFO] processing batch 500000-600000/507880
[33m[INFO] loading file 50-50/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (357862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/357862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79119.0000 - fp: 881.0000 - tn: 319119.0000 - fn: 881.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 5.6299e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-49-50-batch-0-100000
[INFO] processing batch 100000-200000/357862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0213 - tp: 79035.0000 - fp: 965.0000 - tn: 319035.0000 - fn: 965.0000 - accuracy: 0.9952 - precision: 0.9879 - recall: 0.9879 - auc: 0.9999 - val_loss: 8.1090e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-49-50-batch-100000-200000
[INFO] processing batch 200000-300000/357862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0200 - tp: 79147.0000 - fp: 853.0000 - tn: 319147.0000 - fn: 853.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9999 - val_loss: 0.0011 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-001-files-49-50-batch-200000-300000
[INFO] processing batch 300000-400000/357862
[33m[LOSS] 0.0010968048764334526[0m
[33m[INFO] epoch 2/10[0m
[33m[INFO] loading file 1-1/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0600 - tp: 78883.0000 - fp: 1117.0000 - tn: 318883.0000 - fn: 1117.0000 - accuracy: 0.9944 - precision: 0.9860 - recall: 0.9860 - auc: 0.9976 - val_loss: 0.0044 - val_tp: 19992.0000 - val_fp: 8.0000 - val_tn: 79992.0000 - val_fn: 8.0000 - val_accuracy: 0.9998 - val_precision: 0.9996 - val_recall: 0.9996 - val_auc: 0.9997
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-1-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0037 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 19997.0000 - val_fp: 3.0000 - val_tn: 79997.0000 - val_fn: 3.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-1-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0012 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.2561e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-1-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.7701 - tp: 59118.0000 - fp: 20882.0000 - tn: 299118.0000 - fn: 20882.0000 - accuracy: 0.8956 - precision: 0.7390 - recall: 0.7390 - auc: 0.8486 - val_loss: 7.5591 - val_tp: 10620.0000 - val_fp: 9380.0000 - val_tn: 70620.0000 - val_fn: 9380.0000 - val_accuracy: 0.8124 - val_precision: 0.5310 - val_recall: 0.5310 - val_auc: 0.7069
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-1-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.7516 - tp: 42852.0000 - fp: 37148.0000 - tn: 282852.0000 - fn: 37148.0000 - accuracy: 0.8143 - precision: 0.5357 - recall: 0.5357 - auc: 0.7282 - val_loss: 7.5687 - val_tp: 10608.0000 - val_fp: 9392.0000 - val_tn: 70608.0000 - val_fn: 9392.0000 - val_accuracy: 0.8122 - val_precision: 0.5304 - val_recall: 0.5304 - val_auc: 0.7065
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-1-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 2-2/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.8111 - tp: 42293.0000 - fp: 37707.0000 - tn: 282293.0000 - fn: 37707.0000 - accuracy: 0.8115 - precision: 0.5287 - recall: 0.5287 - auc: 0.7230 - val_loss: 7.5683 - val_tp: 10609.0000 - val_fp: 9391.0000 - val_tn: 70609.0000 - val_fn: 9391.0000 - val_accuracy: 0.8122 - val_precision: 0.5304 - val_recall: 0.5304 - val_auc: 0.7065
[INFO] saving weights to checkpoints/lstm-epoch-002-files-1-2-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.6602 - tp: 43467.0000 - fp: 36533.0000 - tn: 283467.0000 - fn: 36533.0000 - accuracy: 0.8173 - precision: 0.5433 - recall: 0.5433 - auc: 0.7307 - val_loss: 1.6135 - val_tp: 17839.0000 - val_fp: 2161.0000 - val_tn: 77839.0000 - val_fn: 2161.0000 - val_accuracy: 0.9568 - val_precision: 0.8920 - val_recall: 0.8920 - val_auc: 0.9325
[INFO] saving weights to checkpoints/lstm-epoch-002-files-1-2-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0328 - tp: 79514.0000 - fp: 486.0000 - tn: 319514.0000 - fn: 486.0000 - accuracy: 0.9976 - precision: 0.9939 - recall: 0.9939 - auc: 0.9984 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-1-2-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.8373 - tp: 52777.0000 - fp: 27223.0000 - tn: 292777.0000 - fn: 27223.0000 - accuracy: 0.8639 - precision: 0.6597 - recall: 0.6597 - auc: 0.8043 - val_loss: 6.7895 - val_tp: 11545.0000 - val_fp: 8455.0000 - val_tn: 71545.0000 - val_fn: 8455.0000 - val_accuracy: 0.8309 - val_precision: 0.5773 - val_recall: 0.5773 - val_auc: 0.7359
[INFO] saving weights to checkpoints/lstm-epoch-002-files-1-2-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.1138 - tp: 65384.0000 - fp: 14616.0000 - tn: 305384.0000 - fn: 14616.0000 - accuracy: 0.9269 - precision: 0.8173 - recall: 0.8173 - auc: 0.9079 - val_loss: 2.0503 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 72847.0000 - val_fn: 7153.0000 - val_accuracy: 0.8569 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.8585
[INFO] saving weights to checkpoints/lstm-epoch-002-files-1-2-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 3-3/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.2855 - tp: 73532.0000 - fp: 6468.0000 - tn: 313532.0000 - fn: 6468.0000 - accuracy: 0.9677 - precision: 0.9191 - recall: 0.9191 - auc: 0.9862 - val_loss: 0.2869 - val_tp: 16680.0000 - val_fp: 3320.0000 - val_tn: 76680.0000 - val_fn: 3320.0000 - val_accuracy: 0.9336 - val_precision: 0.8340 - val_recall: 0.8340 - val_auc: 0.9839
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-3-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0660 - tp: 77200.0000 - fp: 2800.0000 - tn: 317200.0000 - fn: 2800.0000 - accuracy: 0.9860 - precision: 0.9650 - recall: 0.9650 - auc: 0.9992 - val_loss: 0.0022 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-3-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.5562 - tp: 74996.0000 - fp: 5004.0000 - tn: 314996.0000 - fn: 5004.0000 - accuracy: 0.9750 - precision: 0.9374 - recall: 0.9374 - auc: 0.9715 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-3-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0077 - tp: 79963.0000 - fp: 37.0000 - tn: 319963.0000 - fn: 37.0000 - accuracy: 0.9998 - precision: 0.9995 - recall: 0.9995 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-3-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0032 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-3-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 4-4/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-3-4-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0015 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0012 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-002-files-3-4-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-3-4-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 9.0297e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-3-4-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.1430 - tp: 45868.0000 - fp: 34132.0000 - tn: 285868.0000 - fn: 34132.0000 - accuracy: 0.8293 - precision: 0.5734 - recall: 0.5734 - auc: 0.7529 - val_loss: 7.7759 - val_tp: 10350.0000 - val_fp: 9650.0000 - val_tn: 70350.0000 - val_fn: 9650.0000 - val_accuracy: 0.8070 - val_precision: 0.5175 - val_recall: 0.5175 - val_auc: 0.6984
[INFO] saving weights to checkpoints/lstm-epoch-002-files-3-4-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 5-5/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79997.0000 - fp: 3.0000 - tn: 319997.0000 - fn: 3.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.1675 - val_tp: 16068.0000 - val_fp: 3932.0000 - val_tn: 76068.0000 - val_fn: 3932.0000 - val_accuracy: 0.9214 - val_precision: 0.8034 - val_recall: 0.8034 - val_auc: 0.8772
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-5-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.1330 - tp: 51292.0000 - fp: 28708.0000 - tn: 291292.0000 - fn: 28708.0000 - accuracy: 0.8565 - precision: 0.6411 - recall: 0.6411 - auc: 0.7933 - val_loss: 5.7624 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.7766
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-5-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.9934 - tp: 63437.0000 - fp: 16563.0000 - tn: 303437.0000 - fn: 16563.0000 - accuracy: 0.9172 - precision: 0.7930 - recall: 0.7930 - auc: 0.8800 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-5-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0114 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.6330e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-5-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0035 - tp: 79997.0000 - fp: 3.0000 - tn: 319997.0000 - fn: 3.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-5-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 6-6/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0019 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-5-6-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0012 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-5-6-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 8.6984e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-5-6-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.7511e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-5-6-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.2445 - tp: 67626.0000 - fp: 12374.0000 - tn: 307626.0000 - fn: 12374.0000 - accuracy: 0.9381 - precision: 0.8453 - recall: 0.8453 - auc: 0.9105 - val_loss: 5.8122 - val_tp: 12788.0000 - val_fp: 7212.0000 - val_tn: 72788.0000 - val_fn: 7212.0000 - val_accuracy: 0.8558 - val_precision: 0.6394 - val_recall: 0.6394 - val_auc: 0.7746
[INFO] saving weights to checkpoints/lstm-epoch-002-files-5-6-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 7-7/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4818 - tp: 76422.0000 - fp: 3578.0000 - tn: 316422.0000 - fn: 3578.0000 - accuracy: 0.9821 - precision: 0.9553 - recall: 0.9553 - auc: 0.9816 - val_loss: 2.9855e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-7-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0313 - tp: 79046.0000 - fp: 954.0000 - tn: 319046.0000 - fn: 954.0000 - accuracy: 0.9952 - precision: 0.9881 - recall: 0.9881 - auc: 0.9998 - val_loss: 1.9128e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-7-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0283 - tp: 79077.0000 - fp: 923.0000 - tn: 319077.0000 - fn: 923.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9998 - val_loss: 0.1784 - val_tp: 19583.0000 - val_fp: 417.0000 - val_tn: 79583.0000 - val_fn: 417.0000 - val_accuracy: 0.9917 - val_precision: 0.9791 - val_recall: 0.9791 - val_auc: 0.9870
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-7-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1897 - tp: 77782.0000 - fp: 2218.0000 - tn: 317782.0000 - fn: 2218.0000 - accuracy: 0.9889 - precision: 0.9723 - recall: 0.9723 - auc: 0.9858 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-7-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0019 - tp: 79997.0000 - fp: 3.0000 - tn: 319997.0000 - fn: 3.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.5126e-05 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-7-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 8-8/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0135 - tp: 79707.0000 - fp: 293.0000 - tn: 319707.0000 - fn: 293.0000 - accuracy: 0.9985 - precision: 0.9963 - recall: 0.9963 - auc: 0.9996 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-7-8-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.9663e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-7-8-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.3368e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-7-8-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.5971e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-7-8-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.6183 - tp: 65550.0000 - fp: 14450.0000 - tn: 305550.0000 - fn: 14450.0000 - accuracy: 0.9278 - precision: 0.8194 - recall: 0.8194 - auc: 0.8950 - val_loss: 2.9351 - val_tp: 16358.0000 - val_fp: 3642.0000 - val_tn: 76358.0000 - val_fn: 3642.0000 - val_accuracy: 0.9272 - val_precision: 0.8179 - val_recall: 0.8179 - val_auc: 0.8862
[INFO] saving weights to checkpoints/lstm-epoch-002-files-7-8-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 9-9/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.6064 - tp: 65442.0000 - fp: 14558.0000 - tn: 305442.0000 - fn: 14558.0000 - accuracy: 0.9272 - precision: 0.8180 - recall: 0.8180 - auc: 0.8955 - val_loss: 2.9432 - val_tp: 16348.0000 - val_fp: 3652.0000 - val_tn: 76348.0000 - val_fn: 3652.0000 - val_accuracy: 0.9270 - val_precision: 0.8174 - val_recall: 0.8174 - val_auc: 0.8859
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-9-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.1297 - tp: 68238.0000 - fp: 11762.0000 - tn: 308238.0000 - fn: 11762.0000 - accuracy: 0.9412 - precision: 0.8530 - recall: 0.8530 - auc: 0.9149 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-9-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0062 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-9-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0016 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-9-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 9.0005e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-9-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 10-10/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 8.8093e-04 - tp: 79997.0000 - fp: 3.0000 - tn: 319997.0000 - fn: 3.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-9-10-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.2610e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-9-10-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.7567 - tp: 64800.0000 - fp: 15200.0000 - tn: 304800.0000 - fn: 15200.0000 - accuracy: 0.9240 - precision: 0.8100 - recall: 0.8100 - auc: 0.8896 - val_loss: 5.7617 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.7766
[INFO] saving weights to checkpoints/lstm-epoch-002-files-9-10-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.4873 - tp: 71800.0000 - fp: 8200.0000 - tn: 311800.0000 - fn: 8200.0000 - accuracy: 0.9590 - precision: 0.8975 - recall: 0.8975 - auc: 0.9407 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-9-10-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-9-10-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 11-11/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0013 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-11-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 8.0472e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-11-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.9429e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-11-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.5937e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-11-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.7068e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-11-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 12-12/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.1098e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-11-12-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.9064e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-11-12-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.0418 - tp: 68763.0000 - fp: 11237.0000 - tn: 308763.0000 - fn: 11237.0000 - accuracy: 0.9438 - precision: 0.8595 - recall: 0.8595 - auc: 0.9181 - val_loss: 5.7848 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 72822.0000 - val_fn: 7178.0000 - val_accuracy: 0.8564 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.7757
[INFO] saving weights to checkpoints/lstm-epoch-002-files-11-12-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.1983 - tp: 62224.0000 - fp: 17776.0000 - tn: 302224.0000 - fn: 17776.0000 - accuracy: 0.9111 - precision: 0.7778 - recall: 0.7778 - auc: 0.8716 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-11-12-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0067 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-11-12-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 13-13/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0013 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-13-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.0387e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.6679e-04 - val_tp: 19997.0000 - val_fp: 3.0000 - val_tn: 79997.0000 - val_fn: 3.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-13-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.5083e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-13-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.3240 - tp: 67145.0000 - fp: 12855.0000 - tn: 307145.0000 - fn: 12855.0000 - accuracy: 0.9357 - precision: 0.8393 - recall: 0.8393 - auc: 0.9069 - val_loss: 5.7759 - val_tp: 12833.0000 - val_fp: 7167.0000 - val_tn: 72833.0000 - val_fn: 7167.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.7760
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-13-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.1336 - tp: 51342.0000 - fp: 28658.0000 - tn: 291342.0000 - fn: 28658.0000 - accuracy: 0.8567 - precision: 0.6418 - recall: 0.6418 - auc: 0.7929 - val_loss: 5.7864 - val_tp: 12820.0000 - val_fp: 7180.0000 - val_tn: 72820.0000 - val_fn: 7180.0000 - val_accuracy: 0.8564 - val_precision: 0.6410 - val_recall: 0.6410 - val_auc: 0.7756
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-13-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 14-14/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.3707 - tp: 76904.0000 - fp: 3096.0000 - tn: 316904.0000 - fn: 3096.0000 - accuracy: 0.9845 - precision: 0.9613 - recall: 0.9613 - auc: 0.9863 - val_loss: 0.0012 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-13-14-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4219 - tp: 72714.0000 - fp: 7286.0000 - tn: 312714.0000 - fn: 7286.0000 - accuracy: 0.9636 - precision: 0.9089 - recall: 0.9089 - auc: 0.9750 - val_loss: 0.0119 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-13-14-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0038 - tp: 79959.0000 - fp: 41.0000 - tn: 319959.0000 - fn: 41.0000 - accuracy: 0.9998 - precision: 0.9995 - recall: 0.9995 - auc: 1.0000 - val_loss: 1.9883e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-13-14-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.1460e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.1982e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-13-14-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.5920e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.5851e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-13-14-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 15-15/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 8.1275e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.0843e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-15-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.9535e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.6358e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-15-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.7066e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.8138e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-15-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.3782e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.3016e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-15-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.7847 - tp: 61216.0000 - fp: 18784.0000 - tn: 301216.0000 - fn: 18784.0000 - accuracy: 0.9061 - precision: 0.7652 - recall: 0.7652 - auc: 0.8532 - val_loss: 7.5199 - val_tp: 10669.0000 - val_fp: 9331.0000 - val_tn: 70669.0000 - val_fn: 9331.0000 - val_accuracy: 0.8134 - val_precision: 0.5335 - val_recall: 0.5335 - val_auc: 0.7084
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-15-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 16-16/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (497552, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/497552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.5638 - tp: 42459.0000 - fp: 37541.0000 - tn: 282459.0000 - fn: 37541.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5307 - auc: 0.7063 - val_loss: 7.5368 - val_tp: 10648.0000 - val_fp: 9352.0000 - val_tn: 70648.0000 - val_fn: 9352.0000 - val_accuracy: 0.8130 - val_precision: 0.5324 - val_recall: 0.5324 - val_auc: 0.7078
[INFO] saving weights to checkpoints/lstm-epoch-002-files-15-16-batch-0-100000
[INFO] processing batch 100000-200000/497552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.5474 - tp: 42540.0000 - fp: 37460.0000 - tn: 282540.0000 - fn: 37460.0000 - accuracy: 0.8127 - precision: 0.5318 - recall: 0.5318 - auc: 0.7073 - val_loss: 7.5803 - val_tp: 10594.0000 - val_fp: 9406.0000 - val_tn: 70594.0000 - val_fn: 9406.0000 - val_accuracy: 0.8119 - val_precision: 0.5297 - val_recall: 0.5297 - val_auc: 0.7061
[INFO] saving weights to checkpoints/lstm-epoch-002-files-15-16-batch-100000-200000
[INFO] processing batch 200000-300000/497552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.3751 - tp: 78139.0000 - fp: 1861.0000 - tn: 318139.0000 - fn: 1861.0000 - accuracy: 0.9907 - precision: 0.9767 - recall: 0.9767 - auc: 0.9855 - val_loss: 1.8708e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-15-16-batch-200000-300000
[INFO] processing batch 300000-400000/497552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.4571e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6290e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-15-16-batch-300000-400000
[INFO] processing batch 400000-500000/497552
[33m[INFO] loading file 17-17/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (597552, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.6450e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.2498e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-17-batch-0-100000
[INFO] processing batch 100000-200000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.1157e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1987e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-17-batch-100000-200000
[INFO] processing batch 200000-300000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 9.8631e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1970e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-17-batch-200000-300000
[INFO] processing batch 300000-400000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1641 - tp: 79186.0000 - fp: 814.0000 - tn: 319186.0000 - fn: 814.0000 - accuracy: 0.9959 - precision: 0.9898 - recall: 0.9898 - auc: 0.9936 - val_loss: 2.9778 - val_tp: 16305.0000 - val_fp: 3695.0000 - val_tn: 76305.0000 - val_fn: 3695.0000 - val_accuracy: 0.9261 - val_precision: 0.8152 - val_recall: 0.8152 - val_auc: 0.8845
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-17-batch-300000-400000
[INFO] processing batch 400000-500000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.9237 - tp: 65489.0000 - fp: 14511.0000 - tn: 305489.0000 - fn: 14511.0000 - accuracy: 0.9274 - precision: 0.8186 - recall: 0.8186 - auc: 0.8866 - val_loss: 2.8988 - val_tp: 16403.0000 - val_fp: 3597.0000 - val_tn: 76403.0000 - val_fn: 3597.0000 - val_accuracy: 0.9281 - val_precision: 0.8202 - val_recall: 0.8202 - val_auc: 0.8876
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-17-batch-400000-500000
[INFO] processing batch 500000-600000/597552
[33m[INFO] loading file 18-18/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (597552, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.6588 - tp: 71767.0000 - fp: 8233.0000 - tn: 311767.0000 - fn: 8233.0000 - accuracy: 0.9588 - precision: 0.8971 - recall: 0.8971 - auc: 0.9357 - val_loss: 1.4838e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-17-18-batch-0-100000
[INFO] processing batch 100000-200000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.8111 - tp: 56121.0000 - fp: 23879.0000 - tn: 296121.0000 - fn: 23879.0000 - accuracy: 0.8806 - precision: 0.7015 - recall: 0.7015 - auc: 0.8134 - val_loss: 6.1080 - val_tp: 12421.0000 - val_fp: 7579.0000 - val_tn: 72421.0000 - val_fn: 7579.0000 - val_accuracy: 0.8484 - val_precision: 0.6211 - val_recall: 0.6211 - val_auc: 0.7632
[INFO] saving weights to checkpoints/lstm-epoch-002-files-17-18-batch-100000-200000
[INFO] processing batch 200000-300000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.1384 - tp: 49533.0000 - fp: 30467.0000 - tn: 289533.0000 - fn: 30467.0000 - accuracy: 0.8477 - precision: 0.6192 - recall: 0.6192 - auc: 0.7620 - val_loss: 6.1329 - val_tp: 12390.0000 - val_fp: 7610.0000 - val_tn: 72390.0000 - val_fn: 7610.0000 - val_accuracy: 0.8478 - val_precision: 0.6195 - val_recall: 0.6195 - val_auc: 0.7622
[INFO] saving weights to checkpoints/lstm-epoch-002-files-17-18-batch-200000-300000
[INFO] processing batch 300000-400000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.5332 - tp: 52537.0000 - fp: 27463.0000 - tn: 292537.0000 - fn: 27463.0000 - accuracy: 0.8627 - precision: 0.6567 - recall: 0.6567 - auc: 0.7854 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-17-18-batch-300000-400000
[INFO] processing batch 400000-500000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.8355e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-17-18-batch-400000-500000
[INFO] processing batch 500000-600000/597552
[33m[INFO] loading file 19-19/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (597552, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.0523e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1992e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-19-batch-0-100000
[INFO] processing batch 100000-200000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.6598e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-19-batch-100000-200000
[INFO] processing batch 200000-300000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.1839e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-19-batch-200000-300000
[INFO] processing batch 300000-400000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.7440e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-19-batch-300000-400000
[INFO] processing batch 400000-500000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.3221 - tp: 43658.0000 - fp: 36342.0000 - tn: 283658.0000 - fn: 36342.0000 - accuracy: 0.8183 - precision: 0.5457 - recall: 0.5457 - auc: 0.7161 - val_loss: 9.8232 - val_tp: 7811.0000 - val_fp: 12189.0000 - val_tn: 67811.0000 - val_fn: 12189.0000 - val_accuracy: 0.7562 - val_precision: 0.3905 - val_recall: 0.3905 - val_auc: 0.6191
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-19-batch-400000-500000
[INFO] processing batch 500000-600000/597552
[33m[INFO] loading file 20-20/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (597552, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.6398 - tp: 56971.0000 - fp: 23029.0000 - tn: 296971.0000 - fn: 23029.0000 - accuracy: 0.8849 - precision: 0.7121 - recall: 0.7121 - auc: 0.8201 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-19-20-batch-0-100000
[INFO] processing batch 100000-200000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.9079 - tp: 75494.0000 - fp: 4506.0000 - tn: 315494.0000 - fn: 4506.0000 - accuracy: 0.9775 - precision: 0.9437 - recall: 0.9437 - auc: 0.9648 - val_loss: 2.9681 - val_tp: 16317.0000 - val_fp: 3683.0000 - val_tn: 76317.0000 - val_fn: 3683.0000 - val_accuracy: 0.9263 - val_precision: 0.8159 - val_recall: 0.8159 - val_auc: 0.8849
[INFO] saving weights to checkpoints/lstm-epoch-002-files-19-20-batch-100000-200000
[INFO] processing batch 200000-300000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.9408 - tp: 65404.0000 - fp: 14596.0000 - tn: 305404.0000 - fn: 14596.0000 - accuracy: 0.9270 - precision: 0.8176 - recall: 0.8176 - auc: 0.8860 - val_loss: 2.9690 - val_tp: 16316.0000 - val_fp: 3684.0000 - val_tn: 76316.0000 - val_fn: 3684.0000 - val_accuracy: 0.9263 - val_precision: 0.8158 - val_recall: 0.8158 - val_auc: 0.8849
[INFO] saving weights to checkpoints/lstm-epoch-002-files-19-20-batch-200000-300000
[INFO] processing batch 300000-400000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.9234 - tp: 65490.0000 - fp: 14510.0000 - tn: 305490.0000 - fn: 14510.0000 - accuracy: 0.9275 - precision: 0.8186 - recall: 0.8186 - auc: 0.8866 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-19-20-batch-300000-400000
[INFO] processing batch 400000-500000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.3742e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-19-20-batch-400000-500000
[INFO] processing batch 500000-600000/597552
[33m[INFO] loading file 21-21/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (597550, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/597550
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.3387e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-21-batch-0-100000
[INFO] processing batch 100000-200000/597550
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.0075e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-21-batch-100000-200000
[INFO] processing batch 200000-300000/597550
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 8.7616e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-21-batch-200000-300000
[INFO] processing batch 300000-400000/597550
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.6397e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-21-batch-300000-400000
[INFO] processing batch 400000-500000/597550
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.2370e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-21-batch-400000-500000
[INFO] processing batch 500000-600000/597550
[33m[INFO] loading file 22-22/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (366591, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/366591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.0734e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.8380 - val_tp: 12756.0000 - val_fp: 7244.0000 - val_tn: 72756.0000 - val_fn: 7244.0000 - val_accuracy: 0.8551 - val_precision: 0.6378 - val_recall: 0.6378 - val_auc: 0.7736
[INFO] saving weights to checkpoints/lstm-epoch-002-files-21-22-batch-0-100000
[INFO] processing batch 100000-200000/366591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.5675 - tp: 42440.0000 - fp: 37560.0000 - tn: 282440.0000 - fn: 37560.0000 - accuracy: 0.8122 - precision: 0.5305 - recall: 0.5305 - auc: 0.7066 - val_loss: 7.5763 - val_tp: 10599.0000 - val_fp: 9401.0000 - val_tn: 70599.0000 - val_fn: 9401.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.7062
[INFO] saving weights to checkpoints/lstm-epoch-002-files-21-22-batch-100000-200000
[INFO] processing batch 200000-300000/366591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.5916 - tp: 42320.0000 - fp: 37680.0000 - tn: 282320.0000 - fn: 37680.0000 - accuracy: 0.8116 - precision: 0.5290 - recall: 0.5290 - auc: 0.7056 - val_loss: 7.5763 - val_tp: 10599.0000 - val_fp: 9401.0000 - val_tn: 70599.0000 - val_fn: 9401.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.7062
[INFO] saving weights to checkpoints/lstm-epoch-002-files-21-22-batch-200000-300000
[INFO] processing batch 300000-400000/366591
[33m[INFO] loading file 23-23/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (566591, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.5685 - tp: 42435.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37565.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5304 - auc: 0.7065 - val_loss: 2.2050 - val_tp: 17264.0000 - val_fp: 2736.0000 - val_tn: 77264.0000 - val_fn: 2736.0000 - val_accuracy: 0.9453 - val_precision: 0.8632 - val_recall: 0.8632 - val_auc: 0.9145
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-23-batch-0-100000
[INFO] processing batch 100000-200000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.0322e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-23-batch-100000-200000
[INFO] processing batch 200000-300000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.4294e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-23-batch-200000-300000
[INFO] processing batch 300000-400000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.9430e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-23-batch-300000-400000
[INFO] processing batch 400000-500000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.5047e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-23-batch-400000-500000
[INFO] processing batch 500000-600000/566591
[33m[INFO] loading file 24-24/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (566591, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.2611e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-23-24-batch-0-100000
[INFO] processing batch 100000-200000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.9357e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-23-24-batch-100000-200000
[INFO] processing batch 200000-300000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.7224e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-23-24-batch-200000-300000
[INFO] processing batch 300000-400000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.4592e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-23-24-batch-300000-400000
[INFO] processing batch 400000-500000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.3045e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.4716 - val_tp: 18174.0000 - val_fp: 1826.0000 - val_tn: 78174.0000 - val_fn: 1826.0000 - val_accuracy: 0.9635 - val_precision: 0.9087 - val_recall: 0.9087 - val_auc: 0.9429
[INFO] saving weights to checkpoints/lstm-epoch-002-files-23-24-batch-400000-500000
[INFO] processing batch 500000-600000/566591
[33m[INFO] loading file 25-25/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (566591, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7330 - tp: 51545.0000 - fp: 28455.0000 - tn: 291545.0000 - fn: 28455.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.7777 - val_loss: 5.7429 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.7773
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-25-batch-0-100000
[INFO] processing batch 100000-200000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7552 - tp: 51435.0000 - fp: 28565.0000 - tn: 291435.0000 - fn: 28565.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.7768 - val_loss: 5.7566 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.7768
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-25-batch-100000-200000
[INFO] processing batch 200000-300000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7463 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.7772 - val_loss: 5.7276 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 72893.0000 - val_fn: 7107.0000 - val_accuracy: 0.8579 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.7779
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-25-batch-200000-300000
[INFO] processing batch 300000-400000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7497 - tp: 51462.0000 - fp: 28538.0000 - tn: 291462.0000 - fn: 28538.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.7770 - val_loss: 5.7324 - val_tp: 12887.0000 - val_fp: 7113.0000 - val_tn: 72887.0000 - val_fn: 7113.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.7777
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-25-batch-300000-400000
[INFO] processing batch 400000-500000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7594 - tp: 51414.0000 - fp: 28586.0000 - tn: 291414.0000 - fn: 28586.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.7767 - val_loss: 5.7195 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.7782
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-25-batch-400000-500000
[INFO] processing batch 500000-600000/566591
[33m[INFO] loading file 26-26/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (566591, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7425 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.7773 - val_loss: 5.7550 - val_tp: 12859.0000 - val_fp: 7141.0000 - val_tn: 72859.0000 - val_fn: 7141.0000 - val_accuracy: 0.8572 - val_precision: 0.6429 - val_recall: 0.6429 - val_auc: 0.7768
[INFO] saving weights to checkpoints/lstm-epoch-002-files-25-26-batch-0-100000
[INFO] processing batch 100000-200000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.2566 - tp: 66688.0000 - fp: 13312.0000 - tn: 306688.0000 - fn: 13312.0000 - accuracy: 0.9334 - precision: 0.8336 - recall: 0.8336 - auc: 0.9011 - val_loss: 0.0031 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-25-26-batch-100000-200000
[INFO] processing batch 200000-300000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0490 - tp: 79124.0000 - fp: 876.0000 - tn: 319124.0000 - fn: 876.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9994 - val_loss: 7.6930e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-25-26-batch-200000-300000
[INFO] processing batch 300000-400000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0368 - tp: 79074.0000 - fp: 926.0000 - tn: 319074.0000 - fn: 926.0000 - accuracy: 0.9954 - precision: 0.9884 - recall: 0.9884 - auc: 0.9998 - val_loss: 4.9624e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-25-26-batch-300000-400000
[INFO] processing batch 400000-500000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0324 - tp: 79147.0000 - fp: 853.0000 - tn: 319147.0000 - fn: 853.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9998 - val_loss: 4.2527e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-25-26-batch-400000-500000
[INFO] processing batch 500000-600000/566591
[33m[INFO] loading file 27-27/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (506721, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/506721
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0325 - tp: 79103.0000 - fp: 897.0000 - tn: 319103.0000 - fn: 897.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 4.5012e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-27-batch-0-100000
[INFO] processing batch 100000-200000/506721
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0308 - tp: 79105.0000 - fp: 895.0000 - tn: 319105.0000 - fn: 895.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 6.4487e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-27-batch-100000-200000
[INFO] processing batch 200000-300000/506721
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0297 - tp: 79135.0000 - fp: 865.0000 - tn: 319135.0000 - fn: 865.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 2.1154e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-27-batch-200000-300000
[INFO] processing batch 300000-400000/506721
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0300 - tp: 79086.0000 - fp: 914.0000 - tn: 319086.0000 - fn: 914.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 1.8624e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-27-batch-300000-400000
[INFO] processing batch 400000-500000/506721
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0296 - tp: 79067.0000 - fp: 933.0000 - tn: 319067.0000 - fn: 933.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9999 - val_loss: 5.2054e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-27-batch-400000-500000
[INFO] processing batch 500000-600000/506721
[33m[INFO] loading file 28-28/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (340637, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/340637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0379 - tp: 78982.0000 - fp: 1018.0000 - tn: 318982.0000 - fn: 1018.0000 - accuracy: 0.9949 - precision: 0.9873 - recall: 0.9873 - auc: 0.9992 - val_loss: 4.5942e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-27-28-batch-0-100000
[INFO] processing batch 100000-200000/340637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0280 - tp: 79125.0000 - fp: 875.0000 - tn: 319125.0000 - fn: 875.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 2.0159e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-27-28-batch-100000-200000
[INFO] processing batch 200000-300000/340637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0279 - tp: 79100.0000 - fp: 900.0000 - tn: 319100.0000 - fn: 900.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 1.2534e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-27-28-batch-200000-300000
[INFO] processing batch 300000-400000/340637
[33m[INFO] loading file 29-29/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (540637, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0273 - tp: 79116.0000 - fp: 884.0000 - tn: 319116.0000 - fn: 884.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 1.0050e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-29-batch-0-100000
[INFO] processing batch 100000-200000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0279 - tp: 79066.0000 - fp: 934.0000 - tn: 319066.0000 - fn: 934.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9999 - val_loss: 8.9465e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-29-batch-100000-200000
[INFO] processing batch 200000-300000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0261 - tp: 79135.0000 - fp: 865.0000 - tn: 319135.0000 - fn: 865.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 8.3761e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-29-batch-200000-300000
[INFO] processing batch 300000-400000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0260 - tp: 79107.0000 - fp: 893.0000 - tn: 319107.0000 - fn: 893.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 6.2069e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-29-batch-300000-400000
[INFO] processing batch 400000-500000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0252 - tp: 79079.0000 - fp: 921.0000 - tn: 319079.0000 - fn: 921.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9999 - val_loss: 2.0260e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-29-batch-400000-500000
[INFO] processing batch 500000-600000/540637
[33m[INFO] loading file 30-30/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (540637, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0215 - tp: 79115.0000 - fp: 885.0000 - tn: 319115.0000 - fn: 885.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 5.1388e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-29-30-batch-0-100000
[INFO] processing batch 100000-200000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79121.0000 - fp: 879.0000 - tn: 319121.0000 - fn: 879.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 2.6965e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-29-30-batch-100000-200000
[INFO] processing batch 200000-300000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0214 - tp: 79086.0000 - fp: 914.0000 - tn: 319086.0000 - fn: 914.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 7.9405e-05 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-29-30-batch-200000-300000
[INFO] processing batch 300000-400000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0211 - tp: 79105.0000 - fp: 895.0000 - tn: 319105.0000 - fn: 895.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 1.1062e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-29-30-batch-300000-400000
[INFO] processing batch 400000-500000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0214 - tp: 79083.0000 - fp: 917.0000 - tn: 319083.0000 - fn: 917.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9999 - val_loss: 1.6765e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-29-30-batch-400000-500000
[INFO] processing batch 500000-600000/540637
[33m[INFO] loading file 31-31/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (540637, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79124.0000 - fp: 876.0000 - tn: 319124.0000 - fn: 876.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 8.1854e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-31-batch-0-100000
[INFO] processing batch 100000-200000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0209 - tp: 79090.0000 - fp: 910.0000 - tn: 319090.0000 - fn: 910.0000 - accuracy: 0.9955 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 1.0781e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-31-batch-100000-200000
[INFO] processing batch 200000-300000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0213 - tp: 79065.0000 - fp: 935.0000 - tn: 319065.0000 - fn: 935.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9999 - val_loss: 9.5433e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-31-batch-200000-300000
[INFO] processing batch 300000-400000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0205 - tp: 79114.0000 - fp: 886.0000 - tn: 319114.0000 - fn: 886.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 8.4083e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-31-batch-300000-400000
[INFO] processing batch 400000-500000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0206 - tp: 79092.0000 - fp: 908.0000 - tn: 319092.0000 - fn: 908.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 7.3297e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-31-batch-400000-500000
[INFO] processing batch 500000-600000/540637
[33m[INFO] loading file 32-32/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (540637, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0213 - tp: 79084.0000 - fp: 916.0000 - tn: 319084.0000 - fn: 916.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 7.5025e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-31-32-batch-0-100000
[INFO] processing batch 100000-200000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0210 - tp: 79099.0000 - fp: 901.0000 - tn: 319099.0000 - fn: 901.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 6.7026e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-31-32-batch-100000-200000
[INFO] processing batch 200000-300000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79119.0000 - fp: 881.0000 - tn: 319119.0000 - fn: 881.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 6.1602e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-31-32-batch-200000-300000
[INFO] processing batch 300000-400000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0211 - tp: 79096.0000 - fp: 904.0000 - tn: 319096.0000 - fn: 904.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 3.0496e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-31-32-batch-300000-400000
[INFO] processing batch 400000-500000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0206 - tp: 79109.0000 - fp: 891.0000 - tn: 319109.0000 - fn: 891.0000 - accuracy: 0.9955 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 6.9852e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-31-32-batch-400000-500000
[INFO] processing batch 500000-600000/540637
[33m[INFO] loading file 33-33/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (540637, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0203 - tp: 79121.0000 - fp: 879.0000 - tn: 319121.0000 - fn: 879.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 5.7806e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-33-batch-0-100000
[INFO] processing batch 100000-200000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79116.0000 - fp: 884.0000 - tn: 319116.0000 - fn: 884.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 5.0587e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-33-batch-100000-200000
[INFO] processing batch 200000-300000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0209 - tp: 79089.0000 - fp: 911.0000 - tn: 319089.0000 - fn: 911.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 4.4876e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-33-batch-200000-300000
[INFO] processing batch 300000-400000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79126.0000 - fp: 874.0000 - tn: 319126.0000 - fn: 874.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 1.1852e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-33-batch-300000-400000
[INFO] processing batch 400000-500000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79121.0000 - fp: 879.0000 - tn: 319121.0000 - fn: 879.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 4.5311e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-33-batch-400000-500000
[INFO] processing batch 500000-600000/540637
[33m[INFO] loading file 34-34/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (382070, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/382070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0211 - tp: 79095.0000 - fp: 905.0000 - tn: 319095.0000 - fn: 905.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 2.0289e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-33-34-batch-0-100000
[INFO] processing batch 100000-200000/382070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0210 - tp: 79110.0000 - fp: 890.0000 - tn: 319110.0000 - fn: 890.0000 - accuracy: 0.9955 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 3.9569e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-33-34-batch-100000-200000
[INFO] processing batch 200000-300000/382070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0209 - tp: 79114.0000 - fp: 886.0000 - tn: 319114.0000 - fn: 886.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 3.7629e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-33-34-batch-200000-300000
[INFO] processing batch 300000-400000/382070
[33m[INFO] loading file 35-35/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582070, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0206 - tp: 79104.0000 - fp: 896.0000 - tn: 319104.0000 - fn: 896.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 3.4555e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-35-batch-0-100000
[INFO] processing batch 100000-200000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0201 - tp: 79114.0000 - fp: 886.0000 - tn: 319114.0000 - fn: 886.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 3.1322e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-35-batch-100000-200000
[INFO] processing batch 200000-300000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0210 - tp: 79098.0000 - fp: 902.0000 - tn: 319098.0000 - fn: 902.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 5.0176e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-35-batch-200000-300000
[INFO] processing batch 300000-400000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0212 - tp: 79086.0000 - fp: 914.0000 - tn: 319086.0000 - fn: 914.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 4.4286e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-35-batch-300000-400000
[INFO] processing batch 400000-500000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79149.0000 - fp: 851.0000 - tn: 319149.0000 - fn: 851.0000 - accuracy: 0.9957 - precision: 0.9894 - recall: 0.9894 - auc: 0.9999 - val_loss: 4.0341e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-35-batch-400000-500000
[INFO] processing batch 500000-600000/582070
[33m[INFO] loading file 36-36/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582070, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79135.0000 - fp: 865.0000 - tn: 319135.0000 - fn: 865.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 3.6597e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-35-36-batch-0-100000
[INFO] processing batch 100000-200000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0209 - tp: 79109.0000 - fp: 891.0000 - tn: 319109.0000 - fn: 891.0000 - accuracy: 0.9955 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 2.9432e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-35-36-batch-100000-200000
[INFO] processing batch 200000-300000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0198 - tp: 79155.0000 - fp: 845.0000 - tn: 319155.0000 - fn: 845.0000 - accuracy: 0.9958 - precision: 0.9894 - recall: 0.9894 - auc: 0.9999 - val_loss: 2.7735e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-35-36-batch-200000-300000
[INFO] processing batch 300000-400000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79108.0000 - fp: 892.0000 - tn: 319108.0000 - fn: 892.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 2.6178e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-35-36-batch-300000-400000
[INFO] processing batch 400000-500000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0206 - tp: 79105.0000 - fp: 895.0000 - tn: 319105.0000 - fn: 895.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 4.4252e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-35-36-batch-400000-500000
[INFO] processing batch 500000-600000/582070
[33m[INFO] loading file 37-37/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582070, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0206 - tp: 79101.0000 - fp: 899.0000 - tn: 319101.0000 - fn: 899.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 3.2929e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-37-batch-0-100000
[INFO] processing batch 100000-200000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0203 - tp: 79111.0000 - fp: 889.0000 - tn: 319111.0000 - fn: 889.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 2.8550e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-37-batch-100000-200000
[INFO] processing batch 200000-300000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0205 - tp: 79112.0000 - fp: 888.0000 - tn: 319112.0000 - fn: 888.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 2.6007e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-37-batch-200000-300000
[INFO] processing batch 300000-400000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0203 - tp: 79136.0000 - fp: 864.0000 - tn: 319136.0000 - fn: 864.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 2.8873e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-37-batch-300000-400000
[INFO] processing batch 400000-500000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0210 - tp: 79104.0000 - fp: 896.0000 - tn: 319104.0000 - fn: 896.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 8.0842e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-37-batch-400000-500000
[INFO] processing batch 500000-600000/582070
[33m[INFO] loading file 38-38/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582070, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0200 - tp: 79158.0000 - fp: 842.0000 - tn: 319158.0000 - fn: 842.0000 - accuracy: 0.9958 - precision: 0.9895 - recall: 0.9895 - auc: 0.9999 - val_loss: 2.2361e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-37-38-batch-0-100000
[INFO] processing batch 100000-200000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79137.0000 - fp: 863.0000 - tn: 319137.0000 - fn: 863.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 2.1086e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-37-38-batch-100000-200000
[INFO] processing batch 200000-300000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0210 - tp: 79089.0000 - fp: 911.0000 - tn: 319089.0000 - fn: 911.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 1.9368e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-37-38-batch-200000-300000
[INFO] processing batch 300000-400000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0210 - tp: 79109.0000 - fp: 891.0000 - tn: 319109.0000 - fn: 891.0000 - accuracy: 0.9955 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 2.4139e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-37-38-batch-300000-400000
[INFO] processing batch 400000-500000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79138.0000 - fp: 862.0000 - tn: 319138.0000 - fn: 862.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 1.7809e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-37-38-batch-400000-500000
[INFO] processing batch 500000-600000/582070
[33m[INFO] loading file 39-39/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582070, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0201 - tp: 79150.0000 - fp: 850.0000 - tn: 319150.0000 - fn: 850.0000 - accuracy: 0.9957 - precision: 0.9894 - recall: 0.9894 - auc: 0.9999 - val_loss: 0.0016 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-39-batch-0-100000
[INFO] processing batch 100000-200000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0206 - tp: 79125.0000 - fp: 875.0000 - tn: 319125.0000 - fn: 875.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 1.5055e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-39-batch-100000-200000
[INFO] processing batch 200000-300000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0198 - tp: 79159.0000 - fp: 841.0000 - tn: 319159.0000 - fn: 841.0000 - accuracy: 0.9958 - precision: 0.9895 - recall: 0.9895 - auc: 0.9999 - val_loss: 1.4459e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-39-batch-200000-300000
[INFO] processing batch 300000-400000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79104.0000 - fp: 896.0000 - tn: 319104.0000 - fn: 896.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 8.0725e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-39-batch-300000-400000
[INFO] processing batch 400000-500000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0206 - tp: 79129.0000 - fp: 871.0000 - tn: 319129.0000 - fn: 871.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 1.2800e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-39-batch-400000-500000
[INFO] processing batch 500000-600000/582070
[33m[INFO] loading file 40-40/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582070, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79104.0000 - fp: 896.0000 - tn: 319104.0000 - fn: 896.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 2.1622e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-39-40-batch-0-100000
[INFO] processing batch 100000-200000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0209 - tp: 79074.0000 - fp: 926.0000 - tn: 319074.0000 - fn: 926.0000 - accuracy: 0.9954 - precision: 0.9884 - recall: 0.9884 - auc: 0.9999 - val_loss: 9.4465e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-39-40-batch-100000-200000
[INFO] processing batch 200000-300000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0200 - tp: 79144.0000 - fp: 856.0000 - tn: 319144.0000 - fn: 856.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9999 - val_loss: 9.1532e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-39-40-batch-200000-300000
[INFO] processing batch 300000-400000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79101.0000 - fp: 899.0000 - tn: 319101.0000 - fn: 899.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 1.2202e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-39-40-batch-300000-400000
[INFO] processing batch 400000-500000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0200 - tp: 79133.0000 - fp: 867.0000 - tn: 319133.0000 - fn: 867.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 8.5613e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-39-40-batch-400000-500000
[INFO] processing batch 500000-600000/582070
[33m[INFO] loading file 41-41/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (522228, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/522228
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0210 - tp: 79089.0000 - fp: 911.0000 - tn: 319089.0000 - fn: 911.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 1.0971e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-41-batch-0-100000
[INFO] processing batch 100000-200000/522228
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0201 - tp: 79114.0000 - fp: 886.0000 - tn: 319114.0000 - fn: 886.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 1.0290e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-41-batch-100000-200000
[INFO] processing batch 200000-300000/522228
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0211 - tp: 79080.0000 - fp: 920.0000 - tn: 319080.0000 - fn: 920.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9999 - val_loss: 9.7053e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-41-batch-200000-300000
[INFO] processing batch 300000-400000/522228
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0201 - tp: 79138.0000 - fp: 862.0000 - tn: 319138.0000 - fn: 862.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 8.6053e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-41-batch-300000-400000
[INFO] processing batch 400000-500000/522228
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0205 - tp: 79110.0000 - fp: 890.0000 - tn: 319110.0000 - fn: 890.0000 - accuracy: 0.9955 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 8.0972e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-41-batch-400000-500000
[INFO] processing batch 500000-600000/522228
[33m[INFO] loading file 42-42/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (365742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/365742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79109.0000 - fp: 891.0000 - tn: 319109.0000 - fn: 891.0000 - accuracy: 0.9955 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 1.9837e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-41-42-batch-0-100000
[INFO] processing batch 100000-200000/365742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0205 - tp: 79062.0000 - fp: 938.0000 - tn: 319062.0000 - fn: 938.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9999 - val_loss: 2.2948e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-41-42-batch-100000-200000
[INFO] processing batch 200000-300000/365742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79075.0000 - fp: 925.0000 - tn: 319075.0000 - fn: 925.0000 - accuracy: 0.9954 - precision: 0.9884 - recall: 0.9884 - auc: 0.9999 - val_loss: 1.6209e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-41-42-batch-200000-300000
[INFO] processing batch 300000-400000/365742
[33m[INFO] loading file 43-43/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (565742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0205 - tp: 79125.0000 - fp: 875.0000 - tn: 319125.0000 - fn: 875.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 8.4637e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-43-batch-0-100000
[INFO] processing batch 100000-200000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79112.0000 - fp: 888.0000 - tn: 319112.0000 - fn: 888.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 2.3226e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-43-batch-100000-200000
[INFO] processing batch 200000-300000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79123.0000 - fp: 877.0000 - tn: 319123.0000 - fn: 877.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 8.0759e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-43-batch-200000-300000
[INFO] processing batch 300000-400000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0205 - tp: 79124.0000 - fp: 876.0000 - tn: 319124.0000 - fn: 876.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 1.4245e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-43-batch-300000-400000
[INFO] processing batch 400000-500000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79118.0000 - fp: 882.0000 - tn: 319118.0000 - fn: 882.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 1.2145e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-43-batch-400000-500000
[INFO] processing batch 500000-600000/565742
[33m[INFO] loading file 44-44/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (565742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0199 - tp: 79131.0000 - fp: 869.0000 - tn: 319131.0000 - fn: 869.0000 - accuracy: 0.9957 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 1.1243e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-43-44-batch-0-100000
[INFO] processing batch 100000-200000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0206 - tp: 79117.0000 - fp: 883.0000 - tn: 319117.0000 - fn: 883.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 1.0225e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-43-44-batch-100000-200000
[INFO] processing batch 200000-300000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79115.0000 - fp: 885.0000 - tn: 319115.0000 - fn: 885.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 9.1620e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-43-44-batch-200000-300000
[INFO] processing batch 300000-400000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0201 - tp: 79132.0000 - fp: 868.0000 - tn: 319132.0000 - fn: 868.0000 - accuracy: 0.9957 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 8.5162e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-43-44-batch-300000-400000
[INFO] processing batch 400000-500000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0213 - tp: 79106.0000 - fp: 894.0000 - tn: 319106.0000 - fn: 894.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 8.7628e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-43-44-batch-400000-500000
[INFO] processing batch 500000-600000/565742
[33m[INFO] loading file 45-45/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (565742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0211 - tp: 79108.0000 - fp: 892.0000 - tn: 319108.0000 - fn: 892.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 7.9892e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-45-batch-0-100000
[INFO] processing batch 100000-200000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0201 - tp: 79132.0000 - fp: 868.0000 - tn: 319132.0000 - fn: 868.0000 - accuracy: 0.9957 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 7.3956e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-45-batch-100000-200000
[INFO] processing batch 200000-300000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0205 - tp: 79114.0000 - fp: 886.0000 - tn: 319114.0000 - fn: 886.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 6.6319e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-45-batch-200000-300000
[INFO] processing batch 300000-400000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0212 - tp: 79059.0000 - fp: 941.0000 - tn: 319059.0000 - fn: 941.0000 - accuracy: 0.9953 - precision: 0.9882 - recall: 0.9882 - auc: 0.9999 - val_loss: 6.3439e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-45-batch-300000-400000
[INFO] processing batch 400000-500000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0206 - tp: 79122.0000 - fp: 878.0000 - tn: 319122.0000 - fn: 878.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 6.0241e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-45-batch-400000-500000
[INFO] processing batch 500000-600000/565742
[33m[INFO] loading file 46-46/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (565742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79093.0000 - fp: 907.0000 - tn: 319093.0000 - fn: 907.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 5.4664e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-45-46-batch-0-100000
[INFO] processing batch 100000-200000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0200 - tp: 79184.0000 - fp: 816.0000 - tn: 319184.0000 - fn: 816.0000 - accuracy: 0.9959 - precision: 0.9898 - recall: 0.9898 - auc: 0.9999 - val_loss: 8.5546e-04 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-45-46-batch-100000-200000
[INFO] processing batch 200000-300000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0209 - tp: 79070.0000 - fp: 930.0000 - tn: 319070.0000 - fn: 930.0000 - accuracy: 0.9953 - precision: 0.9884 - recall: 0.9884 - auc: 0.9999 - val_loss: 4.8080e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-45-46-batch-200000-300000
[INFO] processing batch 300000-400000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0202 - tp: 79120.0000 - fp: 880.0000 - tn: 319120.0000 - fn: 880.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 4.5044e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-45-46-batch-300000-400000
[INFO] processing batch 400000-500000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0202 - tp: 79132.0000 - fp: 868.0000 - tn: 319132.0000 - fn: 868.0000 - accuracy: 0.9957 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 4.2371e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-45-46-batch-400000-500000
[INFO] processing batch 500000-600000/565742
[33m[INFO] loading file 47-47/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (565742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0203 - tp: 79139.0000 - fp: 861.0000 - tn: 319139.0000 - fn: 861.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 4.0508e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-47-batch-0-100000
[INFO] processing batch 100000-200000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0205 - tp: 79081.0000 - fp: 919.0000 - tn: 319081.0000 - fn: 919.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9999 - val_loss: 3.9675e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-47-batch-100000-200000
[INFO] processing batch 200000-300000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79099.0000 - fp: 901.0000 - tn: 319099.0000 - fn: 901.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 3.8479e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-47-batch-200000-300000
[INFO] processing batch 300000-400000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0201 - tp: 79191.0000 - fp: 809.0000 - tn: 319191.0000 - fn: 809.0000 - accuracy: 0.9960 - precision: 0.9899 - recall: 0.9899 - auc: 0.9999 - val_loss: 3.6183e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-47-batch-300000-400000
[INFO] processing batch 400000-500000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79114.0000 - fp: 886.0000 - tn: 319114.0000 - fn: 886.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 3.3892e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-47-batch-400000-500000
[INFO] processing batch 500000-600000/565742
[33m[INFO] loading file 48-48/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (565742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0206 - tp: 79114.0000 - fp: 886.0000 - tn: 319114.0000 - fn: 886.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 4.3729e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-47-48-batch-0-100000
[INFO] processing batch 100000-200000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0196 - tp: 79171.0000 - fp: 829.0000 - tn: 319171.0000 - fn: 829.0000 - accuracy: 0.9959 - precision: 0.9896 - recall: 0.9896 - auc: 0.9999 - val_loss: 4.2996e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-47-48-batch-100000-200000
[INFO] processing batch 200000-300000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0202 - tp: 79099.0000 - fp: 901.0000 - tn: 319099.0000 - fn: 901.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 8.0632e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-47-48-batch-200000-300000
[INFO] processing batch 300000-400000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79110.0000 - fp: 890.0000 - tn: 319110.0000 - fn: 890.0000 - accuracy: 0.9955 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 4.0670e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-47-48-batch-300000-400000
[INFO] processing batch 400000-500000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0200 - tp: 79134.0000 - fp: 866.0000 - tn: 319134.0000 - fn: 866.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 4.0052e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-47-48-batch-400000-500000
[INFO] processing batch 500000-600000/565742
[33m[INFO] loading file 49-49/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (565742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0211 - tp: 79090.0000 - fp: 910.0000 - tn: 319090.0000 - fn: 910.0000 - accuracy: 0.9955 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 3.9093e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-49-batch-0-100000
[INFO] processing batch 100000-200000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0206 - tp: 79096.0000 - fp: 904.0000 - tn: 319096.0000 - fn: 904.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 1.1033e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-49-batch-100000-200000
[INFO] processing batch 200000-300000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79105.0000 - fp: 895.0000 - tn: 319105.0000 - fn: 895.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 3.8966e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-49-batch-200000-300000
[INFO] processing batch 300000-400000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0206 - tp: 79101.0000 - fp: 899.0000 - tn: 319101.0000 - fn: 899.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 8.0629e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-49-batch-300000-400000
[INFO] processing batch 400000-500000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79107.0000 - fp: 893.0000 - tn: 319107.0000 - fn: 893.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 3.6939e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-49-batch-400000-500000
[INFO] processing batch 500000-600000/565742
[33m[INFO] loading file 50-50/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (415724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/415724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0199 - tp: 79135.0000 - fp: 865.0000 - tn: 319135.0000 - fn: 865.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 3.5843e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-49-50-batch-0-100000
[INFO] processing batch 100000-200000/415724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0203 - tp: 79129.0000 - fp: 871.0000 - tn: 319129.0000 - fn: 871.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 3.5061e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-49-50-batch-100000-200000
[INFO] processing batch 200000-300000/415724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0211 - tp: 79105.0000 - fp: 895.0000 - tn: 319105.0000 - fn: 895.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 3.4311e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-49-50-batch-200000-300000
[INFO] processing batch 300000-400000/415724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0198 - tp: 79156.0000 - fp: 844.0000 - tn: 319156.0000 - fn: 844.0000 - accuracy: 0.9958 - precision: 0.9894 - recall: 0.9894 - auc: 0.9999 - val_loss: 3.4481e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-49-50-batch-300000-400000
[INFO] processing batch 400000-500000/415724
[33m[LOSS] 3.448070353897492e-07[0m
[33m[INFO] epoch 3/10[0m
[33m[INFO] loading file 1-1/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.3195 - tp: 77420.0000 - fp: 2580.0000 - tn: 317420.0000 - fn: 2580.0000 - accuracy: 0.9871 - precision: 0.9678 - recall: 0.9678 - auc: 0.9834 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-1-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0029 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-1-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8076 - val_tp: 17757.0000 - val_fp: 2243.0000 - val_tn: 77757.0000 - val_fn: 2243.0000 - val_accuracy: 0.9551 - val_precision: 0.8878 - val_recall: 0.8878 - val_auc: 0.9299
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-1-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.8596 - tp: 42791.0000 - fp: 37209.0000 - tn: 282791.0000 - fn: 37209.0000 - accuracy: 0.8140 - precision: 0.5349 - recall: 0.5349 - auc: 0.7237 - val_loss: 7.5255 - val_tp: 10662.0000 - val_fp: 9338.0000 - val_tn: 70662.0000 - val_fn: 9338.0000 - val_accuracy: 0.8132 - val_precision: 0.5331 - val_recall: 0.5331 - val_auc: 0.7082
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-1-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.7324 - tp: 43891.0000 - fp: 36109.0000 - tn: 283891.0000 - fn: 36109.0000 - accuracy: 0.8195 - precision: 0.5486 - recall: 0.5486 - auc: 0.7282 - val_loss: 7.5691 - val_tp: 10608.0000 - val_fp: 9392.0000 - val_tn: 70608.0000 - val_fn: 9392.0000 - val_accuracy: 0.8122 - val_precision: 0.5304 - val_recall: 0.5304 - val_auc: 0.7065
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-1-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 2-2/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.7565 - tp: 42490.0000 - fp: 37510.0000 - tn: 282490.0000 - fn: 37510.0000 - accuracy: 0.8125 - precision: 0.5311 - recall: 0.5311 - auc: 0.7255 - val_loss: 7.5457 - val_tp: 10637.0000 - val_fp: 9363.0000 - val_tn: 70637.0000 - val_fn: 9363.0000 - val_accuracy: 0.8127 - val_precision: 0.5318 - val_recall: 0.5318 - val_auc: 0.7074
[INFO] saving weights to checkpoints/lstm-epoch-003-files-1-2-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.5655 - tp: 60066.0000 - fp: 19934.0000 - tn: 300066.0000 - fn: 19934.0000 - accuracy: 0.9003 - precision: 0.7508 - recall: 0.7508 - auc: 0.8568 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-1-2-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0454 - tp: 79807.0000 - fp: 193.0000 - tn: 319807.0000 - fn: 193.0000 - accuracy: 0.9990 - precision: 0.9976 - recall: 0.9976 - auc: 0.9986 - val_loss: 7.5650 - val_tp: 10613.0000 - val_fp: 9387.0000 - val_tn: 70613.0000 - val_fn: 9387.0000 - val_accuracy: 0.8123 - val_precision: 0.5307 - val_recall: 0.5307 - val_auc: 0.7067
[INFO] saving weights to checkpoints/lstm-epoch-003-files-1-2-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.4416 - tp: 43372.0000 - fp: 36628.0000 - tn: 283372.0000 - fn: 36628.0000 - accuracy: 0.8169 - precision: 0.5422 - recall: 0.5422 - auc: 0.7368 - val_loss: 7.6021 - val_tp: 10567.0000 - val_fp: 9433.0000 - val_tn: 70567.0000 - val_fn: 9433.0000 - val_accuracy: 0.8113 - val_precision: 0.5283 - val_recall: 0.5283 - val_auc: 0.7052
[INFO] saving weights to checkpoints/lstm-epoch-003-files-1-2-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.3404 - tp: 60535.0000 - fp: 19465.0000 - tn: 300535.0000 - fn: 19465.0000 - accuracy: 0.9027 - precision: 0.7567 - recall: 0.7567 - auc: 0.9002 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-1-2-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 3-3/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.0946 - tp: 60527.0000 - fp: 19473.0000 - tn: 300527.0000 - fn: 19473.0000 - accuracy: 0.9026 - precision: 0.7566 - recall: 0.7566 - auc: 0.8700 - val_loss: 7.6045 - val_tp: 10564.0000 - val_fp: 9436.0000 - val_tn: 70564.0000 - val_fn: 9436.0000 - val_accuracy: 0.8113 - val_precision: 0.5282 - val_recall: 0.5282 - val_auc: 0.7051
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-3-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.3739 - tp: 57719.0000 - fp: 22281.0000 - tn: 297719.0000 - fn: 22281.0000 - accuracy: 0.8886 - precision: 0.7215 - recall: 0.7215 - auc: 0.8570 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-3-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0201 - tp: 79490.0000 - fp: 510.0000 - tn: 319490.0000 - fn: 510.0000 - accuracy: 0.9974 - precision: 0.9936 - recall: 0.9936 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-3-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0036 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-3-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0021 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-3-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 4-4/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0015 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-3-4-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0013 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-3-4-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.9037e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-3-4-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.5177e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.9407 - val_tp: 8906.0000 - val_fp: 11094.0000 - val_tn: 68906.0000 - val_fn: 11094.0000 - val_accuracy: 0.7781 - val_precision: 0.4453 - val_recall: 0.4453 - val_auc: 0.6533
[INFO] saving weights to checkpoints/lstm-epoch-003-files-3-4-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.8730 - tp: 47441.0000 - fp: 32559.0000 - tn: 287441.0000 - fn: 32559.0000 - accuracy: 0.8372 - precision: 0.5930 - recall: 0.5930 - auc: 0.7630 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-3-4-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 5-5/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.8907 - tp: 67961.0000 - fp: 12039.0000 - tn: 307961.0000 - fn: 12039.0000 - accuracy: 0.9398 - precision: 0.8495 - recall: 0.8495 - auc: 0.9215 - val_loss: 0.2137 - val_tp: 18370.0000 - val_fp: 1630.0000 - val_tn: 78370.0000 - val_fn: 1630.0000 - val_accuracy: 0.9674 - val_precision: 0.9185 - val_recall: 0.9185 - val_auc: 0.9931
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-5-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0717 - tp: 77523.0000 - fp: 2477.0000 - tn: 317523.0000 - fn: 2477.0000 - accuracy: 0.9876 - precision: 0.9690 - recall: 0.9690 - auc: 0.9992 - val_loss: 6.3576e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-5-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.3753 - tp: 75161.0000 - fp: 4839.0000 - tn: 315161.0000 - fn: 4839.0000 - accuracy: 0.9758 - precision: 0.9395 - recall: 0.9395 - auc: 0.9784 - val_loss: 0.0079 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-5-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0037 - tp: 79996.0000 - fp: 4.0000 - tn: 319996.0000 - fn: 4.0000 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - auc: 1.0000 - val_loss: 1.4865e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-5-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0016 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.8422e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-5-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 6-6/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.5949e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-5-6-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 9.3637e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4737e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-5-6-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.7870e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.1803e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-5-6-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.2516e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2747e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-5-6-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4037 - tp: 73504.0000 - fp: 6496.0000 - tn: 313504.0000 - fn: 6496.0000 - accuracy: 0.9675 - precision: 0.9188 - recall: 0.9188 - auc: 0.9830 - val_loss: 0.0043 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-5-6-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 7-7/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0641 - tp: 78253.0000 - fp: 1747.0000 - tn: 318253.0000 - fn: 1747.0000 - accuracy: 0.9913 - precision: 0.9782 - recall: 0.9782 - auc: 0.9991 - val_loss: 0.0012 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-7-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0378 - tp: 78534.0000 - fp: 1466.0000 - tn: 318534.0000 - fn: 1466.0000 - accuracy: 0.9927 - precision: 0.9817 - recall: 0.9817 - auc: 0.9998 - val_loss: 7.1566e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-7-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.3414 - tp: 69429.0000 - fp: 10571.0000 - tn: 309429.0000 - fn: 10571.0000 - accuracy: 0.9471 - precision: 0.8679 - recall: 0.8679 - auc: 0.9813 - val_loss: 0.4387 - val_tp: 12848.0000 - val_fp: 7152.0000 - val_tn: 72848.0000 - val_fn: 7152.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9680
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-7-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0378 - tp: 78791.0000 - fp: 1209.0000 - tn: 318791.0000 - fn: 1209.0000 - accuracy: 0.9940 - precision: 0.9849 - recall: 0.9849 - auc: 0.9998 - val_loss: 8.2025e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-7-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0038 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.3026e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-7-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 8-8/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0049 - tp: 79964.0000 - fp: 36.0000 - tn: 319964.0000 - fn: 36.0000 - accuracy: 0.9998 - precision: 0.9995 - recall: 0.9995 - auc: 0.9998 - val_loss: 1.2156e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-7-8-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0016 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.3880e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-7-8-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0013 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.2139e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-7-8-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.2128 - tp: 75966.0000 - fp: 4034.0000 - tn: 315966.0000 - fn: 4034.0000 - accuracy: 0.9798 - precision: 0.9496 - recall: 0.9496 - auc: 0.9929 - val_loss: 0.4136 - val_tp: 16360.0000 - val_fp: 3640.0000 - val_tn: 76360.0000 - val_fn: 3640.0000 - val_accuracy: 0.9272 - val_precision: 0.8180 - val_recall: 0.8180 - val_auc: 0.9853
[INFO] saving weights to checkpoints/lstm-epoch-003-files-7-8-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1885 - tp: 71513.0000 - fp: 8487.0000 - tn: 311513.0000 - fn: 8487.0000 - accuracy: 0.9576 - precision: 0.8939 - recall: 0.8939 - auc: 0.9936 - val_loss: 0.0144 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-7-8-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 9-9/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0906 - tp: 77501.0000 - fp: 2499.0000 - tn: 317501.0000 - fn: 2499.0000 - accuracy: 0.9875 - precision: 0.9688 - recall: 0.9688 - auc: 0.9979 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-9-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1485 - tp: 75089.0000 - fp: 4911.0000 - tn: 315089.0000 - fn: 4911.0000 - accuracy: 0.9754 - precision: 0.9386 - recall: 0.9386 - auc: 0.9955 - val_loss: 0.0520 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-9-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0072 - tp: 79985.0000 - fp: 15.0000 - tn: 319985.0000 - fn: 15.0000 - accuracy: 0.9999 - precision: 0.9998 - recall: 0.9998 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-9-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0023 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-9-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0015 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-9-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 10-10/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0014 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-9-10-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 8.9057e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2798 - val_tp: 18412.0000 - val_fp: 1588.0000 - val_tn: 78412.0000 - val_fn: 1588.0000 - val_accuracy: 0.9682 - val_precision: 0.9206 - val_recall: 0.9206 - val_auc: 0.9504
[INFO] saving weights to checkpoints/lstm-epoch-003-files-9-10-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.5556 - tp: 75115.0000 - fp: 4885.0000 - tn: 315115.0000 - fn: 4885.0000 - accuracy: 0.9756 - precision: 0.9389 - recall: 0.9389 - auc: 0.9772 - val_loss: 2.0737 - val_tp: 13136.0000 - val_fp: 6864.0000 - val_tn: 73136.0000 - val_fn: 6864.0000 - val_accuracy: 0.8627 - val_precision: 0.6568 - val_recall: 0.6568 - val_auc: 0.7888
[INFO] saving weights to checkpoints/lstm-epoch-003-files-9-10-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1966 - tp: 76004.0000 - fp: 3996.0000 - tn: 316004.0000 - fn: 3996.0000 - accuracy: 0.9800 - precision: 0.9500 - recall: 0.9500 - auc: 0.9877 - val_loss: 3.2484e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-9-10-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0046 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.4805e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-9-10-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 11-11/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0024 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.9897e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-11-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0019 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.5716e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-11-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0751e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-11-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 8.4877e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.1643e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-11-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.1373e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.5220e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-11-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 12-12/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.3637e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6248e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-11-12-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.2779e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.5817e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-11-12-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.3384 - tp: 72109.0000 - fp: 7891.0000 - tn: 312109.0000 - fn: 7891.0000 - accuracy: 0.9605 - precision: 0.9014 - recall: 0.9014 - auc: 0.9850 - val_loss: 0.0173 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-11-12-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1937 - tp: 74537.0000 - fp: 5463.0000 - tn: 314537.0000 - fn: 5463.0000 - accuracy: 0.9727 - precision: 0.9317 - recall: 0.9317 - auc: 0.9935 - val_loss: 0.0304 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-11-12-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0119 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.2036e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-11-12-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 13-13/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0033 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.1435e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-13-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0022 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.5937e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-13-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0017 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.3727e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-13-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.2792 - tp: 72618.0000 - fp: 7382.0000 - tn: 312618.0000 - fn: 7382.0000 - accuracy: 0.9631 - precision: 0.9077 - recall: 0.9077 - auc: 0.9889 - val_loss: 0.0056 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-13-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0293 - tp: 78967.0000 - fp: 1033.0000 - tn: 318967.0000 - fn: 1033.0000 - accuracy: 0.9948 - precision: 0.9871 - recall: 0.9871 - auc: 0.9999 - val_loss: 4.3624e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-13-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 14-14/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.2439 - tp: 72778.0000 - fp: 7222.0000 - tn: 312778.0000 - fn: 7222.0000 - accuracy: 0.9639 - precision: 0.9097 - recall: 0.9097 - auc: 0.9892 - val_loss: 0.4902 - val_tp: 12807.0000 - val_fp: 7193.0000 - val_tn: 72807.0000 - val_fn: 7193.0000 - val_accuracy: 0.8561 - val_precision: 0.6403 - val_recall: 0.6403 - val_auc: 0.9677
[INFO] saving weights to checkpoints/lstm-epoch-003-files-13-14-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0644 - tp: 78071.0000 - fp: 1929.0000 - tn: 318071.0000 - fn: 1929.0000 - accuracy: 0.9904 - precision: 0.9759 - recall: 0.9759 - auc: 0.9995 - val_loss: 0.0024 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-13-14-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0055 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6562e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-13-14-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0027 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.5647e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-13-14-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0016 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6040e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-13-14-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 15-15/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0048 - tp: 79954.0000 - fp: 46.0000 - tn: 319954.0000 - fn: 46.0000 - accuracy: 0.9998 - precision: 0.9994 - recall: 0.9994 - auc: 0.9997 - val_loss: 9.7623e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-15-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0013 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.1359e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-15-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 8.7978e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.7367e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-15-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.7978e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8929 - val_tp: 18892.0000 - val_fp: 1108.0000 - val_tn: 78892.0000 - val_fn: 1108.0000 - val_accuracy: 0.9778 - val_precision: 0.9446 - val_recall: 0.9446 - val_auc: 0.9654
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-15-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.5303 - tp: 42627.0000 - fp: 37373.0000 - tn: 282627.0000 - fn: 37373.0000 - accuracy: 0.8131 - precision: 0.5328 - recall: 0.5328 - auc: 0.7045 - val_loss: 7.5473 - val_tp: 10635.0000 - val_fp: 9365.0000 - val_tn: 70635.0000 - val_fn: 9365.0000 - val_accuracy: 0.8127 - val_precision: 0.5318 - val_recall: 0.5318 - val_auc: 0.7073
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-15-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 16-16/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (455414, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/455414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.5570 - tp: 42494.0000 - fp: 37506.0000 - tn: 282494.0000 - fn: 37506.0000 - accuracy: 0.8125 - precision: 0.5312 - recall: 0.5312 - auc: 0.7039 - val_loss: 7.5562 - val_tp: 10624.0000 - val_fp: 9376.0000 - val_tn: 70624.0000 - val_fn: 9376.0000 - val_accuracy: 0.8125 - val_precision: 0.5312 - val_recall: 0.5312 - val_auc: 0.7070
[INFO] saving weights to checkpoints/lstm-epoch-003-files-15-16-batch-0-100000
[INFO] processing batch 100000-200000/455414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.8447 - tp: 50993.0000 - fp: 29007.0000 - tn: 290993.0000 - fn: 29007.0000 - accuracy: 0.8550 - precision: 0.6374 - recall: 0.6374 - auc: 0.7709 - val_loss: 2.4352e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-15-16-batch-100000-200000
[INFO] processing batch 200000-300000/455414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.0190e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.9171e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-15-16-batch-200000-300000
[INFO] processing batch 300000-400000/455414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.4429e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.4831e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-15-16-batch-300000-400000
[INFO] processing batch 400000-500000/455414
[33m[INFO] loading file 17-17/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (555414, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.7345e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1925e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-17-batch-0-100000
[INFO] processing batch 100000-200000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.4883e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.6801e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-17-batch-100000-200000
[INFO] processing batch 200000-300000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.8434e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.4260e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-17-batch-200000-300000
[INFO] processing batch 300000-400000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.7164 - tp: 71482.0000 - fp: 8518.0000 - tn: 311482.0000 - fn: 8518.0000 - accuracy: 0.9574 - precision: 0.8935 - recall: 0.8935 - auc: 0.9331 - val_loss: 2.9456 - val_tp: 16345.0000 - val_fp: 3655.0000 - val_tn: 76345.0000 - val_fn: 3655.0000 - val_accuracy: 0.9269 - val_precision: 0.8173 - val_recall: 0.8173 - val_auc: 0.8858
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-17-batch-300000-400000
[INFO] processing batch 400000-500000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.9155 - tp: 65530.0000 - fp: 14470.0000 - tn: 305530.0000 - fn: 14470.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.8865 - val_loss: 2.9238 - val_tp: 16372.0000 - val_fp: 3628.0000 - val_tn: 76372.0000 - val_fn: 3628.0000 - val_accuracy: 0.9274 - val_precision: 0.8186 - val_recall: 0.8186 - val_auc: 0.8866
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-17-batch-400000-500000
[INFO] processing batch 500000-600000/555414
[33m[INFO] loading file 18-18/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (555414, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4986 - tp: 77526.0000 - fp: 2474.0000 - tn: 317526.0000 - fn: 2474.0000 - accuracy: 0.9876 - precision: 0.9691 - recall: 0.9691 - auc: 0.9807 - val_loss: 6.1305 - val_tp: 12393.0000 - val_fp: 7607.0000 - val_tn: 72393.0000 - val_fn: 7607.0000 - val_accuracy: 0.8479 - val_precision: 0.6197 - val_recall: 0.6197 - val_auc: 0.7623
[INFO] saving weights to checkpoints/lstm-epoch-003-files-17-18-batch-0-100000
[INFO] processing batch 100000-200000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.1306 - tp: 49572.0000 - fp: 30428.0000 - tn: 289572.0000 - fn: 30428.0000 - accuracy: 0.8479 - precision: 0.6197 - recall: 0.6197 - auc: 0.7622 - val_loss: 6.0395 - val_tp: 12506.0000 - val_fp: 7494.0000 - val_tn: 72506.0000 - val_fn: 7494.0000 - val_accuracy: 0.8501 - val_precision: 0.6253 - val_recall: 0.6253 - val_auc: 0.7658
[INFO] saving weights to checkpoints/lstm-epoch-003-files-17-18-batch-100000-200000
[INFO] processing batch 200000-300000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.1445 - tp: 49503.0000 - fp: 30497.0000 - tn: 289503.0000 - fn: 30497.0000 - accuracy: 0.8475 - precision: 0.6188 - recall: 0.6188 - auc: 0.7617 - val_loss: 6.1474 - val_tp: 12372.0000 - val_fp: 7628.0000 - val_tn: 72372.0000 - val_fn: 7628.0000 - val_accuracy: 0.8474 - val_precision: 0.6186 - val_recall: 0.6186 - val_auc: 0.7616
[INFO] saving weights to checkpoints/lstm-epoch-003-files-17-18-batch-200000-300000
[INFO] processing batch 300000-400000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.3068 - tp: 68551.0000 - fp: 11449.0000 - tn: 308551.0000 - fn: 11449.0000 - accuracy: 0.9428 - precision: 0.8569 - recall: 0.8569 - auc: 0.9106 - val_loss: 2.6664e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-17-18-batch-300000-400000
[INFO] processing batch 400000-500000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.2232e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.2606e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-17-18-batch-400000-500000
[INFO] processing batch 500000-600000/555414
[33m[INFO] loading file 19-19/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (555414, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.0190e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.0025e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-19-batch-0-100000
[INFO] processing batch 100000-200000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 9.6198e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7838e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-19-batch-100000-200000
[INFO] processing batch 200000-300000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 8.2547e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6267e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-19-batch-200000-300000
[INFO] processing batch 300000-400000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.2223 - tp: 78897.0000 - fp: 1103.0000 - tn: 318897.0000 - fn: 1103.0000 - accuracy: 0.9945 - precision: 0.9862 - recall: 0.9862 - auc: 0.9914 - val_loss: 9.7974 - val_tp: 7843.0000 - val_fp: 12157.0000 - val_tn: 67843.0000 - val_fn: 12157.0000 - val_accuracy: 0.7569 - val_precision: 0.3922 - val_recall: 0.3922 - val_auc: 0.6201
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-19-batch-300000-400000
[INFO] processing batch 400000-500000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 9.8375 - tp: 31173.0000 - fp: 48827.0000 - tn: 271173.0000 - fn: 48827.0000 - accuracy: 0.7559 - precision: 0.3897 - recall: 0.3897 - auc: 0.6185 - val_loss: 7.6343 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.7040
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-19-batch-400000-500000
[INFO] processing batch 500000-600000/555414
[33m[INFO] loading file 20-20/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (555414, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.6585e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3976e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-19-20-batch-0-100000
[INFO] processing batch 100000-200000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.4603 - tp: 67789.0000 - fp: 12211.0000 - tn: 307789.0000 - fn: 12211.0000 - accuracy: 0.9389 - precision: 0.8474 - recall: 0.8474 - auc: 0.9046 - val_loss: 2.9625 - val_tp: 16324.0000 - val_fp: 3676.0000 - val_tn: 76324.0000 - val_fn: 3676.0000 - val_accuracy: 0.9265 - val_precision: 0.8162 - val_recall: 0.8162 - val_auc: 0.8851
[INFO] saving weights to checkpoints/lstm-epoch-003-files-19-20-batch-100000-200000
[INFO] processing batch 200000-300000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.9434 - tp: 65391.0000 - fp: 14609.0000 - tn: 305391.0000 - fn: 14609.0000 - accuracy: 0.9270 - precision: 0.8174 - recall: 0.8174 - auc: 0.8859 - val_loss: 2.9424 - val_tp: 16349.0000 - val_fp: 3651.0000 - val_tn: 76349.0000 - val_fn: 3651.0000 - val_accuracy: 0.9270 - val_precision: 0.8174 - val_recall: 0.8174 - val_auc: 0.8859
[INFO] saving weights to checkpoints/lstm-epoch-003-files-19-20-batch-200000-300000
[INFO] processing batch 300000-400000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.3765 - tp: 73168.0000 - fp: 6832.0000 - tn: 313168.0000 - fn: 6832.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9466 - val_loss: 1.2702e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-19-20-batch-300000-400000
[INFO] processing batch 400000-500000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.7651e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2374e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-19-20-batch-400000-500000
[INFO] processing batch 500000-600000/555414
[33m[INFO] loading file 21-21/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (555412, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/555412
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.0849e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2182e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-21-batch-0-100000
[INFO] processing batch 100000-200000/555412
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.8022e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1993e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-21-batch-100000-200000
[INFO] processing batch 200000-300000/555412
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.3710e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1922e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-21-batch-200000-300000
[INFO] processing batch 300000-400000/555412
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.0624e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-21-batch-300000-400000
[INFO] processing batch 400000-500000/555412
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.8213e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-21-batch-400000-500000
[INFO] processing batch 500000-600000/555412
[33m[INFO] loading file 22-22/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (324453, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/324453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.5530 - tp: 62365.0000 - fp: 17635.0000 - tn: 302365.0000 - fn: 17635.0000 - accuracy: 0.9118 - precision: 0.7796 - recall: 0.7796 - auc: 0.8622 - val_loss: 7.5626 - val_tp: 10616.0000 - val_fp: 9384.0000 - val_tn: 70616.0000 - val_fn: 9384.0000 - val_accuracy: 0.8123 - val_precision: 0.5308 - val_recall: 0.5308 - val_auc: 0.7068
[INFO] saving weights to checkpoints/lstm-epoch-003-files-21-22-batch-0-100000
[INFO] processing batch 100000-200000/324453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.5699 - tp: 42428.0000 - fp: 37572.0000 - tn: 282428.0000 - fn: 37572.0000 - accuracy: 0.8121 - precision: 0.5304 - recall: 0.5304 - auc: 0.7065 - val_loss: 7.5900 - val_tp: 10582.0000 - val_fp: 9418.0000 - val_tn: 70582.0000 - val_fn: 9418.0000 - val_accuracy: 0.8116 - val_precision: 0.5291 - val_recall: 0.5291 - val_auc: 0.7057
[INFO] saving weights to checkpoints/lstm-epoch-003-files-21-22-batch-100000-200000
[INFO] processing batch 200000-300000/324453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.5856 - tp: 42350.0000 - fp: 37650.0000 - tn: 282350.0000 - fn: 37650.0000 - accuracy: 0.8117 - precision: 0.5294 - recall: 0.5294 - auc: 0.7059 - val_loss: 7.6077 - val_tp: 10560.0000 - val_fp: 9440.0000 - val_tn: 70560.0000 - val_fn: 9440.0000 - val_accuracy: 0.8112 - val_precision: 0.5280 - val_recall: 0.5280 - val_auc: 0.7050
[INFO] saving weights to checkpoints/lstm-epoch-003-files-21-22-batch-200000-300000
[INFO] processing batch 300000-400000/324453
[33m[INFO] loading file 23-23/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524453, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.1279 - tp: 59512.0000 - fp: 20488.0000 - tn: 299512.0000 - fn: 20488.0000 - accuracy: 0.8976 - precision: 0.7439 - recall: 0.7439 - auc: 0.8399 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-23-batch-0-100000
[INFO] processing batch 100000-200000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.0457e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-23-batch-100000-200000
[INFO] processing batch 200000-300000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 9.0127e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-23-batch-200000-300000
[INFO] processing batch 300000-400000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 8.2356e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-23-batch-300000-400000
[INFO] processing batch 400000-500000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.7207e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-23-batch-400000-500000
[INFO] processing batch 500000-600000/524453
[33m[INFO] loading file 24-24/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524453, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7464e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-23-24-batch-0-100000
[INFO] processing batch 100000-200000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.2589e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-23-24-batch-100000-200000
[INFO] processing batch 200000-300000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.6910e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-23-24-batch-200000-300000
[INFO] processing batch 300000-400000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.9683e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-23-24-batch-300000-400000
[INFO] processing batch 400000-500000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.9515 - tp: 70314.0000 - fp: 9686.0000 - tn: 310314.0000 - fn: 9686.0000 - accuracy: 0.9516 - precision: 0.8789 - recall: 0.8789 - auc: 0.9243 - val_loss: 5.7340 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.7777
[INFO] saving weights to checkpoints/lstm-epoch-003-files-23-24-batch-400000-500000
[INFO] processing batch 500000-600000/524453
[33m[INFO] loading file 25-25/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524453, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7499 - tp: 51461.0000 - fp: 28539.0000 - tn: 291461.0000 - fn: 28539.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.7770 - val_loss: 5.7421 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.7773
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-25-batch-0-100000
[INFO] processing batch 100000-200000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7445 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.7772 - val_loss: 5.7453 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.7772
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-25-batch-100000-200000
[INFO] processing batch 200000-300000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7511 - tp: 51455.0000 - fp: 28545.0000 - tn: 291455.0000 - fn: 28545.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.7770 - val_loss: 5.7558 - val_tp: 12858.0000 - val_fp: 7142.0000 - val_tn: 72858.0000 - val_fn: 7142.0000 - val_accuracy: 0.8572 - val_precision: 0.6429 - val_recall: 0.6429 - val_auc: 0.7768
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-25-batch-200000-300000
[INFO] processing batch 300000-400000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7415 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.7774 - val_loss: 5.7759 - val_tp: 12833.0000 - val_fp: 7167.0000 - val_tn: 72833.0000 - val_fn: 7167.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.7760
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-25-batch-300000-400000
[INFO] processing batch 400000-500000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7405 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.7774 - val_loss: 5.7590 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.7767
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-25-batch-400000-500000
[INFO] processing batch 500000-600000/524453
[33m[INFO] loading file 26-26/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524453, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.5503 - tp: 52173.0000 - fp: 27827.0000 - tn: 292173.0000 - fn: 27827.0000 - accuracy: 0.8609 - precision: 0.6522 - recall: 0.6522 - auc: 0.7765 - val_loss: 2.6362e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-25-26-batch-0-100000
[INFO] processing batch 100000-200000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0370 - tp: 79134.0000 - fp: 866.0000 - tn: 319134.0000 - fn: 866.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9997 - val_loss: 3.4526e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-25-26-batch-100000-200000
[INFO] processing batch 200000-300000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0234 - tp: 79062.0000 - fp: 938.0000 - tn: 319062.0000 - fn: 938.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9999 - val_loss: 3.2108e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-25-26-batch-200000-300000
[INFO] processing batch 300000-400000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79127.0000 - fp: 873.0000 - tn: 319127.0000 - fn: 873.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 2.4709e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-25-26-batch-300000-400000
[INFO] processing batch 400000-500000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79120.0000 - fp: 880.0000 - tn: 319120.0000 - fn: 880.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 2.4582e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-25-26-batch-400000-500000
[INFO] processing batch 500000-600000/524453
[33m[INFO] loading file 27-27/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (464583, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/464583
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0214 - tp: 79063.0000 - fp: 937.0000 - tn: 319063.0000 - fn: 937.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9999 - val_loss: 2.1716e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-27-batch-0-100000
[INFO] processing batch 100000-200000/464583
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0214 - tp: 79068.0000 - fp: 932.0000 - tn: 319068.0000 - fn: 932.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9999 - val_loss: 2.1564e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-27-batch-100000-200000
[INFO] processing batch 200000-300000/464583
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0197 - tp: 79128.0000 - fp: 872.0000 - tn: 319128.0000 - fn: 872.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 1.7502e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-27-batch-200000-300000
[INFO] processing batch 300000-400000/464583
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0206 - tp: 79079.0000 - fp: 921.0000 - tn: 319079.0000 - fn: 921.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9999 - val_loss: 1.3278e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-27-batch-300000-400000
[INFO] processing batch 400000-500000/464583
[33m[INFO] loading file 28-28/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (398499, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/398499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0214 - tp: 79029.0000 - fp: 971.0000 - tn: 319029.0000 - fn: 971.0000 - accuracy: 0.9951 - precision: 0.9879 - recall: 0.9879 - auc: 0.9999 - val_loss: 8.2056e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-27-28-batch-0-100000
[INFO] processing batch 100000-200000/398499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0200 - tp: 79158.0000 - fp: 842.0000 - tn: 319158.0000 - fn: 842.0000 - accuracy: 0.9958 - precision: 0.9895 - recall: 0.9895 - auc: 0.9999 - val_loss: 1.3995e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-27-28-batch-100000-200000
[INFO] processing batch 200000-300000/398499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0203 - tp: 79146.0000 - fp: 854.0000 - tn: 319146.0000 - fn: 854.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9999 - val_loss: 1.2860e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-27-28-batch-200000-300000
[INFO] processing batch 300000-400000/398499
[33m[INFO] loading file 29-29/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (598499, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79137.0000 - fp: 863.0000 - tn: 319137.0000 - fn: 863.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 1.1559e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-29-batch-0-100000
[INFO] processing batch 100000-200000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79086.0000 - fp: 914.0000 - tn: 319086.0000 - fn: 914.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 1.0656e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-29-batch-100000-200000
[INFO] processing batch 200000-300000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0212 - tp: 79072.0000 - fp: 928.0000 - tn: 319072.0000 - fn: 928.0000 - accuracy: 0.9954 - precision: 0.9884 - recall: 0.9884 - auc: 0.9999 - val_loss: 8.1573e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-29-batch-200000-300000
[INFO] processing batch 300000-400000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0206 - tp: 79111.0000 - fp: 889.0000 - tn: 319111.0000 - fn: 889.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 8.8335e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-29-batch-300000-400000
[INFO] processing batch 400000-500000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0209 - tp: 79097.0000 - fp: 903.0000 - tn: 319097.0000 - fn: 903.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 8.0468e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-29-batch-400000-500000
[INFO] processing batch 500000-600000/598499
[33m[INFO] loading file 30-30/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (598499, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0212 - tp: 79048.0000 - fp: 952.0000 - tn: 319048.0000 - fn: 952.0000 - accuracy: 0.9952 - precision: 0.9881 - recall: 0.9881 - auc: 0.9999 - val_loss: 6.9637e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-29-30-batch-0-100000
[INFO] processing batch 100000-200000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0209 - tp: 79101.0000 - fp: 899.0000 - tn: 319101.0000 - fn: 899.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 6.6137e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-29-30-batch-100000-200000
[INFO] processing batch 200000-300000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79111.0000 - fp: 889.0000 - tn: 319111.0000 - fn: 889.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 6.1754e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-29-30-batch-200000-300000
[INFO] processing batch 300000-400000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0210 - tp: 79083.0000 - fp: 917.0000 - tn: 319083.0000 - fn: 917.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9999 - val_loss: 5.4046e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-29-30-batch-300000-400000
[INFO] processing batch 400000-500000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79116.0000 - fp: 884.0000 - tn: 319116.0000 - fn: 884.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 4.9904e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-29-30-batch-400000-500000
[INFO] processing batch 500000-600000/598499
[33m[INFO] loading file 31-31/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (598499, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0212 - tp: 79114.0000 - fp: 886.0000 - tn: 319114.0000 - fn: 886.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 5.4609e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-31-batch-0-100000
[INFO] processing batch 100000-200000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0202 - tp: 79136.0000 - fp: 864.0000 - tn: 319136.0000 - fn: 864.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 4.7328e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-31-batch-100000-200000
[INFO] processing batch 200000-300000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0215 - tp: 79039.0000 - fp: 961.0000 - tn: 319039.0000 - fn: 961.0000 - accuracy: 0.9952 - precision: 0.9880 - recall: 0.9880 - auc: 0.9999 - val_loss: 3.9818e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-31-batch-200000-300000
[INFO] processing batch 300000-400000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0202 - tp: 79144.0000 - fp: 856.0000 - tn: 319144.0000 - fn: 856.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9999 - val_loss: 3.6498e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-31-batch-300000-400000
[INFO] processing batch 400000-500000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79118.0000 - fp: 882.0000 - tn: 319118.0000 - fn: 882.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 3.4933e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-31-batch-400000-500000
[INFO] processing batch 500000-600000/598499
[33m[INFO] loading file 32-32/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (598499, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79100.0000 - fp: 900.0000 - tn: 319100.0000 - fn: 900.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 8.0955e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-31-32-batch-0-100000
[INFO] processing batch 100000-200000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79096.0000 - fp: 904.0000 - tn: 319096.0000 - fn: 904.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 3.4543e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-31-32-batch-100000-200000
[INFO] processing batch 200000-300000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79092.0000 - fp: 908.0000 - tn: 319092.0000 - fn: 908.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 3.2812e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-31-32-batch-200000-300000
[INFO] processing batch 300000-400000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0198 - tp: 79146.0000 - fp: 854.0000 - tn: 319146.0000 - fn: 854.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9999 - val_loss: 3.2141e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-31-32-batch-300000-400000
[INFO] processing batch 400000-500000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0203 - tp: 79112.0000 - fp: 888.0000 - tn: 319112.0000 - fn: 888.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 2.9574e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-31-32-batch-400000-500000
[INFO] processing batch 500000-600000/598499
[33m[INFO] loading file 33-33/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (598499, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0200 - tp: 79179.0000 - fp: 821.0000 - tn: 319179.0000 - fn: 821.0000 - accuracy: 0.9959 - precision: 0.9897 - recall: 0.9897 - auc: 0.9999 - val_loss: 2.7215e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-33-batch-0-100000
[INFO] processing batch 100000-200000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79130.0000 - fp: 870.0000 - tn: 319130.0000 - fn: 870.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 3.1269e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-33-batch-100000-200000
[INFO] processing batch 200000-300000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0200 - tp: 79153.0000 - fp: 847.0000 - tn: 319153.0000 - fn: 847.0000 - accuracy: 0.9958 - precision: 0.9894 - recall: 0.9894 - auc: 0.9999 - val_loss: 2.7733e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-33-batch-200000-300000
[INFO] processing batch 300000-400000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79081.0000 - fp: 919.0000 - tn: 319081.0000 - fn: 919.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9999 - val_loss: 5.4673e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-33-batch-300000-400000
[INFO] processing batch 400000-500000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0206 - tp: 79132.0000 - fp: 868.0000 - tn: 319132.0000 - fn: 868.0000 - accuracy: 0.9957 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 6.1081e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-33-batch-400000-500000
[INFO] processing batch 500000-600000/598499
[33m[INFO] loading file 34-34/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439932, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/439932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79107.0000 - fp: 893.0000 - tn: 319107.0000 - fn: 893.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 5.3389e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-33-34-batch-0-100000
[INFO] processing batch 100000-200000/439932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79132.0000 - fp: 868.0000 - tn: 319132.0000 - fn: 868.0000 - accuracy: 0.9957 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 4.5376e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-33-34-batch-100000-200000
[INFO] processing batch 200000-300000/439932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0209 - tp: 79097.0000 - fp: 903.0000 - tn: 319097.0000 - fn: 903.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 6.1334e-04 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-003-files-33-34-batch-200000-300000
[INFO] processing batch 300000-400000/439932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0206 - tp: 79108.0000 - fp: 892.0000 - tn: 319108.0000 - fn: 892.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 5.4591e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-33-34-batch-300000-400000
[INFO] processing batch 400000-500000/439932
[33m[INFO] loading file 35-35/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539932, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0205 - tp: 79101.0000 - fp: 899.0000 - tn: 319101.0000 - fn: 899.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 4.6683e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-35-batch-0-100000
[INFO] processing batch 100000-200000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79076.0000 - fp: 924.0000 - tn: 319076.0000 - fn: 924.0000 - accuracy: 0.9954 - precision: 0.9884 - recall: 0.9884 - auc: 0.9999 - val_loss: 8.1593e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-35-batch-100000-200000
[INFO] processing batch 200000-300000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0211 - tp: 79121.0000 - fp: 879.0000 - tn: 319121.0000 - fn: 879.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 8.1257e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-35-batch-200000-300000
[INFO] processing batch 300000-400000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79141.0000 - fp: 859.0000 - tn: 319141.0000 - fn: 859.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9999 - val_loss: 5.2964e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-35-batch-300000-400000
[INFO] processing batch 400000-500000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0198 - tp: 79145.0000 - fp: 855.0000 - tn: 319145.0000 - fn: 855.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9999 - val_loss: 3.3263e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-35-batch-400000-500000
[INFO] processing batch 500000-600000/539932
[33m[INFO] loading file 36-36/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539932, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0209 - tp: 79086.0000 - fp: 914.0000 - tn: 319086.0000 - fn: 914.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 0.0012 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-003-files-35-36-batch-0-100000
[INFO] processing batch 100000-200000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0213 - tp: 79077.0000 - fp: 923.0000 - tn: 319077.0000 - fn: 923.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9999 - val_loss: 5.3021e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-35-36-batch-100000-200000
[INFO] processing batch 200000-300000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0206 - tp: 79128.0000 - fp: 872.0000 - tn: 319128.0000 - fn: 872.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 4.2874e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-35-36-batch-200000-300000
[INFO] processing batch 300000-400000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0212 - tp: 79083.0000 - fp: 917.0000 - tn: 319083.0000 - fn: 917.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9999 - val_loss: 3.4057e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-35-36-batch-300000-400000
[INFO] processing batch 400000-500000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79115.0000 - fp: 885.0000 - tn: 319115.0000 - fn: 885.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 3.0855e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-35-36-batch-400000-500000
[INFO] processing batch 500000-600000/539932
[33m[INFO] loading file 37-37/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539932, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79101.0000 - fp: 899.0000 - tn: 319101.0000 - fn: 899.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 2.7072e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-37-batch-0-100000
[INFO] processing batch 100000-200000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0206 - tp: 79105.0000 - fp: 895.0000 - tn: 319105.0000 - fn: 895.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 2.3288e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-37-batch-100000-200000
[INFO] processing batch 200000-300000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0205 - tp: 79099.0000 - fp: 901.0000 - tn: 319099.0000 - fn: 901.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 2.4427e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-37-batch-200000-300000
[INFO] processing batch 300000-400000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0219 - tp: 79058.0000 - fp: 942.0000 - tn: 319058.0000 - fn: 942.0000 - accuracy: 0.9953 - precision: 0.9882 - recall: 0.9882 - auc: 0.9999 - val_loss: 2.1112e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-37-batch-300000-400000
[INFO] processing batch 400000-500000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0209 - tp: 79113.0000 - fp: 887.0000 - tn: 319113.0000 - fn: 887.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 2.5437e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-37-batch-400000-500000
[INFO] processing batch 500000-600000/539932
[33m[INFO] loading file 38-38/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539932, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0209 - tp: 79081.0000 - fp: 919.0000 - tn: 319081.0000 - fn: 919.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9999 - val_loss: 2.3468e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-37-38-batch-0-100000
[INFO] processing batch 100000-200000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0200 - tp: 79138.0000 - fp: 862.0000 - tn: 319138.0000 - fn: 862.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 2.0257e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-37-38-batch-100000-200000
[INFO] processing batch 200000-300000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0201 - tp: 79149.0000 - fp: 851.0000 - tn: 319149.0000 - fn: 851.0000 - accuracy: 0.9957 - precision: 0.9894 - recall: 0.9894 - auc: 0.9999 - val_loss: 3.3154e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-37-38-batch-200000-300000
[INFO] processing batch 300000-400000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0210 - tp: 79110.0000 - fp: 890.0000 - tn: 319110.0000 - fn: 890.0000 - accuracy: 0.9955 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 1.3717e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-37-38-batch-300000-400000
[INFO] processing batch 400000-500000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0203 - tp: 79102.0000 - fp: 898.0000 - tn: 319102.0000 - fn: 898.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 4.1868e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-37-38-batch-400000-500000
[INFO] processing batch 500000-600000/539932
[33m[INFO] loading file 39-39/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539932, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0209 - tp: 79114.0000 - fp: 886.0000 - tn: 319114.0000 - fn: 886.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 8.0686e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-39-batch-0-100000
[INFO] processing batch 100000-200000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0202 - tp: 79121.0000 - fp: 879.0000 - tn: 319121.0000 - fn: 879.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 9.2247e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-39-batch-100000-200000
[INFO] processing batch 200000-300000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0201 - tp: 79097.0000 - fp: 903.0000 - tn: 319097.0000 - fn: 903.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 8.7948e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-39-batch-200000-300000
[INFO] processing batch 300000-400000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0211 - tp: 79093.0000 - fp: 907.0000 - tn: 319093.0000 - fn: 907.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 8.2761e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-39-batch-300000-400000
[INFO] processing batch 400000-500000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0209 - tp: 79075.0000 - fp: 925.0000 - tn: 319075.0000 - fn: 925.0000 - accuracy: 0.9954 - precision: 0.9884 - recall: 0.9884 - auc: 0.9999 - val_loss: 7.7809e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-39-batch-400000-500000
[INFO] processing batch 500000-600000/539932
[33m[INFO] loading file 40-40/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539932, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0201 - tp: 79146.0000 - fp: 854.0000 - tn: 319146.0000 - fn: 854.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9999 - val_loss: 2.8653e-04 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-39-40-batch-0-100000
[INFO] processing batch 100000-200000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79098.0000 - fp: 902.0000 - tn: 319098.0000 - fn: 902.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 6.8210e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-39-40-batch-100000-200000
[INFO] processing batch 200000-300000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79119.0000 - fp: 881.0000 - tn: 319119.0000 - fn: 881.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 7.1319e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-39-40-batch-200000-300000
[INFO] processing batch 300000-400000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0215 - tp: 79107.0000 - fp: 893.0000 - tn: 319107.0000 - fn: 893.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 1.8787e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-39-40-batch-300000-400000
[INFO] processing batch 400000-500000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0203 - tp: 79113.0000 - fp: 887.0000 - tn: 319113.0000 - fn: 887.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 1.8150e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-39-40-batch-400000-500000
[INFO] processing batch 500000-600000/539932
[33m[INFO] loading file 41-41/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (480090, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/480090
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79127.0000 - fp: 873.0000 - tn: 319127.0000 - fn: 873.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 2.6921e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-41-batch-0-100000
[INFO] processing batch 100000-200000/480090
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0210 - tp: 79084.0000 - fp: 916.0000 - tn: 319084.0000 - fn: 916.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 2.6154e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-41-batch-100000-200000
[INFO] processing batch 200000-300000/480090
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0209 - tp: 79088.0000 - fp: 912.0000 - tn: 319088.0000 - fn: 912.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 2.4547e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-41-batch-200000-300000
[INFO] processing batch 300000-400000/480090
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79119.0000 - fp: 881.0000 - tn: 319119.0000 - fn: 881.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 2.7246e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-41-batch-300000-400000
[INFO] processing batch 400000-500000/480090
[33m[INFO] loading file 42-42/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (423604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/423604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0202 - tp: 79139.0000 - fp: 861.0000 - tn: 319139.0000 - fn: 861.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 2.9511e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-41-42-batch-0-100000
[INFO] processing batch 100000-200000/423604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0203 - tp: 79133.0000 - fp: 867.0000 - tn: 319133.0000 - fn: 867.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 2.5957e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-41-42-batch-100000-200000
[INFO] processing batch 200000-300000/423604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0195 - tp: 79132.0000 - fp: 868.0000 - tn: 319132.0000 - fn: 868.0000 - accuracy: 0.9957 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 2.3927e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-41-42-batch-200000-300000
[INFO] processing batch 300000-400000/423604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0203 - tp: 79120.0000 - fp: 880.0000 - tn: 319120.0000 - fn: 880.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 8.0817e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-41-42-batch-300000-400000
[INFO] processing batch 400000-500000/423604
[33m[INFO] loading file 43-43/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (523604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0200 - tp: 79144.0000 - fp: 856.0000 - tn: 319144.0000 - fn: 856.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9999 - val_loss: 2.2086e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-43-batch-0-100000
[INFO] processing batch 100000-200000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79111.0000 - fp: 889.0000 - tn: 319111.0000 - fn: 889.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 8.0823e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-43-batch-100000-200000
[INFO] processing batch 200000-300000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0205 - tp: 79105.0000 - fp: 895.0000 - tn: 319105.0000 - fn: 895.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 4.2570e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-43-batch-200000-300000
[INFO] processing batch 300000-400000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0195 - tp: 79174.0000 - fp: 826.0000 - tn: 319174.0000 - fn: 826.0000 - accuracy: 0.9959 - precision: 0.9897 - recall: 0.9897 - auc: 0.9999 - val_loss: 3.6455e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-43-batch-300000-400000
[INFO] processing batch 400000-500000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0212 - tp: 79067.0000 - fp: 933.0000 - tn: 319067.0000 - fn: 933.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9999 - val_loss: 2.8625e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-43-batch-400000-500000
[INFO] processing batch 500000-600000/523604
[33m[INFO] loading file 44-44/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (523604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79138.0000 - fp: 862.0000 - tn: 319138.0000 - fn: 862.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 2.7428e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-43-44-batch-0-100000
[INFO] processing batch 100000-200000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0209 - tp: 79052.0000 - fp: 948.0000 - tn: 319052.0000 - fn: 948.0000 - accuracy: 0.9953 - precision: 0.9882 - recall: 0.9882 - auc: 0.9999 - val_loss: 2.3524e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-43-44-batch-100000-200000
[INFO] processing batch 200000-300000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0202 - tp: 79135.0000 - fp: 865.0000 - tn: 319135.0000 - fn: 865.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 8.0811e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-43-44-batch-200000-300000
[INFO] processing batch 300000-400000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0205 - tp: 79107.0000 - fp: 893.0000 - tn: 319107.0000 - fn: 893.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 0.0016 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-003-files-43-44-batch-300000-400000
[INFO] processing batch 400000-500000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79088.0000 - fp: 912.0000 - tn: 319088.0000 - fn: 912.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 1.6875e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-43-44-batch-400000-500000
[INFO] processing batch 500000-600000/523604
[33m[INFO] loading file 45-45/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (523604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0206 - tp: 79122.0000 - fp: 878.0000 - tn: 319122.0000 - fn: 878.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 1.7595e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-45-batch-0-100000
[INFO] processing batch 100000-200000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79090.0000 - fp: 910.0000 - tn: 319090.0000 - fn: 910.0000 - accuracy: 0.9955 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 1.6543e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-45-batch-100000-200000
[INFO] processing batch 200000-300000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0205 - tp: 79091.0000 - fp: 909.0000 - tn: 319091.0000 - fn: 909.0000 - accuracy: 0.9955 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 1.4532e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-45-batch-200000-300000
[INFO] processing batch 300000-400000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0205 - tp: 79118.0000 - fp: 882.0000 - tn: 319118.0000 - fn: 882.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 1.4094e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-45-batch-300000-400000
[INFO] processing batch 400000-500000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79108.0000 - fp: 892.0000 - tn: 319108.0000 - fn: 892.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 1.2694e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-45-batch-400000-500000
[INFO] processing batch 500000-600000/523604
[33m[INFO] loading file 46-46/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (523604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0213 - tp: 79053.0000 - fp: 947.0000 - tn: 319053.0000 - fn: 947.0000 - accuracy: 0.9953 - precision: 0.9882 - recall: 0.9882 - auc: 0.9999 - val_loss: 0.0016 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-003-files-45-46-batch-0-100000
[INFO] processing batch 100000-200000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79103.0000 - fp: 897.0000 - tn: 319103.0000 - fn: 897.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 6.3189e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-45-46-batch-100000-200000
[INFO] processing batch 200000-300000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79124.0000 - fp: 876.0000 - tn: 319124.0000 - fn: 876.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 5.9151e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-45-46-batch-200000-300000
[INFO] processing batch 300000-400000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0209 - tp: 79087.0000 - fp: 913.0000 - tn: 319087.0000 - fn: 913.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 5.7897e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-45-46-batch-300000-400000
[INFO] processing batch 400000-500000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0200 - tp: 79127.0000 - fp: 873.0000 - tn: 319127.0000 - fn: 873.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 5.7227e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-45-46-batch-400000-500000
[INFO] processing batch 500000-600000/523604
[33m[INFO] loading file 47-47/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (523604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0204 - tp: 79116.0000 - fp: 884.0000 - tn: 319116.0000 - fn: 884.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 5.7765e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-47-batch-0-100000
[INFO] processing batch 100000-200000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79097.0000 - fp: 903.0000 - tn: 319097.0000 - fn: 903.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 5.6770e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-47-batch-100000-200000
[INFO] processing batch 200000-300000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0198 - tp: 79169.0000 - fp: 831.0000 - tn: 319169.0000 - fn: 831.0000 - accuracy: 0.9958 - precision: 0.9896 - recall: 0.9896 - auc: 0.9999 - val_loss: 8.0646e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-47-batch-200000-300000
[INFO] processing batch 300000-400000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79103.0000 - fp: 897.0000 - tn: 319103.0000 - fn: 897.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 5.4652e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-47-batch-300000-400000
[INFO] processing batch 400000-500000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0195 - tp: 79156.0000 - fp: 844.0000 - tn: 319156.0000 - fn: 844.0000 - accuracy: 0.9958 - precision: 0.9894 - recall: 0.9894 - auc: 0.9999 - val_loss: 5.2482e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-47-batch-400000-500000
[INFO] processing batch 500000-600000/523604
[33m[INFO] loading file 48-48/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (523604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0198 - tp: 79136.0000 - fp: 864.0000 - tn: 319136.0000 - fn: 864.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 5.1937e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-47-48-batch-0-100000
[INFO] processing batch 100000-200000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0205 - tp: 79101.0000 - fp: 899.0000 - tn: 319101.0000 - fn: 899.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 5.0240e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-47-48-batch-100000-200000
[INFO] processing batch 200000-300000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79049.0000 - fp: 951.0000 - tn: 319049.0000 - fn: 951.0000 - accuracy: 0.9952 - precision: 0.9881 - recall: 0.9881 - auc: 0.9999 - val_loss: 4.7842e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-47-48-batch-200000-300000
[INFO] processing batch 300000-400000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0202 - tp: 79152.0000 - fp: 848.0000 - tn: 319152.0000 - fn: 848.0000 - accuracy: 0.9958 - precision: 0.9894 - recall: 0.9894 - auc: 0.9999 - val_loss: 5.1987e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-47-48-batch-300000-400000
[INFO] processing batch 400000-500000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0200 - tp: 79141.0000 - fp: 859.0000 - tn: 319141.0000 - fn: 859.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9999 - val_loss: 4.9122e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-47-48-batch-400000-500000
[INFO] processing batch 500000-600000/523604
[33m[INFO] loading file 49-49/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (523604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0203 - tp: 79152.0000 - fp: 848.0000 - tn: 319152.0000 - fn: 848.0000 - accuracy: 0.9958 - precision: 0.9894 - recall: 0.9894 - auc: 0.9999 - val_loss: 5.6491e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-49-batch-0-100000
[INFO] processing batch 100000-200000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0211 - tp: 79087.0000 - fp: 913.0000 - tn: 319087.0000 - fn: 913.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 3.9885e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-49-batch-100000-200000
[INFO] processing batch 200000-300000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0208 - tp: 79085.0000 - fp: 915.0000 - tn: 319085.0000 - fn: 915.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 3.8539e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-49-batch-200000-300000
[INFO] processing batch 300000-400000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0216 - tp: 79048.0000 - fp: 952.0000 - tn: 319048.0000 - fn: 952.0000 - accuracy: 0.9952 - precision: 0.9881 - recall: 0.9881 - auc: 0.9999 - val_loss: 6.8641e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-49-batch-300000-400000
[INFO] processing batch 400000-500000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0206 - tp: 79100.0000 - fp: 900.0000 - tn: 319100.0000 - fn: 900.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 3.7325e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-49-batch-400000-500000
[INFO] processing batch 500000-600000/523604
[33m[INFO] loading file 50-50/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (373586, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/373586
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0206 - tp: 79086.0000 - fp: 914.0000 - tn: 319086.0000 - fn: 914.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 3.6784e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-49-50-batch-0-100000
[INFO] processing batch 100000-200000/373586
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0207 - tp: 79087.0000 - fp: 913.0000 - tn: 319087.0000 - fn: 913.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 3.5280e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-49-50-batch-100000-200000
[INFO] processing batch 200000-300000/373586
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0206 - tp: 79105.0000 - fp: 895.0000 - tn: 319105.0000 - fn: 895.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 3.4998e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
Using TensorFlow backend.
train.py:185: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version
of pandas will change to not sort by default.

To accept the future behavior, pass 'sort=False'.

To retain the current behavior and silence the warning, pass 'sort=True'.

  df = pd.concat(df_from_each_file, ignore_index=True)
[INFO] saving weights to checkpoints/lstm-epoch-003-files-49-50-batch-200000-300000
[INFO] processing batch 300000-400000/373586
[33m[LOSS] 3.499836516311916e-07[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 3.499836516311916e-07  <  0.001
[STOPPING EARLY]: currentLoss < min_delta => 3.499836516311916e-07  <  0.001
--- 2735.448371887207 seconds ---
2020-02-03 08:46:22.616948: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-02-03 08:46:22.617098: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-02-03 08:46:22.617113: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-02-03 08:46:23.422742: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-02-03 08:46:23.422774: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-02-03 08:46:23.422804: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (***REMOVED***): /proc/driver/nvidia/version does not exist
2020-02-03 08:46:23.422999: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-03 08:46:23.431709: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2112050000 Hz
2020-02-03 08:46:23.433264: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5c506f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-03 08:46:23.433318: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-02-03 08:46:26.321137: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-03 08:46:26.325420: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 08:46:26.327216: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 08:46:26.341303: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-03 08:46:26.342204: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-03 08:46:26.343562: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 08:46:26.344911: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 08:46:26.347904: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
=============================
        SCORING v0.3
=============================
Date: 2020-02-03 08:46:23.417504
[INFO] input_shape (10, 16)
[INFO] LSTM first and last layer neurons: 5
adding core layer 0
[INFO] created DNN
loading weights: checkpoints/*
loading file checkpoints/lstm-epoch-003-files-9-10-batch-400000-500000
[33m[INFO] model summary:[0m
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 10, 5)             440       
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 10, 5)             0         
_________________________________________________________________
lstm_2 (LSTM)                (None, 10, 10)            640       
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 10, 10)            0         
_________________________________________________________________
lstm_3 (LSTM)                (None, 10, 5)             320       
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU)    (None, 10, 5)             0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 10, 5)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 10, 1)             6         
_________________________________________________________________
leaky_re_lu_4 (LeakyReLU)    (None, 10, 1)             0         
_________________________________________________________________
dense_2 (Dense)              (None, 10, 5)             10        
=================================================================
Total params: 1,416
Trainable params: 1,416
Non-trainable params: 0
_________________________________________________________________
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2015-12-31_130240_112.log.part10_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1364 (0.2728%)
[INFO] ** orig:[0:99.9992%,1:0.0008%]
[INFO] ** type:[0:99.9984%,1:0.0014%,2:0.0002%]
[INFO] ** i/f_name:[2:99.9984%,3:0.0016%]
[INFO] ** i/f_dir:[1:99.9986%,0:0.0014%]
[INFO] ** src:[22:38.114%,9:26.0964%,7:18.2424%,1:17.543%,14:0.0016%,11:0.0012%,10:0.001%,15:0.0004%]
[INFO] ** dst:[21:43.3686%,10:20.8412%,8:18.2422%,9:17.5434%,15:0.0016%,22:0.0014%,6:0.0006%,25:0.0004%,24:0.0002%,18:0.0002%,7:0.0002%]
[INFO] ** proto:[0:99.997%,1:0.0016%,2:0.0014%]
[INFO] ** appi_name:[21:99.9962%,30:0.0016%,26:0.0004%,0:0.0004%,31:0.0002%,27:0.0002%,24:0.0002%,22:0.0002%,16:0.0002%,15:0.0002%,5:0.0002%]
[INFO] ** proxy_src_ip:[18:38.114%,20:26.0964%,13:18.2424%,6:17.543%,17:0.0016%,10:0.0012%,11:0.001%,16:0.0004%]
[INFO] ** modbus_function_code:[0.02961:99.9962%,-33.760870000000004:0.0036%,0.9188299999999999:0.0002%]
[INFO] ** modbus_function_description:[7:49.9988%,11:49.9974%,0:0.0036%,15:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.0954%,1:20.841%,5:18.242%,4:17.5424%,2:17.2726%,0:0.0066%]
[INFO] ** service:[0.0048200000000000005:99.997%,-211.73542999999998:0.0016%,-186.44547:0.0004%,-211.08346:0.0004%,-186.43601999999998:0.0002%,-211.08818:0.0002%,-202.75898:0.0002%]
[INFO] ** s_port:[1.45442:26.0956%,-0.32151:20.8412%,-1.27613:18.242%,-0.23351:17.5424%,-0.33484:17.2728%,-71.33197:0.0016%,-9.54647:0.0008%,-0.24151:0.0006%,-64.19493:0.0004%,-1.02014:0.0004%,-71.14798:0.0004%,1.45709:0.0004%,-1.27347:0.0002%,1.46509:0.0002%,-68.79874000000001:0.0002%,-71.14931:0.0002%,-3.22139:0.0002%,-1.2708:0.0002%,1.47576:0.0002%]
[INFO] ** classification:[normal:79.7796%,Single Stage Single Point:20.2204%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 1 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  8.511409579467774
tp :  6707.0
fp :  93293.0
tn :  306707.0
fn :  93293.0
accuracy :  0.6268280148506165
precision :  0.06706999987363815
recall :  0.06706999987363815
auc :  0.4987347722053528

y_eval {0: 64261, 1: 35739}
pred {0: 42446, 1: 57554}
[INFO] confusion matrix for file 
[[ 6707 57554     0     0     0]
 [35739     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[ 6707 57554     0     0     0]
 [35739     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 1 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  8.552704490661622
tp :  2338.0
fp :  97662.0
tn :  302338.0
fn :  97662.0
accuracy :  0.6093520522117615
precision :  0.02338000014424324
recall :  0.02338000014424324
auc :  0.49946820735931396

y_eval {0: 64231, 1: 35769}
pred {0: 38103, 1: 61897}
[INFO] confusion matrix for file 
[[ 2336 61895     0     0     0]
 [35767     2     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[  9043 119449      0      0      0]
 [ 71506      2      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  7.558040867996215
tp :  7312.0
fp :  92688.0
tn :  307312.0
fn :  92688.0
accuracy :  0.6292477250099182
precision :  0.07311999797821045
recall :  0.07311999797821045
auc :  0.5466190576553345

y_eval {0: 70406, 1: 29594}
pred {0: 36906, 1: 63094}
[INFO] confusion matrix for file 
[[ 7312 63094     0     0     0]
 [29594     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[ 16355 182543      0      0      0]
 [101100      2      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.718550315475464
tp :  38892.0
fp :  61108.0
tn :  338892.0
fn :  61108.0
accuracy :  0.7555677890777588
precision :  0.38892000913619995
recall :  0.38892000913619995
auc :  0.764169454574585

y_eval {0: 100000}
pred {0: 38892, 1: 61108}
[INFO] confusion matrix for file 
[[38892 61108     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[ 55247 243651      0      0      0]
 [101100      2      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.495881964492798
tp :  44921.0
fp :  55079.0
tn :  344921.0
fn :  55079.0
accuracy :  0.7796842455863953
precision :  0.449209988117218
recall :  0.449209988117218
auc :  0.7814722061157227

y_eval {0: 100000}
pred {0: 44921, 1: 55079}
[INFO] confusion matrix for file 
[[44921 55079     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[100168 298730      0      0      0]
 [101100      2      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2015-12-31_181648_113.log.part08_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1370 (0.274%)
[INFO] ** orig:[0:99.9948%,2:0.0052%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.9948%,3:0.0052%]
[INFO] ** i/f_dir:[1:99.9948%,0:0.0052%]
[INFO] ** src:[22:38.4402%,9:25.9738%,7:18.1202%,1:17.4598%,21:0.0052%,2:0.0004%,15:0.0002%,11:0.0002%]
[INFO] ** dst:[21:43.345%,10:21.0682%,8:18.1202%,9:17.4594%,15:0.0052%,22:0.0012%,19:0.0004%,26:0.0002%,24:0.0002%]
[INFO] ** proto:[0:99.9946%,1:0.0052%,2:0.0002%]
[INFO] ** appi_name:[21:99.9942%,30:0.0052%,23:0.0002%,22:0.0002%,18:0.0002%]
[INFO] ** proxy_src_ip:[18:38.4402%,20:25.9738%,13:18.1202%,6:17.4598%,17:0.0052%,14:0.0004%,16:0.0002%,10:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9942%,-33.760870000000004:0.0058%]
[INFO] ** modbus_function_description:[7:49.998%,11:49.9962%,0:0.0058%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:25.9726%,1:21.0682%,5:18.1198%,4:17.459%,2:17.3718%,0:0.0086%]
[INFO] ** service:[0.0048200000000000005:99.9942%,-211.73542999999998:0.0052%,-211.07873999999998:0.0004%,-211.08818:0.0002%]
[INFO] ** s_port:[1.45442:25.973%,-0.32151:21.0682%,-1.27613:18.12%,-0.23351:17.4592%,-0.33484:17.372%,-71.33197:0.0052%,-0.24151:0.0006%,1.45709:0.0004%,8.38348:0.0004%,-1.27347:0.0002%,1.46509:0.0002%,1.47576:0.0002%,-71.14931:0.0002%,-1.02014:0.0002%]
[INFO] ** classification:[normal:80.1196%,Multi Stage Multi Point:14.47%,Single Stage Multi Point:5.4104%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  6.328792486190796
tp :  31036.0
fp :  68964.0
tn :  331036.0
fn :  68964.0
accuracy :  0.7241442203521729
precision :  0.31036001443862915
recall :  0.31036001443862915
auc :  0.6442759037017822

y_eval {0: 72948, 2: 27052}
pred {0: 42559, 1: 57441}
[INFO] confusion matrix for file 
[[31036 41912     0     0     0]
 [    0     0     0     0     0]
 [11523 15529     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[131204 340642      0      0      0]
 [101100      2      0      0      0]
 [ 11523  15529      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.7968802738189695
tp :  37913.0
fp :  62087.0
tn :  337913.0
fn :  62087.0
accuracy :  0.75165194272995
precision :  0.3791300058364868
recall :  0.3791300058364868
auc :  0.7517730593681335

y_eval {0: 100000}
pred {0: 37913, 1: 62087}
[INFO] confusion matrix for file 
[[37913 62087     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[169117 402729      0      0      0]
 [101100      2      0      0      0]
 [ 11523  15529      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.799844834518433
tp :  36719.0
fp :  63281.0
tn :  336719.0
fn :  63281.0
accuracy :  0.7468758821487427
precision :  0.36719000339508057
recall :  0.36719000339508057
auc :  0.7551974654197693

y_eval {0: 100000}
pred {0: 36719, 1: 63281}
[INFO] confusion matrix for file 
[[36719 63281     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[205836 466010      0      0      0]
 [101100      2      0      0      0]
 [ 11523  15529      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  5.708119295501709
tp :  37190.0
fp :  62810.0
tn :  337190.0
fn :  62810.0
accuracy :  0.748760461807251
precision :  0.3718999922275543
recall :  0.3718999922275543
auc :  0.6964799761772156

y_eval {0: 74770, 4: 25230}
pred {0: 38591, 1: 61409}
[INFO] confusion matrix for file 
[[37190 37580     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [ 1401 23829     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[243026 503590      0      0      0]
 [101100      2      0      0      0]
 [ 11523  15529      0      0      0]
 [     0      0      0      0      0]
 [  1401  23829      0      0      0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 4 0 ... 4 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  8.21184172592163
tp :  38060.0
fp :  61940.0
tn :  338060.0
fn :  61940.0
accuracy :  0.7522398233413696
precision :  0.3806000053882599
recall :  0.3806000053882599
auc :  0.6458905935287476

y_eval {0: 52880, 4: 47120}
pred {0: 44977, 1: 55023}
[INFO] confusion matrix for file 
[[38060 14820     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [ 6917 40203     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[281086 518410      0      0      0]
 [101100      2      0      0      0]
 [ 11523  15529      0      0      0]
 [     0      0      0      0      0]
 [  8318  64032      0      0      0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2015-12-31_181648_113.log.part09_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1359 (0.2718%)
[INFO] ** orig:[0:99.9966%,2:0.0034%]
[INFO] ** type:[0:99.9996%,1:0.0004%]
[INFO] ** i/f_name:[2:99.9938%,3:0.0062%]
[INFO] ** i/f_dir:[1:99.9942%,0:0.0058%]
[INFO] ** src:[22:38.4204%,9:25.9634%,7:18.123%,1:17.486%,21:0.0034%,14:0.0028%,15:0.0006%,2:0.0004%]
[INFO] ** dst:[21:43.3316%,10:21.0518%,8:18.123%,9:17.486%,15:0.0062%,22:0.0008%,24:0.0002%,18:0.0002%,7:0.0002%]
[INFO] ** proto:[0:99.9934%,1:0.0062%,2:0.0004%]
[INFO] ** appi_name:[21:99.9934%,30:0.0062%,31:0.0002%,27:0.0002%]
[INFO] ** proxy_src_ip:[18:38.4204%,20:25.9634%,13:18.123%,6:17.486%,17:0.0062%,16:0.0006%,14:0.0004%]
[INFO] ** modbus_function_code:[0.02961:99.9934%,-33.760870000000004:0.0066%]
[INFO] ** modbus_function_description:[7:49.9972%,11:49.9962%,0:0.0066%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:25.9624%,1:21.0518%,5:18.1226%,4:17.4856%,2:17.3686%,0:0.009%]
[INFO] ** service:[0.0048200000000000005:99.9934%,-211.73542999999998:0.0062%,-186.43601999999998:0.0002%,-202.75898:0.0002%]
[INFO] ** s_port:[1.45442:25.9628%,-0.32151:21.0518%,-1.27613:18.1226%,-0.23351:17.4858%,-0.33484:17.3686%,-71.33197:0.0062%,-1.02014:0.0006%,-1.27347:0.0002%,11.862:0.0002%,1.45709:0.0002%,-0.24950999999999998:0.0002%,1.46509:0.0002%,1.47576:0.0002%,13.431270000000001:0.0002%,-1.2708:0.0002%]
[INFO] ** classification:[normal:73.9096%,Multi Stage Multi Point:26.0904%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 4 0 ... 4 4 4] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  8.347627668762208
tp :  35590.0
fp :  64410.0
tn :  335590.0
fn :  64410.0
accuracy :  0.7423599362373352
precision :  0.35589998960494995
recall :  0.35589998960494995
auc :  0.6307727098464966

y_eval {0: 52975, 4: 47025}
pred {0: 42486, 1: 57514}
[INFO] confusion matrix for file 
[[35590 17385     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [ 6896 40129     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[316676 535795      0      0      0]
 [101100      2      0      0      0]
 [ 11523  15529      0      0      0]
 [     0      0      0      0      0]
 [ 15214 104161      0      0      0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [4 0 4 ... 0 4 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  8.30823724822998
tp :  35727.0
fp :  64273.0
tn :  335727.0
fn :  64273.0
accuracy :  0.7429078817367554
precision :  0.3572700023651123
recall :  0.3572700023651123
auc :  0.6343675255775452

y_eval {0: 53029, 4: 46971}
pred {0: 38080, 1: 61920}
[INFO] confusion matrix for file 
[[35727 17302     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [ 2353 44618     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[352403 553097      0      0      0]
 [101100      2      0      0      0]
 [ 11523  15529      0      0      0]
 [     0      0      0      0      0]
 [ 17567 148779      0      0      0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [4 4 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  7.0659851062774655
tp :  36120.0
fp :  63880.0
tn :  336120.0
fn :  63880.0
accuracy :  0.7444798946380615
precision :  0.3612000048160553
recall :  0.3612000048160553
auc :  0.662826657295227

y_eval {0: 63544, 4: 36456}
pred {0: 36899, 1: 63101}
[INFO] confusion matrix for file 
[[36120 27424     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [  779 35677     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[388523 580521      0      0      0]
 [101100      2      0      0      0]
 [ 11523  15529      0      0      0]
 [     0      0      0      0      0]
 [ 18346 184456      0      0      0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.7237607948303224
tp :  38603.0
fp :  61397.0
tn :  338603.0
fn :  61397.0
accuracy :  0.7544122934341431
precision :  0.386029988527298
recall :  0.386029988527298
auc :  0.7636825442314148

y_eval {0: 100000}
pred {0: 38603, 1: 61397}
[INFO] confusion matrix for file 
[[38603 61397     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[427126 641918      0      0      0]
 [101100      2      0      0      0]
 [ 11523  15529      0      0      0]
 [     0      0      0      0      0]
 [ 18346 184456      0      0      0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.4998969913482667
tp :  44785.0
fp :  55215.0
tn :  344785.0
fn :  55215.0
accuracy :  0.7791399955749512
precision :  0.44784998893737793
recall :  0.44784998893737793
auc :  0.7813194990158081

y_eval {0: 100000}
pred {0: 44785, 1: 55215}
[INFO] confusion matrix for file 
[[44785 55215     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[471911 697133      0      0      0]
 [101100      2      0      0      0]
 [ 11523  15529      0      0      0]
 [     0      0      0      0      0]
 [ 18346 184456      0      0      0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2015-12-31_233049_114.log.part11_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1361 (0.2722%)
[INFO] ** orig:[0:99.9996%,2:0.0004%]
[INFO] ** type:[0:99.9994%,1:0.0004%,2:0.0002%]
[INFO] ** i/f_name:[2:99.9968%,3:0.0032%]
[INFO] ** i/f_dir:[1:99.9972%,0:0.0028%]
[INFO] ** src:[22:38.4512%,9:25.9642%,7:18.089%,1:17.4908%,14:0.0028%,11:0.0008%,21:0.0004%,15:0.0004%,2:0.0004%]
[INFO] ** dst:[21:43.3436%,10:21.0714%,8:18.0896%,9:17.4906%,15:0.0032%,22:0.001%,24:0.0002%,18:0.0002%,7:0.0002%]
[INFO] ** proto:[0:99.9964%,1:0.0032%,2:0.0004%]
[INFO] ** appi_name:[21:99.9956%,30:0.0032%,31:0.0002%,27:0.0002%,24:0.0002%,16:0.0002%,15:0.0002%,5:0.0002%]
[INFO] ** proxy_src_ip:[18:38.4512%,20:25.9642%,13:18.089%,6:17.4908%,17:0.0032%,10:0.0008%,16:0.0004%,14:0.0004%]
[INFO] ** modbus_function_code:[0.02961:99.9956%,-33.760870000000004:0.0042%,0.9188299999999999:0.0002%]
[INFO] ** modbus_function_description:[7:49.999%,11:49.9966%,0:0.0042%,15:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:25.9632%,1:21.0714%,5:18.0886%,4:17.4902%,2:17.3796%,0:0.007%]
[INFO] ** service:[0.0048200000000000005:99.9964%,-211.73542999999998:0.0032%,-186.43601999999998:0.0002%,-202.75898:0.0002%]
[INFO] ** s_port:[1.45442:25.9636%,-0.32151:21.0714%,-1.27613:18.0886%,-0.23351:17.4904%,-0.33484:17.3798%,-71.33197:0.0032%,6.286230000000001:0.0008%,1.45709:0.0004%,-1.02014:0.0004%,-1.27347:0.0002%,11.862:0.0002%,-0.24950999999999998:0.0002%,1.47576:0.0002%,-0.24151:0.0002%,13.431270000000001:0.0002%,-1.2708:0.0002%]
[INFO] ** classification:[normal:95.0874%,Single Stage Single Point:4.9126%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.753873076248169
tp :  42428.0
fp :  57572.0
tn :  342428.0
fn :  57572.0
accuracy :  0.769711971282959
precision :  0.42427998781204224
recall :  0.42427998781204224
auc :  0.7495934963226318

y_eval {0: 100000}
pred {0: 42428, 1: 57572}
[INFO] confusion matrix for file 
[[42428 57572     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[514339 754705      0      0      0]
 [101100      2      0      0      0]
 [ 11523  15529      0      0      0]
 [     0      0      0      0      0]
 [ 18346 184456      0      0      0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.804513018035889
tp :  37881.0
fp :  62119.0
tn :  337881.0
fn :  62119.0
accuracy :  0.7515240907669067
precision :  0.37880998849868774
recall :  0.37880998849868774
auc :  0.7510530352592468

y_eval {0: 100000}
pred {0: 37881, 1: 62119}
[INFO] confusion matrix for file 
[[37881 62119     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[552220 816824      0      0      0]
 [101100      2      0      0      0]
 [ 11523  15529      0      0      0]
 [     0      0      0      0      0]
 [ 18346 184456      0      0      0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  3.9769094642639162
tp :  29382.0
fp :  70618.0
tn :  329382.0
fn :  70618.0
accuracy :  0.7175279855728149
precision :  0.29381999373435974
recall :  0.29381999373435974
auc :  0.7044192552566528

y_eval {0: 92639, 1: 7361}
pred {0: 36743, 1: 63257}
[INFO] confusion matrix for file 
[[29382 63257     0     0     0]
 [ 7361     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[581602 880081      0      0      0]
 [108461      2      0      0      0]
 [ 11523  15529      0      0      0]
 [     0      0      0      0      0]
 [ 18346 184456      0      0      0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  5.491263161087036
tp :  21486.0
fp :  78514.0
tn :  321486.0
fn :  78514.0
accuracy :  0.6859440803527832
precision :  0.2148600071668625
recall :  0.2148600071668625
auc :  0.6429105401039124

y_eval {0: 82798, 1: 17202}
pred {0: 38688, 1: 61312}
[INFO] confusion matrix for file 
[[21486 61312     0     0     0]
 [17202     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[603088 941393      0      0      0]
 [125663      2      0      0      0]
 [ 11523  15529      0      0      0]
 [     0      0      0      0      0]
 [ 18346 184456      0      0      0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.4938757663726805
tp :  44927.0
fp :  55073.0
tn :  344927.0
fn :  55073.0
accuracy :  0.7797077894210815
precision :  0.44927000999450684
recall :  0.44927000999450684
auc :  0.781713604927063

y_eval {0: 100000}
pred {0: 44927, 1: 55073}
[INFO] confusion matrix for file 
[[44927 55073     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[648015 996466      0      0      0]
 [125663      2      0      0      0]
 [ 11523  15529      0      0      0]
 [     0      0      0      0      0]
 [ 18346 184456      0      0      0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-01_151435_117.log.part03_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1365 (0.273%)
[INFO] ** orig:[0:99.9976%,2:0.0024%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.9966%,3:0.0034%]
[INFO] ** i/f_dir:[1:99.9966%,0:0.0034%]
[INFO] ** src:[22:38.1462%,9:26.099%,7:18.1904%,1:17.5592%,21:0.0028%,14:0.001%,3:0.0006%,15:0.0004%,2:0.0004%]
[INFO] ** dst:[21:43.376%,10:20.8688%,8:18.1902%,9:17.5592%,15:0.0034%,22:0.0008%,18:0.0004%,16:0.0004%,6:0.0004%,24:0.0002%,2:0.0002%]
[INFO] ** proto:[0:99.9958%,1:0.0034%,2:0.0008%]
[INFO] ** appi_name:[21:99.9952%,30:0.0034%,7:0.0006%,31:0.0004%,26:0.0002%,22:0.0002%]
[INFO] ** proxy_src_ip:[18:38.1462%,20:26.099%,13:18.1904%,6:17.5592%,17:0.0034%,1:0.0006%,16:0.0004%,14:0.0004%,7:0.0004%]
[INFO] ** modbus_function_code:[0.02961:99.9952%,-33.760870000000004:0.0048%]
[INFO] ** modbus_function_description:[7:49.9978%,11:49.9974%,0:0.0048%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.0982%,1:20.8688%,5:18.19%,4:17.5588%,2:17.2772%,0:0.007%]
[INFO] ** service:[0.0048200000000000005:99.9952%,-211.73542999999998:0.0034%,-211.09762999999998:0.0006%,-186.43601999999998:0.0004%,-211.08346:0.0002%,-211.08818:0.0002%]
[INFO] ** s_port:[1.45442:26.0986%,-0.32151:20.8688%,-1.27613:18.1902%,-0.23351:17.559%,-0.33484:17.2774%,-71.33197:0.0034%,-1.02014:0.0004%,-71.14931:0.0002%,-0.24151:0.0002%,4.42897:0.0002%,-71.14798:0.0002%,1.47576:0.0002%,-1.27347:0.0002%,-0.78282:0.0002%,-2.92807:0.0002%,-4.88132:0.0002%,1.45709:0.0002%,9.18344:0.0002%]
[INFO] ** classification:[normal:84.2104%,Single Stage Single Point:15.7896%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  7.462971284484864
tp :  13408.0
fp :  86592.0
tn :  313408.0
fn :  86592.0
accuracy :  0.6536321640014648
precision :  0.13407999277114868
recall :  0.13407999277114868
auc :  0.5446203351020813

y_eval {0: 70708, 1: 29292}
pred {0: 42700, 1: 57300}
[INFO] confusion matrix for file 
[[13408 57300     0     0     0]
 [29292     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[ 661423 1053766       0       0       0]
 [ 154955       2       0       0       0]
 [  11523   15529       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 1 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  8.557874276733399
tp :  2370.0
fp :  97630.0
tn :  302370.0
fn :  97630.0
accuracy :  0.6094800233840942
precision :  0.02370000071823597
recall :  0.02370000071823597
auc :  0.49911370873451233

y_eval {0: 64215, 1: 35785}
pred {0: 38155, 1: 61845}
[INFO] confusion matrix for file 
[[ 2370 61845     0     0     0]
 [35785     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[ 663793 1115611       0       0       0]
 [ 190740       2       0       0       0]
 [  11523   15529       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  5.028503048706055
tp :  23121.0
fp :  76879.0
tn :  323121.0
fn :  76879.0
accuracy :  0.6924839019775391
precision :  0.23120999336242676
recall :  0.23120999336242676
auc :  0.6576767563819885

y_eval {0: 86129, 1: 13871}
pred {0: 36990, 1: 63010}
[INFO] confusion matrix for file 
[[23120 63009     0     0     0]
 [13870     1     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[ 686913 1178620       0       0       0]
 [ 204610       3       0       0       0]
 [  11523   15529       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.717446951293945
tp :  38743.0
fp :  61257.0
tn :  338743.0
fn :  61257.0
accuracy :  0.7549717426300049
precision :  0.38743001222610474
recall :  0.38743001222610474
auc :  0.76470947265625

y_eval {0: 100000}
pred {0: 38743, 1: 61257}
[INFO] confusion matrix for file 
[[38743 61257     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[ 725656 1239877       0       0       0]
 [ 204610       3       0       0       0]
 [  11523   15529       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.495865210723877
tp :  44825.0
fp :  55175.0
tn :  344825.0
fn :  55175.0
accuracy :  0.7792999744415283
precision :  0.4482499957084656
recall :  0.4482499957084656
auc :  0.7818509340286255

y_eval {0: 100000}
pred {0: 44825, 1: 55175}
[INFO] confusion matrix for file 
[[44825 55175     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[ 770481 1295052       0       0       0]
 [ 204610       3       0       0       0]
 [  11523   15529       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-01_151435_117.log.part12_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1377 (0.2754%)
[INFO] ** orig:[0:99.9964%,2:0.0036%]
[INFO] ** type:[0:99.9994%,1:0.0004%,2:0.0002%]
[INFO] ** i/f_name:[2:99.996%,3:0.004%]
[INFO] ** i/f_dir:[1:99.9964%,0:0.0036%]
[INFO] ** src:[22:38.049%,9:26.1306%,7:18.2264%,1:17.587%,21:0.0036%,11:0.0014%,10:0.001%,14:0.0004%,15:0.0002%,8:0.0002%,4:0.0002%]
[INFO] ** dst:[21:43.355%,10:20.8256%,8:18.226%,9:17.5868%,15:0.004%,6:0.001%,22:0.0006%,25:0.0004%,24:0.0002%,18:0.0002%,7:0.0002%]
[INFO] ** proto:[0:99.9942%,1:0.004%,2:0.0018%]
[INFO] ** appi_name:[21:99.9932%,30:0.004%,22:0.0006%,26:0.0004%,0:0.0004%,31:0.0002%,27:0.0002%,24:0.0002%,16:0.0002%,15:0.0002%,5:0.0002%,3:0.0002%]
[INFO] ** proxy_src_ip:[18:38.049%,20:26.1306%,13:18.2264%,6:17.587%,17:0.004%,10:0.0014%,11:0.001%,21:0.0002%,16:0.0002%,0:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9932%,-33.760870000000004:0.0066%,0.9188299999999999:0.0002%]
[INFO] ** modbus_function_description:[7:49.9974%,11:49.9958%,0:0.0066%,15:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.13%,1:20.8244%,5:18.2258%,4:17.5864%,2:17.2242%,0:0.0092%]
[INFO] ** service:[0.0048200000000000005:99.9942%,-211.73542999999998:0.004%,-211.08818:0.0006%,-186.44547:0.0004%,-211.08346:0.0004%,-186.43601999999998:0.0002%,-202.75898:0.0002%]
[INFO] ** s_port:[1.45442:26.1304%,-0.32151:20.8246%,-1.27613:18.226%,-0.23351:17.5866%,-0.33484:17.2244%,-71.33197:0.004%,-6.49859:0.0008%,-71.14931:0.0006%,-0.24151:0.0004%,-64.19493:0.0004%,-71.14798:0.0004%,-68.79874000000001:0.0002%,-1.81611:0.0002%,1.47576:0.0002%,-1.27347:0.0002%,-61.95768:0.0002%,-1.02014:0.0002%,-1.2708:0.0002%]
[INFO] ** classification:[normal:97.1716%,Single Stage Single Point:2.8284%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.740047729873657
tp :  42647.0
fp :  57353.0
tn :  342647.0
fn :  57353.0
accuracy :  0.7705878615379333
precision :  0.426470011472702
recall :  0.426470011472702
auc :  0.7505909204483032

y_eval {0: 100000}
pred {0: 42647, 1: 57353}
[INFO] confusion matrix for file 
[[42647 57353     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[ 813128 1352405       0       0       0]
 [ 204610       3       0       0       0]
 [  11523   15529       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.789773655700684
tp :  38135.0
fp :  61865.0
tn :  338135.0
fn :  61865.0
accuracy :  0.7525396347045898
precision :  0.38135001063346863
recall :  0.38135001063346863
auc :  0.7521001696586609

y_eval {0: 100000}
pred {0: 38135, 1: 61865}
[INFO] confusion matrix for file 
[[38135 61865     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[ 851263 1414270       0       0       0]
 [ 204610       3       0       0       0]
 [  11523   15529       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.7808851623535156
tp :  36969.0
fp :  63031.0
tn :  336969.0
fn :  63031.0
accuracy :  0.7478766441345215
precision :  0.3696900010108948
recall :  0.3696900010108948
auc :  0.7569551467895508

y_eval {0: 100000}
pred {0: 36969, 1: 63031}
[INFO] confusion matrix for file 
[[36969 63031     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[ 888232 1477301       0       0       0]
 [ 204610       3       0       0       0]
 [  11523   15529       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.710557405090332
tp :  38847.0
fp :  61153.0
tn :  338847.0
fn :  61153.0
accuracy :  0.7553882002830505
precision :  0.38846999406814575
recall :  0.38846999406814575
auc :  0.7649974822998047

y_eval {0: 100000}
pred {0: 38847, 1: 61153}
[INFO] confusion matrix for file 
[[38847 61153     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[ 927079 1538454       0       0       0]
 [ 204610       3       0       0       0]
 [  11523   15529       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 1 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.295215266418457
tp :  53378.0
fp :  46622.0
tn :  353378.0
fn :  46622.0
accuracy :  0.8135122060775757
precision :  0.5337799787521362
recall :  0.5337799787521362
auc :  0.8157564401626587

y_eval {0: 85858, 1: 14142}
pred {0: 45178, 1: 54822}
[INFO] confusion matrix for file 
[[42207 43651     0     0     0]
 [ 2971 11171     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[ 969286 1582105       0       0       0]
 [ 207581   11174       0       0       0]
 [  11523   15529       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-01_151435_117.log.part13_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1365 (0.273%)
[INFO] ** orig:[0:99.9986%,2:0.0014%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.998%,3:0.002%]
[INFO] ** i/f_dir:[1:99.998%,0:0.002%]
[INFO] ** src:[22:38.1186%,9:26.0918%,7:18.2288%,1:17.558%,21:0.0018%,14:0.0006%,15:0.0004%]
[INFO] ** dst:[21:43.3702%,10:20.8392%,8:18.2288%,9:17.5578%,15:0.002%,22:0.0012%,24:0.0004%,18:0.0002%,6:0.0002%]
[INFO] ** proto:[0:99.9976%,1:0.002%,2:0.0004%]
[INFO] ** appi_name:[21:99.9976%,30:0.002%,31:0.0002%,22:0.0002%]
[INFO] ** proxy_src_ip:[18:38.1186%,20:26.0918%,13:18.2288%,6:17.558%,17:0.002%,16:0.0004%,7:0.0004%]
[INFO] ** modbus_function_code:[0.02961:99.9976%,-33.760870000000004:0.0024%]
[INFO] ** modbus_function_description:[7:49.9998%,11:49.9978%,0:0.0024%]
[INFO] ** modbus_transaction_id:65534 (13.1068%)
[INFO] ** scada_tag:[3:26.0906%,1:20.839%,5:18.2282%,4:17.5572%,2:17.2792%,0:0.0058%]
[INFO] ** service:[0.0048200000000000005:99.9976%,-211.73542999999998:0.002%,-186.43601999999998:0.0002%,-211.08818:0.0002%]
[INFO] ** s_port:[1.45442:26.0908%,-0.32151:20.8392%,-1.27613:18.2284%,-0.23351:17.5576%,-0.33484:17.2794%,-71.33197:0.002%,1.45709:0.0006%,-1.27347:0.0004%,-1.02014:0.0004%,-0.24950999999999998:0.0002%,1.46509:0.0002%,1.47576:0.0002%,4.42897:0.0002%,-0.24151:0.0002%,-71.14931:0.0002%]
[INFO] ** classification:[normal:87.5394%,Single Stage Single Point:12.4606%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 1 0 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.9656854395866394
tp :  75849.0
fp :  24151.0
tn :  375849.0
fn :  24151.0
accuracy :  0.9033956527709961
precision :  0.7584900259971619
recall :  0.7584900259971619
auc :  0.9262917041778564

y_eval {0: 53028, 1: 46972}
pred {0: 42663, 1: 57337}
[INFO] confusion matrix for file 
[[35770 17258     0     0     0]
 [ 6893 40079     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1005056 1599363       0       0       0]
 [ 214474   51253       0       0       0]
 [  11523   15529       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.1554365427017212
tp :  51174.0
fp :  48826.0
tn :  351174.0
fn :  48826.0
accuracy :  0.8046958446502686
precision :  0.5117400288581848
recall :  0.5117400288581848
auc :  0.8117645382881165

y_eval {0: 84669, 1: 15331}
pred {0: 38127, 1: 61873}
[INFO] confusion matrix for file 
[[36985 47684     0     0     0]
 [ 1142 14189     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1042041 1647047       0       0       0]
 [ 215616   65442       0       0       0]
 [  11523   15529       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.7912942558288574
tp :  36945.0
fp :  63055.0
tn :  336945.0
fn :  63055.0
accuracy :  0.7477800250053406
precision :  0.36945000290870667
recall :  0.36945000290870667
auc :  0.756232738494873

y_eval {0: 100000}
pred {0: 36945, 1: 63055}
[INFO] confusion matrix for file 
[[36945 63055     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1078986 1710102       0       0       0]
 [ 215616   65442       0       0       0]
 [  11523   15529       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.7255010913848876
tp :  38733.0
fp :  61267.0
tn :  338733.0
fn :  61267.0
accuracy :  0.7549319267272949
precision :  0.38732999563217163
recall :  0.38732999563217163
auc :  0.7635502815246582

y_eval {0: 100000}
pred {0: 38733, 1: 61267}
[INFO] confusion matrix for file 
[[38733 61267     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1117719 1771369       0       0       0]
 [ 215616   65442       0       0       0]
 [  11523   15529       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.4961961071014405
tp :  44832.0
fp :  55168.0
tn :  344832.0
fn :  55168.0
accuracy :  0.7793279886245728
precision :  0.4483200013637543
recall :  0.4483200013637543
auc :  0.7814419865608215

y_eval {0: 100000}
pred {0: 44832, 1: 55168}
[INFO] confusion matrix for file 
[[44832 55168     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1162551 1826537       0       0       0]
 [ 215616   65442       0       0       0]
 [  11523   15529       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-01_203011_118.log.part06_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1366 (0.2732%)
[INFO] ** orig:[0:99.9988%,2:0.0008%,1:0.0004%]
[INFO] ** type:[0:99.9986%,1:0.001%,2:0.0004%]
[INFO] ** i/f_name:[2:99.998%,3:0.002%]
[INFO] ** i/f_dir:[1:99.9982%,0:0.0018%]
[INFO] ** src:[22:38.138%,9:26.0904%,7:18.1762%,1:17.5892%,10:0.0018%,11:0.0016%,14:0.0012%,21:0.0008%,15:0.0006%,4:0.0002%]
[INFO] ** dst:[21:43.3838%,10:20.845%,8:18.1758%,9:17.589%,15:0.002%,22:0.0014%,6:0.0014%,25:0.0004%,24:0.0004%,18:0.0004%,7:0.0004%]
[INFO] ** proto:[0:99.9954%,2:0.0026%,1:0.002%]
[INFO] ** appi_name:[21:99.9944%,30:0.002%,26:0.0008%,22:0.0006%,31:0.0004%,27:0.0004%,15:0.0004%,0:0.0004%,24:0.0002%,16:0.0002%,5:0.0002%]
[INFO] ** proxy_src_ip:[18:38.138%,20:26.0904%,13:18.1762%,6:17.5892%,17:0.002%,11:0.0018%,10:0.0016%,16:0.0006%,21:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9944%,-33.760870000000004:0.0052%,0.9188299999999999:0.0004%]
[INFO] ** modbus_function_description:[7:49.998%,11:49.9964%,0:0.0052%,15:0.0004%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.0894%,1:20.8438%,5:18.1758%,4:17.5888%,2:17.294%,0:0.0082%]
[INFO] ** service:[0.0048200000000000005:99.9954%,-211.73542999999998:0.002%,-211.08346:0.0008%,-211.08818:0.0006%,-186.44547:0.0004%,-186.43601999999998:0.0004%,-202.75898:0.0004%]
[INFO] ** s_port:[1.45442:26.0898%,-0.32151:20.844%,-1.27613:18.1758%,-0.23351:17.589%,-0.33484:17.294%,-71.33197:0.002%,-6.46392:0.0008%,-71.14798:0.0008%,1.45709:0.0006%,-71.14931:0.0006%,-1.02014:0.0006%,-1.27347:0.0004%,-68.79874000000001:0.0004%,-64.19493:0.0004%,-1.81611:0.0004%,-6.49859:0.0002%,-0.24151:0.0002%]
[INFO] ** classification:[normal:90.7904%,Single Stage Multi Point:5.7378%,Single Stage Single Point:3.4718%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.7441890605926513
tp :  42677.0
fp :  57323.0
tn :  342677.0
fn :  57323.0
accuracy :  0.7707079648971558
precision :  0.42677000164985657
recall :  0.42677000164985657
auc :  0.7505096197128296

y_eval {0: 100000}
pred {0: 42677, 1: 57323}
[INFO] confusion matrix for file 
[[42677 57323     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1205228 1883860       0       0       0]
 [ 215616   65442       0       0       0]
 [  11523   15529       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.791383239746094
tp :  38122.0
fp :  61878.0
tn :  338122.0
fn :  61878.0
accuracy :  0.7524878978729248
precision :  0.3812200129032135
recall :  0.3812200129032135
auc :  0.7524163722991943

y_eval {0: 100000}
pred {0: 38122, 1: 61878}
[INFO] confusion matrix for file 
[[38122 61878     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1243350 1945738       0       0       0]
 [ 215616   65442       0       0       0]
 [  11523   15529       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.7871344146728516
tp :  36985.0
fp :  63015.0
tn :  336985.0
fn :  63015.0
accuracy :  0.7479397654533386
precision :  0.3698500096797943
recall :  0.3698500096797943
auc :  0.7564067840576172

y_eval {0: 100000}
pred {0: 36985, 1: 63015}
[INFO] confusion matrix for file 
[[36985 63015     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1280335 2008753       0       0       0]
 [ 215616   65442       0       0       0]
 [  11523   15529       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.0302300548553465
tp :  55084.0
fp :  44916.0
tn :  355084.0
fn :  44916.0
accuracy :  0.8203360438346863
precision :  0.5508400201797485
recall :  0.5508400201797485
auc :  0.8285222053527832

y_eval {0: 82641, 1: 17359}
pred {0: 38791, 1: 61209}
[INFO] confusion matrix for file 
[[38258 44383     0     0     0]
 [  533 16826     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1318593 2053136       0       0       0]
 [ 216149   82268       0       0       0]
 [  11523   15529       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 2 2] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  5.99213413772583
tp :  40122.0
fp :  59878.0
tn :  340122.0
fn :  59878.0
accuracy :  0.7604877948760986
precision :  0.4012199938297272
recall :  0.4012199938297272
auc :  0.6980609893798828

y_eval {0: 71311, 2: 28689}
pred {0: 45000, 1: 55000}
[INFO] confusion matrix for file 
[[40122 31189     0     0     0]
 [    0     0     0     0     0]
 [ 4878 23811     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1358715 2084325       0       0       0]
 [ 216149   82268       0       0       0]
 [  16401   39340       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-01_203011_118.log.part07_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1366 (0.2732%)
[INFO] ** orig:[0:99.9996%,2:0.0004%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.9994%,3:0.0006%]
[INFO] ** i/f_dir:[1:99.9994%,0:0.0006%]
[INFO] ** src:[22:38.0718%,9:26.1174%,7:18.2344%,1:17.5754%,21:0.0008%,14:0.0002%]
[INFO] ** dst:[21:43.3758%,10:20.813%,8:18.2342%,9:17.5754%,15:0.0006%,22:0.0004%,24:0.0002%,18:0.0002%,6:0.0002%]
[INFO] ** proto:[0:99.999%,1:0.0006%,2:0.0004%]
[INFO] ** appi_name:[21:99.999%,30:0.0006%,31:0.0002%,22:0.0002%]
[INFO] ** proxy_src_ip:[18:38.0718%,20:26.1174%,13:18.2344%,6:17.5754%,17:0.0006%,7:0.0004%]
[INFO] ** modbus_function_code:[0.02961:99.999%,-33.760870000000004:0.001%]
[INFO] ** modbus_function_description:[7:49.9996%,11:49.9994%,0:0.001%]
[INFO] ** modbus_transaction_id:65301 (13.0602%)
[INFO] ** scada_tag:[3:26.1164%,1:20.813%,5:18.2338%,4:17.575%,2:17.2586%,0:0.0032%]
[INFO] ** service:[0.0048200000000000005:99.999%,-211.73542999999998:0.0006%,-186.43601999999998:0.0002%,-211.08818:0.0002%]
[INFO] ** s_port:[1.45442:26.1168%,-0.32151:20.813%,-1.27613:18.234%,-0.23351:17.5752%,-0.33484:17.2588%,-71.33197:0.0006%,-1.27347:0.0002%,1.45709:0.0002%,1.46509:0.0002%,1.47576:0.0002%,4.42897:0.0002%,-0.24151:0.0002%,-71.14931:0.0002%,-1.2708:0.0002%]
[INFO] ** classification:[normal:89.2092%,Single Stage Multi Point:10.7908%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [2 0 0 ... 2 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  8.33646636352539
tp :  35715.0
fp :  64285.0
tn :  335715.0
fn :  64285.0
accuracy :  0.7428600192070007
precision :  0.35714998841285706
recall :  0.35714998841285706
auc :  0.631596028804779

y_eval {0: 53027, 2: 46973}
pred {0: 42625, 1: 57375}
[INFO] confusion matrix for file 
[[35715 17312     0     0     0]
 [    0     0     0     0     0]
 [ 6910 40063     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1394430 2101637       0       0       0]
 [ 216149   82268       0       0       0]
 [  23311   79403       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 2 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  3.610630849075317
tp :  37724.0
fp :  62276.0
tn :  337724.0
fn :  62276.0
accuracy :  0.7508959174156189
precision :  0.37724000215530396
recall :  0.37724000215530396
auc :  0.7349808216094971

y_eval {0: 93019, 2: 6981}
pred {0: 38261, 1: 61739}
[INFO] confusion matrix for file 
[[37724 55295     0     0     0]
 [    0     0     0     0     0]
 [  537  6444     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1432154 2156932       0       0       0]
 [ 216149   82268       0       0       0]
 [  23848   85847       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.789380542373657
tp :  36915.0
fp :  63085.0
tn :  336915.0
fn :  63085.0
accuracy :  0.7476603984832764
precision :  0.3691500127315521
recall :  0.3691500127315521
auc :  0.7559597492218018

y_eval {0: 100000}
pred {0: 36915, 1: 63085}
[INFO] confusion matrix for file 
[[36915 63085     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1469069 2220017       0       0       0]
 [ 216149   82268       0       0       0]
 [  23848   85847       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.7124997287750245
tp :  38916.0
fp :  61084.0
tn :  338916.0
fn :  61084.0
accuracy :  0.7556642293930054
precision :  0.38916000723838806
recall :  0.38916000723838806
auc :  0.7645025849342346

y_eval {0: 100000}
pred {0: 38916, 1: 61084}
[INFO] confusion matrix for file 
[[38916 61084     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1507985 2281101       0       0       0]
 [ 216149   82268       0       0       0]
 [  23848   85847       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.5032660831451414
tp :  44761.0
fp :  55239.0
tn :  344761.0
fn :  55239.0
accuracy :  0.7790436744689941
precision :  0.4476099908351898
recall :  0.4476099908351898
auc :  0.7805317640304565

y_eval {0: 100000}
pred {0: 44761, 1: 55239}
[INFO] confusion matrix for file 
[[44761 55239     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1552746 2336340       0       0       0]
 [ 216149   82268       0       0       0]
 [  23848   85847       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-02_014558_119.log.part06_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1366 (0.2732%)
[INFO] ** orig:[0:99.997%,2:0.003%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.9964%,3:0.0036%]
[INFO] ** i/f_dir:[1:99.9964%,0:0.0036%]
[INFO] ** src:[22:38.0288%,9:26.1242%,7:18.2114%,1:17.6294%,21:0.003%,2:0.0008%,14:0.0006%,3:0.0006%,15:0.0004%,4:0.0004%,11:0.0002%,8:0.0002%]
[INFO] ** dst:[21:43.357%,10:20.7952%,8:18.2116%,9:17.629%,15:0.0036%,22:0.0012%,16:0.0008%,19:0.0004%,17:0.0004%,6:0.0004%,26:0.0002%,24:0.0002%]
[INFO] ** proto:[0:99.9958%,1:0.0036%,2:0.0006%]
[INFO] ** appi_name:[21:99.9942%,30:0.0036%,17:0.0008%,22:0.0004%,28:0.0002%,26:0.0002%,23:0.0002%,18:0.0002%,7:0.0002%]
[INFO] ** proxy_src_ip:[18:38.0288%,20:26.1242%,13:18.2114%,6:17.6294%,17:0.0036%,14:0.0008%,1:0.0006%,21:0.0004%,16:0.0004%,10:0.0002%,0:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9942%,-33.760870000000004:0.0058%]
[INFO] ** modbus_function_description:[7:49.9974%,11:49.9968%,0:0.0058%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.123%,1:20.7952%,5:18.211%,4:17.6288%,2:17.2336%,0:0.0084%]
[INFO] ** service:[0.0048200000000000005:99.9942%,-211.73542999999998:0.0036%,-205.44247:0.0008%,-211.07873999999998:0.0004%,-211.08818:0.0004%,-211.09762999999998:0.0002%,-211.08346:0.0002%,-185.9872:0.0002%]
[INFO] ** s_port:[1.45442:26.1234%,-0.32151:20.7952%,-1.27613:18.2112%,-0.23351:17.629%,-0.33484:17.2336%,-71.33197:0.0036%,1.45709:0.0006%,9.89942:0.0004%,-1.02014:0.0004%,-71.14931:0.0004%,-58.035180000000004:0.0002%,-5.1466400000000005:0.0002%,-0.24151:0.0002%,-5.08665:0.0002%,1.46509:0.0002%,-71.14798:0.0002%,-0.24950999999999998:0.0002%,2.05573:0.0002%,-43.76509:0.0002%,-1.27347:0.0002%,-58.032509999999995:0.0002%]
[INFO] ** classification:[normal:81.41%,Single Stage Single Point:18.59%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 1 0 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.473677464389801
tp :  66838.0
fp :  33162.0
tn :  366838.0
fn :  33162.0
accuracy :  0.8673518896102905
precision :  0.6683800220489502
recall :  0.6683800220489502
auc :  0.8745083212852478

y_eval {0: 67398, 1: 32602}
pred {0: 42780, 1: 57220}
[INFO] confusion matrix for file 
[[38508 28890     0     0     0]
 [ 4272 28330     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1591254 2365230       0       0       0]
 [ 220421  110598       0       0       0]
 [  23848   85847       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 1 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.808240346622467
tp :  80464.0
fp :  19536.0
tn :  380464.0
fn :  19536.0
accuracy :  0.9218561053276062
precision :  0.804639995098114
recall :  0.804639995098114
auc :  0.9359248876571655

y_eval {0: 53052, 1: 46948}
pred {0: 38170, 1: 61830}
[INFO] confusion matrix for file 
[[35843 17209     0     0     0]
 [ 2327 44621     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1627097 2382439       0       0       0]
 [ 222748  155219       0       0       0]
 [  23848   85847       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.215920381736755
tp :  49868.0
fp :  50132.0
tn :  349868.0
fn :  50132.0
accuracy :  0.7994723320007324
precision :  0.4986799955368042
recall :  0.4986799955368042
auc :  0.8084182739257812

y_eval {0: 86600, 1: 13400}
pred {0: 37068, 1: 62932}
[INFO] confusion matrix for file 
[[36768 49832     0     0     0]
 [  300 13100     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1663865 2432271       0       0       0]
 [ 223048  168319       0       0       0]
 [  23848   85847       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.724310662841797
tp :  38809.0
fp :  61191.0
tn :  338809.0
fn :  61191.0
accuracy :  0.7552361488342285
precision :  0.38809001445770264
recall :  0.38809001445770264
auc :  0.7635759115219116

y_eval {0: 100000}
pred {0: 38809, 1: 61191}
[INFO] confusion matrix for file 
[[38809 61191     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1702674 2493462       0       0       0]
 [ 223048  168319       0       0       0]
 [  23848   85847       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.4897381229400635
tp :  45120.0
fp :  54880.0
tn :  345120.0
fn :  54880.0
accuracy :  0.7804797887802124
precision :  0.451200008392334
recall :  0.451200008392334
auc :  0.7821550965309143

y_eval {0: 100000}
pred {0: 45120, 1: 54880}
[INFO] confusion matrix for file 
[[45120 54880     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1747794 2548342       0       0       0]
 [ 223048  168319       0       0       0]
 [  23848   85847       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-02_121729_121.log.part12_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1368 (0.2736%)
[INFO] ** orig:[0:99.9986%,1:0.0008%,2:0.0006%]
[INFO] ** type:[0:99.9984%,1:0.0014%,2:0.0002%]
[INFO] ** i/f_name:[2:99.9978%,3:0.0022%]
[INFO] ** i/f_dir:[1:99.998%,0:0.002%]
[INFO] ** src:[22:38.1136%,9:26.1176%,7:18.2158%,1:17.5472%,14:0.0016%,11:0.0014%,10:0.001%,21:0.0006%,15:0.0004%,2:0.0004%,4:0.0002%,3:0.0002%]
[INFO] ** dst:[21:43.4022%,10:20.8284%,8:18.2156%,9:17.547%,15:0.0022%,22:0.002%,6:0.0008%,26:0.0004%,25:0.0004%,19:0.0004%,24:0.0002%,18:0.0002%,7:0.0002%]
[INFO] ** proto:[0:99.996%,1:0.0022%,2:0.0018%]
[INFO] ** appi_name:[21:99.9946%,30:0.0022%,22:0.0006%,26:0.0004%,0:0.0004%,31:0.0002%,27:0.0002%,24:0.0002%,23:0.0002%,18:0.0002%,16:0.0002%,15:0.0002%,14:0.0002%,5:0.0002%]
[INFO] ** proxy_src_ip:[18:38.1136%,20:26.1176%,13:18.2158%,6:17.5472%,17:0.0022%,10:0.0014%,11:0.001%,16:0.0004%,14:0.0004%,21:0.0002%,1:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9946%,-33.760870000000004:0.0052%,0.9188299999999999:0.0002%]
[INFO] ** modbus_function_description:[7:49.9984%,11:49.9962%,0:0.0052%,15:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.1164%,1:20.8284%,5:18.2154%,4:17.5466%,2:17.285%,0:0.0082%]
[INFO] ** service:[0.0048200000000000005:99.9954%,-211.73542999999998:0.0022%,-211.08818:0.0006%,-186.44547:0.0004%,-211.08346:0.0004%,-211.07873999999998:0.0004%,-186.42657:0.0002%,-186.43601999999998:0.0002%,-202.75898:0.0002%]
[INFO] ** s_port:[1.45442:26.1168%,-0.32151:20.8284%,-1.27613:18.2154%,-0.23351:17.5468%,-0.33484:17.2852%,-71.33197:0.0022%,-10.59042:0.0008%,-71.14931:0.0006%,-64.19493:0.0004%,-1.02014:0.0004%,-0.24151:0.0004%,-71.14798:0.0004%,1.45709:0.0004%,10.54739:0.0004%,1.47576:0.0002%,1.46509:0.0002%,-1.27347:0.0002%,-68.79874000000001:0.0002%,13.34061:0.0002%,-1.2708:0.0002%,15.264529999999999:0.0002%]
[INFO] ** classification:[normal:99.9996%,Single Stage Multi Point:0.0004%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.7369491344451906
tp :  42734.0
fp :  57266.0
tn :  342734.0
fn :  57266.0
accuracy :  0.7709360718727112
precision :  0.42734000086784363
recall :  0.42734000086784363
auc :  0.7507588267326355

y_eval {0: 100000}
pred {0: 42734, 1: 57266}
[INFO] confusion matrix for file 
[[42734 57266     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1790528 2605608       0       0       0]
 [ 223048  168319       0       0       0]
 [  23848   85847       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.792223826980591
tp :  38111.0
fp :  61889.0
tn :  338111.0
fn :  61889.0
accuracy :  0.7524440884590149
precision :  0.3811100125312805
recall :  0.3811100125312805
auc :  0.7519680261611938

y_eval {0: 100000}
pred {0: 38111, 1: 61889}
[INFO] confusion matrix for file 
[[38111 61889     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1828639 2667497       0       0       0]
 [ 223048  168319       0       0       0]
 [  23848   85847       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.791826800918579
tp :  36928.0
fp :  63072.0
tn :  336928.0
fn :  63072.0
accuracy :  0.7477124929428101
precision :  0.36928001046180725
recall :  0.36928001046180725
auc :  0.7562248706817627

y_eval {0: 100000}
pred {0: 36928, 1: 63072}
[INFO] confusion matrix for file 
[[36928 63072     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1865567 2730569       0       0       0]
 [ 223048  168319       0       0       0]
 [  23848   85847       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.721355051803589
tp :  38749.0
fp :  61251.0
tn :  338749.0
fn :  61251.0
accuracy :  0.7549961805343628
precision :  0.38749000430107117
recall :  0.38749000430107117
auc :  0.7641751766204834

y_eval {0: 100000}
pred {0: 38749, 1: 61251}
[INFO] confusion matrix for file 
[[38749 61251     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1904316 2791820       0       0       0]
 [ 223048  168319       0       0       0]
 [  23848   85847       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.4998237995147705
tp :  44969.0
fp :  55031.0
tn :  344969.0
fn :  55031.0
accuracy :  0.7798761129379272
precision :  0.4496900141239166
recall :  0.4496900141239166
auc :  0.7811619639396667

y_eval {0: 99998, 2: 2}
pred {0: 44969, 1: 55031}
[INFO] confusion matrix for file 
[[44969 55029     0     0     0]
 [    0     0     0     0     0]
 [    0     2     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1949285 2846849       0       0       0]
 [ 223048  168319       0       0       0]
 [  23848   85849       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-02_121729_121.log.part13_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1368 (0.2736%)
[INFO] ** orig:[0:99.9996%,2:0.0004%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.9994%,3:0.0006%]
[INFO] ** i/f_dir:[1:99.9994%,0:0.0006%]
[INFO] ** src:[22:38.162%,9:26.1664%,7:18.0742%,1:17.5958%,21:0.0008%,17:0.0002%,15:0.0002%,14:0.0002%,8:0.0002%]
[INFO] ** dst:[21:43.4352%,10:20.8932%,8:18.0744%,9:17.5952%,22:0.0006%,18:0.0006%,15:0.0006%,6:0.0002%]
[INFO] ** proto:[0:99.9986%,2:0.0008%,1:0.0006%]
[INFO] ** appi_name:[21:99.9986%,31:0.0006%,30:0.0006%,22:0.0002%]
[INFO] ** proxy_src_ip:[18:38.162%,20:26.1664%,13:18.0742%,6:17.5958%,17:0.0006%,7:0.0004%,16:0.0002%,2:0.0002%,0:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9986%,-33.760870000000004:0.0014%]
[INFO] ** modbus_function_description:[7:49.9998%,11:49.9988%,0:0.0014%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.166%,1:20.893%,5:18.0738%,4:17.5948%,2:17.2688%,0:0.0036%]
[INFO] ** service:[0.0048200000000000005:99.9986%,-211.73542999999998:0.0006%,-186.43601999999998:0.0006%,-211.08818:0.0002%]
[INFO] ** s_port:[1.45442:26.1662%,-0.32151:20.8932%,-1.27613:18.074%,-0.23351:17.5952%,-0.33484:17.2688%,-71.33197:0.0006%,15.43653:0.0004%,-0.24151:0.0004%,-0.24950999999999998:0.0002%,1.46509:0.0002%,4.42897:0.0002%,-71.14931:0.0002%,-1.02014:0.0002%,-1.2708:0.0002%]
[INFO] ** classification:[normal:92.8338%,Multi Stage Single Point:7.1662%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.750564108276367
tp :  42496.0
fp :  57504.0
tn :  342496.0
fn :  57504.0
accuracy :  0.7699841260910034
precision :  0.4249599874019623
recall :  0.4249599874019623
auc :  0.7498127818107605

y_eval {0: 100000}
pred {0: 42496, 1: 57504}
[INFO] confusion matrix for file 
[[42496 57504     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1991781 2904353       0       0       0]
 [ 223048  168319       0       0       0]
 [  23848   85849       0       0       0]
 [      0       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  4.604082204437256
tp :  26944.0
fp :  73056.0
tn :  326944.0
fn :  73056.0
accuracy :  0.7077761888504028
precision :  0.2694399952888489
recall :  0.2694399952888489
auc :  0.6720898151397705

y_eval {0: 88734, 3: 11266}
pred {0: 38210, 1: 61790}
[INFO] confusion matrix for file 
[[26944 61790     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [11266     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2018725 2966143       0       0       0]
 [ 223048  168319       0       0       0]
 [  23848   85849       0       0       0]
 [  11266       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  4.003071850967407
tp :  29340.0
fp :  70660.0
tn :  329340.0
fn :  70660.0
accuracy :  0.7173598408699036
precision :  0.29339998960494995
recall :  0.29339998960494995
auc :  0.7030290365219116

y_eval {0: 92435, 3: 7565}
pred {0: 36905, 1: 63095}
[INFO] confusion matrix for file 
[[29340 63095     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [ 7565     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2048065 3029238       0       0       0]
 [ 223048  168319       0       0       0]
 [  23848   85849       0       0       0]
 [  18831       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.7191665359497073
tp :  38667.0
fp :  61333.0
tn :  338667.0
fn :  61333.0
accuracy :  0.7546677589416504
precision :  0.38666999340057373
recall :  0.38666999340057373
auc :  0.7645395994186401

y_eval {0: 100000}
pred {0: 38667, 1: 61333}
[INFO] confusion matrix for file 
[[38667 61333     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2086732 3090571       0       0       0]
 [ 223048  168319       0       0       0]
 [  23848   85849       0       0       0]
 [  18831       0       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  5.223651742553711
tp :  28114.0
fp :  71886.0
tn :  328114.0
fn :  71886.0
accuracy :  0.7124559283256531
precision :  0.281139999628067
recall :  0.281139999628067
auc :  0.6640880703926086

y_eval {0: 83000, 3: 17000}
pred {0: 45112, 1: 54888}
[INFO] confusion matrix for file 
[[28114 54886     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [16998     2     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2114846 3145457       0       0       0]
 [ 223048  168319       0       0       0]
 [  23848   85849       0       0       0]
 [  35829       2       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-02_121729_121.log.part14_sorted-labeled.csv
[INFO] process dataset, shape: (439824, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (439824, 17)

[INFO] analyzing data
[INFO] 439824 rows
[INFO] ** unixtime:1201 (0.27306%)
[INFO] ** orig:[0:99.99955%,2:0.00045%]
[INFO] ** type:[0:99.99977%,1:0.00023%]
[INFO] ** i/f_name:[2:99.99864%,3:0.00136%]
[INFO] ** i/f_dir:[1:99.99886%,0:0.00114%]
[INFO] ** src:[22:38.09456%,9:26.09703%,7:18.22161%,1:17.58408%,14:0.00091%,21:0.00068%,15:0.00068%,4:0.00023%,3:0.00023%]
[INFO] ** dst:[21:43.35416%,10:20.83674%,8:18.22115%,9:17.58385%,22:0.00159%,15:0.00136%,24:0.00045%,25:0.00023%,6:0.00023%,2:0.00023%]
[INFO] ** proto:[0:99.99818%,1:0.00136%,2:0.00045%]
[INFO] ** appi_name:[21:99.99795%,30:0.00136%,26:0.00023%,8:0.00023%,0:0.00023%]
[INFO] ** proxy_src_ip:[18:38.09456%,20:26.09703%,13:18.22161%,6:17.58408%,17:0.00136%,16:0.00068%,21:0.00023%,7:0.00023%,1:0.00023%]
[INFO] ** modbus_function_code:[0.02961:99.99795%,-33.760870000000004:0.00205%]
[INFO] ** modbus_function_description:[7:49.99955%,11:49.99841%,0:0.00205%]
[INFO] ** modbus_transaction_id:65536 (14.90051%)
[INFO] ** scada_tag:[3:26.09612%,1:20.83652%,5:18.22092%,4:17.5834%,2:17.25758%,0:0.00546%]
[INFO] ** service:[0.0048200000000000005:99.99795%,-211.73542999999998:0.00136%,-186.44547:0.00023%,-211.08346:0.00023%,-211.35747999999998:0.00023%]
[INFO] ** s_port:[1.45442:26.09635%,-0.32151:20.83674%,-1.27613:18.22115%,-0.23351:17.58362%,-0.33484:17.25781%,-71.33197:0.00136%,-1.02014:0.00068%,-1.27347:0.00045%,1.45709:0.00045%,-0.24151:0.00045%,-71.14798:0.00023%,1.47576:0.00023%,-64.19493:0.00023%,-1.2708:0.00023%]
[INFO] ** classification:[normal:93.34597%,Single Stage Single Point:4.48861%,Multi Stage Single Point:2.16541%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [3 0 0 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  4.883872039794922
tp :  28928.0
fp :  71072.0
tn :  328928.0
fn :  71072.0
accuracy :  0.7157118916511536
precision :  0.2892799973487854
recall :  0.2892799973487854
auc :  0.6572420001029968

y_eval {0: 86777, 1: 3699, 3: 9524}
pred {0: 42151, 1: 57849}
[INFO] confusion matrix for file 
[[28928 57849     0     0     0]
 [ 3699     0     0     0     0]
 [    0     0     0     0     0]
 [ 9524     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2143774 3203306       0       0       0]
 [ 226747  168319       0       0       0]
 [  23848   85849       0       0       0]
 [  45353       2       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 100000-200000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  5.374672941589355
tp :  21678.0
fp :  78322.0
tn :  321678.0
fn :  78322.0
accuracy :  0.6867120265960693
precision :  0.21678000688552856
recall :  0.21678000688552856
auc :  0.6395436525344849

y_eval {0: 83957, 1: 16043}
pred {0: 37721, 1: 62279}
[INFO] confusion matrix for file 
[[21678 62279     0     0     0]
 [16043     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2165452 3265585       0       0       0]
 [ 242790  168319       0       0       0]
 [  23848   85849       0       0       0]
 [  45353       2       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 200000-300000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.772195473098755
tp :  37298.0
fp :  62702.0
tn :  337298.0
fn :  62702.0
accuracy :  0.7491917014122009
precision :  0.372979998588562
recall :  0.372979998588562
auc :  0.7586499452590942

y_eval {0: 100000}
pred {0: 37298, 1: 62702}
[INFO] confusion matrix for file 
[[37298 62702     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2202750 3328287       0       0       0]
 [ 242790  168319       0       0       0]
 [  23848   85849       0       0       0]
 [  45353       2       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 300000-400000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.6278807468414307
tp :  41150.0
fp :  58850.0
tn :  341150.0
fn :  58850.0
accuracy :  0.7645999193191528
precision :  0.4115000069141388
recall :  0.4115000069141388
auc :  0.7714413404464722

y_eval {0: 100000}
pred {0: 41150, 1: 58850}
[INFO] confusion matrix for file 
[[41150 58850     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2243900 3387137       0       0       0]
 [ 242790  168319       0       0       0]
 [  23848   85849       0       0       0]
 [  45353       2       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 400000-500000/439824
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-02_172943_122.log.part03_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1376 (0.2752%)
[INFO] ** orig:[0:99.9976%,2:0.002%,1:0.0004%]
[INFO] ** type:[0:99.9988%,1:0.001%,2:0.0002%]
[INFO] ** i/f_name:[2:99.9944%,3:0.0056%]
[INFO] ** i/f_dir:[1:99.9946%,0:0.0054%]
[INFO] ** src:[22:38.2234%,9:26.124%,7:18.075%,1:17.571%,14:0.0036%,21:0.0022%,2:0.0004%,11:0.0002%,10:0.0002%]
[INFO] ** dst:[21:43.4342%,10:20.913%,8:18.0748%,9:17.5708%,15:0.0056%,22:0.0006%,25:0.0004%,24:0.0002%,18:0.0002%,7:0.0002%]
[INFO] ** proto:[0:99.9936%,1:0.0056%,2:0.0008%]
[INFO] ** appi_name:[21:99.9934%,30:0.0056%,0:0.0004%,31:0.0002%,27:0.0002%,15:0.0002%]
[INFO] ** proxy_src_ip:[18:38.2234%,20:26.124%,13:18.075%,6:17.571%,17:0.0056%,14:0.0004%,11:0.0002%,10:0.0002%,7:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9934%,-33.760870000000004:0.0064%,0.9188299999999999:0.0002%]
[INFO] ** modbus_function_description:[7:49.997%,11:49.9964%,0:0.0064%,15:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.1234%,1:20.9128%,5:18.0748%,4:17.5704%,2:17.3102%,0:0.0084%]
[INFO] ** service:[0.0048200000000000005:99.9936%,-211.73542999999998:0.0056%,-186.44547:0.0004%,-186.43601999999998:0.0002%,-202.75898:0.0002%]
[INFO] ** s_port:[1.45442:26.1238%,-0.32151:20.913%,-1.27613:18.0748%,-0.23351:17.5706%,-0.33484:17.3104%,-71.33197:0.0056%,-0.24151:0.0004%,-64.19493:0.0004%,-1.27347:0.0002%,-10.59042:0.0002%,11.862:0.0002%,1.47576:0.0002%,13.431270000000001:0.0002%]
[INFO] ** classification:[normal:94.9296%,Single Stage Single Point:5.0704%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.748193391418457
tp :  42673.0
fp :  57327.0
tn :  342673.0
fn :  57327.0
accuracy :  0.7706918716430664
precision :  0.4267300069332123
recall :  0.4267300069332123
auc :  0.7497928738594055

y_eval {0: 100000}
pred {0: 42673, 1: 57327}
[INFO] confusion matrix for file 
[[42673 57327     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2286573 3444464       0       0       0]
 [ 242790  168319       0       0       0]
 [  23848   85849       0       0       0]
 [  45353       2       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.788598225402832
tp :  38135.0
fp :  61865.0
tn :  338135.0
fn :  61865.0
accuracy :  0.7525399923324585
precision :  0.38135001063346863
recall :  0.38135001063346863
auc :  0.7522846460342407

y_eval {0: 100000}
pred {0: 38135, 1: 61865}
[INFO] confusion matrix for file 
[[38135 61865     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2324708 3506329       0       0       0]
 [ 242790  168319       0       0       0]
 [  23848   85849       0       0       0]
 [  45353       2       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.7858111610412597
tp :  36947.0
fp :  63053.0
tn :  336947.0
fn :  63053.0
accuracy :  0.7477879524230957
precision :  0.3694700002670288
recall :  0.3694700002670288
auc :  0.7564021944999695

y_eval {0: 100000}
pred {0: 36947, 1: 63053}
[INFO] confusion matrix for file 
[[36947 63053     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2361655 3569382       0       0       0]
 [ 242790  168319       0       0       0]
 [  23848   85849       0       0       0]
 [  45353       2       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.7208641426086424
tp :  38567.0
fp :  61433.0
tn :  338567.0
fn :  61433.0
accuracy :  0.7542679905891418
precision :  0.385670006275177
recall :  0.385670006275177
auc :  0.7645424604415894

y_eval {0: 100000}
pred {0: 38567, 1: 61433}
[INFO] confusion matrix for file 
[[38567 61433     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2400222 3630815       0       0       0]
 [ 242790  168319       0       0       0]
 [  23848   85849       0       0       0]
 [  45353       2       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  6.5710751289367675
tp :  19658.0
fp :  80342.0
tn :  319658.0
fn :  80342.0
accuracy :  0.6786320805549622
precision :  0.19657999277114868
recall :  0.19657999277114868
auc :  0.6057095527648926

y_eval {0: 74648, 1: 25352}
pred {0: 45010, 1: 54990}
[INFO] confusion matrix for file 
[[19658 54990     0     0     0]
 [25352     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2419880 3685805       0       0       0]
 [ 268142  168319       0       0       0]
 [  23848   85849       0       0       0]
 [  45353       2       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-02_172943_122.log.part04_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1377 (0.2754%)
[INFO] ** orig:[0:99.995%,2:0.005%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.9944%,3:0.0056%]
[INFO] ** i/f_dir:[1:99.9944%,0:0.0056%]
[INFO] ** src:[22:38.203%,9:26.1368%,7:18.1014%,1:17.5508%,21:0.005%,3:0.0008%,15:0.0006%,14:0.0006%,4:0.0004%,2:0.0004%,8:0.0002%]
[INFO] ** dst:[21:43.4462%,10:20.893%,8:18.1012%,9:17.5504%,15:0.0056%,22:0.0016%,16:0.0008%,6:0.0006%,17:0.0004%,24:0.0002%]
[INFO] ** proto:[0:99.9938%,1:0.0056%,2:0.0006%]
[INFO] ** appi_name:[21:99.9926%,30:0.0056%,17:0.0008%,26:0.0004%,28:0.0002%,22:0.0002%,7:0.0002%]
[INFO] ** proxy_src_ip:[18:38.203%,20:26.1368%,13:18.1014%,6:17.5508%,17:0.0056%,1:0.0008%,16:0.0006%,21:0.0004%,14:0.0004%,0:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9926%,-33.760870000000004:0.0074%]
[INFO] ** modbus_function_description:[7:49.9972%,11:49.9954%,0:0.0074%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.1358%,1:20.8928%,5:18.1008%,4:17.55%,2:17.31%,0:0.0106%]
[INFO] ** service:[0.0048200000000000005:99.9926%,-211.73542999999998:0.0056%,-205.44247:0.0008%,-211.08346:0.0004%,-211.09762999999998:0.0002%,-185.9872:0.0002%,-211.08818:0.0002%]
[INFO] ** s_port:[1.45442:26.136%,-0.32151:20.893%,-1.27613:18.101%,-0.23351:17.5502%,-0.33484:17.31%,-71.33197:0.0056%,1.45709:0.0006%,-1.02014:0.0006%,-71.14798:0.0004%,-0.24151:0.0004%,-5.1466400000000005:0.0002%,-58.035180000000004:0.0002%,-1.2708:0.0002%,-71.14931:0.0002%,1.47576:0.0002%,-1.27347:0.0002%,-5.08665:0.0002%,-0.24950999999999998:0.0002%,2.05573:0.0002%,-43.76509:0.0002%,-58.032509999999995:0.0002%]
[INFO] ** classification:[normal:64.3482%,Single Stage Single Point:35.6518%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  8.476987084960937
tp :  6914.0
fp :  93086.0
tn :  306914.0
fn :  93086.0
accuracy :  0.6276559233665466
precision :  0.0691400021314621
recall :  0.0691400021314621
auc :  0.49996912479400635

y_eval {0: 64457, 1: 35543}
pred {0: 42457, 1: 57543}
[INFO] confusion matrix for file 
[[ 6914 57543     0     0     0]
 [35543     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2426794 3743348       0       0       0]
 [ 303685  168319       0       0       0]
 [  23848   85849       0       0       0]
 [  45353       2       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  8.50444882965088
tp :  2384.0
fp :  97616.0
tn :  302384.0
fn :  97616.0
accuracy :  0.6095362901687622
precision :  0.023840000852942467
recall :  0.023840000852942467
auc :  0.5009707808494568

y_eval {0: 64588, 1: 35412}
pred {0: 37796, 1: 62204}
[INFO] confusion matrix for file 
[[ 2384 62204     0     0     0]
 [35412     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2429178 3805552       0       0       0]
 [ 339097  168319       0       0       0]
 [  23848   85849       0       0       0]
 [  45353       2       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  8.55183641204834
tp :  1183.0
fp :  98817.0
tn :  301183.0
fn :  98817.0
accuracy :  0.6047318577766418
precision :  0.011830000206828117
recall :  0.011830000206828117
auc :  0.5027847290039062

y_eval {0: 64276, 1: 35724}
pred {0: 36907, 1: 63093}
[INFO] confusion matrix for file 
[[ 1183 63093     0     0     0]
 [35724     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2430361 3868645       0       0       0]
 [ 374821  168319       0       0       0]
 [  23848   85849       0       0       0]
 [  45353       2       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 1 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  8.472188745117187
tp :  3008.0
fp :  96992.0
tn :  303008.0
fn :  96992.0
accuracy :  0.6120322346687317
precision :  0.030079999938607216
recall :  0.030079999938607216
auc :  0.512600302696228

y_eval {0: 64281, 1: 35719}
pred {0: 38727, 1: 61273}
[INFO] confusion matrix for file 
[[ 3008 61273     0     0     0]
 [35719     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2433369 3929918       0       0       0]
 [ 410540  168319       0       0       0]
 [  23848   85849       0       0       0]
 [  45353       2       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 0 ... 1 1 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  8.26898226928711
tp :  9305.0
fp :  90695.0
tn :  309305.0
fn :  90695.0
accuracy :  0.637220025062561
precision :  0.09305000305175781
recall :  0.09305000305175781
auc :  0.5318381190299988

y_eval {0: 64139, 1: 35861}
pred {0: 45166, 1: 54834}
[INFO] confusion matrix for file 
[[ 9305 54834     0     0     0]
 [35861     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2442674 3984752       0       0       0]
 [ 446401  168319       0       0       0]
 [  23848   85849       0       0       0]
 [  45353       2       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-02_172943_122.log.part05_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1367 (0.2734%)
[INFO] ** orig:[0:99.9992%,2:0.0008%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.9984%,3:0.0016%]
[INFO] ** i/f_dir:[1:99.9984%,0:0.0016%]
[INFO] ** src:[22:38.0648%,9:26.1164%,7:18.2044%,1:17.6118%,21:0.001%,14:0.0008%,3:0.0004%,2:0.0004%]
[INFO] ** dst:[21:43.368%,10:20.8128%,8:18.2044%,9:17.6114%,15:0.0016%,22:0.0006%,16:0.0004%,24:0.0002%,18:0.0002%,6:0.0002%,2:0.0002%]
[INFO] ** proto:[0:99.998%,1:0.0016%,2:0.0004%]
[INFO] ** appi_name:[21:99.9974%,30:0.0016%,7:0.0006%,31:0.0002%,22:0.0002%]
[INFO] ** proxy_src_ip:[18:38.0648%,20:26.1164%,13:18.2044%,6:17.6118%,17:0.0016%,14:0.0004%,1:0.0004%,7:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9974%,-33.760870000000004:0.0026%]
[INFO] ** modbus_function_description:[7:49.9992%,11:49.9982%,0:0.0026%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.1154%,1:20.8126%,5:18.204%,4:17.6112%,2:17.2518%,0:0.005%]
[INFO] ** service:[0.0048200000000000005:99.9974%,-211.73542999999998:0.0016%,-211.09762999999998:0.0006%,-186.43601999999998:0.0002%,-211.08818:0.0002%]
[INFO] ** s_port:[1.45442:26.1158%,-0.32151:20.8128%,-1.27613:18.204%,-0.23351:17.6114%,-0.33484:17.252%,-71.33197:0.0016%,1.45709:0.0004%,-1.2708:0.0002%,-71.14931:0.0002%,-0.24151:0.0002%,-2.02544:0.0002%,1.46509:0.0002%,10.73138:0.0002%,-0.24950999999999998:0.0002%,14.88321:0.0002%,-1.27347:0.0002%,-2.81074:0.0002%]
[INFO] ** classification:[normal:97.0224%,Single Stage Single Point:2.9776%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  5.148600673675537
tp :  27727.0
fp :  72273.0
tn :  327727.0
fn :  72273.0
accuracy :  0.7109079957008362
precision :  0.27726998925209045
recall :  0.27726998925209045
auc :  0.6452078223228455

y_eval {0: 85112, 1: 14888}
pred {0: 42615, 1: 57385}
[INFO] confusion matrix for file 
[[27727 57385     0     0     0]
 [14888     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2470401 4042137       0       0       0]
 [ 461289  168319       0       0       0]
 [  23848   85849       0       0       0]
 [  45353       2       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.790295202636719
tp :  38184.0
fp :  61816.0
tn :  338184.0
fn :  61816.0
accuracy :  0.7527361512184143
precision :  0.3818399906158447
recall :  0.3818399906158447
auc :  0.7522786855697632

y_eval {0: 100000}
pred {0: 38184, 1: 61816}
[INFO] confusion matrix for file 
[[38184 61816     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2508585 4103953       0       0       0]
 [ 461289  168319       0       0       0]
 [  23848   85849       0       0       0]
 [  45353       2       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.787267420196533
tp :  37051.0
fp : Using TensorFlow backend.
 62949.0
tn :  337051.0
fn :  62949.0
accuracy :  0.7482040524482727
precision :  0.3705100119113922
recall :  0.3705100119113922
auc :  0.7558563947677612

y_eval {0: 100000}
pred {0: 37051, 1: 62949}
[INFO] confusion matrix for file 
[[37051 62949     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2545636 4166902       0       0       0]
 [ 461289  168319       0       0       0]
 [  23848   85849       0       0       0]
 [  45353       2       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.720228601074219
tp :  38832.0
fp :  61168.0
tn :  338832.0
fn :  61168.0
accuracy :  0.7553281188011169
precision :  0.3883199989795685
recall :  0.3883199989795685
auc :  0.7639711499214172

y_eval {0: 100000}
pred {0: 38832, 1: 61168}
[INFO] confusion matrix for file 
[[38832 61168     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2584468 4228070       0       0       0]
 [ 461289  168319       0       0       0]
 [  23848   85849       0       0       0]
 [  45353       2       0       0       0]
 [  18346  184456       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.4923825202941896
tp :  44907.0
fp :  55093.0
tn :  344907.0
fn :  55093.0
accuracy :  0.7796280980110168
precision :  0.449070006608963
recall :  0.449070006608963
auc :  0.7817882299423218

y_eval {0: 100000}
pred {0: 44907, 1: 55093}
[INFO] confusion matrix for file 
[[44907 55093     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2629375 4283163       0       0       0]
 [ 461289  168319       0       0       0]
 [  23848   85849       0       0       0]
 [  45353       2       0       0       0]
 [  18346  184456       0       0       0]]
--- 212.8164324760437 seconds ---
