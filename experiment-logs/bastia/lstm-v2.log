2020-02-03 08:49:57.772392: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-02-03 08:49:57.772570: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-02-03 08:49:57.772585: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-02-03 08:49:58.571289: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-02-03 08:49:58.571345: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-02-03 08:49:58.571375: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (***REMOVED***): /proc/driver/nvidia/version does not exist
2020-02-03 08:49:58.571524: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-03 08:49:58.580316: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2112050000 Hz
2020-02-03 08:49:58.581823: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x49d8720 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-03 08:49:58.581876: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-02-03 08:50:02.297992: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-03 08:50:02.315309: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 08:50:02.323030: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 08:50:02.385758: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-03 08:50:02.389580: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-03 08:50:02.395092: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 08:50:02.400595: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 08:50:02.414545: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-03 08:50:06.162769: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-03 08:50:06.166937: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 08:50:06.168794: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 08:50:06.182966: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-03 08:50:06.183941: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-03 08:50:06.185345: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 08:50:06.186705: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 08:50:06.190452: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
=============================
        TRAINING v0.3
=============================
Date: 2020-02-03 08:49:58.565671
[INFO] input_shape (10, 16)
[INFO] LSTM first and last layer neurons: 5
adding core layer 0
[INFO] created DNN
[33m[INFO] epoch 1/10[0m
[33m[INFO] loading file 1-1/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 5s - loss: 1.0642 - tp: 18819.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 61181.0000 - accuracy: 0.8470 - precision: 1.0000 - recall: 0.2352 - auc: 0.9981 - val_loss: 0.3731 - val_tp: 18000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 2000.0000 - val_accuracy: 0.9800 - val_precision: 1.0000 - val_recall: 0.9000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-1-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.2178 - tp: 76384.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 3616.0000 - accuracy: 0.9910 - precision: 1.0000 - recall: 0.9548 - auc: 1.0000 - val_loss: 0.0577 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-1-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0955 - tp: 78303.0000 - fp: 231.0000 - tn: 319769.0000 - fn: 1697.0000 - accuracy: 0.9952 - precision: 0.9971 - recall: 0.9788 - auc: 0.9983 - val_loss: 2.4813 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.7180
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-1-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.3302 - tp: 40464.0000 - fp: 35624.0000 - tn: 284376.0000 - fn: 39536.0000 - accuracy: 0.8121 - precision: 0.5318 - recall: 0.5058 - auc: 0.8228 - val_loss: 0.8775 - val_tp: 10626.0000 - val_fp: 8901.0000 - val_tn: 71099.0000 - val_fn: 9374.0000 - val_accuracy: 0.8173 - val_precision: 0.5442 - val_recall: 0.5313 - val_auc: 0.8845
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-1-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.8292 - tp: 33440.0000 - fp: 29205.0000 - tn: 290795.0000 - fn: 46560.0000 - accuracy: 0.8106 - precision: 0.5338 - recall: 0.4180 - auc: 0.8831 - val_loss: 0.7466 - val_tp: 10603.0000 - val_fp: 8707.0000 - val_tn: 71293.0000 - val_fn: 9397.0000 - val_accuracy: 0.8190 - val_precision: 0.5491 - val_recall: 0.5301 - val_auc: 0.8839
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-1-batch-400000-500000
[33m[INFO] loading file 2-2/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.7477 - tp: 33020.0000 - fp: 28886.0000 - tn: 291114.0000 - fn: 46980.0000 - accuracy: 0.8103 - precision: 0.5334 - recall: 0.4128 - auc: 0.8819 - val_loss: 0.7127 - val_tp: 9523.0000 - val_fp: 8477.0000 - val_tn: 71523.0000 - val_fn: 10477.0000 - val_accuracy: 0.8105 - val_precision: 0.5291 - val_recall: 0.4762 - val_auc: 0.8828
[INFO] saving weights to checkpoints/lstm-epoch-001-files-1-2-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.5209 - tp: 63764.0000 - fp: 11698.0000 - tn: 308302.0000 - fn: 16236.0000 - accuracy: 0.9302 - precision: 0.8450 - recall: 0.7970 - auc: 0.9611 - val_loss: 0.2029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-1-2-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.3545 - tp: 72396.0000 - fp: 7562.0000 - tn: 312438.0000 - fn: 7604.0000 - accuracy: 0.9621 - precision: 0.9054 - recall: 0.9050 - auc: 0.9765 - val_loss: 1.1353 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 70593.0000 - val_fn: 9407.0000 - val_accuracy: 0.8119 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.8829
[INFO] saving weights to checkpoints/lstm-epoch-001-files-1-2-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.7886 - tp: 39497.0000 - fp: 35005.0000 - tn: 284995.0000 - fn: 40503.0000 - accuracy: 0.8112 - precision: 0.5301 - recall: 0.4937 - auc: 0.8822 - val_loss: 0.6979 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 70602.0000 - val_fn: 9398.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8832
[INFO] saving weights to checkpoints/lstm-epoch-001-files-1-2-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.5005 - tp: 66170.0000 - fp: 12409.0000 - tn: 307591.0000 - fn: 13830.0000 - accuracy: 0.9344 - precision: 0.8421 - recall: 0.8271 - auc: 0.9606 - val_loss: 0.1975 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-1-2-batch-400000-500000
[33m[INFO] loading file 3-3/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.7262 - tp: 44233.0000 - fp: 33972.0000 - tn: 286028.0000 - fn: 35767.0000 - accuracy: 0.8257 - precision: 0.5656 - recall: 0.5529 - auc: 0.8917 - val_loss: 0.6971 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 70571.0000 - val_fn: 9429.0000 - val_accuracy: 0.8114 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.8830
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-3-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.6132 - tp: 57372.0000 - fp: 22094.0000 - tn: 297906.0000 - fn: 22628.0000 - accuracy: 0.8882 - precision: 0.7220 - recall: 0.7171 - auc: 0.9306 - val_loss: 0.3439 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-3-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1290 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0320 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-3-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0341 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0113 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-3-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0192 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0056 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-3-batch-400000-500000
[33m[INFO] loading file 4-4/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0130 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0032 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-3-4-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0095 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0020 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-3-4-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0075 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0013 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-3-4-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4498 - tp: 71528.0000 - fp: 8472.0000 - tn: 311528.0000 - fn: 8472.0000 - accuracy: 0.9576 - precision: 0.8941 - recall: 0.8941 - auc: 0.9659 - val_loss: 1.4948 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 67806.0000 - val_fn: 12194.0000 - val_accuracy: 0.7561 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.8478
[INFO] saving weights to checkpoints/lstm-epoch-001-files-3-4-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.6271 - tp: 56887.0000 - fp: 23113.0000 - tn: 296887.0000 - fn: 23113.0000 - accuracy: 0.8844 - precision: 0.7111 - recall: 0.7111 - auc: 0.9280 - val_loss: 0.3486 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-3-4-batch-400000-500000
[33m[INFO] loading file 5-5/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.5341 - tp: 62445.0000 - fp: 17555.0000 - tn: 302445.0000 - fn: 17555.0000 - accuracy: 0.9122 - precision: 0.7806 - recall: 0.7806 - auc: 0.9456 - val_loss: 0.6984 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9261
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-5-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.6597 - tp: 51316.0000 - fp: 28684.0000 - tn: 291316.0000 - fn: 28684.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9120 - val_loss: 0.5268 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 77052.0000 - val_fn: 2948.0000 - val_accuracy: 0.9410 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.9755
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-5-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1081 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0202 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-5-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0195 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0070 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-5-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0105 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0035 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-5-batch-400000-500000
[33m[INFO] loading file 6-6/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0069 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0020 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-5-6-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0050 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0013 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-5-6-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0038 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.5827e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-5-6-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0030 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6374 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 75632.0000 - val_fn: 4368.0000 - val_accuracy: 0.9126 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.8635
[INFO] saving weights to checkpoints/lstm-epoch-001-files-5-6-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.9325 - tp: 51195.0000 - fp: 28805.0000 - tn: 291195.0000 - fn: 28805.0000 - accuracy: 0.8560 - precision: 0.6399 - recall: 0.6399 - auc: 0.9168 - val_loss: 0.5600 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 72768.0000 - val_fn: 7232.0000 - val_accuracy: 0.8554 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.9673
[INFO] saving weights to checkpoints/lstm-epoch-001-files-5-6-batch-400000-500000
[33m[INFO] loading file 7-7/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.5076 - tp: 51210.0000 - fp: 28790.0000 - tn: 291210.0000 - fn: 28790.0000 - accuracy: 0.8561 - precision: 0.6401 - recall: 0.6401 - auc: 0.9658 - val_loss: 0.4400 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 72803.0000 - val_fn: 7197.0000 - val_accuracy: 0.8561 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.9676
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-7-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4039 - tp: 51284.0000 - fp: 27577.0000 - tn: 292423.0000 - fn: 28716.0000 - accuracy: 0.8593 - precision: 0.6503 - recall: 0.6410 - auc: 0.9661 - val_loss: 0.3258 - val_tp: 12860.0000 - val_fp: 21.0000 - val_tn: 79979.0000 - val_fn: 7140.0000 - val_accuracy: 0.9284 - val_precision: 0.9984 - val_recall: 0.6430 - val_auc: 0.9836
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-7-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.3155 - tp: 64870.0000 - fp: 14269.0000 - tn: 305731.0000 - fn: 15130.0000 - accuracy: 0.9265 - precision: 0.8197 - recall: 0.8109 - auc: 0.9827 - val_loss: 0.1970 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-7-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0382 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0038 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-7-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0175 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0016 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-7-batch-400000-500000
[33m[INFO] loading file 8-8/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0114 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.8695e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-7-8-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0084 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4777e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-7-8-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0065 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.7198e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-7-8-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.3696 - tp: 73166.0000 - fp: 6834.0000 - tn: 313166.0000 - fn: 6834.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9756 - val_loss: 0.3309 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 76368.0000 - val_fn: 3632.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9837
[INFO] saving weights to checkpoints/lstm-epoch-001-files-7-8-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.3108 - tp: 65505.0000 - fp: 14495.0000 - tn: 305505.0000 - fn: 14495.0000 - accuracy: 0.9275 - precision: 0.8188 - recall: 0.8188 - auc: 0.9830 - val_loss: 0.2730 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 76383.0000 - val_fn: 3617.0000 - val_accuracy: 0.9277 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.9878
[INFO] saving weights to checkpoints/lstm-epoch-001-files-7-8-batch-400000-500000
[33m[INFO] loading file 9-9/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.2063 - tp: 67975.0000 - fp: 11391.0000 - tn: 308609.0000 - fn: 12025.0000 - accuracy: 0.9415 - precision: 0.8565 - recall: 0.8497 - auc: 0.9912 - val_loss: 0.1354 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-9-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1103 - tp: 78431.0000 - fp: 1499.0000 - tn: 318501.0000 - fn: 1569.0000 - accuracy: 0.9923 - precision: 0.9812 - recall: 0.9804 - auc: 0.9948 - val_loss: 0.0147 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-9-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0212 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.4024e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-9-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0111 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.6069e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-9-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0072 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2056e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-9-batch-400000-500000
[33m[INFO] loading file 10-10/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0050 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.3778e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-9-10-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0124 - tp: 79936.0000 - fp: 64.0000 - tn: 319936.0000 - fn: 64.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 0.9995 - val_loss: 3.5891 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.7763
[INFO] saving weights to checkpoints/lstm-epoch-001-files-9-10-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4999 - tp: 59949.0000 - fp: 19735.0000 - tn: 300265.0000 - fn: 20051.0000 - accuracy: 0.9005 - precision: 0.7523 - recall: 0.7494 - auc: 0.9622 - val_loss: 0.2926 - val_tp: 12813.0000 - val_fp: 7187.0000 - val_tn: 72813.0000 - val_fn: 7187.0000 - val_accuracy: 0.8563 - val_precision: 0.6406 - val_recall: 0.6406 - val_auc: 0.9677
[INFO] saving weights to checkpoints/lstm-epoch-001-files-9-10-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0894 - tp: 77537.0000 - fp: 2361.0000 - tn: 317639.0000 - fn: 2463.0000 - accuracy: 0.9879 - precision: 0.9704 - recall: 0.9692 - auc: 0.9996 - val_loss: 0.0011 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-9-10-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0149 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.7821e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-9-10-batch-400000-500000
[33m[INFO] loading file 11-11/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0107 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4445e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-11-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0082 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3891e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-11-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0064 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.4548e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-11-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0054 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.3179e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-11-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0044 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.4341e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-11-batch-400000-500000
[33m[INFO] loading file 12-12/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0035 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.2954e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-11-12-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8606 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 76689.0000 - val_fn: 3311.0000 - val_accuracy: 0.9338 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8965
[INFO] saving weights to checkpoints/lstm-epoch-001-files-11-12-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.6360 - tp: 60900.0000 - fp: 19029.0000 - tn: 300971.0000 - fn: 19100.0000 - accuracy: 0.9047 - precision: 0.7619 - recall: 0.7613 - auc: 0.9526 - val_loss: 0.2665 - val_tp: 17100.0000 - val_fp: 2900.0000 - val_tn: 77100.0000 - val_fn: 2900.0000 - val_accuracy: 0.9420 - val_precision: 0.8550 - val_recall: 0.8550 - val_auc: 0.9872
[INFO] saving weights to checkpoints/lstm-epoch-001-files-11-12-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1821 - tp: 74688.0000 - fp: 5280.0000 - tn: 314720.0000 - fn: 5312.0000 - accuracy: 0.9735 - precision: 0.9340 - recall: 0.9336 - auc: 0.9978 - val_loss: 0.0471 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-11-12-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0245 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0021 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-11-12-batch-400000-500000
[33m[INFO] loading file 13-13/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0096 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4002e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-13-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0060 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.4797e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-13-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0051 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4573 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 75075.0000 - val_fn: 4925.0000 - val_accuracy: 0.9015 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.8461
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-13-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.5564 - tp: 60483.0000 - fp: 19471.0000 - tn: 300529.0000 - fn: 19517.0000 - accuracy: 0.9025 - precision: 0.7565 - recall: 0.7560 - auc: 0.9574 - val_loss: 0.2140 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-13-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.2269 - tp: 78377.0000 - fp: 1623.0000 - tn: 318377.0000 - fn: 1623.0000 - accuracy: 0.9919 - precision: 0.9797 - recall: 0.9797 - auc: 0.9982 - val_loss: 0.1508 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-13-batch-400000-500000
[33m[INFO] loading file 14-14/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.2872 - tp: 67129.0000 - fp: 12871.0000 - tn: 307129.0000 - fn: 12871.0000 - accuracy: 0.9356 - precision: 0.8391 - recall: 0.8391 - auc: 0.9846 - val_loss: 0.3022 - val_tp: 12810.0000 - val_fp: 7190.0000 - val_tn: 72810.0000 - val_fn: 7190.0000 - val_accuracy: 0.8562 - val_precision: 0.6405 - val_recall: 0.6405 - val_auc: 0.9677
[INFO] saving weights to checkpoints/lstm-epoch-001-files-13-14-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1291 - tp: 76421.0000 - fp: 3575.0000 - tn: 316425.0000 - fn: 3579.0000 - accuracy: 0.9821 - precision: 0.9553 - recall: 0.9553 - auc: 0.9991 - val_loss: 0.0239 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-13-14-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0294 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0099 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-13-14-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0155 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0054 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-13-14-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0096 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0035 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-13-14-batch-400000-500000
[33m[INFO] loading file 15-15/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0072 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0023 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-15-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0053 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0016 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-15-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0041 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0011 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-15-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0034 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.7817 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 71586.0000 - val_fn: 8414.0000 - val_accuracy: 0.8317 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.7315
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-15-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.4830 - tp: 42561.0000 - fp: 37439.0000 - tn: 282561.0000 - fn: 37439.0000 - accuracy: 0.8128 - precision: 0.5320 - recall: 0.5320 - auc: 0.6992 - val_loss: 7.5550 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 70627.0000 - val_fn: 9373.0000 - val_accuracy: 0.8125 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.7013
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-15-batch-400000-500000
[33m[INFO] loading file 16-16/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.4550 - tp: 42492.0000 - fp: 37508.0000 - tn: 282492.0000 - fn: 37508.0000 - accuracy: 0.8125 - precision: 0.5311 - recall: 0.5311 - auc: 0.6979 - val_loss: 7.5624 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 70618.0000 - val_fn: 9382.0000 - val_accuracy: 0.8124 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.7012
[INFO] saving weights to checkpoints/lstm-epoch-001-files-15-16-batch-0-100000
[INFO] processing batch 100000-200000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.1775 - tp: 58381.0000 - fp: 21619.0000 - tn: 298381.0000 - fn: 21619.0000 - accuracy: 0.8919 - precision: 0.7298 - recall: 0.7298 - auc: 0.8235 - val_loss: 0.0865 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-15-16-batch-100000-200000
[INFO] processing batch 200000-300000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0549 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0084 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-15-16-batch-200000-300000
[INFO] processing batch 300000-400000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0150 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-15-16-batch-300000-400000
[INFO] processing batch 400000-500000/439690
[33m[INFO] loading file 17-17/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0093 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-17-batch-0-100000
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.5323e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-17-batch-100000-200000
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0043 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.4190e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-17-batch-200000-300000
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.4337 - tp: 68607.0000 - fp: 11393.0000 - tn: 308607.0000 - fn: 11393.0000 - accuracy: 0.9430 - precision: 0.8576 - recall: 0.8576 - auc: 0.8878 - val_loss: 1.1556 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 76369.0000 - val_fn: 3631.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.8410
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-17-batch-300000-400000
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.9753 - tp: 65526.0000 - fp: 14474.0000 - tn: 305526.0000 - fn: 14474.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.8645 - val_loss: 0.4484 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 78648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9730 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9510
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-17-batch-400000-500000
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 18-18/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.5103 - tp: 72130.0000 - fp: 7870.0000 - tn: 312130.0000 - fn: 7870.0000 - accuracy: 0.9607 - precision: 0.9016 - recall: 0.9016 - auc: 0.9337 - val_loss: 1.5329 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 72369.0000 - val_fn: 7631.0000 - val_accuracy: 0.8474 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.7663
[INFO] saving weights to checkpoints/lstm-epoch-001-files-17-18-batch-0-100000
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.1154 - tp: 49699.0000 - fp: 30301.0000 - tn: 289699.0000 - fn: 30301.0000 - accuracy: 0.8485 - precision: 0.6212 - recall: 0.6212 - auc: 0.8289 - val_loss: 0.9618 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 72357.0000 - val_fn: 7643.0000 - val_accuracy: 0.8471 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.8965
[INFO] saving weights to checkpoints/lstm-epoch-001-files-17-18-batch-100000-200000
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.8999 - tp: 49541.0000 - fp: 30459.0000 - tn: 289541.0000 - fn: 30459.0000 - accuracy: 0.8477 - precision: 0.6193 - recall: 0.6193 - auc: 0.9042 - val_loss: 0.8492 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 72397.0000 - val_fn: 7603.0000 - val_accuracy: 0.8479 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.9053
[INFO] saving weights to checkpoints/lstm-epoch-001-files-17-18-batch-200000-300000
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4060 - tp: 74509.0000 - fp: 5491.0000 - tn: 314509.0000 - fn: 5491.0000 - accuracy: 0.9725 - precision: 0.9314 - recall: 0.9314 - auc: 0.9811 - val_loss: 0.1162 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-17-18-batch-300000-400000
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0428 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-17-18-batch-400000-500000
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 19-19/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0180 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0054 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-19-batch-0-100000
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0114 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-19-batch-100000-200000
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0080 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0023 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-19-batch-200000-300000
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.7391 - tp: 69321.0000 - fp: 10679.0000 - tn: 309321.0000 - fn: 10679.0000 - accuracy: 0.9466 - precision: 0.8665 - recall: 0.8665 - auc: 0.9080 - val_loss: 2.3875 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 67882.0000 - val_fn: 12118.0000 - val_accuracy: 0.7576 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.5870
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-19-batch-300000-400000
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.5771 - tp: 31237.0000 - fp: 48763.0000 - tn: 271237.0000 - fn: 48763.0000 - accuracy: 0.7562 - precision: 0.3905 - recall: 0.3905 - auc: 0.7116 - val_loss: 0.4851 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-19-batch-400000-500000
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 20-20/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.3538 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2306 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 79491.0000 - val_fn: 509.0000 - val_accuracy: 0.9898 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9936
[INFO] saving weights to checkpoints/lstm-epoch-001-files-19-20-batch-0-100000
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.5939 - tp: 65427.0000 - fp: 14573.0000 - tn: 305427.0000 - fn: 14573.0000 - accuracy: 0.9271 - precision: 0.8178 - recall: 0.8178 - auc: 0.9547 - val_loss: 0.5811 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 76357.0000 - val_fn: 3643.0000 - val_accuracy: 0.9271 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.9545
[INFO] saving weights to checkpoints/lstm-epoch-001-files-19-20-batch-100000-200000
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.5731 - tp: 65351.0000 - fp: 14649.0000 - tn: 305351.0000 - fn: 14649.0000 - accuracy: 0.9268 - precision: 0.8169 - recall: 0.8169 - auc: 0.9542 - val_loss: 0.5592 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 76371.0000 - val_fn: 3629.0000 - val_accuracy: 0.9274 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.9553
[INFO] saving weights to checkpoints/lstm-epoch-001-files-19-20-batch-200000-300000
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.2358 - tp: 76024.0000 - fp: 3976.0000 - tn: 316024.0000 - fn: 3976.0000 - accuracy: 0.9801 - precision: 0.9503 - recall: 0.9503 - auc: 0.9861 - val_loss: 0.0584 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-19-20-batch-300000-400000
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0209 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0036 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-19-20-batch-400000-500000
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 21-21/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539688, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0065 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0016 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-21-batch-0-100000
[INFO] processing batch 100000-200000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.5977e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-21-batch-100000-200000
[INFO] processing batch 200000-300000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0032 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.7577e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-21-batch-200000-300000
[INFO] processing batch 300000-400000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0026 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8030e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-21-batch-300000-400000
[INFO] processing batch 400000-500000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0021 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.4475e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-21-batch-400000-500000
[INFO] processing batch 500000-600000/539688
[33m[INFO] loading file 22-22/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (308729, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/308729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.4888 - tp: 55006.0000 - fp: 24994.0000 - tn: 295006.0000 - fn: 24994.0000 - accuracy: 0.8750 - precision: 0.6876 - recall: 0.6876 - auc: 0.7360 - val_loss: 3.1522 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.5310
[INFO] saving weights to checkpoints/lstm-epoch-001-files-21-22-batch-0-100000
[INFO] processing batch 100000-200000/308729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.8701 - tp: 42398.0000 - fp: 37602.0000 - tn: 282398.0000 - fn: 37602.0000 - accuracy: 0.8120 - precision: 0.5300 - recall: 0.5300 - auc: 0.5299 - val_loss: 2.6416 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.5267
[INFO] saving weights to checkpoints/lstm-epoch-001-files-21-22-batch-100000-200000
[INFO] processing batch 200000-300000/308729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.4275 - tp: 42370.0000 - fp: 37630.0000 - tn: 282370.0000 - fn: 37630.0000 - accuracy: 0.8119 - precision: 0.5296 - recall: 0.5296 - auc: 0.5295 - val_loss: 2.2348 - val_tp: 10624.0000 - val_fp: 9376.0000 - val_tn: 70624.0000 - val_fn: 9376.0000 - val_accuracy: 0.8125 - val_precision: 0.5312 - val_recall: 0.5312 - val_auc: 0.5305
[INFO] saving weights to checkpoints/lstm-epoch-001-files-21-22-batch-200000-300000
[INFO] processing batch 300000-400000/308729
[33m[INFO] loading file 23-23/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (508729, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.9409 - tp: 66876.0000 - fp: 13124.0000 - tn: 306876.0000 - fn: 13124.0000 - accuracy: 0.9344 - precision: 0.8360 - recall: 0.8360 - auc: 0.8358 - val_loss: 0.2336 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-23-batch-0-100000
[INFO] processing batch 100000-200000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1859 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1482 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-23-batch-100000-200000
[INFO] processing batch 200000-300000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1251 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1059 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-23-batch-200000-300000
[INFO] processing batch 300000-400000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0923 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0806 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-23-batch-300000-400000
[INFO] processing batch 400000-500000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0717 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0637 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-23-batch-400000-500000
[INFO] processing batch 500000-600000/508729
[33m[INFO] loading file 24-24/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (508729, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0575 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0517 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-23-24-batch-0-100000
[INFO] processing batch 100000-200000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0471 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0428 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-23-24-batch-100000-200000
[INFO] processing batch 200000-300000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0392 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0359 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-23-24-batch-200000-300000
[INFO] processing batch 300000-400000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0330 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0304 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-23-24-batch-300000-400000
[INFO] processing batch 400000-500000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.0029 - tp: 64722.0000 - fp: 15278.0000 - tn: 304722.0000 - fn: 15278.0000 - accuracy: 0.9236 - precision: 0.8090 - recall: 0.8090 - auc: 0.8676 - val_loss: 1.6823 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 72899.0000 - val_fn: 7101.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.7781
[INFO] saving weights to checkpoints/lstm-epoch-001-files-23-24-batch-400000-500000
[INFO] processing batch 500000-600000/508729
[33m[INFO] loading file 25-25/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (508729, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.4797 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.8139 - val_loss: 1.2907 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.8608
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-25-batch-0-100000
[INFO] processing batch 100000-200000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.1447 - tp: 51501.0000 - fp: 28499.0000 - tn: 291501.0000 - fn: 28499.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.8964 - val_loss: 1.0178 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9104
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-25-batch-100000-200000
[INFO] processing batch 200000-300000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.9218 - tp: 51466.0000 - fp: 28534.0000 - tn: 291466.0000 - fn: 28534.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9106 - val_loss: 0.8385 - val_tp: 12880.0000 - val_fp: 7120.0000 - val_tn: 72880.0000 - val_fn: 7120.0000 - val_accuracy: 0.8576 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.9111
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-25-batch-200000-300000
[INFO] processing batch 300000-400000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.7891 - tp: 51440.0000 - fp: 28560.0000 - tn: 291440.0000 - fn: 28560.0000 - accuracy: 0.8572 - precision: 0.6430 - recall: 0.6430 - auc: 0.9111 - val_loss: 0.7481 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9105
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-25-batch-300000-400000
[INFO] processing batch 400000-500000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.7282 - tp: 51504.0000 - fp: 28496.0000 - tn: 291504.0000 - fn: 28496.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9106 - val_loss: 0.7101 - val_tp: 12887.0000 - val_fp: 7113.0000 - val_tn: 72887.0000 - val_fn: 7113.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9107
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-25-batch-400000-500000
[INFO] processing batch 500000-600000/508729
[33m[INFO] loading file 26-26/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (508729, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.0053 - tp: 51522.0000 - fp: 28478.0000 - tn: 291522.0000 - fn: 28478.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.8511 - val_loss: 1.7648 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 72898.0000 - val_fn: 7102.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.6891
[INFO] saving weights to checkpoints/lstm-epoch-001-files-25-26-batch-0-100000
[INFO] processing batch 100000-200000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.5512 - tp: 51489.0000 - fp: 28511.0000 - tn: 291489.0000 - fn: 28511.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.7882 - val_loss: 1.3839 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.8218
[INFO] saving weights to checkpoints/lstm-epoch-001-files-25-26-batch-100000-200000
[INFO] processing batch 200000-300000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.2698 - tp: 51538.0000 - fp: 28462.0000 - tn: 291538.0000 - fn: 28462.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.8220 - val_loss: 1.1680 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 72881.0000 - val_fn: 7119.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.8225
[INFO] saving weights to checkpoints/lstm-epoch-001-files-25-26-batch-200000-300000
[INFO] processing batch 300000-400000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.0891 - tp: 51546.0000 - fp: 28454.0000 - tn: 291546.0000 - fn: 28454.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.8222 - val_loss: 1.0192 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.8215
[INFO] saving weights to checkpoints/lstm-epoch-001-files-25-26-batch-300000-400000
[INFO] processing batch 400000-500000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.9616 - tp: 51558.0000 - fp: 28442.0000 - tn: 291558.0000 - fn: 28442.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.8432 - val_loss: 0.9126 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-001-files-25-26-batch-400000-500000
[INFO] processing batch 500000-600000/508729
[33m[INFO] loading file 27-27/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (448859, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/448859
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.8769 - tp: 51380.0000 - fp: 28620.0000 - tn: 291380.0000 - fn: 28620.0000 - accuracy: 0.8569 - precision: 0.6423 - recall: 0.6423 - auc: 0.9100 - val_loss: 0.8387 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 72902.0000 - val_fn: 7098.0000 - val_accuracy: 0.8580 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.9115
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-27-batch-0-100000
[INFO] processing batch 100000-200000/448859
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.8154 - tp: 51537.0000 - fp: 28463.0000 - tn: 291537.0000 - fn: 28463.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9112 - val_loss: 0.7930 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 72882.0000 - val_fn: 7118.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-27-batch-100000-200000
[INFO] processing batch 200000-300000/448859
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.7766 - tp: 51524.0000 - fp: 28476.0000 - tn: 291524.0000 - fn: 28476.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.7634 - val_tp: 12819.0000 - val_fp: 7181.0000 - val_tn: 72819.0000 - val_fn: 7181.0000 - val_accuracy: 0.8564 - val_precision: 0.6410 - val_recall: 0.6410 - val_auc: 0.9110
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-27-batch-200000-300000
[INFO] processing batch 300000-400000/448859
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.7503 - tp: 51466.0000 - fp: 28534.0000 - tn: 291466.0000 - fn: 28534.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9104 - val_loss: 0.7382 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9115
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-27-batch-300000-400000
[INFO] processing batch 400000-500000/448859
[33m[INFO] loading file 28-28/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (382775, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/382775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.7314 - tp: 51405.0000 - fp: 28595.0000 - tn: 291405.0000 - fn: 28595.0000 - accuracy: 0.8570 - precision: 0.6426 - recall: 0.6426 - auc: 0.9102 - val_loss: 0.7220 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-001-files-27-28-batch-0-100000
[INFO] processing batch 100000-200000/382775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.7165 - tp: 51432.0000 - fp: 28568.0000 - tn: 291432.0000 - fn: 28568.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9106 - val_loss: 0.7100 - val_tp: 12858.0000 - val_fp: 7142.0000 - val_tn: 72858.0000 - val_fn: 7142.0000 - val_accuracy: 0.8572 - val_precision: 0.6429 - val_recall: 0.6429 - val_auc: 0.9105
[INFO] saving weights to checkpoints/lstm-epoch-001-files-27-28-batch-100000-200000
[INFO] processing batch 200000-300000/382775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.7048 - tp: 51485.0000 - fp: 28515.0000 - tn: 291485.0000 - fn: 28515.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9112 - val_loss: 0.7016 - val_tp: 12821.0000 - val_fp: 7179.0000 - val_tn: 72821.0000 - val_fn: 7179.0000 - val_accuracy: 0.8564 - val_precision: 0.6410 - val_recall: 0.6410 - val_auc: 0.9102
[INFO] saving weights to checkpoints/lstm-epoch-001-files-27-28-batch-200000-300000
[INFO] processing batch 300000-400000/382775
[33m[INFO] loading file 29-29/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582775, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.6961 - tp: 51504.0000 - fp: 28496.0000 - tn: 291504.0000 - fn: 28496.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6927 - val_tp: 12859.0000 - val_fp: 7141.0000 - val_tn: 72859.0000 - val_fn: 7141.0000 - val_accuracy: 0.8572 - val_precision: 0.6429 - val_recall: 0.6429 - val_auc: 0.9104
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-29-batch-0-100000
[INFO] processing batch 100000-200000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.6890 - tp: 51530.0000 - fp: 28470.0000 - tn: 291530.0000 - fn: 28470.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6874 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 72830.0000 - val_fn: 7170.0000 - val_accuracy: 0.8566 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.9105
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-29-batch-100000-200000
[INFO] processing batch 200000-300000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.6837 - tp: 51481.0000 - fp: 28519.0000 - tn: 291481.0000 - fn: 28519.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9110 - val_loss: 0.6788 - val_tp: 12940.0000 - val_fp: 7060.0000 - val_tn: 72940.0000 - val_fn: 7060.0000 - val_accuracy: 0.8588 - val_precision: 0.6470 - val_recall: 0.6470 - val_auc: 0.9118
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-29-batch-200000-300000
[INFO] processing batch 300000-400000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.6786 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9110 - val_loss: 0.6775 - val_tp: 12858.0000 - val_fp: 7142.0000 - val_tn: 72858.0000 - val_fn: 7142.0000 - val_accuracy: 0.8572 - val_precision: 0.6429 - val_recall: 0.6429 - val_auc: 0.9097
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-29-batch-300000-400000
[INFO] processing batch 400000-500000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.6752 - tp: 51477.0000 - fp: 28523.0000 - tn: 291477.0000 - fn: 28523.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6733 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9113
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-29-batch-400000-500000
[INFO] processing batch 500000-600000/582775
[33m[INFO] loading file 30-30/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582775, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.6716 - tp: 51543.0000 - fp: 28457.0000 - tn: 291543.0000 - fn: 28457.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9108 - val_loss: 0.6706 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9106
[INFO] saving weights to checkpoints/lstm-epoch-001-files-29-30-batch-0-100000
[INFO] processing batch 100000-200000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.6697 - tp: 51441.0000 - fp: 28559.0000 - tn: 291441.0000 - fn: 28559.0000 - accuracy: 0.8572 - precision: 0.6430 - recall: 0.6430 - auc: 0.9107 - val_loss: 0.6684 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-001-files-29-30-batch-100000-200000
[INFO] processing batch 200000-300000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.6672 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6661 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9108
[INFO] saving weights to checkpoints/lstm-epoch-001-files-29-30-batch-200000-300000
[INFO] processing batch 300000-400000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.6649 - tp: 51533.0000 - fp: 28467.0000 - tn: 291533.0000 - fn: 28467.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9109 - val_loss: 0.6648 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/lstm-epoch-001-files-29-30-batch-300000-400000
[INFO] processing batch 400000-500000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.6630 - tp: 51561.0000 - fp: 28439.0000 - tn: 291561.0000 - fn: 28439.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9109 - val_loss: 0.6629 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9109
[INFO] saving weights to checkpoints/lstm-epoch-001-files-29-30-batch-400000-500000
[INFO] processing batch 500000-600000/582775
[33m[INFO] loading file 31-31/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582775, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.6619 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6598 - val_tp: 12919.0000 - val_fp: 7081.0000 - val_tn: 72919.0000 - val_fn: 7081.0000 - val_accuracy: 0.8584 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.9119
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-31-batch-0-100000
[INFO] processing batch 100000-200000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.5763 - tp: 51499.0000 - fp: 28386.0000 - tn: 291614.0000 - fn: 28501.0000 - accuracy: 0.8578 - precision: 0.6447 - recall: 0.6437 - auc: 0.9374 - val_loss: 0.2546 - val_tp: 12897.0000 - val_fp: 4288.0000 - val_tn: 75712.0000 - val_fn: 7103.0000 - val_accuracy: 0.8861 - val_precision: 0.7505 - val_recall: 0.6449 - val_auc: 0.9685
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-31-batch-100000-200000
[INFO] processing batch 200000-300000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.2530 - tp: 72815.0000 - fp: 6529.0000 - tn: 313471.0000 - fn: 7185.0000 - accuracy: 0.9657 - precision: 0.9177 - recall: 0.9102 - auc: 0.9915 - val_loss: 0.1221 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-31-batch-200000-300000
[INFO] processing batch 300000-400000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1961 - tp: 74641.0000 - fp: 5358.0000 - tn: 314642.0000 - fn: 5359.0000 - accuracy: 0.9732 - precision: 0.9330 - recall: 0.9330 - auc: 0.9950 - val_loss: 0.0854 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-31-batch-300000-400000
[INFO] processing batch 400000-500000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1408 - tp: 76779.0000 - fp: 3221.0000 - tn: 316779.0000 - fn: 3221.0000 - accuracy: 0.9839 - precision: 0.9597 - recall: 0.9597 - auc: 0.9968 - val_loss: 0.0598 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-31-batch-400000-500000
[INFO] processing batch 500000-600000/582775
[33m[INFO] loading file 32-32/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582775, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1353 - tp: 76779.0000 - fp: 3221.0000 - tn: 316779.0000 - fn: 3221.0000 - accuracy: 0.9839 - precision: 0.9597 - recall: 0.9597 - auc: 0.9974 - val_loss: 0.2596 - val_tp: 17792.0000 - val_fp: 2206.0000 - val_tn: 77794.0000 - val_fn: 2208.0000 - val_accuracy: 0.9559 - val_precision: 0.8897 - val_recall: 0.8896 - val_auc: 0.9943
[INFO] saving weights to checkpoints/lstm-epoch-001-files-31-32-batch-0-100000
[INFO] processing batch 100000-200000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1364 - tp: 76587.0000 - fp: 3413.0000 - tn: 316587.0000 - fn: 3413.0000 - accuracy: 0.9829 - precision: 0.9573 - recall: 0.9573 - auc: 0.9975 - val_loss: 0.0470 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-31-32-batch-100000-200000
[INFO] processing batch 200000-300000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1296 - tp: 76801.0000 - fp: 3199.0000 - tn: 316801.0000 - fn: 3199.0000 - accuracy: 0.9840 - precision: 0.9600 - recall: 0.9600 - auc: 0.9981 - val_loss: 0.0421 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-31-32-batch-200000-300000
[INFO] processing batch 300000-400000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1253 - tp: 76930.0000 - fp: 3070.0000 - tn: 316930.0000 - fn: 3070.0000 - accuracy: 0.9847 - precision: 0.9616 - recall: 0.9616 - auc: 0.9985 - val_loss: 0.0404 - val_tp: 19996.0000 - val_fp: 4.0000 - val_tn: 79996.0000 - val_fn: 4.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-31-32-batch-300000-400000
[INFO] processing batch 400000-500000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1288 - tp: 76786.0000 - fp: 3214.0000 - tn: 316786.0000 - fn: 3214.0000 - accuracy: 0.9839 - precision: 0.9598 - recall: 0.9598 - auc: 0.9988 - val_loss: 0.0389 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-31-32-batch-400000-500000
[INFO] processing batch 500000-600000/582775
[33m[INFO] loading file 33-33/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582775, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1306 - tp: 76700.0000 - fp: 3300.0000 - tn: 316700.0000 - fn: 3300.0000 - accuracy: 0.9835 - precision: 0.9588 - recall: 0.9588 - auc: 0.9988 - val_loss: 0.0391 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-33-batch-0-100000
[INFO] processing batch 100000-200000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1259 - tp: 76844.0000 - fp: 3156.0000 - tn: 316844.0000 - fn: 3156.0000 - accuracy: 0.9842 - precision: 0.9606 - recall: 0.9606 - auc: 0.9989 - val_loss: 0.0379 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-33-batch-100000-200000
[INFO] processing batch 200000-300000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1277 - tp: 76761.0000 - fp: 3239.0000 - tn: 316761.0000 - fn: 3239.0000 - accuracy: 0.9838 - precision: 0.9595 - recall: 0.9595 - auc: 0.9991 - val_loss: 0.0379 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-33-batch-200000-300000
[INFO] processing batch 300000-400000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1286 - tp: 76684.0000 - fp: 3316.0000 - tn: 316684.0000 - fn: 3316.0000 - accuracy: 0.9834 - precision: 0.9585 - recall: 0.9585 - auc: 0.9991 - val_loss: 0.0383 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-33-batch-300000-400000
[INFO] processing batch 400000-500000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1278 - tp: 76675.0000 - fp: 3325.0000 - tn: 316675.0000 - fn: 3325.0000 - accuracy: 0.9834 - precision: 0.9584 - recall: 0.9584 - auc: 0.9992 - val_loss: 0.0380 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-33-batch-400000-500000
[INFO] processing batch 500000-600000/582775
[33m[INFO] loading file 34-34/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (424208, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/424208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1276 - tp: 76638.0000 - fp: 3362.0000 - tn: 316638.0000 - fn: 3362.0000 - accuracy: 0.9832 - precision: 0.9580 - recall: 0.9580 - auc: 0.9993 - val_loss: 0.0387 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-33-34-batch-0-100000
[INFO] processing batch 100000-200000/424208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1201 - tp: 76880.0000 - fp: 3120.0000 - tn: 316880.0000 - fn: 3120.0000 - accuracy: 0.9844 - precision: 0.9610 - recall: 0.9610 - auc: 0.9994 - val_loss: 0.0363 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-33-34-batch-100000-200000
[INFO] processing batch 200000-300000/424208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1222 - tp: 76745.0000 - fp: 3255.0000 - tn: 316745.0000 - fn: 3255.0000 - accuracy: 0.9837 - precision: 0.9593 - recall: 0.9593 - auc: 0.9994 - val_loss: 0.0368 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-33-34-batch-200000-300000
[INFO] processing batch 300000-400000/424208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1173 - tp: 76882.0000 - fp: 3118.0000 - tn: 316882.0000 - fn: 3118.0000 - accuracy: 0.9844 - precision: 0.9610 - recall: 0.9610 - auc: 0.9995 - val_loss: 0.0354 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-33-34-batch-300000-400000
[INFO] processing batch 400000-500000/424208
[33m[INFO] loading file 35-35/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524208, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1217 - tp: 76693.0000 - fp: 3307.0000 - tn: 316693.0000 - fn: 3307.0000 - accuracy: 0.9835 - precision: 0.9587 - recall: 0.9587 - auc: 0.9994 - val_loss: 0.0362 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-35-batch-0-100000
[INFO] processing batch 100000-200000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1191 - tp: 76709.0000 - fp: 3291.0000 - tn: 316709.0000 - fn: 3291.0000 - accuracy: 0.9835 - precision: 0.9589 - recall: 0.9589 - auc: 0.9994 - val_loss: 0.0364 - val_tp: 19997.0000 - val_fp: 3.0000 - val_tn: 79997.0000 - val_fn: 3.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-35-batch-100000-200000
[INFO] processing batch 200000-300000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1180 - tp: 76702.0000 - fp: 3298.0000 - tn: 316702.0000 - fn: 3298.0000 - accuracy: 0.9835 - precision: 0.9588 - recall: 0.9588 - auc: 0.9994 - val_loss: 0.0354 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-35-batch-200000-300000
[INFO] processing batch 300000-400000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1165 - tp: 76683.0000 - fp: 3317.0000 - tn: 316683.0000 - fn: 3317.0000 - accuracy: 0.9834 - precision: 0.9585 - recall: 0.9585 - auc: 0.9994 - val_loss: 0.0357 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-35-batch-300000-400000
[INFO] processing batch 400000-500000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1103 - tp: 76874.0000 - fp: 3126.0000 - tn: 316874.0000 - fn: 3126.0000 - accuracy: 0.9844 - precision: 0.9609 - recall: 0.9609 - auc: 0.9995 - val_loss: 0.0333 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-35-batch-400000-500000
[INFO] processing batch 500000-600000/524208
[33m[INFO] loading file 36-36/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524208, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1125 - tp: 76707.0000 - fp: 3293.0000 - tn: 316707.0000 - fn: 3293.0000 - accuracy: 0.9835 - precision: 0.9588 - recall: 0.9588 - auc: 0.9994 - val_loss: 0.0338 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-35-36-batch-0-100000
[INFO] processing batch 100000-200000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1092 - tp: 76762.0000 - fp: 3238.0000 - tn: 316762.0000 - fn: 3238.0000 - accuracy: 0.9838 - precision: 0.9595 - recall: 0.9595 - auc: 0.9995 - val_loss: 0.0332 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-35-36-batch-100000-200000
[INFO] processing batch 200000-300000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1059 - tp: 76838.0000 - fp: 3162.0000 - tn: 316838.0000 - fn: 3162.0000 - accuracy: 0.9842 - precision: 0.9605 - recall: 0.9605 - auc: 0.9995 - val_loss: 0.0318 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-35-36-batch-200000-300000
[INFO] processing batch 300000-400000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1048 - tp: 76804.0000 - fp: 3196.0000 - tn: 316804.0000 - fn: 3196.0000 - accuracy: 0.9840 - precision: 0.9600 - recall: 0.9600 - auc: 0.9995 - val_loss: 0.0319 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-35-36-batch-300000-400000
[INFO] processing batch 400000-500000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1023 - tp: 76823.0000 - fp: 3177.0000 - tn: 316823.0000 - fn: 3177.0000 - accuracy: 0.9841 - precision: 0.9603 - recall: 0.9603 - auc: 0.9995 - val_loss: 0.0311 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-35-36-batch-400000-500000
[INFO] processing batch 500000-600000/524208
[33m[INFO] loading file 37-37/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524208, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1011 - tp: 76781.0000 - fp: 3219.0000 - tn: 316781.0000 - fn: 3219.0000 - accuracy: 0.9839 - precision: 0.9598 - recall: 0.9598 - auc: 0.9995 - val_loss: 0.0303 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-37-batch-0-100000
[INFO] processing batch 100000-200000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0979 - tp: 76817.0000 - fp: 3183.0000 - tn: 316817.0000 - fn: 3183.0000 - accuracy: 0.9841 - precision: 0.9602 - recall: 0.9602 - auc: 0.9995 - val_loss: 0.0297 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-37-batch-100000-200000
[INFO] processing batch 200000-300000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0973 - tp: 76759.0000 - fp: 3241.0000 - tn: 316759.0000 - fn: 3241.0000 - accuracy: 0.9838 - precision: 0.9595 - recall: 0.9595 - auc: 0.9995 - val_loss: 0.0291 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-37-batch-200000-300000
[INFO] processing batch 300000-400000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0943 - tp: 76812.0000 - fp: 3188.0000 - tn: 316812.0000 - fn: 3188.0000 - accuracy: 0.9841 - precision: 0.9602 - recall: 0.9602 - auc: 0.9995 - val_loss: 0.0277 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-37-batch-300000-400000
[INFO] processing batch 400000-500000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0901 - tp: 76922.0000 - fp: 3078.0000 - tn: 316922.0000 - fn: 3078.0000 - accuracy: 0.9846 - precision: 0.9615 - recall: 0.9615 - auc: 0.9995 - val_loss: 0.0262 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-37-batch-400000-500000
[INFO] processing batch 500000-600000/524208
[33m[INFO] loading file 38-38/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524208, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0898 - tp: 76812.0000 - fp: 3188.0000 - tn: 316812.0000 - fn: 3188.0000 - accuracy: 0.9841 - precision: 0.9602 - recall: 0.9602 - auc: 0.9995 - val_loss: 0.0264 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-37-38-batch-0-100000
[INFO] processing batch 100000-200000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0860 - tp: 76921.0000 - fp: 3079.0000 - tn: 316921.0000 - fn: 3079.0000 - accuracy: 0.9846 - precision: 0.9615 - recall: 0.9615 - auc: 0.9995 - val_loss: 0.0242 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-37-38-batch-100000-200000
[INFO] processing batch 200000-300000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0861 - tp: 76792.0000 - fp: 3208.0000 - tn: 316792.0000 - fn: 3208.0000 - accuracy: 0.9840 - precision: 0.9599 - recall: 0.9599 - auc: 0.9995 - val_loss: 0.0241 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-37-38-batch-200000-300000
[INFO] processing batch 300000-400000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0843 - tp: 76798.0000 - fp: 3202.0000 - tn: 316798.0000 - fn: 3202.0000 - accuracy: 0.9840 - precision: 0.9600 - recall: 0.9600 - auc: 0.9995 - val_loss: 0.0229 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-37-38-batch-300000-400000
[INFO] processing batch 400000-500000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0830 - tp: 76762.0000 - fp: 3238.0000 - tn: 316762.0000 - fn: 3238.0000 - accuracy: 0.9838 - precision: 0.9595 - recall: 0.9595 - auc: 0.9995 - val_loss: 0.0220 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-37-38-batch-400000-500000
[INFO] processing batch 500000-600000/524208
[33m[INFO] loading file 39-39/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524208, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0803 - tp: 76835.0000 - fp: 3165.0000 - tn: 316835.0000 - fn: 3165.0000 - accuracy: 0.9842 - precision: 0.9604 - recall: 0.9604 - auc: 0.9995 - val_loss: 0.0204 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-39-batch-0-100000
[INFO] processing batch 100000-200000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0808 - tp: 76650.0000 - fp: 3350.0000 - tn: 316650.0000 - fn: 3350.0000 - accuracy: 0.9833 - precision: 0.9581 - recall: 0.9581 - auc: 0.9994 - val_loss: 0.0206 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-39-batch-100000-200000
[INFO] processing batch 200000-300000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0773 - tp: 76738.0000 - fp: 3262.0000 - tn: 316738.0000 - fn: 3262.0000 - accuracy: 0.9837 - precision: 0.9592 - recall: 0.9592 - auc: 0.9995 - val_loss: 0.0196 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-39-batch-200000-300000
[INFO] processing batch 300000-400000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0751 - tp: 76772.0000 - fp: 3228.0000 - tn: 316772.0000 - fn: 3228.0000 - accuracy: 0.9839 - precision: 0.9596 - recall: 0.9596 - auc: 0.9995 - val_loss: 0.0186 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-39-batch-300000-400000
[INFO] processing batch 400000-500000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0735 - tp: 76749.0000 - fp: 3251.0000 - tn: 316749.0000 - fn: 3251.0000 - accuracy: 0.9837 - precision: 0.9594 - recall: 0.9594 - auc: 0.9995 - val_loss: 0.0176 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-39-batch-400000-500000
[INFO] processing batch 500000-600000/524208
[33m[INFO] loading file 40-40/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524208, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0695 - tp: 76910.0000 - fp: 3090.0000 - tn: 316910.0000 - fn: 3090.0000 - accuracy: 0.9846 - precision: 0.9614 - recall: 0.9614 - auc: 0.9995 - val_loss: 0.0160 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-39-40-batch-0-100000
[INFO] processing batch 100000-200000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0699 - tp: 76783.0000 - fp: 3217.0000 - tn: 316783.0000 - fn: 3217.0000 - accuracy: 0.9839 - precision: 0.9598 - recall: 0.9598 - auc: 0.9995 - val_loss: 0.0152 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-39-40-batch-100000-200000
[INFO] processing batch 200000-300000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0673 - tp: 76827.0000 - fp: 3173.0000 - tn: 316827.0000 - fn: 3173.0000 - accuracy: 0.9841 - precision: 0.9603 - recall: 0.9603 - auc: 0.9995 - val_loss: 0.0146 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-39-40-batch-200000-300000
[INFO] processing batch 300000-400000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0673 - tp: 76755.0000 - fp: 3245.0000 - tn: 316755.0000 - fn: 3245.0000 - accuracy: 0.9838 - precision: 0.9594 - recall: 0.9594 - auc: 0.9995 - val_loss: 0.0139 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-39-40-batch-300000-400000
[INFO] processing batch 400000-500000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0657 - tp: 76725.0000 - fp: 3275.0000 - tn: 316725.0000 - fn: 3275.0000 - accuracy: 0.9836 - precision: 0.9591 - recall: 0.9591 - auc: 0.9995 - val_loss: 0.0129 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-39-40-batch-400000-500000
[INFO] processing batch 500000-600000/524208
[33m[INFO] loading file 41-41/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (464366, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/464366
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0517 - tp: 78280.0000 - fp: 1720.0000 - tn: 318280.0000 - fn: 1720.0000 - accuracy: 0.9914 - precision: 0.9785 - recall: 0.9785 - auc: 0.9998 - val_loss: 0.0079 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-41-batch-0-100000
[INFO] processing batch 100000-200000/464366
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0371 - tp: 79130.0000 - fp: 870.0000 - tn: 319130.0000 - fn: 870.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 0.0059 - val_tp: 19997.0000 - val_fp: 3.0000 - val_tn: 79997.0000 - val_fn: 3.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-41-batch-100000-200000
[INFO] processing batch 200000-300000/464366
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0345 - tp: 79094.0000 - fp: 906.0000 - tn: 319094.0000 - fn: 906.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 0.0032 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-41-batch-200000-300000
[INFO] processing batch 300000-400000/464366
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0328 - tp: 79106.0000 - fp: 894.0000 - tn: 319106.0000 - fn: 894.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 0.0025 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-41-batch-300000-400000
[INFO] processing batch 400000-500000/464366
[33m[INFO] loading file 42-42/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (407880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/407880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0318 - tp: 79105.0000 - fp: 895.0000 - tn: 319105.0000 - fn: 895.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 0.0027 - val_tp: 19997.0000 - val_fp: 3.0000 - val_tn: 79997.0000 - val_fn: 3.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-41-42-batch-0-100000
[INFO] processing batch 100000-200000/407880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0320 - tp: 79055.0000 - fp: 945.0000 - tn: 319055.0000 - fn: 945.0000 - accuracy: 0.9953 - precision: 0.9882 - recall: 0.9882 - auc: 0.9998 - val_loss: 0.0024 - val_tp: 19997.0000 - val_fp: 3.0000 - val_tn: 79997.0000 - val_fn: 3.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-001-files-41-42-batch-100000-200000
[INFO] processing batch 200000-300000/407880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0298 - tp: 79103.0000 - fp: 897.0000 - tn: 319103.0000 - fn: 897.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 0.0013 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-41-42-batch-200000-300000
[INFO] processing batch 300000-400000/407880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0307 - tp: 79069.0000 - fp: 931.0000 - tn: 319069.0000 - fn: 931.0000 - accuracy: 0.9953 - precision: 0.9884 - recall: 0.9884 - auc: 0.9998 - val_loss: 0.0012 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-41-42-batch-300000-400000
[INFO] processing batch 400000-500000/407880
[33m[INFO] loading file 43-43/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (507880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0289 - tp: 79129.0000 - fp: 871.0000 - tn: 319129.0000 - fn: 871.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9998 - val_loss: 9.8195e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-43-batch-0-100000
[INFO] processing batch 100000-200000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0297 - tp: 79067.0000 - fp: 933.0000 - tn: 319067.0000 - fn: 933.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9998 - val_loss: 8.6470e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-43-batch-100000-200000
[INFO] processing batch 200000-300000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0287 - tp: 79093.0000 - fp: 907.0000 - tn: 319093.0000 - fn: 907.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 7.6285e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-43-batch-200000-300000
[INFO] processing batch 300000-400000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0289 - tp: 79079.0000 - fp: 921.0000 - tn: 319079.0000 - fn: 921.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9998 - val_loss: 6.7111e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-43-batch-300000-400000
[INFO] processing batch 400000-500000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0285 - tp: 79112.0000 - fp: 888.0000 - tn: 319112.0000 - fn: 888.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9998 - val_loss: 5.9743e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-43-batch-400000-500000
[INFO] processing batch 500000-600000/507880
[33m[INFO] loading file 44-44/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (507880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0287 - tp: 79085.0000 - fp: 915.0000 - tn: 319085.0000 - fn: 915.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9998 - val_loss: 0.0012 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-001-files-43-44-batch-0-100000
[INFO] processing batch 100000-200000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0283 - tp: 79118.0000 - fp: 882.0000 - tn: 319118.0000 - fn: 882.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9998 - val_loss: 4.9897e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-43-44-batch-100000-200000
[INFO] processing batch 200000-300000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0285 - tp: 79081.0000 - fp: 919.0000 - tn: 319081.0000 - fn: 919.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9999 - val_loss: 4.4741e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-43-44-batch-200000-300000
[INFO] processing batch 300000-400000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0284 - tp: 79066.0000 - fp: 934.0000 - tn: 319066.0000 - fn: 934.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9998 - val_loss: 3.9864e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-43-44-batch-300000-400000
[INFO] processing batch 400000-500000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0286 - tp: 79068.0000 - fp: 932.0000 - tn: 319068.0000 - fn: 932.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9998 - val_loss: 0.0016 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-001-files-43-44-batch-400000-500000
[INFO] processing batch 500000-600000/507880
[33m[INFO] loading file 45-45/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (507880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0268 - tp: 79149.0000 - fp: 851.0000 - tn: 319149.0000 - fn: 851.0000 - accuracy: 0.9957 - precision: 0.9894 - recall: 0.9894 - auc: 0.9999 - val_loss: 3.4721e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-45-batch-0-100000
[INFO] processing batch 100000-200000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0269 - tp: 79162.0000 - fp: 838.0000 - tn: 319162.0000 - fn: 838.0000 - accuracy: 0.9958 - precision: 0.9895 - recall: 0.9895 - auc: 0.9999 - val_loss: 3.1754e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-45-batch-100000-200000
[INFO] processing batch 200000-300000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0267 - tp: 79152.0000 - fp: 848.0000 - tn: 319152.0000 - fn: 848.0000 - accuracy: 0.9958 - precision: 0.9894 - recall: 0.9894 - auc: 0.9999 - val_loss: 6.4637e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-45-batch-200000-300000
[INFO] processing batch 300000-400000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0286 - tp: 79052.0000 - fp: 948.0000 - tn: 319052.0000 - fn: 948.0000 - accuracy: 0.9953 - precision: 0.9882 - recall: 0.9882 - auc: 0.9998 - val_loss: 2.7073e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-45-batch-300000-400000
[INFO] processing batch 400000-500000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0276 - tp: 79105.0000 - fp: 895.0000 - tn: 319105.0000 - fn: 895.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 6.1369e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-45-batch-400000-500000
[INFO] processing batch 500000-600000/507880
[33m[INFO] loading file 46-46/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (507880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0287 - tp: 79058.0000 - fp: 942.0000 - tn: 319058.0000 - fn: 942.0000 - accuracy: 0.9953 - precision: 0.9882 - recall: 0.9882 - auc: 0.9998 - val_loss: 2.3340e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-45-46-batch-0-100000
[INFO] processing batch 100000-200000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0282 - tp: 79094.0000 - fp: 906.0000 - tn: 319094.0000 - fn: 906.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 2.2170e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-45-46-batch-100000-200000
[INFO] processing batch 200000-300000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0267 - tp: 79144.0000 - fp: 856.0000 - tn: 319144.0000 - fn: 856.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9999 - val_loss: 5.7542e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-45-46-batch-200000-300000
[INFO] processing batch 300000-400000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0274 - tp: 79128.0000 - fp: 872.0000 - tn: 319128.0000 - fn: 872.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9998 - val_loss: 5.9705e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-45-46-batch-300000-400000
[INFO] processing batch 400000-500000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0282 - tp: 79060.0000 - fp: 940.0000 - tn: 319060.0000 - fn: 940.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9998 - val_loss: 9.5892e-04 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-001-files-45-46-batch-400000-500000
[INFO] processing batch 500000-600000/507880
[33m[INFO] loading file 47-47/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (507880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0268 - tp: 79143.0000 - fp: 857.0000 - tn: 319143.0000 - fn: 857.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9998 - val_loss: 1.7344e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-47-batch-0-100000
[INFO] processing batch 100000-200000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0263 - tp: 79180.0000 - fp: 820.0000 - tn: 319180.0000 - fn: 820.0000 - accuracy: 0.9959 - precision: 0.9898 - recall: 0.9898 - auc: 0.9999 - val_loss: 5.4210e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-47-batch-100000-200000
[INFO] processing batch 200000-300000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0279 - tp: 79078.0000 - fp: 922.0000 - tn: 319078.0000 - fn: 922.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9998 - val_loss: 1.5063e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-47-batch-200000-300000
[INFO] processing batch 300000-400000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0273 - tp: 79105.0000 - fp: 895.0000 - tn: 319105.0000 - fn: 895.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 1.4084e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-47-batch-300000-400000
[INFO] processing batch 400000-500000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0266 - tp: 79134.0000 - fp: 866.0000 - tn: 319134.0000 - fn: 866.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 5.4851e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-47-batch-400000-500000
[INFO] processing batch 500000-600000/507880
[33m[INFO] loading file 48-48/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (507880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0269 - tp: 79130.0000 - fp: 870.0000 - tn: 319130.0000 - fn: 870.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 1.2415e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-47-48-batch-0-100000
[INFO] processing batch 100000-200000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0267 - tp: 79131.0000 - fp: 869.0000 - tn: 319131.0000 - fn: 869.0000 - accuracy: 0.9957 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 1.1576e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-47-48-batch-100000-200000
[INFO] processing batch 200000-300000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0286 - tp: 79056.0000 - fp: 944.0000 - tn: 319056.0000 - fn: 944.0000 - accuracy: 0.9953 - precision: 0.9882 - recall: 0.9882 - auc: 0.9998 - val_loss: 1.0757e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-47-48-batch-200000-300000
[INFO] processing batch 300000-400000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0285 - tp: 79100.0000 - fp: 900.0000 - tn: 319100.0000 - fn: 900.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9997 - val_loss: 1.0860e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-47-48-batch-300000-400000
[INFO] processing batch 400000-500000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0263 - tp: 79154.0000 - fp: 846.0000 - tn: 319154.0000 - fn: 846.0000 - accuracy: 0.9958 - precision: 0.9894 - recall: 0.9894 - auc: 0.9998 - val_loss: 1.0511e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-47-48-batch-400000-500000
[INFO] processing batch 500000-600000/507880
[33m[INFO] loading file 49-49/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (507880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0274 - tp: 79111.0000 - fp: 889.0000 - tn: 319111.0000 - fn: 889.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9998 - val_loss: 1.0226e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-49-batch-0-100000
[INFO] processing batch 100000-200000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0259 - tp: 79168.0000 - fp: 832.0000 - tn: 319168.0000 - fn: 832.0000 - accuracy: 0.9958 - precision: 0.9896 - recall: 0.9896 - auc: 0.9999 - val_loss: 9.5103e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-49-batch-100000-200000
[INFO] processing batch 200000-300000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0275 - tp: 79093.0000 - fp: 907.0000 - tn: 319093.0000 - fn: 907.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 9.4103e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-49-batch-200000-300000
[INFO] processing batch 300000-400000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0287 - tp: 79070.0000 - fp: 930.0000 - tn: 319070.0000 - fn: 930.0000 - accuracy: 0.9953 - precision: 0.9884 - recall: 0.9884 - auc: 0.9998 - val_loss: 9.1028e-04 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-49-batch-300000-400000
[INFO] processing batch 400000-500000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0284 - tp: 79056.0000 - fp: 944.0000 - tn: 319056.0000 - fn: 944.0000 - accuracy: 0.9953 - precision: 0.9882 - recall: 0.9882 - auc: 0.9998 - val_loss: 5.0030e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-49-batch-400000-500000
[INFO] processing batch 500000-600000/507880
[33m[INFO] loading file 50-50/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (357862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/357862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0271 - tp: 79120.0000 - fp: 880.0000 - tn: 319120.0000 - fn: 880.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9998 - val_loss: 8.6313e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-49-50-batch-0-100000
[INFO] processing batch 100000-200000/357862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0279 - tp: 79079.0000 - fp: 921.0000 - tn: 319079.0000 - fn: 921.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9998 - val_loss: 8.2323e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-49-50-batch-100000-200000
[INFO] processing batch 200000-300000/357862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0273 - tp: 79107.0000 - fp: 893.0000 - tn: 319107.0000 - fn: 893.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 9.1209e-04 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-001-files-49-50-batch-200000-300000
[INFO] processing batch 300000-400000/357862
[33m[LOSS] 0.0009120923321461305[0m
[33m[INFO] epoch 2/10[0m
[33m[INFO] loading file 1-1/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.6577 - tp: 71502.0000 - fp: 8498.0000 - tn: 311502.0000 - fn: 8498.0000 - accuracy: 0.9575 - precision: 0.8938 - recall: 0.8938 - auc: 0.9525 - val_loss: 1.7647 - val_tp: 13043.0000 - val_fp: 6957.0000 - val_tn: 73043.0000 - val_fn: 6957.0000 - val_accuracy: 0.8609 - val_precision: 0.6521 - val_recall: 0.6521 - val_auc: 0.9037
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-1-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4304 - tp: 72219.0000 - fp: 7781.0000 - tn: 312219.0000 - fn: 7781.0000 - accuracy: 0.9611 - precision: 0.9027 - recall: 0.9027 - auc: 0.9830 - val_loss: 0.1460 - val_tp: 19309.0000 - val_fp: 691.0000 - val_tn: 79309.0000 - val_fn: 691.0000 - val_accuracy: 0.9862 - val_precision: 0.9654 - val_recall: 0.9654 - val_auc: 0.9997
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-1-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1490 - tp: 76615.0000 - fp: 3385.0000 - tn: 316615.0000 - fn: 3385.0000 - accuracy: 0.9831 - precision: 0.9577 - recall: 0.9577 - auc: 0.9980 - val_loss: 0.1053 - val_tp: 19299.0000 - val_fp: 701.0000 - val_tn: 79299.0000 - val_fn: 701.0000 - val_accuracy: 0.9860 - val_precision: 0.9650 - val_recall: 0.9650 - val_auc: 0.9997
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-1-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.0060 - tp: 57318.0000 - fp: 22682.0000 - tn: 297318.0000 - fn: 22682.0000 - accuracy: 0.8866 - precision: 0.7165 - recall: 0.7165 - auc: 0.8424 - val_loss: 7.6432 - val_tp: 9900.0000 - val_fp: 10100.0000 - val_tn: 69900.0000 - val_fn: 10100.0000 - val_accuracy: 0.7980 - val_precision: 0.4950 - val_recall: 0.4950 - val_auc: 0.7024
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-1-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.1347 - tp: 42111.0000 - fp: 37889.0000 - tn: 282111.0000 - fn: 37889.0000 - accuracy: 0.8106 - precision: 0.5264 - recall: 0.5264 - auc: 0.7174 - val_loss: 7.5683 - val_tp: 10609.0000 - val_fp: 9391.0000 - val_tn: 70609.0000 - val_fn: 9391.0000 - val_accuracy: 0.8122 - val_precision: 0.5304 - val_recall: 0.5304 - val_auc: 0.7065
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-1-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 2-2/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.1446 - tp: 42358.0000 - fp: 37642.0000 - tn: 282358.0000 - fn: 37642.0000 - accuracy: 0.8118 - precision: 0.5295 - recall: 0.5295 - auc: 0.7173 - val_loss: 7.5683 - val_tp: 10609.0000 - val_fp: 9391.0000 - val_tn: 70609.0000 - val_fn: 9391.0000 - val_accuracy: 0.8122 - val_precision: 0.5304 - val_recall: 0.5304 - val_auc: 0.7065
[INFO] saving weights to checkpoints/lstm-epoch-002-files-1-2-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.1379 - tp: 42393.0000 - fp: 37607.0000 - tn: 282393.0000 - fn: 37607.0000 - accuracy: 0.8120 - precision: 0.5299 - recall: 0.5299 - auc: 0.7175 - val_loss: 1.5917 - val_tp: 18025.0000 - val_fp: 1975.0000 - val_tn: 78025.0000 - val_fn: 1975.0000 - val_accuracy: 0.9605 - val_precision: 0.9013 - val_recall: 0.9013 - val_auc: 0.9383
[INFO] saving weights to checkpoints/lstm-epoch-002-files-1-2-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0053 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-1-2-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.2064 - tp: 52632.0000 - fp: 27368.0000 - tn: 292632.0000 - fn: 27368.0000 - accuracy: 0.8632 - precision: 0.6579 - recall: 0.6579 - auc: 0.7945 - val_loss: 7.5731 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.7063
[INFO] saving weights to checkpoints/lstm-epoch-002-files-1-2-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.1588 - tp: 42254.0000 - fp: 37746.0000 - tn: 282254.0000 - fn: 37746.0000 - accuracy: 0.8113 - precision: 0.5282 - recall: 0.5282 - auc: 0.7165 - val_loss: 1.7907 - val_tp: 17778.0000 - val_fp: 2222.0000 - val_tn: 77778.0000 - val_fn: 2222.0000 - val_accuracy: 0.9556 - val_precision: 0.8889 - val_recall: 0.8889 - val_auc: 0.9306
[INFO] saving weights to checkpoints/lstm-epoch-002-files-1-2-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 3-3/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.4446 - tp: 72473.0000 - fp: 7527.0000 - tn: 312473.0000 - fn: 7527.0000 - accuracy: 0.9624 - precision: 0.9059 - recall: 0.9059 - auc: 0.9433 - val_loss: 7.5876 - val_tp: 10585.0000 - val_fp: 9415.0000 - val_tn: 70585.0000 - val_fn: 9415.0000 - val_accuracy: 0.8117 - val_precision: 0.5293 - val_recall: 0.5293 - val_auc: 0.7058
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-3-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.1508 - tp: 42271.0000 - fp: 37729.0000 - tn: 282271.0000 - fn: 37729.0000 - accuracy: 0.8114 - precision: 0.5284 - recall: 0.5284 - auc: 0.7170 - val_loss: 7.5940 - val_tp: 10577.0000 - val_fp: 9423.0000 - val_tn: 70577.0000 - val_fn: 9423.0000 - val_accuracy: 0.8115 - val_precision: 0.5289 - val_recall: 0.5289 - val_auc: 0.7055
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-3-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4623 - tp: 77605.0000 - fp: 2395.0000 - tn: 317605.0000 - fn: 2395.0000 - accuracy: 0.9880 - precision: 0.9701 - recall: 0.9701 - auc: 0.9821 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-3-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0013 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-3-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.3597e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-3-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 4-4/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.2749e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-3-4-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.2934e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.0602e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-3-4-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.6971e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-3-4-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.3078e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-3-4-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.5064 - tp: 45878.0000 - fp: 34122.0000 - tn: 285878.0000 - fn: 34122.0000 - accuracy: 0.8294 - precision: 0.5735 - recall: 0.5735 - auc: 0.7427 - val_loss: 7.7754 - val_tp: 10352.0000 - val_fp: 9648.0000 - val_tn: 70352.0000 - val_fn: 9648.0000 - val_accuracy: 0.8070 - val_precision: 0.5176 - val_recall: 0.5176 - val_auc: 0.6985
[INFO] saving weights to checkpoints/lstm-epoch-002-files-3-4-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 5-5/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0044 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.1672 - val_tp: 16070.0000 - val_fp: 3930.0000 - val_tn: 76070.0000 - val_fn: 3930.0000 - val_accuracy: 0.9214 - val_precision: 0.8035 - val_recall: 0.8035 - val_auc: 0.8772
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-5-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.4690 - tp: 51303.0000 - fp: 28697.0000 - tn: 291303.0000 - fn: 28697.0000 - accuracy: 0.8565 - precision: 0.6413 - recall: 0.6413 - auc: 0.7840 - val_loss: 5.7577 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.7767
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-5-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.1683 - tp: 63439.0000 - fp: 16561.0000 - tn: 303439.0000 - fn: 16561.0000 - accuracy: 0.9172 - precision: 0.7930 - recall: 0.7930 - auc: 0.8752 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-5-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0028 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-5-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.3014e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-5-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 6-6/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.2172e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-5-6-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.1759e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-5-6-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.6028e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-5-6-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.2074e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-5-6-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.3615 - tp: 67635.0000 - fp: 12365.0000 - tn: 307635.0000 - fn: 12365.0000 - accuracy: 0.9382 - precision: 0.8454 - recall: 0.8454 - auc: 0.9070 - val_loss: 5.8122 - val_tp: 12788.0000 - val_fp: 7212.0000 - val_tn: 72788.0000 - val_fn: 7212.0000 - val_accuracy: 0.8558 - val_precision: 0.6394 - val_recall: 0.6394 - val_auc: 0.7746
[INFO] saving weights to checkpoints/lstm-epoch-002-files-5-6-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 7-7/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.5024 - tp: 60778.0000 - fp: 19222.0000 - tn: 300778.0000 - fn: 19222.0000 - accuracy: 0.9039 - precision: 0.7597 - recall: 0.7597 - auc: 0.8567 - val_loss: 0.0131 - val_tp: 19962.0000 - val_fp: 38.0000 - val_tn: 79962.0000 - val_fn: 38.0000 - val_accuracy: 0.9992 - val_precision: 0.9981 - val_recall: 0.9981 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-7-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0416 - tp: 78923.0000 - fp: 1077.0000 - tn: 318923.0000 - fn: 1077.0000 - accuracy: 0.9946 - precision: 0.9865 - recall: 0.9865 - auc: 0.9997 - val_loss: 0.0049 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-7-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0347 - tp: 79066.0000 - fp: 934.0000 - tn: 319066.0000 - fn: 934.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9998 - val_loss: 0.1031 - val_tp: 19583.0000 - val_fp: 417.0000 - val_tn: 79583.0000 - val_fn: 417.0000 - val_accuracy: 0.9917 - val_precision: 0.9791 - val_recall: 0.9791 - val_auc: 0.9951
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-7-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4833 - tp: 69450.0000 - fp: 10550.0000 - tn: 309450.0000 - fn: 10550.0000 - accuracy: 0.9473 - precision: 0.8681 - recall: 0.8681 - auc: 0.9839 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-7-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0175 - tp: 79327.0000 - fp: 673.0000 - tn: 319327.0000 - fn: 673.0000 - accuracy: 0.9966 - precision: 0.9916 - recall: 0.9916 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-7-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 8-8/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0032 - tp: 79854.0000 - fp: 146.0000 - tn: 319854.0000 - fn: 146.0000 - accuracy: 0.9993 - precision: 0.9982 - recall: 0.9982 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-7-8-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0014 - tp: 79934.0000 - fp: 66.0000 - tn: 319934.0000 - fn: 66.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-7-8-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.6490e-04 - tp: 79979.0000 - fp: 21.0000 - tn: 319979.0000 - fn: 21.0000 - accuracy: 0.9999 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-7-8-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.3160e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-7-8-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.7518 - tp: 66179.0000 - fp: 13821.0000 - tn: 306179.0000 - fn: 13821.0000 - accuracy: 0.9309 - precision: 0.8272 - recall: 0.8272 - auc: 0.9301 - val_loss: 0.3387 - val_tp: 16650.0000 - val_fp: 3350.0000 - val_tn: 76650.0000 - val_fn: 3350.0000 - val_accuracy: 0.9330 - val_precision: 0.8325 - val_recall: 0.8325 - val_auc: 0.9897
[INFO] saving weights to checkpoints/lstm-epoch-002-files-7-8-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 9-9/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.2501 - tp: 70252.0000 - fp: 9748.0000 - tn: 310252.0000 - fn: 9748.0000 - accuracy: 0.9513 - precision: 0.8781 - recall: 0.8781 - auc: 0.9913 - val_loss: 0.1068 - val_tp: 19232.0000 - val_fp: 768.0000 - val_tn: 79232.0000 - val_fn: 768.0000 - val_accuracy: 0.9846 - val_precision: 0.9616 - val_recall: 0.9616 - val_auc: 0.9989
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-9-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1600 - tp: 73818.0000 - fp: 6182.0000 - tn: 313818.0000 - fn: 6182.0000 - accuracy: 0.9691 - precision: 0.9227 - recall: 0.9227 - auc: 0.9959 - val_loss: 0.2292 - val_tp: 16314.0000 - val_fp: 3686.0000 - val_tn: 76314.0000 - val_fn: 3686.0000 - val_accuracy: 0.9263 - val_precision: 0.8157 - val_recall: 0.8157 - val_auc: 0.9902
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-9-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0291 - tp: 78173.0000 - fp: 1827.0000 - tn: 318173.0000 - fn: 1827.0000 - accuracy: 0.9909 - precision: 0.9772 - recall: 0.9772 - auc: 0.9998 - val_loss: 1.2283e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-9-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.9924e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-9-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.7432e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-9-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 10-10/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.8650e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-9-10-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 8.2945e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-9-10-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.6870 - tp: 65991.0000 - fp: 14009.0000 - tn: 305991.0000 - fn: 14009.0000 - accuracy: 0.9300 - precision: 0.8249 - recall: 0.8249 - auc: 0.9684 - val_loss: 0.1913 - val_tp: 19895.0000 - val_fp: 105.0000 - val_tn: 79895.0000 - val_fn: 105.0000 - val_accuracy: 0.9979 - val_precision: 0.9948 - val_recall: 0.9948 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-9-10-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.2481 - tp: 68478.0000 - fp: 11522.0000 - tn: 308478.0000 - fn: 11522.0000 - accuracy: 0.9424 - precision: 0.8560 - recall: 0.8560 - auc: 0.9879 - val_loss: 0.1628 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-9-10-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0337 - tp: 79916.0000 - fp: 84.0000 - tn: 319916.0000 - fn: 84.0000 - accuracy: 0.9996 - precision: 0.9990 - recall: 0.9990 - auc: 1.0000 - val_loss: 1.1817e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-9-10-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 11-11/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0017 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1322e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-11-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 8.9613e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.4957e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-11-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.5823e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.9374e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-11-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.2887e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4777e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-11-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.0423e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3392e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-11-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 12-12/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.8009e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2206e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-11-12-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.2480e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1924e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-11-12-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.3832 - tp: 67977.0000 - fp: 12023.0000 - tn: 307977.0000 - fn: 12023.0000 - accuracy: 0.9399 - precision: 0.8497 - recall: 0.8497 - auc: 0.9813 - val_loss: 0.3402 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 72822.0000 - val_fn: 7178.0000 - val_accuracy: 0.8564 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9678
[INFO] saving weights to checkpoints/lstm-epoch-002-files-11-12-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.2671 - tp: 66085.0000 - fp: 13915.0000 - tn: 306085.0000 - fn: 13915.0000 - accuracy: 0.9304 - precision: 0.8261 - recall: 0.8261 - auc: 0.9846 - val_loss: 0.3101 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9680
[INFO] saving weights to checkpoints/lstm-epoch-002-files-11-12-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0701 - tp: 77880.0000 - fp: 2120.0000 - tn: 317880.0000 - fn: 2120.0000 - accuracy: 0.9894 - precision: 0.9735 - recall: 0.9735 - auc: 0.9994 - val_loss: 0.0060 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-11-12-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 13-13/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0023 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.5363e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-13-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.9861e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0851e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-13-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 9.6707e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.1504e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-13-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4920 - tp: 66709.0000 - fp: 13291.0000 - tn: 306709.0000 - fn: 13291.0000 - accuracy: 0.9335 - precision: 0.8339 - recall: 0.8339 - auc: 0.9760 - val_loss: 0.3130 - val_tp: 13309.0000 - val_fp: 6691.0000 - val_tn: 73309.0000 - val_fn: 6691.0000 - val_accuracy: 0.8662 - val_precision: 0.6654 - val_recall: 0.6654 - val_auc: 0.9681
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-13-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1402 - tp: 75876.0000 - fp: 4124.0000 - tn: 315876.0000 - fn: 4124.0000 - accuracy: 0.9794 - precision: 0.9485 - recall: 0.9485 - auc: 0.9980 - val_loss: 0.0380 - val_tp: 19995.0000 - val_fp: 5.0000 - val_tn: 79995.0000 - val_fn: 5.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-13-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 14-14/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0674 - tp: 79081.0000 - fp: 919.0000 - tn: 319081.0000 - fn: 919.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9996 - val_loss: 0.0216 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-13-14-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4347 - tp: 68309.0000 - fp: 11691.0000 - tn: 308309.0000 - fn: 11691.0000 - accuracy: 0.9415 - precision: 0.8539 - recall: 0.8539 - auc: 0.9840 - val_loss: 0.0865 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-13-14-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0127 - tp: 79950.0000 - fp: 50.0000 - tn: 319950.0000 - fn: 50.0000 - accuracy: 0.9998 - precision: 0.9994 - recall: 0.9994 - auc: 1.0000 - val_loss: 6.8257e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-13-14-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.2046e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.2355e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-13-14-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.2196e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3036e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-13-14-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 15-15/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.5966e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.9985e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-15-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.3058e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.6302e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-15-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.3986e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.4759e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-15-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.1000e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.6154e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-15-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.7845 - tp: 61216.0000 - fp: 18784.0000 - tn: 301216.0000 - fn: 18784.0000 - accuracy: 0.9061 - precision: 0.7652 - recall: 0.7652 - auc: 0.8532 - val_loss: 7.5199 - val_tp: 10669.0000 - val_fp: 9331.0000 - val_tn: 70669.0000 - val_fn: 9331.0000 - val_accuracy: 0.8134 - val_precision: 0.5335 - val_recall: 0.5335 - val_auc: 0.7084
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-15-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 16-16/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (497552, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/497552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.5636 - tp: 42459.0000 - fp: 37541.0000 - tn: 282459.0000 - fn: 37541.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5307 - auc: 0.7067 - val_loss: 7.5368 - val_tp: 10648.0000 - val_fp: 9352.0000 - val_tn: 70648.0000 - val_fn: 9352.0000 - val_accuracy: 0.8130 - val_precision: 0.5324 - val_recall: 0.5324 - val_auc: 0.7078
[INFO] saving weights to checkpoints/lstm-epoch-002-files-15-16-batch-0-100000
[INFO] processing batch 100000-200000/497552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.5473 - tp: 42540.0000 - fp: 37460.0000 - tn: 282540.0000 - fn: 37460.0000 - accuracy: 0.8127 - precision: 0.5318 - recall: 0.5318 - auc: 0.7073 - val_loss: 7.5803 - val_tp: 10594.0000 - val_fp: 9406.0000 - val_tn: 70594.0000 - val_fn: 9406.0000 - val_accuracy: 0.8119 - val_precision: 0.5297 - val_recall: 0.5297 - val_auc: 0.7061
[INFO] saving weights to checkpoints/lstm-epoch-002-files-15-16-batch-100000-200000
[INFO] processing batch 200000-300000/497552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.3750 - tp: 78139.0000 - fp: 1861.0000 - tn: 318139.0000 - fn: 1861.0000 - accuracy: 0.9907 - precision: 0.9767 - recall: 0.9767 - auc: 0.9855 - val_loss: 4.0207e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-15-16-batch-200000-300000
[INFO] processing batch 300000-400000/497552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.2417e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.5729e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-15-16-batch-300000-400000
[INFO] processing batch 400000-500000/497552
[33m[INFO] loading file 17-17/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (597552, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.4083e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9671e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-17-batch-0-100000
[INFO] processing batch 100000-200000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.0428e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4242e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-17-batch-100000-200000
[INFO] processing batch 200000-300000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 9.6427e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.3737e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-17-batch-200000-300000
[INFO] processing batch 300000-400000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.1640 - tp: 79186.0000 - fp: 814.0000 - tn: 319186.0000 - fn: 814.0000 - accuracy: 0.9959 - precision: 0.9898 - recall: 0.9898 - auc: 0.9936 - val_loss: 2.9778 - val_tp: 16305.0000 - val_fp: 3695.0000 - val_tn: 76305.0000 - val_fn: 3695.0000 - val_accuracy: 0.9261 - val_precision: 0.8152 - val_recall: 0.8152 - val_auc: 0.8845
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-17-batch-300000-400000
[INFO] processing batch 400000-500000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.9236 - tp: 65489.0000 - fp: 14511.0000 - tn: 305489.0000 - fn: 14511.0000 - accuracy: 0.9274 - precision: 0.8186 - recall: 0.8186 - auc: 0.8866 - val_loss: 2.8988 - val_tp: 16403.0000 - val_fp: 3597.0000 - val_tn: 76403.0000 - val_fn: 3597.0000 - val_accuracy: 0.9281 - val_precision: 0.8202 - val_recall: 0.8202 - val_auc: 0.8876
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-17-batch-400000-500000
[INFO] processing batch 500000-600000/597552
[33m[INFO] loading file 18-18/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (597552, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.6588 - tp: 71767.0000 - fp: 8233.0000 - tn: 311767.0000 - fn: 8233.0000 - accuracy: 0.9588 - precision: 0.8971 - recall: 0.8971 - auc: 0.9357 - val_loss: 2.8399e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-17-18-batch-0-100000
[INFO] processing batch 100000-200000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.8111 - tp: 56121.0000 - fp: 23879.0000 - tn: 296121.0000 - fn: 23879.0000 - accuracy: 0.8806 - precision: 0.7015 - recall: 0.7015 - auc: 0.8134 - val_loss: 6.1080 - val_tp: 12421.0000 - val_fp: 7579.0000 - val_tn: 72421.0000 - val_fn: 7579.0000 - val_accuracy: 0.8484 - val_precision: 0.6211 - val_recall: 0.6211 - val_auc: 0.7632
[INFO] saving weights to checkpoints/lstm-epoch-002-files-17-18-batch-100000-200000
[INFO] processing batch 200000-300000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.1384 - tp: 49533.0000 - fp: 30467.0000 - tn: 289533.0000 - fn: 30467.0000 - accuracy: 0.8477 - precision: 0.6192 - recall: 0.6192 - auc: 0.7620 - val_loss: 6.1329 - val_tp: 12390.0000 - val_fp: 7610.0000 - val_tn: 72390.0000 - val_fn: 7610.0000 - val_accuracy: 0.8478 - val_precision: 0.6195 - val_recall: 0.6195 - val_auc: 0.7622
[INFO] saving weights to checkpoints/lstm-epoch-002-files-17-18-batch-200000-300000
[INFO] processing batch 300000-400000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.5331 - tp: 52537.0000 - fp: 27463.0000 - tn: 292537.0000 - fn: 27463.0000 - accuracy: 0.8627 - precision: 0.6567 - recall: 0.6567 - auc: 0.7854 - val_loss: 1.4636e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-17-18-batch-300000-400000
[INFO] processing batch 400000-500000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.4048e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6534e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-17-18-batch-400000-500000
[INFO] processing batch 500000-600000/597552
[33m[INFO] loading file 19-19/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (597552, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.4465e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.8975e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-19-batch-0-100000
[INFO] processing batch 100000-200000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.6721e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.5326e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-19-batch-100000-200000
[INFO] processing batch 200000-300000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.3009e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6987e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-19-batch-200000-300000
[INFO] processing batch 300000-400000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.0056e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6341e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-19-batch-300000-400000
[INFO] processing batch 400000-500000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.3221 - tp: 43658.0000 - fp: 36342.0000 - tn: 283658.0000 - fn: 36342.0000 - accuracy: 0.8183 - precision: 0.5457 - recall: 0.5457 - auc: 0.7161 - val_loss: 9.8232 - val_tp: 7811.0000 - val_fp: 12189.0000 - val_tn: 67811.0000 - val_fn: 12189.0000 - val_accuracy: 0.7562 - val_precision: 0.3905 - val_recall: 0.3905 - val_auc: 0.6191
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-19-batch-400000-500000
[INFO] processing batch 500000-600000/597552
[33m[INFO] loading file 20-20/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (597552, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.6398 - tp: 56971.0000 - fp: 23029.0000 - tn: 296971.0000 - fn: 23029.0000 - accuracy: 0.8849 - precision: 0.7121 - recall: 0.7121 - auc: 0.8201 - val_loss: 1.8808e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-19-20-batch-0-100000
[INFO] processing batch 100000-200000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.9079 - tp: 75494.0000 - fp: 4506.0000 - tn: 315494.0000 - fn: 4506.0000 - accuracy: 0.9775 - precision: 0.9437 - recall: 0.9437 - auc: 0.9648 - val_loss: 2.9681 - val_tp: 16317.0000 - val_fp: 3683.0000 - val_tn: 76317.0000 - val_fn: 3683.0000 - val_accuracy: 0.9263 - val_precision: 0.8159 - val_recall: 0.8159 - val_auc: 0.8849
[INFO] saving weights to checkpoints/lstm-epoch-002-files-19-20-batch-100000-200000
[INFO] processing batch 200000-300000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.9407 - tp: 65404.0000 - fp: 14596.0000 - tn: 305404.0000 - fn: 14596.0000 - accuracy: 0.9270 - precision: 0.8176 - recall: 0.8176 - auc: 0.8860 - val_loss: 2.9690 - val_tp: 16316.0000 - val_fp: 3684.0000 - val_tn: 76316.0000 - val_fn: 3684.0000 - val_accuracy: 0.9263 - val_precision: 0.8158 - val_recall: 0.8158 - val_auc: 0.8849
[INFO] saving weights to checkpoints/lstm-epoch-002-files-19-20-batch-200000-300000
[INFO] processing batch 300000-400000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.9234 - tp: 65490.0000 - fp: 14510.0000 - tn: 305490.0000 - fn: 14510.0000 - accuracy: 0.9275 - precision: 0.8186 - recall: 0.8186 - auc: 0.8866 - val_loss: 1.3749e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-19-20-batch-300000-400000
[INFO] processing batch 400000-500000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.5068e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2088e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-19-20-batch-400000-500000
[INFO] processing batch 500000-600000/597552
[33m[INFO] loading file 21-21/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (597550, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/597550
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.3466e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.4572e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-21-batch-0-100000
[INFO] processing batch 100000-200000/597550
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.9581e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2496e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-21-batch-100000-200000
[INFO] processing batch 200000-300000/597550
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.8165e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2216e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-21-batch-200000-300000
[INFO] processing batch 300000-400000/597550
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.6281e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1988e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-21-batch-300000-400000
[INFO] processing batch 400000-500000/597550
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.4794e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2638e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-21-batch-400000-500000
[INFO] processing batch 500000-600000/597550
[33m[INFO] loading file 22-22/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (366591, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/366591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.3393e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.8380 - val_tp: 12756.0000 - val_fp: 7244.0000 - val_tn: 72756.0000 - val_fn: 7244.0000 - val_accuracy: 0.8551 - val_precision: 0.6378 - val_recall: 0.6378 - val_auc: 0.7736
[INFO] saving weights to checkpoints/lstm-epoch-002-files-21-22-batch-0-100000
[INFO] processing batch 100000-200000/366591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.5674 - tp: 42440.0000 - fp: 37560.0000 - tn: 282440.0000 - fn: 37560.0000 - accuracy: 0.8122 - precision: 0.5305 - recall: 0.5305 - auc: 0.7066 - val_loss: 7.5763 - val_tp: 10599.0000 - val_fp: 9401.0000 - val_tn: 70599.0000 - val_fn: 9401.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.7062
[INFO] saving weights to checkpoints/lstm-epoch-002-files-21-22-batch-100000-200000
[INFO] processing batch 200000-300000/366591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.5916 - tp: 42320.0000 - fp: 37680.0000 - tn: 282320.0000 - fn: 37680.0000 - accuracy: 0.8116 - precision: 0.5290 - recall: 0.5290 - auc: 0.7056 - val_loss: 7.5763 - val_tp: 10599.0000 - val_fp: 9401.0000 - val_tn: 70599.0000 - val_fn: 9401.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.7062
[INFO] saving weights to checkpoints/lstm-epoch-002-files-21-22-batch-200000-300000
[INFO] processing batch 300000-400000/366591
[33m[INFO] loading file 23-23/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (566591, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.5685 - tp: 42435.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37565.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5304 - auc: 0.7065 - val_loss: 2.2050 - val_tp: 17264.0000 - val_fp: 2736.0000 - val_tn: 77264.0000 - val_fn: 2736.0000 - val_accuracy: 0.9453 - val_precision: 0.8632 - val_recall: 0.8632 - val_auc: 0.9145
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-23-batch-0-100000
[INFO] processing batch 100000-200000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 9.7070e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2123e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-23-batch-100000-200000
[INFO] processing batch 200000-300000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 8.8232e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1987e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-23-batch-200000-300000
[INFO] processing batch 300000-400000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 8.0432e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2049e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-23-batch-300000-400000
[INFO] processing batch 400000-500000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.1158e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1930e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-23-batch-400000-500000
[INFO] processing batch 500000-600000/566591
[33m[INFO] loading file 24-24/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (566591, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.7425e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1922e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-23-24-batch-0-100000
[INFO] processing batch 100000-200000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.8293e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1926e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-23-24-batch-100000-200000
[INFO] processing batch 200000-300000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.2141e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1941e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-23-24-batch-200000-300000
[INFO] processing batch 300000-400000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.7644e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1942e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-23-24-batch-300000-400000
[INFO] processing batch 400000-500000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.4089e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.4716 - val_tp: 18174.0000 - val_fp: 1826.0000 - val_tn: 78174.0000 - val_fn: 1826.0000 - val_accuracy: 0.9635 - val_precision: 0.9087 - val_recall: 0.9087 - val_auc: 0.9429
[INFO] saving weights to checkpoints/lstm-epoch-002-files-23-24-batch-400000-500000
[INFO] processing batch 500000-600000/566591
[33m[INFO] loading file 25-25/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (566591, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7330 - tp: 51545.0000 - fp: 28455.0000 - tn: 291545.0000 - fn: 28455.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.7777 - val_loss: 5.7429 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.7773
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-25-batch-0-100000
[INFO] processing batch 100000-200000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7552 - tp: 51435.0000 - fp: 28565.0000 - tn: 291435.0000 - fn: 28565.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.7768 - val_loss: 5.7566 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.7768
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-25-batch-100000-200000
[INFO] processing batch 200000-300000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7463 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.7772 - val_loss: 5.7276 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 72893.0000 - val_fn: 7107.0000 - val_accuracy: 0.8579 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.7779
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-25-batch-200000-300000
[INFO] processing batch 300000-400000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7497 - tp: 51462.0000 - fp: 28538.0000 - tn: 291462.0000 - fn: 28538.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.7770 - val_loss: 5.7324 - val_tp: 12887.0000 - val_fp: 7113.0000 - val_tn: 72887.0000 - val_fn: 7113.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.7777
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-25-batch-300000-400000
[INFO] processing batch 400000-500000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7594 - tp: 51414.0000 - fp: 28586.0000 - tn: 291414.0000 - fn: 28586.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.7767 - val_loss: 5.7195 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.7782
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-25-batch-400000-500000
[INFO] processing batch 500000-600000/566591
[33m[INFO] loading file 26-26/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (566591, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7425 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.7773 - val_loss: 5.7550 - val_tp: 12859.0000 - val_fp: 7141.0000 - val_tn: 72859.0000 - val_fn: 7141.0000 - val_accuracy: 0.8572 - val_precision: 0.6429 - val_recall: 0.6429 - val_auc: 0.7768
[INFO] saving weights to checkpoints/lstm-epoch-002-files-25-26-batch-0-100000
[INFO] processing batch 100000-200000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.5840 - tp: 70307.0000 - fp: 9693.0000 - tn: 310307.0000 - fn: 9693.0000 - accuracy: 0.9515 - precision: 0.8788 - recall: 0.8788 - auc: 0.9359 - val_loss: 0.0372 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-25-26-batch-100000-200000
[INFO] processing batch 200000-300000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0615 - tp: 79077.0000 - fp: 923.0000 - tn: 319077.0000 - fn: 923.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9995 - val_loss: 0.0161 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-25-26-batch-200000-300000
[INFO] processing batch 300000-400000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0476 - tp: 79065.0000 - fp: 935.0000 - tn: 319065.0000 - fn: 935.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9998 - val_loss: 0.0111 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-25-26-batch-300000-400000
[INFO] processing batch 400000-500000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0421 - tp: 79105.0000 - fp: 895.0000 - tn: 319105.0000 - fn: 895.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 0.0082 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-25-26-batch-400000-500000
[INFO] processing batch 500000-600000/566591
[33m[INFO] loading file 27-27/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (506721, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/506721
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0396 - tp: 79052.0000 - fp: 948.0000 - tn: 319052.0000 - fn: 948.0000 - accuracy: 0.9953 - precision: 0.9882 - recall: 0.9882 - auc: 0.9998 - val_loss: 0.0066 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-27-batch-0-100000
[INFO] processing batch 100000-200000/506721
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0369 - tp: 79106.0000 - fp: 894.0000 - tn: 319106.0000 - fn: 894.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 0.0051 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-27-batch-100000-200000
[INFO] processing batch 200000-300000/506721
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0341 - tp: 79135.0000 - fp: 865.0000 - tn: 319135.0000 - fn: 865.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 0.0040 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-27-batch-200000-300000
[INFO] processing batch 300000-400000/506721
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0337 - tp: 79087.0000 - fp: 913.0000 - tn: 319087.0000 - fn: 913.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 0.0033 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-27-batch-300000-400000
[INFO] processing batch 400000-500000/506721
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0317 - tp: 79147.0000 - fp: 853.0000 - tn: 319147.0000 - fn: 853.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9999 - val_loss: 0.0030 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-27-batch-400000-500000
[INFO] processing batch 500000-600000/506721
[33m[INFO] loading file 28-28/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (340637, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/340637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0322 - tp: 79086.0000 - fp: 914.0000 - tn: 319086.0000 - fn: 914.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9998 - val_loss: 0.0026 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-27-28-batch-0-100000
[INFO] processing batch 100000-200000/340637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0320 - tp: 79086.0000 - fp: 914.0000 - tn: 319086.0000 - fn: 914.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9998 - val_loss: 0.0030 - val_tp: 19997.0000 - val_fp: 3.0000 - val_tn: 79997.0000 - val_fn: 3.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-27-28-batch-100000-200000
[INFO] processing batch 200000-300000/340637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0305 - tp: 79137.0000 - fp: 863.0000 - tn: 319137.0000 - fn: 863.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9998 - val_loss: 0.0021 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-27-28-batch-200000-300000
[INFO] processing batch 300000-400000/340637
[33m[INFO] loading file 29-29/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (540637, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0306 - tp: 79085.0000 - fp: 915.0000 - tn: 319085.0000 - fn: 915.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9998 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-29-batch-0-100000
[INFO] processing batch 100000-200000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0299 - tp: 79091.0000 - fp: 909.0000 - tn: 319091.0000 - fn: 909.0000 - accuracy: 0.9955 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 0.0013 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-29-batch-100000-200000
[INFO] processing batch 200000-300000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0286 - tp: 79158.0000 - fp: 842.0000 - tn: 319158.0000 - fn: 842.0000 - accuracy: 0.9958 - precision: 0.9895 - recall: 0.9895 - auc: 0.9998 - val_loss: 0.0011 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-29-batch-200000-300000
[INFO] processing batch 300000-400000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0284 - tp: 79151.0000 - fp: 849.0000 - tn: 319151.0000 - fn: 849.0000 - accuracy: 0.9958 - precision: 0.9894 - recall: 0.9894 - auc: 0.9999 - val_loss: 9.8484e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-29-batch-300000-400000
[INFO] processing batch 400000-500000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0292 - tp: 79082.0000 - fp: 918.0000 - tn: 319082.0000 - fn: 918.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9998 - val_loss: 0.0012 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-29-batch-400000-500000
[INFO] processing batch 500000-600000/540637
[33m[INFO] loading file 30-30/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (540637, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0295 - tp: 79073.0000 - fp: 927.0000 - tn: 319073.0000 - fn: 927.0000 - accuracy: 0.9954 - precision: 0.9884 - recall: 0.9884 - auc: 0.9998 - val_loss: 0.0016 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-29-30-batch-0-100000
[INFO] processing batch 100000-200000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0289 - tp: 79078.0000 - fp: 922.0000 - tn: 319078.0000 - fn: 922.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9998 - val_loss: 6.7789e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-29-30-batch-100000-200000
[INFO] processing batch 200000-300000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0280 - tp: 79131.0000 - fp: 869.0000 - tn: 319131.0000 - fn: 869.0000 - accuracy: 0.9957 - precision: 0.9891 - recall: 0.9891 - auc: 0.9998 - val_loss: 9.3039e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-29-30-batch-200000-300000
[INFO] processing batch 300000-400000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0284 - tp: 79095.0000 - fp: 905.0000 - tn: 319095.0000 - fn: 905.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 8.7088e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-29-30-batch-300000-400000
[INFO] processing batch 400000-500000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0280 - tp: 79139.0000 - fp: 861.0000 - tn: 319139.0000 - fn: 861.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9998 - val_loss: 7.5814e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-29-30-batch-400000-500000
[INFO] processing batch 500000-600000/540637
[33m[INFO] loading file 31-31/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (540637, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0280 - tp: 79103.0000 - fp: 897.0000 - tn: 319103.0000 - fn: 897.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 4.4036e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-31-batch-0-100000
[INFO] processing batch 100000-200000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0275 - tp: 79132.0000 - fp: 868.0000 - tn: 319132.0000 - fn: 868.0000 - accuracy: 0.9957 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 4.1488e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-31-batch-100000-200000
[INFO] processing batch 200000-300000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0281 - tp: 79098.0000 - fp: 902.0000 - tn: 319098.0000 - fn: 902.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 3.7563e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-31-batch-200000-300000
[INFO] processing batch 300000-400000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0272 - tp: 79127.0000 - fp: 873.0000 - tn: 319127.0000 - fn: 873.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 3.3487e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-31-batch-300000-400000
[INFO] processing batch 400000-500000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0276 - tp: 79102.0000 - fp: 898.0000 - tn: 319102.0000 - fn: 898.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 3.1377e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-31-batch-400000-500000
[INFO] processing batch 500000-600000/540637
[33m[INFO] loading file 32-32/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (540637, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0278 - tp: 79117.0000 - fp: 883.0000 - tn: 319117.0000 - fn: 883.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9998 - val_loss: 6.6550e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-31-32-batch-0-100000
[INFO] processing batch 100000-200000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0281 - tp: 79087.0000 - fp: 913.0000 - tn: 319087.0000 - fn: 913.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9998 - val_loss: 2.6464e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-31-32-batch-100000-200000
[INFO] processing batch 200000-300000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0280 - tp: 79084.0000 - fp: 916.0000 - tn: 319084.0000 - fn: 916.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9998 - val_loss: 2.4876e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-31-32-batch-200000-300000
[INFO] processing batch 300000-400000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0281 - tp: 79141.0000 - fp: 859.0000 - tn: 319141.0000 - fn: 859.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9998 - val_loss: 0.0013 - val_tp: 19997.0000 - val_fp: 3.0000 - val_tn: 79997.0000 - val_fn: 3.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-002-files-31-32-batch-300000-400000
[INFO] processing batch 400000-500000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0277 - tp: 79095.0000 - fp: 905.0000 - tn: 319095.0000 - fn: 905.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 2.2076e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-31-32-batch-400000-500000
[INFO] processing batch 500000-600000/540637
[33m[INFO] loading file 33-33/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (540637, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0278 - tp: 79098.0000 - fp: 902.0000 - tn: 319098.0000 - fn: 902.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 2.1099e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-33-batch-0-100000
[INFO] processing batch 100000-200000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0271 - tp: 79144.0000 - fp: 856.0000 - tn: 319144.0000 - fn: 856.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9998 - val_loss: 1.9940e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-33-batch-100000-200000
[INFO] processing batch 200000-300000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0276 - tp: 79109.0000 - fp: 891.0000 - tn: 319109.0000 - fn: 891.0000 - accuracy: 0.9955 - precision: 0.9889 - recall: 0.9889 - auc: 0.9998 - val_loss: 1.8481e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-33-batch-200000-300000
[INFO] processing batch 300000-400000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0281 - tp: 79093.0000 - fp: 907.0000 - tn: 319093.0000 - fn: 907.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 0.0013 - val_tp: 19997.0000 - val_fp: 3.0000 - val_tn: 79997.0000 - val_fn: 3.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-33-batch-300000-400000
[INFO] processing batch 400000-500000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0276 - tp: 79102.0000 - fp: 898.0000 - tn: 319102.0000 - fn: 898.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 1.7208e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-33-batch-400000-500000
[INFO] processing batch 500000-600000/540637
[33m[INFO] loading file 34-34/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (382070, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/382070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0263 - tp: 79161.0000 - fp: 839.0000 - tn: 319161.0000 - fn: 839.0000 - accuracy: 0.9958 - precision: 0.9895 - recall: 0.9895 - auc: 0.9999 - val_loss: 1.6751e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-33-34-batch-0-100000
[INFO] processing batch 100000-200000/382070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0273 - tp: 79108.0000 - fp: 892.0000 - tn: 319108.0000 - fn: 892.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 5.4304e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-33-34-batch-100000-200000
[INFO] processing batch 200000-300000/382070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0279 - tp: 79120.0000 - fp: 880.0000 - tn: 319120.0000 - fn: 880.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9998 - val_loss: 5.3690e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-33-34-batch-200000-300000
[INFO] processing batch 300000-400000/382070
[33m[INFO] loading file 35-35/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582070, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0271 - tp: 79123.0000 - fp: 877.0000 - tn: 319123.0000 - fn: 877.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9998 - val_loss: 1.4217e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-35-batch-0-100000
[INFO] processing batch 100000-200000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0275 - tp: 79106.0000 - fp: 894.0000 - tn: 319106.0000 - fn: 894.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 4.5887e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-35-batch-100000-200000
[INFO] processing batch 200000-300000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0275 - tp: 79114.0000 - fp: 886.0000 - tn: 319114.0000 - fn: 886.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9998 - val_loss: 1.2807e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-35-batch-200000-300000
[INFO] processing batch 300000-400000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0279 - tp: 79087.0000 - fp: 913.0000 - tn: 319087.0000 - fn: 913.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9998 - val_loss: 1.1958e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-35-batch-300000-400000
[INFO] processing batch 400000-500000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0272 - tp: 79112.0000 - fp: 888.0000 - tn: 319112.0000 - fn: 888.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 1.1540e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-35-batch-400000-500000
[INFO] processing batch 500000-600000/582070
[33m[INFO] loading file 36-36/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582070, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0282 - tp: 79065.0000 - fp: 935.0000 - tn: 319065.0000 - fn: 935.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9998 - val_loss: 1.0933e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-35-36-batch-0-100000
[INFO] processing batch 100000-200000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0272 - tp: 79116.0000 - fp: 884.0000 - tn: 319116.0000 - fn: 884.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9998 - val_loss: 1.0501e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-35-36-batch-100000-200000
[INFO] processing batch 200000-300000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0281 - tp: 79091.0000 - fp: 909.0000 - tn: 319091.0000 - fn: 909.0000 - accuracy: 0.9955 - precision: 0.9886 - recall: 0.9886 - auc: 0.9998 - val_loss: 5.0826e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-35-36-batch-200000-300000
[INFO] processing batch 300000-400000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0271 - tp: 79112.0000 - fp: 888.0000 - tn: 319112.0000 - fn: 888.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9998 - val_loss: 9.1877e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-35-36-batch-300000-400000
[INFO] processing batch 400000-500000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0281 - tp: 79081.0000 - fp: 919.0000 - tn: 319081.0000 - fn: 919.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9998 - val_loss: 8.6230e-04 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-002-files-35-36-batch-400000-500000
[INFO] processing batch 500000-600000/582070
[33m[INFO] loading file 37-37/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582070, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0282 - tp: 79058.0000 - fp: 942.0000 - tn: 319058.0000 - fn: 942.0000 - accuracy: 0.9953 - precision: 0.9882 - recall: 0.9882 - auc: 0.9998 - val_loss: 8.5797e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-37-batch-0-100000
[INFO] processing batch 100000-200000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0278 - tp: 79075.0000 - fp: 925.0000 - tn: 319075.0000 - fn: 925.0000 - accuracy: 0.9954 - precision: 0.9884 - recall: 0.9884 - auc: 0.9998 - val_loss: 8.2808e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-37-batch-100000-200000
[INFO] processing batch 200000-300000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0279 - tp: 79086.0000 - fp: 914.0000 - tn: 319086.0000 - fn: 914.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9998 - val_loss: 4.3410e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-37-batch-200000-300000
[INFO] processing batch 300000-400000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0281 - tp: 79065.0000 - fp: 935.0000 - tn: 319065.0000 - fn: 935.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9998 - val_loss: 7.9857e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-37-batch-300000-400000
[INFO] processing batch 400000-500000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0271 - tp: 79114.0000 - fp: 886.0000 - tn: 319114.0000 - fn: 886.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9998 - val_loss: 8.8190e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-37-batch-400000-500000
[INFO] processing batch 500000-600000/582070
[33m[INFO] loading file 38-38/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582070, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0265 - tp: 79138.0000 - fp: 862.0000 - tn: 319138.0000 - fn: 862.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 6.9666e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-37-38-batch-0-100000
[INFO] processing batch 100000-200000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0271 - tp: 79126.0000 - fp: 874.0000 - tn: 319126.0000 - fn: 874.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9998 - val_loss: 6.8280e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-37-38-batch-100000-200000
[INFO] processing batch 200000-300000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0275 - tp: 79090.0000 - fp: 910.0000 - tn: 319090.0000 - fn: 910.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9998 - val_loss: 6.4717e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-37-38-batch-200000-300000
[INFO] processing batch 300000-400000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0273 - tp: 79101.0000 - fp: 899.0000 - tn: 319101.0000 - fn: 899.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 6.1910e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-37-38-batch-300000-400000
[INFO] processing batch 400000-500000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0274 - tp: 79096.0000 - fp: 904.0000 - tn: 319096.0000 - fn: 904.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 6.2688e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-37-38-batch-400000-500000
[INFO] processing batch 500000-600000/582070
[33m[INFO] loading file 39-39/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582070, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0276 - tp: 79077.0000 - fp: 923.0000 - tn: 319077.0000 - fn: 923.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9998 - val_loss: 8.6511e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-39-batch-0-100000
[INFO] processing batch 100000-200000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0275 - tp: 79098.0000 - fp: 902.0000 - tn: 319098.0000 - fn: 902.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 5.5587e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-39-batch-100000-200000
[INFO] processing batch 200000-300000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0276 - tp: 79075.0000 - fp: 925.0000 - tn: 319075.0000 - fn: 925.0000 - accuracy: 0.9954 - precision: 0.9884 - recall: 0.9884 - auc: 0.9998 - val_loss: 5.2638e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-39-batch-200000-300000
[INFO] processing batch 300000-400000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0263 - tp: 79149.0000 - fp: 851.0000 - tn: 319149.0000 - fn: 851.0000 - accuracy: 0.9957 - precision: 0.9894 - recall: 0.9894 - auc: 0.9999 - val_loss: 5.0142e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-39-batch-300000-400000
[INFO] processing batch 400000-500000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0272 - tp: 79097.0000 - fp: 903.0000 - tn: 319097.0000 - fn: 903.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 4.7483e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-39-batch-400000-500000
[INFO] processing batch 500000-600000/582070
[33m[INFO] loading file 40-40/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582070, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0266 - tp: 79113.0000 - fp: 887.0000 - tn: 319113.0000 - fn: 887.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 4.5265e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-39-40-batch-0-100000
[INFO] processing batch 100000-200000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0272 - tp: 79123.0000 - fp: 877.0000 - tn: 319123.0000 - fn: 877.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9998 - val_loss: 4.3894e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-39-40-batch-100000-200000
[INFO] processing batch 200000-300000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0263 - tp: 79143.0000 - fp: 857.0000 - tn: 319143.0000 - fn: 857.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9999 - val_loss: 4.8994e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-39-40-batch-200000-300000
[INFO] processing batch 300000-400000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0282 - tp: 79094.0000 - fp: 906.0000 - tn: 319094.0000 - fn: 906.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 0.0011 - val_tp: 19997.0000 - val_fp: 3.0000 - val_tn: 79997.0000 - val_fn: 3.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-002-files-39-40-batch-300000-400000
[INFO] processing batch 400000-500000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0277 - tp: 79093.0000 - fp: 907.0000 - tn: 319093.0000 - fn: 907.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 7.2222e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-39-40-batch-400000-500000
[INFO] processing batch 500000-600000/582070
[33m[INFO] loading file 41-41/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (522228, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/522228
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0273 - tp: 79093.0000 - fp: 907.0000 - tn: 319093.0000 - fn: 907.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 4.3272e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-41-batch-0-100000
[INFO] processing batch 100000-200000/522228
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0274 - tp: 79123.0000 - fp: 877.0000 - tn: 319123.0000 - fn: 877.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9998 - val_loss: 8.6154e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-41-batch-100000-200000
[INFO] processing batch 200000-300000/522228
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0274 - tp: 79103.0000 - fp: 897.0000 - tn: 319103.0000 - fn: 897.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 4.5131e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-41-batch-200000-300000
[INFO] processing batch 300000-400000/522228
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0277 - tp: 79098.0000 - fp: 902.0000 - tn: 319098.0000 - fn: 902.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 4.3017e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-41-batch-300000-400000
[INFO] processing batch 400000-500000/522228
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0276 - tp: 79097.0000 - fp: 903.0000 - tn: 319097.0000 - fn: 903.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 9.0381e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-41-batch-400000-500000
[INFO] processing batch 500000-600000/522228
[33m[INFO] loading file 42-42/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (365742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/365742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0274 - tp: 79115.0000 - fp: 885.0000 - tn: 319115.0000 - fn: 885.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9998 - val_loss: 0.0026 - val_tp: 19992.0000 - val_fp: 8.0000 - val_tn: 79992.0000 - val_fn: 8.0000 - val_accuracy: 0.9998 - val_precision: 0.9996 - val_recall: 0.9996 - val_auc: 0.9998
[INFO] saving weights to checkpoints/lstm-epoch-002-files-41-42-batch-0-100000
[INFO] processing batch 100000-200000/365742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0275 - tp: 79114.0000 - fp: 886.0000 - tn: 319114.0000 - fn: 886.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9998 - val_loss: 4.3899e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-41-42-batch-100000-200000
[INFO] processing batch 200000-300000/365742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0277 - tp: 79080.0000 - fp: 920.0000 - tn: 319080.0000 - fn: 920.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9998 - val_loss: 7.9960e-04 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-002-files-41-42-batch-200000-300000
[INFO] processing batch 300000-400000/365742
[33m[INFO] loading file 43-43/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (565742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0277 - tp: 79097.0000 - fp: 903.0000 - tn: 319097.0000 - fn: 903.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 5.4058e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-43-batch-0-100000
[INFO] processing batch 100000-200000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0270 - tp: 79108.0000 - fp: 892.0000 - tn: 319108.0000 - fn: 892.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 4.2885e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-43-batch-100000-200000
[INFO] processing batch 200000-300000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0270 - tp: 79139.0000 - fp: 861.0000 - tn: 319139.0000 - fn: 861.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9998 - val_loss: 4.2148e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-43-batch-200000-300000
[INFO] processing batch 300000-400000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0271 - tp: 79110.0000 - fp: 890.0000 - tn: 319110.0000 - fn: 890.0000 - accuracy: 0.9955 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 3.8300e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-43-batch-300000-400000
[INFO] processing batch 400000-500000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0278 - tp: 79056.0000 - fp: 944.0000 - tn: 319056.0000 - fn: 944.0000 - accuracy: 0.9953 - precision: 0.9882 - recall: 0.9882 - auc: 0.9998 - val_loss: 3.4842e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-43-batch-400000-500000
[INFO] processing batch 500000-600000/565742
[33m[INFO] loading file 44-44/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (565742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0265 - tp: 79135.0000 - fp: 865.0000 - tn: 319135.0000 - fn: 865.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9998 - val_loss: 3.7389e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-43-44-batch-0-100000
[INFO] processing batch 100000-200000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0270 - tp: 79117.0000 - fp: 883.0000 - tn: 319117.0000 - fn: 883.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9998 - val_loss: 7.4781e-04 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-002-files-43-44-batch-100000-200000
[INFO] processing batch 200000-300000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0272 - tp: 79091.0000 - fp: 909.0000 - tn: 319091.0000 - fn: 909.0000 - accuracy: 0.9955 - precision: 0.9886 - recall: 0.9886 - auc: 0.9999 - val_loss: 3.2310e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-43-44-batch-200000-300000
[INFO] processing batch 300000-400000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0269 - tp: 79138.0000 - fp: 862.0000 - tn: 319138.0000 - fn: 862.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 3.0708e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-43-44-batch-300000-400000
[INFO] processing batch 400000-500000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0277 - tp: 79107.0000 - fp: 893.0000 - tn: 319107.0000 - fn: 893.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 3.2348e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-43-44-batch-400000-500000
[INFO] processing batch 500000-600000/565742
[33m[INFO] loading file 45-45/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (565742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0271 - tp: 79108.0000 - fp: 892.0000 - tn: 319108.0000 - fn: 892.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 3.9665e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-45-batch-0-100000
[INFO] processing batch 100000-200000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0278 - tp: 79065.0000 - fp: 935.0000 - tn: 319065.0000 - fn: 935.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9998 - val_loss: 3.0258e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-45-batch-100000-200000
[INFO] processing batch 200000-300000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0272 - tp: 79100.0000 - fp: 900.0000 - tn: 319100.0000 - fn: 900.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 2.9020e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-45-batch-200000-300000
[INFO] processing batch 300000-400000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0272 - tp: 79109.0000 - fp: 891.0000 - tn: 319109.0000 - fn: 891.0000 - accuracy: 0.9955 - precision: 0.9889 - recall: 0.9889 - auc: 0.9998 - val_loss: 3.2043e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-45-batch-300000-400000
[INFO] processing batch 400000-500000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0271 - tp: 79110.0000 - fp: 890.0000 - tn: 319110.0000 - fn: 890.0000 - accuracy: 0.9955 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 2.7499e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-45-batch-400000-500000
[INFO] processing batch 500000-600000/565742
[33m[INFO] loading file 46-46/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (565742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0275 - tp: 79096.0000 - fp: 904.0000 - tn: 319096.0000 - fn: 904.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 3.9950e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-45-46-batch-0-100000
[INFO] processing batch 100000-200000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0278 - tp: 79108.0000 - fp: 892.0000 - tn: 319108.0000 - fn: 892.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 4.1518e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-45-46-batch-100000-200000
[INFO] processing batch 200000-300000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0270 - tp: 79115.0000 - fp: 885.0000 - tn: 319115.0000 - fn: 885.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 2.7097e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-45-46-batch-200000-300000
[INFO] processing batch 300000-400000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0278 - tp: 79060.0000 - fp: 940.0000 - tn: 319060.0000 - fn: 940.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9998 - val_loss: 2.4725e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-45-46-batch-300000-400000
[INFO] processing batch 400000-500000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0286 - tp: 79049.0000 - fp: 951.0000 - tn: 319049.0000 - fn: 951.0000 - accuracy: 0.9952 - precision: 0.9881 - recall: 0.9881 - auc: 0.9998 - val_loss: 2.3683e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-45-46-batch-400000-500000
[INFO] processing batch 500000-600000/565742
[33m[INFO] loading file 47-47/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (565742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0272 - tp: 79097.0000 - fp: 903.0000 - tn: 319097.0000 - fn: 903.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 2.5762e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-47-batch-0-100000
[INFO] processing batch 100000-200000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0267 - tp: 79125.0000 - fp: 875.0000 - tn: 319125.0000 - fn: 875.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 2.3648e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-47-batch-100000-200000
[INFO] processing batch 200000-300000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0282 - tp: 79055.0000 - fp: 945.0000 - tn: 319055.0000 - fn: 945.0000 - accuracy: 0.9953 - precision: 0.9882 - recall: 0.9882 - auc: 0.9998 - val_loss: 2.1503e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-47-batch-200000-300000
[INFO] processing batch 300000-400000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0279 - tp: 79084.0000 - fp: 916.0000 - tn: 319084.0000 - fn: 916.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9998 - val_loss: 2.1113e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-47-batch-300000-400000
[INFO] processing batch 400000-500000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0271 - tp: 79099.0000 - fp: 901.0000 - tn: 319099.0000 - fn: 901.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 2.0227e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-47-batch-400000-500000
[INFO] processing batch 500000-600000/565742
[33m[INFO] loading file 48-48/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (565742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0272 - tp: 79105.0000 - fp: 895.0000 - tn: 319105.0000 - fn: 895.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 1.9212e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-47-48-batch-0-100000
[INFO] processing batch 100000-200000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0263 - tp: 79136.0000 - fp: 864.0000 - tn: 319136.0000 - fn: 864.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 1.8845e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-47-48-batch-100000-200000
[INFO] processing batch 200000-300000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0267 - tp: 79124.0000 - fp: 876.0000 - tn: 319124.0000 - fn: 876.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 8.2395e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-47-48-batch-200000-300000
[INFO] processing batch 300000-400000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0284 - tp: 79059.0000 - fp: 941.0000 - tn: 319059.0000 - fn: 941.0000 - accuracy: 0.9953 - precision: 0.9882 - recall: 0.9882 - auc: 0.9998 - val_loss: 0.0048 - val_tp: 19988.0000 - val_fp: 12.0000 - val_tn: 79988.0000 - val_fn: 12.0000 - val_accuracy: 0.9998 - val_precision: 0.9994 - val_recall: 0.9994 - val_auc: 0.9996
[INFO] saving weights to checkpoints/lstm-epoch-002-files-47-48-batch-300000-400000
[INFO] processing batch 400000-500000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0266 - tp: 79137.0000 - fp: 863.0000 - tn: 319137.0000 - fn: 863.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9998 - val_loss: 3.2634e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-47-48-batch-400000-500000
[INFO] processing batch 500000-600000/565742
[33m[INFO] loading file 49-49/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (565742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0285 - tp: 79050.0000 - fp: 950.0000 - tn: 319050.0000 - fn: 950.0000 - accuracy: 0.9952 - precision: 0.9881 - recall: 0.9881 - auc: 0.9998 - val_loss: 1.7612e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-49-batch-0-100000
[INFO] processing batch 100000-200000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0278 - tp: 79078.0000 - fp: 922.0000 - tn: 319078.0000 - fn: 922.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9998 - val_loss: 0.0016 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-49-batch-100000-200000
[INFO] processing batch 200000-300000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0265 - tp: 79133.0000 - fp: 867.0000 - tn: 319133.0000 - fn: 867.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9998 - val_loss: 1.8427e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-49-batch-200000-300000
[INFO] processing batch 300000-400000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0267 - tp: 79139.0000 - fp: 861.0000 - tn: 319139.0000 - fn: 861.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 0.0016 - val_tp: 19997.0000 - val_fp: 3.0000 - val_tn: 79997.0000 - val_fn: 3.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-49-batch-300000-400000
[INFO] processing batch 400000-500000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0278 - tp: 79081.0000 - fp: 919.0000 - tn: 319081.0000 - fn: 919.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9998 - val_loss: 4.1179e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-49-batch-400000-500000
[INFO] processing batch 500000-600000/565742
[33m[INFO] loading file 50-50/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (415724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/415724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0273 - tp: 79093.0000 - fp: 907.0000 - tn: 319093.0000 - fn: 907.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 4.1300e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-49-50-batch-0-100000
[INFO] processing batch 100000-200000/415724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0274 - tp: 79084.0000 - fp: 916.0000 - tn: 319084.0000 - fn: 916.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9998 - val_loss: 2.4177e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-49-50-batch-100000-200000
[INFO] processing batch 200000-300000/415724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0283 - tp: 79066.0000 - fp: 934.0000 - tn: 319066.0000 - fn: 934.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9998 - val_loss: 2.1141e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-49-50-batch-200000-300000
[INFO] processing batch 300000-400000/415724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0273 - tp: 79113.0000 - fp: 887.0000 - tn: 319113.0000 - fn: 887.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9998 - val_loss: 2.3911e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-49-50-batch-300000-400000
[INFO] processing batch 400000-500000/415724
[33m[LOSS] 2.3910872070700863e-05[0m
[33m[INFO] epoch 3/10[0m
[33m[INFO] loading file 1-1/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.0743 - tp: 73999.0000 - fp: 6001.0000 - tn: 313999.0000 - fn: 6001.0000 - accuracy: 0.9700 - precision: 0.9250 - recall: 0.9250 - auc: 0.9547 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-1-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0015 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-1-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.3648e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8076 - val_tp: 17757.0000 - val_fp: 2243.0000 - val_tn: 77757.0000 - val_fn: 2243.0000 - val_accuracy: 0.9551 - val_precision: 0.8878 - val_recall: 0.8878 - val_auc: 0.9299
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-1-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.1632 - tp: 42391.0000 - fp: 37609.0000 - tn: 282391.0000 - fn: 37609.0000 - accuracy: 0.8120 - precision: 0.5299 - recall: 0.5299 - auc: 0.7169 - val_loss: 7.5255 - val_tp: 10662.0000 - val_fp: 9338.0000 - val_tn: 70662.0000 - val_fn: 9338.0000 - val_accuracy: 0.8132 - val_precision: 0.5331 - val_recall: 0.5331 - val_auc: 0.7082
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-1-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.1414 - tp: 42414.0000 - fp: 37586.0000 - tn: 282414.0000 - fn: 37586.0000 - accuracy: 0.8121 - precision: 0.5302 - recall: 0.5302 - auc: 0.7174 - val_loss: 7.5691 - val_tp: 10608.0000 - val_fp: 9392.0000 - val_tn: 70608.0000 - val_fn: 9392.0000 - val_accuracy: 0.8122 - val_precision: 0.5304 - val_recall: 0.5304 - val_auc: 0.7065
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-1-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 2-2/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.1501 - tp: 42344.0000 - fp: 37656.0000 - tn: 282344.0000 - fn: 37656.0000 - accuracy: 0.8117 - precision: 0.5293 - recall: 0.5293 - auc: 0.7168 - val_loss: 7.5457 - val_tp: 10637.0000 - val_fp: 9363.0000 - val_tn: 70637.0000 - val_fn: 9363.0000 - val_accuracy: 0.8127 - val_precision: 0.5318 - val_recall: 0.5318 - val_auc: 0.7074
[INFO] saving weights to checkpoints/lstm-epoch-003-files-1-2-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.7710 - tp: 60214.0000 - fp: 19786.0000 - tn: 300214.0000 - fn: 19786.0000 - accuracy: 0.9011 - precision: 0.7527 - recall: 0.7527 - auc: 0.8513 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-1-2-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0403 - tp: 79807.0000 - fp: 193.0000 - tn: 319807.0000 - fn: 193.0000 - accuracy: 0.9990 - precision: 0.9976 - recall: 0.9976 - auc: 0.9985 - val_loss: 7.5650 - val_tp: 10613.0000 - val_fp: 9387.0000 - val_tn: 70613.0000 - val_fn: 9387.0000 - val_accuracy: 0.8123 - val_precision: 0.5307 - val_recall: 0.5307 - val_auc: 0.7067
[INFO] saving weights to checkpoints/lstm-epoch-003-files-1-2-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.1544 - tp: 42352.0000 - fp: 37648.0000 - tn: 282352.0000 - fn: 37648.0000 - accuracy: 0.8118 - precision: 0.5294 - recall: 0.5294 - auc: 0.7172 - val_loss: 7.6021 - val_tp: 10567.0000 - val_fp: 9433.0000 - val_tn: 70567.0000 - val_fn: 9433.0000 - val_accuracy: 0.8113 - val_precision: 0.5283 - val_recall: 0.5283 - val_auc: 0.7052
[INFO] saving weights to checkpoints/lstm-epoch-003-files-1-2-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.8225 - tp: 59969.0000 - fp: 20031.0000 - tn: 299969.0000 - fn: 20031.0000 - accuracy: 0.8998 - precision: 0.7496 - recall: 0.7496 - auc: 0.8493 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-1-2-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 3-3/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.2102 - tp: 52649.0000 - fp: 27351.0000 - tn: 292649.0000 - fn: 27351.0000 - accuracy: 0.8632 - precision: 0.6581 - recall: 0.6581 - auc: 0.7942 - val_loss: 7.6045 - val_tp: 10564.0000 - val_fp: 9436.0000 - val_tn: 70564.0000 - val_fn: 9436.0000 - val_accuracy: 0.8113 - val_precision: 0.5282 - val_recall: 0.5282 - val_auc: 0.7051
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-3-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.6492 - tp: 50344.0000 - fp: 29656.0000 - tn: 290344.0000 - fn: 29656.0000 - accuracy: 0.8517 - precision: 0.6293 - recall: 0.6293 - auc: 0.7768 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-3-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0044 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-3-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.5378e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-3-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.5928e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-3-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 4-4/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.3942e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-3-4-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.7341e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-3-4-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.3473e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-3-4-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.0232e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.9407 - val_tp: 8906.0000 - val_fp: 11094.0000 - val_tn: 68906.0000 - val_fn: 11094.0000 - val_accuracy: 0.7781 - val_precision: 0.4453 - val_recall: 0.4453 - val_auc: 0.6533
[INFO] saving weights to checkpoints/lstm-epoch-003-files-3-4-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.2262 - tp: 47315.0000 - fp: 32685.0000 - tn: 287315.0000 - fn: 32685.0000 - accuracy: 0.8366 - precision: 0.5914 - recall: 0.5914 - auc: 0.7536 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-3-4-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 5-5/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.2848 - tp: 68107.0000 - fp: 11893.0000 - tn: 308107.0000 - fn: 11893.0000 - accuracy: 0.9405 - precision: 0.8513 - recall: 0.8513 - auc: 0.9101 - val_loss: 5.8114 - val_tp: 12789.0000 - val_fp: 7211.0000 - val_tn: 72789.0000 - val_fn: 7211.0000 - val_accuracy: 0.8558 - val_precision: 0.6395 - val_recall: 0.6395 - val_auc: 0.7747
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-5-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.4502 - tp: 51359.0000 - fp: 28641.0000 - tn: 291359.0000 - fn: 28641.0000 - accuracy: 0.8568 - precision: 0.6420 - recall: 0.6420 - auc: 0.7846 - val_loss: 5.7880 - val_tp: 12818.0000 - val_fp: 7182.0000 - val_tn: 72818.0000 - val_fn: 7182.0000 - val_accuracy: 0.8564 - val_precision: 0.6409 - val_recall: 0.6409 - val_auc: 0.7756
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-5-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.2740 - tp: 78582.0000 - fp: 1418.0000 - tn: 318582.0000 - fn: 1418.0000 - accuracy: 0.9929 - precision: 0.9823 - recall: 0.9823 - auc: 0.9894 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-5-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 8.8928e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-5-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.8029e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-5-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 6-6/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.4076e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-5-6-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.6786e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-5-6-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.2579e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-5-6-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 9.8402e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-5-6-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.2437 - tp: 52495.0000 - fp: 27505.0000 - tn: 292495.0000 - fn: 27505.0000 - accuracy: 0.8625 - precision: 0.6562 - recall: 0.6562 - auc: 0.7927 - val_loss: 5.8138 - val_tp: 12786.0000 - val_fp: 7214.0000 - val_tn: 72786.0000 - val_fn: 7214.0000 - val_accuracy: 0.8557 - val_precision: 0.6393 - val_recall: 0.6393 - val_auc: 0.7746
[INFO] saving weights to checkpoints/lstm-epoch-003-files-5-6-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 7-7/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.3785 - tp: 51728.0000 - fp: 28272.0000 - tn: 291728.0000 - fn: 28272.0000 - accuracy: 0.8586 - precision: 0.6466 - recall: 0.6466 - auc: 0.7875 - val_loss: 4.8185 - val_tp: 14001.0000 - val_fp: 5999.0000 - val_tn: 74001.0000 - val_fn: 5999.0000 - val_accuracy: 0.8800 - val_precision: 0.7000 - val_recall: 0.7000 - val_auc: 0.8129
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-7-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.2849 - tp: 77784.0000 - fp: 2216.0000 - tn: 317784.0000 - fn: 2216.0000 - accuracy: 0.9889 - precision: 0.9723 - recall: 0.9723 - auc: 0.9896 - val_loss: 1.9031e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-7-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.8910 - tp: 71305.0000 - fp: 8695.0000 - tn: 311305.0000 - fn: 8695.0000 - accuracy: 0.9565 - precision: 0.8913 - recall: 0.8913 - auc: 0.9389 - val_loss: 2.6077 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 72847.0000 - val_fn: 7153.0000 - val_accuracy: 0.8569 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.7795
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-7-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.1402 - tp: 65077.0000 - fp: 14923.0000 - tn: 305077.0000 - fn: 14923.0000 - accuracy: 0.9254 - precision: 0.8135 - recall: 0.8135 - auc: 0.9248 - val_loss: 0.1341 - val_tp: 19250.0000 - val_fp: 750.0000 - val_tn: 79250.0000 - val_fn: 750.0000 - val_accuracy: 0.9850 - val_precision: 0.9625 - val_recall: 0.9625 - val_auc: 0.9996
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-7-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0190 - tp: 79538.0000 - fp: 462.0000 - tn: 319538.0000 - fn: 462.0000 - accuracy: 0.9977 - precision: 0.9942 - recall: 0.9942 - auc: 0.9999 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-7-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 8-8/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0038 - tp: 79899.0000 - fp: 101.0000 - tn: 319899.0000 - fn: 101.0000 - accuracy: 0.9995 - precision: 0.9987 - recall: 0.9987 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-7-8-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.7982e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-7-8-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.7946e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-7-8-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.7853 - tp: 76033.0000 - fp: 3967.0000 - tn: 316033.0000 - fn: 3967.0000 - accuracy: 0.9802 - precision: 0.9504 - recall: 0.9504 - auc: 0.9690 - val_loss: 2.9335 - val_tp: 16360.0000 - val_fp: 3640.0000 - val_tn: 76360.0000 - val_fn: 3640.0000 - val_accuracy: 0.9272 - val_precision: 0.8180 - val_recall: 0.8180 - val_auc: 0.8863
[INFO] saving weights to checkpoints/lstm-epoch-003-files-7-8-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.7209 - tp: 65483.0000 - fp: 14517.0000 - tn: 305483.0000 - fn: 14517.0000 - accuracy: 0.9274 - precision: 0.8185 - recall: 0.8185 - auc: 0.8912 - val_loss: 2.9182 - val_tp: 16379.0000 - val_fp: 3621.0000 - val_tn: 76379.0000 - val_fn: 3621.0000 - val_accuracy: 0.9276 - val_precision: 0.8189 - val_recall: 0.8189 - val_auc: 0.8868
[INFO] saving weights to checkpoints/lstm-epoch-003-files-7-8-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 9-9/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.6542 - tp: 65290.0000 - fp: 14710.0000 - tn: 305290.0000 - fn: 14710.0000 - accuracy: 0.9264 - precision: 0.8161 - recall: 0.8161 - auc: 0.8935 - val_loss: 2.9416 - val_tp: 16350.0000 - val_fp: 3650.0000 - val_tn: 76350.0000 - val_fn: 3650.0000 - val_accuracy: 0.9270 - val_precision: 0.8175 - val_recall: 0.8175 - val_auc: 0.8859
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-9-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.7318 - tp: 76003.0000 - fp: 3997.0000 - tn: 316003.0000 - fn: 3997.0000 - accuracy: 0.9800 - precision: 0.9500 - recall: 0.9500 - auc: 0.9709 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-9-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0022 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-9-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.2328e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-9-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.6218e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-9-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 10-10/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.4218e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-9-10-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.7618e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2798 - val_tp: 18412.0000 - val_fp: 1588.0000 - val_tn: 78412.0000 - val_fn: 1588.0000 - val_accuracy: 0.9682 - val_precision: 0.9206 - val_recall: 0.9206 - val_auc: 0.9504
[INFO] saving weights to checkpoints/lstm-epoch-003-files-9-10-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.1760 - tp: 51323.0000 - fp: 28677.0000 - tn: 291323.0000 - fn: 28677.0000 - accuracy: 0.8566 - precision: 0.6415 - recall: 0.6415 - auc: 0.7911 - val_loss: 0.2289 - val_tp: 19716.0000 - val_fp: 284.0000 - val_tn: 79716.0000 - val_fn: 284.0000 - val_accuracy: 0.9943 - val_precision: 0.9858 - val_recall: 0.9858 - val_auc: 0.9911
[INFO] saving weights to checkpoints/lstm-epoch-003-files-9-10-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0074 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-9-10-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0010 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-9-10-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 11-11/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7823e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-11-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.7918e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-11-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.7565e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-11-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.1148e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-11-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.6470e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-11-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 12-12/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.3513e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-11-12-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.1168e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-11-12-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.7340 - tp: 53660.0000 - fp: 26340.0000 - tn: 293660.0000 - fn: 26340.0000 - accuracy: 0.8683 - precision: 0.6708 - recall: 0.6708 - auc: 0.8088 - val_loss: 5.7590 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.7767
[INFO] saving weights to checkpoints/lstm-epoch-003-files-11-12-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4988 - tp: 77295.0000 - fp: 2705.0000 - tn: 317295.0000 - fn: 2705.0000 - accuracy: 0.9865 - precision: 0.9662 - recall: 0.9662 - auc: 0.9804 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-11-12-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-11-12-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 13-13/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.9499e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-13-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.0076e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-13-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.8182e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-13-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.0408 - tp: 52039.0000 - fp: 27961.0000 - tn: 292039.0000 - fn: 27961.0000 - accuracy: 0.8602 - precision: 0.6505 - recall: 0.6505 - auc: 0.7968 - val_loss: 5.7872 - val_tp: 12819.0000 - val_fp: 7181.0000 - val_tn: 72819.0000 - val_fn: 7181.0000 - val_accuracy: 0.8564 - val_precision: 0.6410 - val_recall: 0.6410 - val_auc: 0.7756
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-13-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.1127 - tp: 51390.0000 - fp: 28610.0000 - tn: 291390.0000 - fn: 28610.0000 - accuracy: 0.8569 - precision: 0.6424 - recall: 0.6424 - auc: 0.7937 - val_loss: 5.7872 - val_tp: 12819.0000 - val_fp: 7181.0000 - val_tn: 72819.0000 - val_fn: 7181.0000 - val_accuracy: 0.8564 - val_precision: 0.6410 - val_recall: 0.6410 - val_auc: 0.7756
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-13-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 14-14/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.1367 - tp: 56963.0000 - fp: 23037.0000 - tn: 296963.0000 - fn: 23037.0000 - accuracy: 0.8848 - precision: 0.7120 - recall: 0.7120 - auc: 0.8333 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-13-14-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0057 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-13-14-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 9.2049e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-13-14-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.1427e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-13-14-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.4000e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-13-14-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 15-15/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.5149e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-15-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.9039e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.0602e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-15-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.5068e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-15-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.2021e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8929 - val_tp: 18892.0000 - val_fp: 1108.0000 - val_tn: 78892.0000 - val_fn: 1108.0000 - val_accuracy: 0.9778 - val_precision: 0.9446 - val_recall: 0.9446 - val_auc: 0.9654
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-15-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.5298 - tp: 42627.0000 - fp: 37373.0000 - tn: 282627.0000 - fn: 37373.0000 - accuracy: 0.8131 - precision: 0.5328 - recall: 0.5328 - auc: 0.7080 - val_loss: 7.5473 - val_tp: 10635.0000 - val_fp: 9365.0000 - val_tn: 70635.0000 - val_fn: 9365.0000 - val_accuracy: 0.8127 - val_precision: 0.5318 - val_recall: 0.5318 - val_auc: 0.7073
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-15-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 16-16/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (455414, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/455414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.5566 - tp: 42494.0000 - fp: 37506.0000 - tn: 282494.0000 - fn: 37506.0000 - accuracy: 0.8125 - precision: 0.5312 - recall: 0.5312 - auc: 0.7070 - val_loss: 7.5562 - val_tp: 10624.0000 - val_fp: 9376.0000 - val_tn: 70624.0000 - val_fn: 9376.0000 - val_accuracy: 0.8125 - val_precision: 0.5312 - val_recall: 0.5312 - val_auc: 0.7070
[INFO] saving weights to checkpoints/lstm-epoch-003-files-15-16-batch-0-100000
[INFO] processing batch 100000-200000/455414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.8443 - tp: 50993.0000 - fp: 29007.0000 - tn: 290993.0000 - fn: 29007.0000 - accuracy: 0.8550 - precision: 0.6374 - recall: 0.6374 - auc: 0.7734 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-15-16-batch-100000-200000
[INFO] processing batch 200000-300000/455414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.9776e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-15-16-batch-200000-300000
[INFO] processing batch 300000-400000/455414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7377e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-15-16-batch-300000-400000
[INFO] processing batch 400000-500000/455414
[33m[INFO] loading file 17-17/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (555414, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.8208e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-17-batch-0-100000
[INFO] processing batch 100000-200000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.0179e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-17-batch-100000-200000
[INFO] processing batch 200000-300000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.4205e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-17-batch-200000-300000
[INFO] processing batch 300000-400000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.7162 - tp: 71482.0000 - fp: 8518.0000 - tn: 311482.0000 - fn: 8518.0000 - accuracy: 0.9574 - precision: 0.8935 - recall: 0.8935 - auc: 0.9335 - val_loss: 2.9456 - val_tp: 16345.0000 - val_fp: 3655.0000 - val_tn: 76345.0000 - val_fn: 3655.0000 - val_accuracy: 0.9269 - val_precision: 0.8173 - val_recall: 0.8173 - val_auc: 0.8858
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-17-batch-300000-400000
[INFO] processing batch 400000-500000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.9154 - tp: 65530.0000 - fp: 14470.0000 - tn: 305530.0000 - fn: 14470.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.8870 - val_loss: 2.9238 - val_tp: 16372.0000 - val_fp: 3628.0000 - val_tn: 76372.0000 - val_fn: 3628.0000 - val_accuracy: 0.9274 - val_precision: 0.8186 - val_recall: 0.8186 - val_auc: 0.8866
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-17-batch-400000-500000
[INFO] processing batch 500000-600000/555414
[33m[INFO] loading file 18-18/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (555414, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.4985 - tp: 77526.0000 - fp: 2474.0000 - tn: 317526.0000 - fn: 2474.0000 - accuracy: 0.9876 - precision: 0.9691 - recall: 0.9691 - auc: 0.9807 - val_loss: 6.1305 - val_tp: 12393.0000 - val_fp: 7607.0000 - val_tn: 72393.0000 - val_fn: 7607.0000 - val_accuracy: 0.8479 - val_precision: 0.6197 - val_recall: 0.6197 - val_auc: 0.7623
[INFO] saving weights to checkpoints/lstm-epoch-003-files-17-18-batch-0-100000
[INFO] processing batch 100000-200000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.1305 - tp: 49572.0000 - fp: 30428.0000 - tn: 289572.0000 - fn: 30428.0000 - accuracy: 0.8479 - precision: 0.6197 - recall: 0.6197 - auc: 0.7623 - val_loss: 6.0395 - val_tp: 12506.0000 - val_fp: 7494.0000 - val_tn: 72506.0000 - val_fn: 7494.0000 - val_accuracy: 0.8501 - val_precision: 0.6253 - val_recall: 0.6253 - val_auc: 0.7658
[INFO] saving weights to checkpoints/lstm-epoch-003-files-17-18-batch-100000-200000
[INFO] processing batch 200000-300000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.1444 - tp: 49503.0000 - fp: 30497.0000 - tn: 289503.0000 - fn: 30497.0000 - accuracy: 0.8475 - precision: 0.6188 - recall: 0.6188 - auc: 0.7617 - val_loss: 6.1474 - val_tp: 12372.0000 - val_fp: 7628.0000 - val_tn: 72372.0000 - val_fn: 7628.0000 - val_accuracy: 0.8474 - val_precision: 0.6186 - val_recall: 0.6186 - val_auc: 0.7616
[INFO] saving weights to checkpoints/lstm-epoch-003-files-17-18-batch-200000-300000
[INFO] processing batch 300000-400000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.3067 - tp: 68551.0000 - fp: 11449.0000 - tn: 308551.0000 - fn: 11449.0000 - accuracy: 0.9428 - precision: 0.8569 - recall: 0.8569 - auc: 0.9106 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-17-18-batch-300000-400000
[INFO] processing batch 400000-500000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.3822e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-17-18-batch-400000-500000
[INFO] processing batch 500000-600000/555414
[33m[INFO] loading file 19-19/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (555414, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.1807e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-19-batch-0-100000
[INFO] processing batch 100000-200000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.0014e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-19-batch-100000-200000
[INFO] processing batch 200000-300000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 8.7745e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-19-batch-200000-300000
[INFO] processing batch 300000-400000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.2222 - tp: 78897.0000 - fp: 1103.0000 - tn: 318897.0000 - fn: 1103.0000 - accuracy: 0.9945 - precision: 0.9862 - recall: 0.9862 - auc: 0.9914 - val_loss: 9.7974 - val_tp: 7843.0000 - val_fp: 12157.0000 - val_tn: 67843.0000 - val_fn: 12157.0000 - val_accuracy: 0.7569 - val_precision: 0.3922 - val_recall: 0.3922 - val_auc: 0.6201
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-19-batch-300000-400000
[INFO] processing batch 400000-500000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 9.8375 - tp: 31173.0000 - fp: 48827.0000 - tn: 271173.0000 - fn: 48827.0000 - accuracy: 0.7559 - precision: 0.3897 - recall: 0.3897 - auc: 0.6185 - val_loss: 7.6343 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.7040
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-19-batch-400000-500000
[INFO] processing batch 500000-600000/555414
[33m[INFO] loading file 20-20/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (555414, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.1688e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-19-20-batch-0-100000
[INFO] processing batch 100000-200000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.4602 - tp: 67789.0000 - fp: 12211.0000 - tn: 307789.0000 - fn: 12211.0000 - accuracy: 0.9389 - precision: 0.8474 - recall: 0.8474 - auc: 0.9046 - val_loss: 2.9625 - val_tp: 16324.0000 - val_fp: 3676.0000 - val_tn: 76324.0000 - val_fn: 3676.0000 - val_accuracy: 0.9265 - val_precision: 0.8162 - val_recall: 0.8162 - val_auc: 0.8851
[INFO] saving weights to checkpoints/lstm-epoch-003-files-19-20-batch-100000-200000
[INFO] processing batch 200000-300000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.9434 - tp: 65391.0000 - fp: 14609.0000 - tn: 305391.0000 - fn: 14609.0000 - accuracy: 0.9270 - precision: 0.8174 - recall: 0.8174 - auc: 0.8859 - val_loss: 2.9424 - val_tp: 16349.0000 - val_fp: 3651.0000 - val_tn: 76349.0000 - val_fn: 3651.0000 - val_accuracy: 0.9270 - val_precision: 0.8174 - val_recall: 0.8174 - val_auc: 0.8859
[INFO] saving weights to checkpoints/lstm-epoch-003-files-19-20-batch-200000-300000
[INFO] processing batch 300000-400000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.3765 - tp: 73168.0000 - fp: 6832.0000 - tn: 313168.0000 - fn: 6832.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9466 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-19-20-batch-300000-400000
[INFO] processing batch 400000-500000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.6636e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-19-20-batch-400000-500000
[INFO] processing batch 500000-600000/555414
[33m[INFO] loading file 21-21/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (555412, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/555412
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.1905e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-21-batch-0-100000
[INFO] processing batch 100000-200000/555412
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.7818e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-21-batch-100000-200000
[INFO] processing batch 200000-300000/555412
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.4101e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-21-batch-200000-300000
[INFO] processing batch 300000-400000/555412
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 2.0918e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-21-batch-300000-400000
[INFO] processing batch 400000-500000/555412
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.8384e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-21-batch-400000-500000
[INFO] processing batch 500000-600000/555412
[33m[INFO] loading file 22-22/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (324453, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/324453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 3.5530 - tp: 62365.0000 - fp: 17635.0000 - tn: 302365.0000 - fn: 17635.0000 - accuracy: 0.9118 - precision: 0.7796 - recall: 0.7796 - auc: 0.8622 - val_loss: 7.5626 - val_tp: 10616.0000 - val_fp: 9384.0000 - val_tn: 70616.0000 - val_fn: 9384.0000 - val_accuracy: 0.8123 - val_precision: 0.5308 - val_recall: 0.5308 - val_auc: 0.7068
[INFO] saving weights to checkpoints/lstm-epoch-003-files-21-22-batch-0-100000
[INFO] processing batch 100000-200000/324453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.5699 - tp: 42428.0000 - fp: 37572.0000 - tn: 282428.0000 - fn: 37572.0000 - accuracy: 0.8121 - precision: 0.5304 - recall: 0.5304 - auc: 0.7065 - val_loss: 7.5900 - val_tp: 10582.0000 - val_fp: 9418.0000 - val_tn: 70582.0000 - val_fn: 9418.0000 - val_accuracy: 0.8116 - val_precision: 0.5291 - val_recall: 0.5291 - val_auc: 0.7057
[INFO] saving weights to checkpoints/lstm-epoch-003-files-21-22-batch-100000-200000
[INFO] processing batch 200000-300000/324453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.5856 - tp: 42350.0000 - fp: 37650.0000 - tn: 282350.0000 - fn: 37650.0000 - accuracy: 0.8117 - precision: 0.5294 - recall: 0.5294 - auc: 0.7059 - val_loss: 7.6077 - val_tp: 10560.0000 - val_fp: 9440.0000 - val_tn: 70560.0000 - val_fn: 9440.0000 - val_accuracy: 0.8112 - val_precision: 0.5280 - val_recall: 0.5280 - val_auc: 0.7050
[INFO] saving weights to checkpoints/lstm-epoch-003-files-21-22-batch-200000-300000
[INFO] processing batch 300000-400000/324453
[33m[INFO] loading file 23-23/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524453, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.1278 - tp: 59512.0000 - fp: 20488.0000 - tn: 299512.0000 - fn: 20488.0000 - accuracy: 0.8976 - precision: 0.7439 - recall: 0.7439 - auc: 0.8399 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-23-batch-0-100000
[INFO] processing batch 100000-200000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.1301e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-23-batch-100000-200000
[INFO] processing batch 200000-300000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 9.8801e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-23-batch-200000-300000
[INFO] processing batch 300000-400000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 8.7069e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-23-batch-300000-400000
[INFO] processing batch 400000-500000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 7.7063e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-23-batch-400000-500000
[INFO] processing batch 500000-600000/524453
[33m[INFO] loading file 24-24/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524453, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.7825e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-23-24-batch-0-100000
[INFO] processing batch 100000-200000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 6.1202e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-23-24-batch-100000-200000
[INFO] processing batch 200000-300000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.3740e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-23-24-batch-200000-300000
[INFO] processing batch 300000-400000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.7974e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-23-24-batch-300000-400000
[INFO] processing batch 400000-500000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 1.9515 - tp: 70314.0000 - fp: 9686.0000 - tn: 310314.0000 - fn: 9686.0000 - accuracy: 0.9516 - precision: 0.8789 - recall: 0.8789 - auc: 0.9243 - val_loss: 5.7340 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.7777
[INFO] saving weights to checkpoints/lstm-epoch-003-files-23-24-batch-400000-500000
[INFO] processing batch 500000-600000/524453
[33m[INFO] loading file 25-25/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524453, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7499 - tp: 51461.0000 - fp: 28539.0000 - tn: 291461.0000 - fn: 28539.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.7770 - val_loss: 5.7421 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.7773
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-25-batch-0-100000
[INFO] processing batch 100000-200000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7445 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.7772 - val_loss: 5.7453 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.7772
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-25-batch-100000-200000
[INFO] processing batch 200000-300000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7511 - tp: 51455.0000 - fp: 28545.0000 - tn: 291455.0000 - fn: 28545.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.7770 - val_loss: 5.7558 - val_tp: 12858.0000 - val_fp: 7142.0000 - val_tn: 72858.0000 - val_fn: 7142.0000 - val_accuracy: 0.8572 - val_precision: 0.6429 - val_recall: 0.6429 - val_auc: 0.7768
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-25-batch-200000-300000
[INFO] processing batch 300000-400000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7415 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.7774 - val_loss: 5.7759 - val_tp: 12833.0000 - val_fp: 7167.0000 - val_tn: 72833.0000 - val_fn: 7167.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.7760
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-25-batch-300000-400000
[INFO] processing batch 400000-500000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7405 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.7774 - val_loss: 5.7590 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.7767
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-25-batch-400000-500000
[INFO] processing batch 500000-600000/524453
[33m[INFO] loading file 26-26/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524453, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.7143 - tp: 51526.0000 - fp: 28474.0000 - tn: 291526.0000 - fn: 28474.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.7748 - val_loss: 5.7268 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.7779
[INFO] saving weights to checkpoints/lstm-epoch-003-files-25-26-batch-0-100000
[INFO] processing batch 100000-200000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.0826 - tp: 51547.0000 - fp: 28453.0000 - tn: 291547.0000 - fn: 28453.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.7948 - val_loss: 5.7703 - val_tp: 12840.0000 - val_fp: 7160.0000 - val_tn: 72840.0000 - val_fn: 7160.0000 - val_accuracy: 0.8568 - val_precision: 0.6420 - val_recall: 0.6420 - val_auc: 0.7762
[INFO] saving weights to checkpoints/lstm-epoch-003-files-25-26-batch-100000-200000
[INFO] processing batch 200000-300000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.1134 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.7938 - val_loss: 5.7171 - val_tp: 12906.0000 - val_fp: 7094.0000 - val_tn: 72906.0000 - val_fn: 7094.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.7783
[INFO] saving weights to checkpoints/lstm-epoch-003-files-25-26-batch-200000-300000
[INFO] processing batch 300000-400000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.0934 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.7945 - val_loss: 5.7421 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.7773
[INFO] saving weights to checkpoints/lstm-epoch-003-files-25-26-batch-300000-400000
[INFO] processing batch 400000-500000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 5.0942 - tp: 51530.0000 - fp: 28470.0000 - tn: 291530.0000 - fn: 28470.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.7945 - val_loss: 5.7300 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.7778
[INFO] saving weights to checkpoints/lstm-epoch-003-files-25-26-batch-400000-500000
[INFO] processing batch 500000-600000/524453
[33m[INFO] loading file 27-27/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (464583, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/464583
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 4.1387 - tp: 56137.0000 - fp: 23863.0000 - tn: 296137.0000 - fn: 23863.0000 - accuracy: 0.8807 - precision: 0.7017 - recall: 0.7017 - auc: 0.8311 - val_loss: 0.5532 - val_tp: 19278.0000 - val_fp: 722.0000 - val_tn: 79278.0000 - val_fn: 722.0000 - val_accuracy: 0.9856 - val_precision: 0.9639 - val_recall: 0.9639 - val_auc: 0.9766
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-27-batch-0-100000
[INFO] processing batch 100000-200000/464583
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0398 - tp: 79034.0000 - fp: 966.0000 - tn: 319034.0000 - fn: 966.0000 - accuracy: 0.9952 - precision: 0.9879 - recall: 0.9879 - auc: 0.9995 - val_loss: 0.0029 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-27-batch-100000-200000
[INFO] processing batch 200000-300000/464583
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0286 - tp: 79160.0000 - fp: 840.0000 - tn: 319160.0000 - fn: 840.0000 - accuracy: 0.9958 - precision: 0.9895 - recall: 0.9895 - auc: 0.9999 - val_loss: 0.0017 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-27-batch-200000-300000
[INFO] processing batch 300000-400000/464583
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0294 - tp: 79113.0000 - fp: 887.0000 - tn: 319113.0000 - fn: 887.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9998 - val_loss: 0.0022 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-27-batch-300000-400000
[INFO] processing batch 400000-500000/464583
[33m[INFO] loading file 28-28/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (398499, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/398499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0300 - tp: 79061.0000 - fp: 939.0000 - tn: 319061.0000 - fn: 939.0000 - accuracy: 0.9953 - precision: 0.9883 - recall: 0.9883 - auc: 0.9998 - val_loss: 0.0030 - val_tp: 19996.0000 - val_fp: 4.0000 - val_tn: 79996.0000 - val_fn: 4.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-003-files-27-28-batch-0-100000
[INFO] processing batch 100000-200000/398499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0296 - tp: 79083.0000 - fp: 917.0000 - tn: 319083.0000 - fn: 917.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9998 - val_loss: 0.0019 - val_tp: 19997.0000 - val_fp: 3.0000 - val_tn: 79997.0000 - val_fn: 3.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-003-files-27-28-batch-100000-200000
[INFO] processing batch 200000-300000/398499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0286 - tp: 79139.0000 - fp: 861.0000 - tn: 319139.0000 - fn: 861.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9998 - val_loss: 7.8369e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-27-28-batch-200000-300000
[INFO] processing batch 300000-400000/398499
[33m[INFO] loading file 29-29/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (598499, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0275 - tp: 79147.0000 - fp: 853.0000 - tn: 319147.0000 - fn: 853.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9999 - val_loss: 5.3652e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-29-batch-0-100000
[INFO] processing batch 100000-200000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0277 - tp: 79146.0000 - fp: 854.0000 - tn: 319146.0000 - fn: 854.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9998 - val_loss: 4.9695e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-29-batch-100000-200000
[INFO] processing batch 200000-300000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0274 - tp: 79140.0000 - fp: 860.0000 - tn: 319140.0000 - fn: 860.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9999 - val_loss: 0.0021 - val_tp: 19997.0000 - val_fp: 3.0000 - val_tn: 79997.0000 - val_fn: 3.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-29-batch-200000-300000
[INFO] processing batch 300000-400000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0277 - tp: 79135.0000 - fp: 865.0000 - tn: 319135.0000 - fn: 865.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9998 - val_loss: 5.5512e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-29-batch-300000-400000
[INFO] processing batch 400000-500000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0275 - tp: 79137.0000 - fp: 863.0000 - tn: 319137.0000 - fn: 863.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 8.4125e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-29-batch-400000-500000
[INFO] processing batch 500000-600000/598499
[33m[INFO] loading file 30-30/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (598499, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0279 - tp: 79120.0000 - fp: 880.0000 - tn: 319120.0000 - fn: 880.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 3.9734e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-29-30-batch-0-100000
[INFO] processing batch 100000-200000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0286 - tp: 79076.0000 - fp: 924.0000 - tn: 319076.0000 - fn: 924.0000 - accuracy: 0.9954 - precision: 0.9884 - recall: 0.9884 - auc: 0.9998 - val_loss: 0.0011 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-003-files-29-30-batch-100000-200000
[INFO] processing batch 200000-300000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0273 - tp: 79125.0000 - fp: 875.0000 - tn: 319125.0000 - fn: 875.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 7.4290e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-29-30-batch-200000-300000
[INFO] processing batch 300000-400000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0276 - tp: 79112.0000 - fp: 888.0000 - tn: 319112.0000 - fn: 888.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9998 - val_loss: 2.9697e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-29-30-batch-300000-400000
[INFO] processing batch 400000-500000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0278 - tp: 79102.0000 - fp: 898.0000 - tn: 319102.0000 - fn: 898.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 2.7503e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-29-30-batch-400000-500000
[INFO] processing batch 500000-600000/598499
[33m[INFO] loading file 31-31/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (598499, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0280 - tp: 79099.0000 - fp: 901.0000 - tn: 319099.0000 - fn: 901.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 2.3390e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-31-batch-0-100000
[INFO] processing batch 100000-200000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0274 - tp: 79126.0000 - fp: 874.0000 - tn: 319126.0000 - fn: 874.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 2.1917e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-31-batch-100000-200000
[INFO] processing batch 200000-300000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0271 - tp: 79124.0000 - fp: 876.0000 - tn: 319124.0000 - fn: 876.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 1.9492e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-31-batch-200000-300000
[INFO] processing batch 300000-400000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0273 - tp: 79118.0000 - fp: 882.0000 - tn: 319118.0000 - fn: 882.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 1.7457e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-31-batch-300000-400000
[INFO] processing batch 400000-500000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0271 - tp: 79134.0000 - fp: 866.0000 - tn: 319134.0000 - fn: 866.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9998 - val_loss: 9.7926e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-31-batch-400000-500000
[INFO] processing batch 500000-600000/598499
[33m[INFO] loading file 32-32/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (598499, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0276 - tp: 79105.0000 - fp: 895.0000 - tn: 319105.0000 - fn: 895.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 9.5189e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-31-32-batch-0-100000
[INFO] processing batch 100000-200000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0271 - tp: 79110.0000 - fp: 890.0000 - tn: 319110.0000 - fn: 890.0000 - accuracy: 0.9955 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 1.4357e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-31-32-batch-100000-200000
[INFO] processing batch 200000-300000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0272 - tp: 79111.0000 - fp: 889.0000 - tn: 319111.0000 - fn: 889.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 1.3172e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-31-32-batch-200000-300000
[INFO] processing batch 300000-400000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0275 - tp: 79114.0000 - fp: 886.0000 - tn: 319114.0000 - fn: 886.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9998 - val_loss: 0.0051 - val_tp: 19987.0000 - val_fp: 13.0000 - val_tn: 79987.0000 - val_fn: 13.0000 - val_accuracy: 0.9997 - val_precision: 0.9994 - val_recall: 0.9994 - val_auc: 0.9997
[INFO] saving weights to checkpoints/lstm-epoch-003-files-31-32-batch-300000-400000
[INFO] processing batch 400000-500000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0273 - tp: 79132.0000 - fp: 868.0000 - tn: 319132.0000 - fn: 868.0000 - accuracy: 0.9957 - precision: 0.9891 - recall: 0.9891 - auc: 0.9998 - val_loss: 1.1568e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-31-32-batch-400000-500000
[INFO] processing batch 500000-600000/598499
[33m[INFO] loading file 33-33/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (598499, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0267 - tp: 79115.0000 - fp: 885.0000 - tn: 319115.0000 - fn: 885.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 9.6532e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-33-batch-0-100000
[INFO] processing batch 100000-200000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0282 - tp: 79081.0000 - fp: 919.0000 - tn: 319081.0000 - fn: 919.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9998 - val_loss: 9.8115e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-33-batch-100000-200000
[INFO] processing batch 200000-300000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0293 - tp: 79034.0000 - fp: 966.0000 - tn: 319034.0000 - fn: 966.0000 - accuracy: 0.9952 - precision: 0.9879 - recall: 0.9879 - auc: 0.9998 - val_loss: 8.9755e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-33-batch-200000-300000
[INFO] processing batch 300000-400000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0272 - tp: 79116.0000 - fp: 884.0000 - tn: 319116.0000 - fn: 884.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9998 - val_loss: 9.5951e-04 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-33-batch-300000-400000
[INFO] processing batch 400000-500000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0275 - tp: 79125.0000 - fp: 875.0000 - tn: 319125.0000 - fn: 875.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9998 - val_loss: 9.0258e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-33-batch-400000-500000
[INFO] processing batch 500000-600000/598499
[33m[INFO] loading file 34-34/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439932, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/439932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0278 - tp: 79083.0000 - fp: 917.0000 - tn: 319083.0000 - fn: 917.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9998 - val_loss: 5.0254e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-33-34-batch-0-100000
[INFO] processing batch 100000-200000/439932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0269 - tp: 79106.0000 - fp: 894.0000 - tn: 319106.0000 - fn: 894.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 7.7060e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-33-34-batch-100000-200000
[INFO] processing batch 200000-300000/439932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0278 - tp: 79094.0000 - fp: 906.0000 - tn: 319094.0000 - fn: 906.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 0.0013 - val_tp: 19997.0000 - val_fp: 3.0000 - val_tn: 79997.0000 - val_fn: 3.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-003-files-33-34-batch-200000-300000
[INFO] processing batch 300000-400000/439932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0270 - tp: 79112.0000 - fp: 888.0000 - tn: 319112.0000 - fn: 888.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9998 - val_loss: 6.6921e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-33-34-batch-300000-400000
[INFO] processing batch 400000-500000/439932
[33m[INFO] loading file 35-35/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539932, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0272 - tp: 79098.0000 - fp: 902.0000 - tn: 319098.0000 - fn: 902.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9999 - val_loss: 6.5319e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-35-batch-0-100000
[INFO] processing batch 100000-200000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0278 - tp: 79077.0000 - fp: 923.0000 - tn: 319077.0000 - fn: 923.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9998 - val_loss: 6.0347e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-35-batch-100000-200000
[INFO] processing batch 200000-300000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0269 - tp: 79152.0000 - fp: 848.0000 - tn: 319152.0000 - fn: 848.0000 - accuracy: 0.9958 - precision: 0.9894 - recall: 0.9894 - auc: 0.9998 - val_loss: 8.6269e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-35-batch-200000-300000
[INFO] processing batch 300000-400000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0274 - tp: 79109.0000 - fp: 891.0000 - tn: 319109.0000 - fn: 891.0000 - accuracy: 0.9955 - precision: 0.9889 - recall: 0.9889 - auc: 0.9998 - val_loss: 5.3666e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-35-batch-300000-400000
[INFO] processing batch 400000-500000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0259 - tp: 79148.0000 - fp: 852.0000 - tn: 319148.0000 - fn: 852.0000 - accuracy: 0.9957 - precision: 0.9894 - recall: 0.9894 - auc: 0.9999 - val_loss: 5.2150e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-35-batch-400000-500000
[INFO] processing batch 500000-600000/539932
[33m[INFO] loading file 36-36/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539932, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0271 - tp: 79120.0000 - fp: 880.0000 - tn: 319120.0000 - fn: 880.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9998 - val_loss: 0.0013 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-003-files-35-36-batch-0-100000
[INFO] processing batch 100000-200000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0274 - tp: 79107.0000 - fp: 893.0000 - tn: 319107.0000 - fn: 893.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 4.3842e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-35-36-batch-100000-200000
[INFO] processing batch 200000-300000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0270 - tp: 79126.0000 - fp: 874.0000 - tn: 319126.0000 - fn: 874.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9998 - val_loss: 4.1732e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-35-36-batch-200000-300000
[INFO] processing batch 300000-400000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0269 - tp: 79133.0000 - fp: 867.0000 - tn: 319133.0000 - fn: 867.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9998 - val_loss: 5.2461e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-35-36-batch-300000-400000
[INFO] processing batch 400000-500000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0268 - tp: 79141.0000 - fp: 859.0000 - tn: 319141.0000 - fn: 859.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9998 - val_loss: 4.0095e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-35-36-batch-400000-500000
[INFO] processing batch 500000-600000/539932
[33m[INFO] loading file 37-37/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539932, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0263 - tp: 79141.0000 - fp: 859.0000 - tn: 319141.0000 - fn: 859.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9999 - val_loss: 3.6611e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-37-batch-0-100000
[INFO] processing batch 100000-200000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0265 - tp: 79137.0000 - fp: 863.0000 - tn: 319137.0000 - fn: 863.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 3.3360e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-37-batch-100000-200000
[INFO] processing batch 200000-300000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0272 - tp: 79126.0000 - fp: 874.0000 - tn: 319126.0000 - fn: 874.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9998 - val_loss: 3.2800e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-37-batch-200000-300000
[INFO] processing batch 300000-400000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0276 - tp: 79100.0000 - fp: 900.0000 - tn: 319100.0000 - fn: 900.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 3.1688e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-37-batch-300000-400000
[INFO] processing batch 400000-500000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0266 - tp: 79167.0000 - fp: 833.0000 - tn: 319167.0000 - fn: 833.0000 - accuracy: 0.9958 - precision: 0.9896 - recall: 0.9896 - auc: 0.9998 - val_loss: 3.2181e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-37-batch-400000-500000
[INFO] processing batch 500000-600000/539932
[33m[INFO] loading file 38-38/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539932, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0268 - tp: 79127.0000 - fp: 873.0000 - tn: 319127.0000 - fn: 873.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 2.8736e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-37-38-batch-0-100000
[INFO] processing batch 100000-200000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0269 - tp: 79136.0000 - fp: 864.0000 - tn: 319136.0000 - fn: 864.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9998 - val_loss: 2.8254e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-37-38-batch-100000-200000
[INFO] processing batch 200000-300000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0257 - tp: 79175.0000 - fp: 825.0000 - tn: 319175.0000 - fn: 825.0000 - accuracy: 0.9959 - precision: 0.9897 - recall: 0.9897 - auc: 0.9999 - val_loss: 5.4819e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-37-38-batch-200000-300000
[INFO] processing batch 300000-400000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0270 - tp: 79117.0000 - fp: 883.0000 - tn: 319117.0000 - fn: 883.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9998 - val_loss: 2.5507e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-37-38-batch-300000-400000
[INFO] processing batch 400000-500000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0272 - tp: 79101.0000 - fp: 899.0000 - tn: 319101.0000 - fn: 899.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 4.9543e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-37-38-batch-400000-500000
[INFO] processing batch 500000-600000/539932
[33m[INFO] loading file 39-39/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539932, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0273 - tp: 79096.0000 - fp: 904.0000 - tn: 319096.0000 - fn: 904.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 8.2984e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-39-batch-0-100000
[INFO] processing batch 100000-200000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0270 - tp: 79101.0000 - fp: 899.0000 - tn: 319101.0000 - fn: 899.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9999 - val_loss: 2.3640e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-39-batch-100000-200000
[INFO] processing batch 200000-300000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0274 - tp: 79089.0000 - fp: 911.0000 - tn: 319089.0000 - fn: 911.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9998 - val_loss: 2.3512e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-39-batch-200000-300000
[INFO] processing batch 300000-400000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0267 - tp: 79146.0000 - fp: 854.0000 - tn: 319146.0000 - fn: 854.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9999 - val_loss: 2.2660e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-39-batch-300000-400000
[INFO] processing batch 400000-500000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0276 - tp: 79071.0000 - fp: 929.0000 - tn: 319071.0000 - fn: 929.0000 - accuracy: 0.9954 - precision: 0.9884 - recall: 0.9884 - auc: 0.9998 - val_loss: 2.1154e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-39-batch-400000-500000
[INFO] processing batch 500000-600000/539932
[33m[INFO] loading file 40-40/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539932, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0267 - tp: 79137.0000 - fp: 863.0000 - tn: 319137.0000 - fn: 863.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 5.1109e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-39-40-batch-0-100000
[INFO] processing batch 100000-200000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0265 - tp: 79141.0000 - fp: 859.0000 - tn: 319141.0000 - fn: 859.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9999 - val_loss: 1.9071e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-39-40-batch-100000-200000
[INFO] processing batch 200000-300000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0267 - tp: 79135.0000 - fp: 865.0000 - tn: 319135.0000 - fn: 865.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9998 - val_loss: 1.8330e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-39-40-batch-200000-300000
[INFO] processing batch 300000-400000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0286 - tp: 79097.0000 - fp: 903.0000 - tn: 319097.0000 - fn: 903.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9997 - val_loss: 4.9859e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-39-40-batch-300000-400000
[INFO] processing batch 400000-500000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0276 - tp: 79093.0000 - fp: 907.0000 - tn: 319093.0000 - fn: 907.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 2.6477e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-39-40-batch-400000-500000
[INFO] processing batch 500000-600000/539932
[33m[INFO] loading file 41-41/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (480090, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/480090
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0275 - tp: 79080.0000 - fp: 920.0000 - tn: 319080.0000 - fn: 920.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9998 - val_loss: 0.0010 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-41-batch-0-100000
[INFO] processing batch 100000-200000/480090
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0268 - tp: 79138.0000 - fp: 862.0000 - tn: 319138.0000 - fn: 862.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9998 - val_loss: 8.9051e-04 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-41-batch-100000-200000
[INFO] processing batch 200000-300000/480090
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0274 - tp: 79096.0000 - fp: 904.0000 - tn: 319096.0000 - fn: 904.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 2.0257e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-41-batch-200000-300000
[INFO] processing batch 300000-400000/480090
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0283 - tp: 79107.0000 - fp: 893.0000 - tn: 319107.0000 - fn: 893.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 2.1756e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-41-batch-300000-400000
[INFO] processing batch 400000-500000/480090
[33m[INFO] loading file 42-42/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (423604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/423604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0270 - tp: 79128.0000 - fp: 872.0000 - tn: 319128.0000 - fn: 872.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9998 - val_loss: 0.0014 - val_tp: 19997.0000 - val_fp: 3.0000 - val_tn: 79997.0000 - val_fn: 3.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-003-files-41-42-batch-0-100000
[INFO] processing batch 100000-200000/423604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0281 - tp: 79086.0000 - fp: 914.0000 - tn: 319086.0000 - fn: 914.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9998 - val_loss: 0.0015 - val_tp: 19997.0000 - val_fp: 3.0000 - val_tn: 79997.0000 - val_fn: 3.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-003-files-41-42-batch-100000-200000
[INFO] processing batch 200000-300000/423604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0266 - tp: 79136.0000 - fp: 864.0000 - tn: 319136.0000 - fn: 864.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9998 - val_loss: 2.3537e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-41-42-batch-200000-300000
[INFO] processing batch 300000-400000/423604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0272 - tp: 79117.0000 - fp: 883.0000 - tn: 319117.0000 - fn: 883.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9998 - val_loss: 0.0013 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-003-files-41-42-batch-300000-400000
[INFO] processing batch 400000-500000/423604
[33m[INFO] loading file 43-43/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (523604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0261 - tp: 79165.0000 - fp: 835.0000 - tn: 319165.0000 - fn: 835.0000 - accuracy: 0.9958 - precision: 0.9896 - recall: 0.9896 - auc: 0.9999 - val_loss: 2.0685e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-43-batch-0-100000
[INFO] processing batch 100000-200000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0269 - tp: 79119.0000 - fp: 881.0000 - tn: 319119.0000 - fn: 881.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9998 - val_loss: 8.2626e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-43-batch-100000-200000
[INFO] processing batch 200000-300000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0277 - tp: 79096.0000 - fp: 904.0000 - tn: 319096.0000 - fn: 904.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 2.1128e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-43-batch-200000-300000
[INFO] processing batch 300000-400000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0266 - tp: 79138.0000 - fp: 862.0000 - tn: 319138.0000 - fn: 862.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 1.9284e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-43-batch-300000-400000
[INFO] processing batch 400000-500000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0274 - tp: 79092.0000 - fp: 908.0000 - tn: 319092.0000 - fn: 908.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 1.8725e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-43-batch-400000-500000
[INFO] processing batch 500000-600000/523604
[33m[INFO] loading file 44-44/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (523604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0275 - tp: 79076.0000 - fp: 924.0000 - tn: 319076.0000 - fn: 924.0000 - accuracy: 0.9954 - precision: 0.9884 - recall: 0.9884 - auc: 0.9998 - val_loss: 1.7701e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-43-44-batch-0-100000
[INFO] processing batch 100000-200000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0268 - tp: 79141.0000 - fp: 859.0000 - tn: 319141.0000 - fn: 859.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9998 - val_loss: 1.9218e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-43-44-batch-100000-200000
[INFO] processing batch 200000-300000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0258 - tp: 79174.0000 - fp: 826.0000 - tn: 319174.0000 - fn: 826.0000 - accuracy: 0.9959 - precision: 0.9897 - recall: 0.9897 - auc: 0.9999 - val_loss: 8.2384e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-43-44-batch-200000-300000
[INFO] processing batch 300000-400000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0262 - tp: 79135.0000 - fp: 865.0000 - tn: 319135.0000 - fn: 865.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9999 - val_loss: 0.0024 - val_tp: 19997.0000 - val_fp: 3.0000 - val_tn: 79997.0000 - val_fn: 3.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-003-files-43-44-batch-300000-400000
[INFO] processing batch 400000-500000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0275 - tp: 79074.0000 - fp: 926.0000 - tn: 319074.0000 - fn: 926.0000 - accuracy: 0.9954 - precision: 0.9884 - recall: 0.9884 - auc: 0.9998 - val_loss: 1.5949e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-43-44-batch-400000-500000
[INFO] processing batch 500000-600000/523604
[33m[INFO] loading file 45-45/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (523604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0271 - tp: 79119.0000 - fp: 881.0000 - tn: 319119.0000 - fn: 881.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9998 - val_loss: 1.6115e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-45-batch-0-100000
[INFO] processing batch 100000-200000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0265 - tp: 79126.0000 - fp: 874.0000 - tn: 319126.0000 - fn: 874.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 1.5087e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-45-batch-100000-200000
[INFO] processing batch 200000-300000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0274 - tp: 79092.0000 - fp: 908.0000 - tn: 319092.0000 - fn: 908.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 1.5002e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-45-batch-200000-300000
[INFO] processing batch 300000-400000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0267 - tp: 79143.0000 - fp: 857.0000 - tn: 319143.0000 - fn: 857.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9998 - val_loss: 1.4897e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-45-batch-300000-400000
[INFO] processing batch 400000-500000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0272 - tp: 79089.0000 - fp: 911.0000 - tn: 319089.0000 - fn: 911.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9998 - val_loss: 1.4572e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-45-batch-400000-500000
[INFO] processing batch 500000-600000/523604
[33m[INFO] loading file 46-46/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (523604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0269 - tp: 79122.0000 - fp: 878.0000 - tn: 319122.0000 - fn: 878.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9998 - val_loss: 0.0016 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-003-files-45-46-batch-0-100000
[INFO] processing batch 100000-200000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0273 - tp: 79118.0000 - fp: 882.0000 - tn: 319118.0000 - fn: 882.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9998 - val_loss: 8.2150e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-45-46-batch-100000-200000
[INFO] processing batch 200000-300000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0270 - tp: 79118.0000 - fp: 882.0000 - tn: 319118.0000 - fn: 882.0000 - accuracy: 0.9956 - precision: 0.9890 - recall: 0.9890 - auc: 0.9999 - val_loss: 1.4843e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-45-46-batch-200000-300000
[INFO] processing batch 300000-400000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0263 - tp: 79127.0000 - fp: 873.0000 - tn: 319127.0000 - fn: 873.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9999 - val_loss: 4.6942e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-45-46-batch-300000-400000
[INFO] processing batch 400000-500000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0265 - tp: 79150.0000 - fp: 850.0000 - tn: 319150.0000 - fn: 850.0000 - accuracy: 0.9958 - precision: 0.9894 - recall: 0.9894 - auc: 0.9999 - val_loss: 1.3276e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-45-46-batch-400000-500000
[INFO] processing batch 500000-600000/523604
[33m[INFO] loading file 47-47/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (523604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0273 - tp: 79099.0000 - fp: 901.0000 - tn: 319099.0000 - fn: 901.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 1.3384e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-47-batch-0-100000
[INFO] processing batch 100000-200000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0271 - tp: 79091.0000 - fp: 909.0000 - tn: 319091.0000 - fn: 909.0000 - accuracy: 0.9955 - precision: 0.9886 - recall: 0.9886 - auc: 0.9998 - val_loss: 1.2556e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-47-batch-100000-200000
[INFO] processing batch 200000-300000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0273 - tp: 79098.0000 - fp: 902.0000 - tn: 319098.0000 - fn: 902.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 8.1778e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-47-batch-200000-300000
[INFO] processing batch 300000-400000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0277 - tp: 79082.0000 - fp: 918.0000 - tn: 319082.0000 - fn: 918.0000 - accuracy: 0.9954 - precision: 0.9885 - recall: 0.9885 - auc: 0.9998 - val_loss: 8.1751e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-47-batch-300000-400000
[INFO] processing batch 400000-500000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0269 - tp: 79129.0000 - fp: 871.0000 - tn: 319129.0000 - fn: 871.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9998 - val_loss: 1.1437e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-47-batch-400000-500000
[INFO] processing batch 500000-600000/523604
[33m[INFO] loading file 48-48/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (523604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0273 - tp: 79101.0000 - fp: 899.0000 - tn: 319101.0000 - fn: 899.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 1.2051e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-47-48-batch-0-100000
[INFO] processing batch 100000-200000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0262 - tp: 79151.0000 - fp: 849.0000 - tn: 319151.0000 - fn: 849.0000 - accuracy: 0.9958 - precision: 0.9894 - recall: 0.9894 - auc: 0.9999 - val_loss: 1.1158e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-47-48-batch-100000-200000
[INFO] processing batch 200000-300000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0274 - tp: 79125.0000 - fp: 875.0000 - tn: 319125.0000 - fn: 875.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9998 - val_loss: 4.6627e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-47-48-batch-200000-300000
[INFO] processing batch 300000-400000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0273 - tp: 79108.0000 - fp: 892.0000 - tn: 319108.0000 - fn: 892.0000 - accuracy: 0.9955 - precision: 0.9888 - recall: 0.9888 - auc: 0.9998 - val_loss: 1.2295e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-47-48-batch-300000-400000
[INFO] processing batch 400000-500000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0261 - tp: 79154.0000 - fp: 846.0000 - tn: 319154.0000 - fn: 846.0000 - accuracy: 0.9958 - precision: 0.9894 - recall: 0.9894 - auc: 0.9999 - val_loss: 1.1236e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-47-48-batch-400000-500000
[INFO] processing batch 500000-600000/523604
[33m[INFO] loading file 49-49/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (523604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0277 - tp: 79087.0000 - fp: 913.0000 - tn: 319087.0000 - fn: 913.0000 - accuracy: 0.9954 - precision: 0.9886 - recall: 0.9886 - auc: 0.9998 - val_loss: 1.2955e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-49-batch-0-100000
[INFO] processing batch 100000-200000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0274 - tp: 79142.0000 - fp: 858.0000 - tn: 319142.0000 - fn: 858.0000 - accuracy: 0.9957 - precision: 0.9893 - recall: 0.9893 - auc: 0.9998 - val_loss: 1.1067e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-49-batch-100000-200000
[INFO] processing batch 200000-300000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0270 - tp: 79115.0000 - fp: 885.0000 - tn: 319115.0000 - fn: 885.0000 - accuracy: 0.9956 - precision: 0.9889 - recall: 0.9889 - auc: 0.9999 - val_loss: 1.3643e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-49-batch-200000-300000
[INFO] processing batch 300000-400000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0267 - tp: 79130.0000 - fp: 870.0000 - tn: 319130.0000 - fn: 870.0000 - accuracy: 0.9956 - precision: 0.9891 - recall: 0.9891 - auc: 0.9998 - val_loss: 3.8279e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-49-batch-300000-400000
[INFO] processing batch 400000-500000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0266 - tp: 79136.0000 - fp: 864.0000 - tn: 319136.0000 - fn: 864.0000 - accuracy: 0.9957 - precision: 0.9892 - recall: 0.9892 - auc: 0.9998 - val_loss: 1.1418e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-49-batch-400000-500000
[INFO] processing batch 500000-600000/523604
[33m[INFO] loading file 50-50/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (373586, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/373586
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0260 - tp: 79149.0000 - fp: 851.0000 - tn: 319149.0000 - fn: 851.0000 - accuracy: 0.9957 - precision: 0.9894 - recall: 0.9894 - auc: 0.9999 - val_loss: 1.1050e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-49-50-batch-0-100000
[INFO] processing batch 100000-200000/373586
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0276 - tp: 79097.0000 - fp: 903.0000 - tn: 319097.0000 - fn: 903.0000 - accuracy: 0.9955 - precision: 0.9887 - recall: 0.9887 - auc: 0.9998 - val_loss: 1.2248e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-49-50-batch-100000-200000
[INFO] processing batch 200000-300000/373586
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 4s - loss: 0.0279 - tp: 79073.0000 - fp: 927.0000 - tn: 319073.0000 - fn: 927.0000 - accuracy: 0.9954 - precision: 0.9884 - recall: 0.9884 - auc: 0.9998 - val_loss: 1.0827e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
Using TensorFlow backend.
train.py:185: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version
of pandas will change to not sort by default.

To accept the future behavior, pass 'sort=False'.

To retain the current behavior and silence the warning, pass 'sort=True'.

  df = pd.concat(df_from_each_file, ignore_index=True)
[INFO] saving weights to checkpoints/lstm-epoch-003-files-49-50-batch-200000-300000
[INFO] processing batch 300000-400000/373586
[33m[LOSS] 1.0827457554114517e-05[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 1.0827457554114517e-05  <  0.001
[STOPPING EARLY]: currentLoss < min_delta => 1.0827457554114517e-05  <  0.001
--- 2718.603621482849 seconds ---
2020-02-03 09:35:18.800780: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-02-03 09:35:18.800930: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-02-03 09:35:18.800945: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-02-03 09:35:19.600172: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-02-03 09:35:19.600204: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-02-03 09:35:19.600235: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (***REMOVED***): /proc/driver/nvidia/version does not exist
2020-02-03 09:35:19.600442: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-03 09:35:19.609561: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2112050000 Hz
2020-02-03 09:35:19.610844: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5eb4850 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-03 09:35:19.610892: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-02-03 09:35:22.501041: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-03 09:35:22.505031: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 09:35:22.506845: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 09:35:22.520709: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-03 09:35:22.521654: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-03 09:35:22.523002: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 09:35:22.524359: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 09:35:22.527519: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
=============================
        SCORING v0.3
=============================
Date: 2020-02-03 09:35:19.594802
[INFO] input_shape (10, 16)
[INFO] LSTM first and last layer neurons: 5
adding core layer 0
[INFO] created DNN
loading weights: checkpoints/*
loading file checkpoints/lstm-epoch-003-files-9-10-batch-400000-500000
[33m[INFO] model summary:[0m
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 10, 5)             440       
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 10, 5)             0         
_________________________________________________________________
lstm_2 (LSTM)                (None, 10, 10)            640       
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 10, 10)            0         
_________________________________________________________________
lstm_3 (LSTM)                (None, 10, 5)             320       
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU)    (None, 10, 5)             0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 10, 5)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 10, 1)             6         
_________________________________________________________________
leaky_re_lu_4 (LeakyReLU)    (None, 10, 1)             0         
_________________________________________________________________
dense_2 (Dense)              (None, 10, 5)             10        
=================================================================
Total params: 1,416
Trainable params: 1,416
Non-trainable params: 0
_________________________________________________________________
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2015-12-31_130240_112.log.part10_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1364 (0.2728%)
[INFO] ** orig:[0:99.9992%,1:0.0008%]
[INFO] ** type:[0:99.9984%,1:0.0014%,2:0.0002%]
[INFO] ** i/f_name:[2:99.9984%,3:0.0016%]
[INFO] ** i/f_dir:[1:99.9986%,0:0.0014%]
[INFO] ** src:[22:38.114%,9:26.0964%,7:18.2424%,1:17.543%,14:0.0016%,11:0.0012%,10:0.001%,15:0.0004%]
[INFO] ** dst:[21:43.3686%,10:20.8412%,8:18.2422%,9:17.5434%,15:0.0016%,22:0.0014%,6:0.0006%,25:0.0004%,24:0.0002%,18:0.0002%,7:0.0002%]
[INFO] ** proto:[0:99.997%,1:0.0016%,2:0.0014%]
[INFO] ** appi_name:[21:99.9962%,30:0.0016%,26:0.0004%,0:0.0004%,31:0.0002%,27:0.0002%,24:0.0002%,22:0.0002%,16:0.0002%,15:0.0002%,5:0.0002%]
[INFO] ** proxy_src_ip:[18:38.114%,20:26.0964%,13:18.2424%,6:17.543%,17:0.0016%,10:0.0012%,11:0.001%,16:0.0004%]
[INFO] ** modbus_function_code:[0.02961:99.9962%,-33.760870000000004:0.0036%,0.9188299999999999:0.0002%]
[INFO] ** modbus_function_description:[7:49.9988%,11:49.9974%,0:0.0036%,15:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.0954%,1:20.841%,5:18.242%,4:17.5424%,2:17.2726%,0:0.0066%]
[INFO] ** service:[0.0048200000000000005:99.997%,-211.73542999999998:0.0016%,-186.44547:0.0004%,-211.08346:0.0004%,-186.43601999999998:0.0002%,-211.08818:0.0002%,-202.75898:0.0002%]
[INFO] ** s_port:[1.45442:26.0956%,-0.32151:20.8412%,-1.27613:18.242%,-0.23351:17.5424%,-0.33484:17.2728%,-71.33197:0.0016%,-9.54647:0.0008%,-0.24151:0.0006%,-64.19493:0.0004%,-1.02014:0.0004%,-71.14798:0.0004%,1.45709:0.0004%,-1.27347:0.0002%,1.46509:0.0002%,-68.79874000000001:0.0002%,-71.14931:0.0002%,-3.22139:0.0002%,-1.2708:0.0002%,1.47576:0.0002%]
[INFO] ** classification:[normal:79.7796%,Single Stage Single Point:20.2204%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 1 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  5.760447277069092
tp :  64261.0
fp :  35739.0
tn :  364261.0
fn :  35739.0
accuracy :  0.8570441603660583
precision :  0.6426100134849548
recall :  0.6426100134849548
auc :  0.7766312956809998

y_eval {0: 64261, 1: 35739}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64261     0     0     0     0]
 [35739     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[64261     0     0     0     0]
 [35739     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 1 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  5.765121698760987
tp :  64232.0
fp :  35768.0
tn :  364232.0
fn :  35768.0
accuracy :  0.8569281101226807
precision :  0.6423199772834778
recall :  0.6423199772834778
auc :  0.7764490842819214

y_eval {0: 64231, 1: 35769}
pred {0: 99999, 1: 1}
[INFO] confusion matrix for file 
[[64231     0     0     0     0]
 [35768     1     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[128492      0      0      0      0]
 [ 71507      1      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  4.769990176963806
tp :  70406.0
fp :  29594.0
tn :  370406.0
fn :  29594.0
accuracy :  0.8816237449645996
precision :  0.7040600180625916
recall :  0.7040600180625916
auc :  0.8150375485420227

y_eval {0: 70406, 1: 29594}
pred {0: 100000}
[INFO] confusion matrix for file 
[[70406     0     0     0     0]
 [29594     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[198898      0      0      0      0]
 [101101      1      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[298898      0      0      0      0]
 [101101      1      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[398898      0      0      0      0]
 [101101      1      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2015-12-31_181648_113.log.part08_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1370 (0.274%)
[INFO] ** orig:[0:99.9948%,2:0.0052%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.9948%,3:0.0052%]
[INFO] ** i/f_dir:[1:99.9948%,0:0.0052%]
[INFO] ** src:[22:38.4402%,9:25.9738%,7:18.1202%,1:17.4598%,21:0.0052%,2:0.0004%,15:0.0002%,11:0.0002%]
[INFO] ** dst:[21:43.345%,10:21.0682%,8:18.1202%,9:17.4594%,15:0.0052%,22:0.0012%,19:0.0004%,26:0.0002%,24:0.0002%]
[INFO] ** proto:[0:99.9946%,1:0.0052%,2:0.0002%]
[INFO] ** appi_name:[21:99.9942%,30:0.0052%,23:0.0002%,22:0.0002%,18:0.0002%]
[INFO] ** proxy_src_ip:[18:38.4402%,20:25.9738%,13:18.1202%,6:17.4598%,17:0.0052%,14:0.0004%,16:0.0002%,10:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9942%,-33.760870000000004:0.0058%]
[INFO] ** modbus_function_description:[7:49.998%,11:49.9962%,0:0.0058%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:25.9726%,1:21.0682%,5:18.1198%,4:17.459%,2:17.3718%,0:0.0086%]
[INFO] ** service:[0.0048200000000000005:99.9942%,-211.73542999999998:0.0052%,-211.07873999999998:0.0004%,-211.08818:0.0002%]
[INFO] ** s_port:[1.45442:25.973%,-0.32151:21.0682%,-1.27613:18.12%,-0.23351:17.4592%,-0.33484:17.372%,-71.33197:0.0052%,-0.24151:0.0006%,1.45709:0.0004%,8.38348:0.0004%,-1.27347:0.0002%,1.46509:0.0002%,1.47576:0.0002%,-71.14931:0.0002%,-1.02014:0.0002%]
[INFO] ** classification:[normal:80.1196%,Multi Stage Multi Point:14.47%,Single Stage Multi Point:5.4104%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  4.36026855506897
tp :  72948.0
fp :  27052.0
tn :  372948.0
fn :  27052.0
accuracy :  0.8917920589447021
precision :  0.7294800281524658
recall :  0.7294800281524658
auc :  0.8309250473976135

y_eval {0: 72948, 2: 27052}
pred {0: 100000}
[INFO] confusion matrix for file 
[[72948     0     0     0     0]
 [    0     0     0     0     0]
 [27052     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[471846      0      0      0      0]
 [101101      1      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[571846      0      0      0      0]
 [101101      1      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[671846      0      0      0      0]
 [101101      1      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  4.066596619415283
tp :  74770.0
fp :  25230.0
tn :  374770.0
fn :  25230.0
accuracy :  0.8990797400474548
precision :  0.7476999759674072
recall :  0.7476999759674072
auc :  0.8423125147819519

y_eval {0: 74770, 4: 25230}
pred {0: 100000}
[INFO] confusion matrix for file 
[[74770     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [25230     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[746616      0      0      0      0]
 [101101      1      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [ 25230      0      0      0      0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 4 0 ... 4 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  7.59484861907959
tp :  52880.0
fp :  47120.0
tn :  352880.0
fn :  47120.0
accuracy :  0.8115200996398926
precision :  0.5288000106811523
recall :  0.5288000106811523
auc :  0.7055000066757202

y_eval {0: 52880, 4: 47120}
pred {0: 100000}
[INFO] confusion matrix for file 
[[52880     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [47120     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[799496      0      0      0      0]
 [101101      1      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [ 72350      0      0      0      0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2015-12-31_181648_113.log.part09_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1359 (0.2718%)
[INFO] ** orig:[0:99.9966%,2:0.0034%]
[INFO] ** type:[0:99.9996%,1:0.0004%]
[INFO] ** i/f_name:[2:99.9938%,3:0.0062%]
[INFO] ** i/f_dir:[1:99.9942%,0:0.0058%]
[INFO] ** src:[22:38.4204%,9:25.9634%,7:18.123%,1:17.486%,21:0.0034%,14:0.0028%,15:0.0006%,2:0.0004%]
[INFO] ** dst:[21:43.3316%,10:21.0518%,8:18.123%,9:17.486%,15:0.0062%,22:0.0008%,24:0.0002%,18:0.0002%,7:0.0002%]
[INFO] ** proto:[0:99.9934%,1:0.0062%,2:0.0004%]
[INFO] ** appi_name:[21:99.9934%,30:0.0062%,31:0.0002%,27:0.0002%]
[INFO] ** proxy_src_ip:[18:38.4204%,20:25.9634%,13:18.123%,6:17.486%,17:0.0062%,16:0.0006%,14:0.0004%]
[INFO] ** modbus_function_code:[0.02961:99.9934%,-33.760870000000004:0.0066%]
[INFO] ** modbus_function_description:[7:49.9972%,11:49.9962%,0:0.0066%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:25.9624%,1:21.0518%,5:18.1226%,4:17.4856%,2:17.3686%,0:0.009%]
[INFO] ** service:[0.0048200000000000005:99.9934%,-211.73542999999998:0.0062%,-186.43601999999998:0.0002%,-202.75898:0.0002%]
[INFO] ** s_port:[1.45442:25.9628%,-0.32151:21.0518%,-1.27613:18.1226%,-0.23351:17.4858%,-0.33484:17.3686%,-71.33197:0.0062%,-1.02014:0.0006%,-1.27347:0.0002%,11.862:0.0002%,1.45709:0.0002%,-0.24950999999999998:0.0002%,1.46509:0.0002%,1.47576:0.0002%,13.431270000000001:0.0002%,-1.2708:0.0002%]
[INFO] ** classification:[normal:73.9096%,Multi Stage Multi Point:26.0904%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 4 0 ... 4 4 4] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  7.579536442565918
tp :  52975.0
fp :  47025.0
tn :  352975.0
fn :  47025.0
accuracy :  0.8118999004364014
precision :  0.5297499895095825
recall :  0.5297499895095825
auc :  0.7060937285423279

y_eval {0: 52975, 4: 47025}
pred {0: 100000}
[INFO] confusion matrix for file 
[[52975     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [47025     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[852471      0      0      0      0]
 [101101      1      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [119375      0      0      0      0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [4 0 4 ... 0 4 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  7.570832633972168
tp :  53029.0
fp :  46971.0
tn :  353029.0
fn :  46971.0
accuracy :  0.8121159672737122
precision :  0.5302900075912476
recall :  0.5302900075912476
auc :  0.7064312696456909

y_eval {0: 53029, 4: 46971}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53029     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [46971     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[905500      0      0      0      0]
 [101101      1      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [166346      0      0      0      0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [4 4 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  5.876014482688904
tp :  63544.0
fp :  36456.0
tn :  363544.0
fn :  36456.0
accuracy :  0.8541760444641113
precision :  0.6354399919509888
recall :  0.6354399919509888
auc :  0.7721499800682068

y_eval {0: 63544, 4: 36456}
pred {0: 100000}
[INFO] confusion matrix for file 
[[63544     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [36456     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[969044      0      0      0      0]
 [101101      1      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [202802      0      0      0      0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.0001507286787033081
tp :  99997.0
fp :  3.0
tn :  399997.0
fn :  3.0
accuracy :  0.9999879598617554
precision :  0.999970018863678
recall :  0.999970018863678
auc :  1.0

y_eval {0: 100000}
pred {0: 99997, 1: 3}
[INFO] confusion matrix for file 
[[99997     3     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1069041       3       0       0       0]
 [ 101101       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1169041       3       0       0       0]
 [ 101101       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2015-12-31_233049_114.log.part11_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1361 (0.2722%)
[INFO] ** orig:[0:99.9996%,2:0.0004%]
[INFO] ** type:[0:99.9994%,1:0.0004%,2:0.0002%]
[INFO] ** i/f_name:[2:99.9968%,3:0.0032%]
[INFO] ** i/f_dir:[1:99.9972%,0:0.0028%]
[INFO] ** src:[22:38.4512%,9:25.9642%,7:18.089%,1:17.4908%,14:0.0028%,11:0.0008%,21:0.0004%,15:0.0004%,2:0.0004%]
[INFO] ** dst:[21:43.3436%,10:21.0714%,8:18.0896%,9:17.4906%,15:0.0032%,22:0.001%,24:0.0002%,18:0.0002%,7:0.0002%]
[INFO] ** proto:[0:99.9964%,1:0.0032%,2:0.0004%]
[INFO] ** appi_name:[21:99.9956%,30:0.0032%,31:0.0002%,27:0.0002%,24:0.0002%,16:0.0002%,15:0.0002%,5:0.0002%]
[INFO] ** proxy_src_ip:[18:38.4512%,20:25.9642%,13:18.089%,6:17.4908%,17:0.0032%,10:0.0008%,16:0.0004%,14:0.0004%]
[INFO] ** modbus_function_code:[0.02961:99.9956%,-33.760870000000004:0.0042%,0.9188299999999999:0.0002%]
[INFO] ** modbus_function_description:[7:49.999%,11:49.9966%,0:0.0042%,15:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:25.9632%,1:21.0714%,5:18.0886%,4:17.4902%,2:17.3796%,0:0.007%]
[INFO] ** service:[0.0048200000000000005:99.9964%,-211.73542999999998:0.0032%,-186.43601999999998:0.0002%,-202.75898:0.0002%]
[INFO] ** s_port:[1.45442:25.9636%,-0.32151:21.0714%,-1.27613:18.0886%,-0.23351:17.4904%,-0.33484:17.3798%,-71.33197:0.0032%,6.286230000000001:0.0008%,1.45709:0.0004%,-1.02014:0.0004%,-1.27347:0.0002%,11.862:0.0002%,-0.24950999999999998:0.0002%,1.47576:0.0002%,-0.24151:0.0002%,13.431270000000001:0.0002%,-1.2708:0.0002%]
[INFO] ** classification:[normal:95.0874%,Single Stage Single Point:4.9126%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00010045973062515259
tp :  99998.0
fp :  2.0
tn :  399998.0
fn :  2.0
accuracy :  0.9999920129776001
precision :  0.9999799728393555
recall :  0.9999799728393555
auc :  0.9999937415122986

y_eval {0: 100000}
pred {0: 99998, 1: 2}
[INFO] confusion matrix for file 
[[99998     2     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1269039       5       0       0       0]
 [ 101101       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1369039       5       0       0       0]
 [ 101101       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.186453112411499
tp :  92639.0
fp :  7361.0
tn :  392639.0
fn :  7361.0
accuracy :  0.9705557823181152
precision :  0.9263899922370911
recall :  0.9263899922370911
auc :  0.9539936780929565

y_eval {0: 92639, 1: 7361}
pred {0: 100000}
[INFO] confusion matrix for file 
[[92639     0     0     0     0]
 [ 7361     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1461678       5       0       0       0]
 [ 108462       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.7727331483840945
tp :  82796.0
fp :  17204.0
tn :  382796.0
fn :  17204.0
accuracy :  0.9311842322349548
precision :  0.8279600143432617
recall :  0.8279600143432617
auc :  0.8924866914749146

y_eval {0: 82798, 1: 17202}
pred {0: 99998, 1: 2}
[INFO] confusion matrix for file 
[[82796     2     0     0     0]
 [17202     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1544474       7       0       0       0]
 [ 125664       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1644474       7       0       0       0]
 [ 125664       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-01_151435_117.log.part03_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1365 (0.273%)
[INFO] ** orig:[0:99.9976%,2:0.0024%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.9966%,3:0.0034%]
[INFO] ** i/f_dir:[1:99.9966%,0:0.0034%]
[INFO] ** src:[22:38.1462%,9:26.099%,7:18.1904%,1:17.5592%,21:0.0028%,14:0.001%,3:0.0006%,15:0.0004%,2:0.0004%]
[INFO] ** dst:[21:43.376%,10:20.8688%,8:18.1902%,9:17.5592%,15:0.0034%,22:0.0008%,18:0.0004%,16:0.0004%,6:0.0004%,24:0.0002%,2:0.0002%]
[INFO] ** proto:[0:99.9958%,1:0.0034%,2:0.0008%]
[INFO] ** appi_name:[21:99.9952%,30:0.0034%,7:0.0006%,31:0.0004%,26:0.0002%,22:0.0002%]
[INFO] ** proxy_src_ip:[18:38.1462%,20:26.099%,13:18.1904%,6:17.5592%,17:0.0034%,1:0.0006%,16:0.0004%,14:0.0004%,7:0.0004%]
[INFO] ** modbus_function_code:[0.02961:99.9952%,-33.760870000000004:0.0048%]
[INFO] ** modbus_function_description:[7:49.9978%,11:49.9974%,0:0.0048%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.0982%,1:20.8688%,5:18.19%,4:17.5588%,2:17.2772%,0:0.007%]
[INFO] ** service:[0.0048200000000000005:99.9952%,-211.73542999999998:0.0034%,-211.09762999999998:0.0006%,-186.43601999999998:0.0004%,-211.08346:0.0002%,-211.08818:0.0002%]
[INFO] ** s_port:[1.45442:26.0986%,-0.32151:20.8688%,-1.27613:18.1902%,-0.23351:17.559%,-0.33484:17.2774%,-71.33197:0.0034%,-1.02014:0.0004%,-71.14931:0.0002%,-0.24151:0.0002%,4.42897:0.0002%,-71.14798:0.0002%,1.47576:0.0002%,-1.27347:0.0002%,-0.78282:0.0002%,-2.92807:0.0002%,-4.88132:0.0002%,1.45709:0.0002%,9.18344:0.0002%]
[INFO] ** classification:[normal:84.2104%,Single Stage Single Point:15.7896%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  4.721313484191895
tp :  70708.0
fp :  29292.0
tn :  370708.0
fn :  29292.0
accuracy :  0.8828315734863281
precision :  0.7070800065994263
recall :  0.7070800065994263
auc :  0.8169249892234802

y_eval {0: 70708, 1: 29292}
pred {0: 100000}
[INFO] confusion matrix for file 
[[70708     0     0     0     0]
 [29292     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1715182       7       0       0       0]
 [ 154956       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 1 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  5.767861625671387
tp :  64215.0
fp :  35785.0
tn :  364215.0
fn :  35785.0
accuracy :  0.8568599820137024
precision :  0.6421499848365784
recall :  0.6421499848365784
auc :  0.7763437032699585

y_eval {0: 64215, 1: 35785}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64215     0     0     0     0]
 [35785     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1779397       7       0       0       0]
 [ 190741       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.2357415403366088
tp :  86129.0
fp :  13871.0
tn :  386129.0
fn :  13871.0
accuracy :  0.944516122341156
precision :  0.8612899780273438
recall :  0.8612899780273438
auc :  0.9133062362670898

y_eval {0: 86129, 1: 13871}
pred {0: 100000}
[INFO] confusion matrix for file 
[[86129     0     0     0     0]
 [13871     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1865526       7       0       0       0]
 [ 204612       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1965526       7       0       0       0]
 [ 204612       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2065526       7       0       0       0]
 [ 204612       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-01_151435_117.log.part12_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1377 (0.2754%)
[INFO] ** orig:[0:99.9964%,2:0.0036%]
[INFO] ** type:[0:99.9994%,1:0.0004%,2:0.0002%]
[INFO] ** i/f_name:[2:99.996%,3:0.004%]
[INFO] ** i/f_dir:[1:99.9964%,0:0.0036%]
[INFO] ** src:[22:38.049%,9:26.1306%,7:18.2264%,1:17.587%,21:0.0036%,11:0.0014%,10:0.001%,14:0.0004%,15:0.0002%,8:0.0002%,4:0.0002%]
[INFO] ** dst:[21:43.355%,10:20.8256%,8:18.226%,9:17.5868%,15:0.004%,6:0.001%,22:0.0006%,25:0.0004%,24:0.0002%,18:0.0002%,7:0.0002%]
[INFO] ** proto:[0:99.9942%,1:0.004%,2:0.0018%]
[INFO] ** appi_name:[21:99.9932%,30:0.004%,22:0.0006%,26:0.0004%,0:0.0004%,31:0.0002%,27:0.0002%,24:0.0002%,16:0.0002%,15:0.0002%,5:0.0002%,3:0.0002%]
[INFO] ** proxy_src_ip:[18:38.049%,20:26.1306%,13:18.2264%,6:17.587%,17:0.004%,10:0.0014%,11:0.001%,21:0.0002%,16:0.0002%,0:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9932%,-33.760870000000004:0.0066%,0.9188299999999999:0.0002%]
[INFO] ** modbus_function_description:[7:49.9974%,11:49.9958%,0:0.0066%,15:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.13%,1:20.8244%,5:18.2258%,4:17.5864%,2:17.2242%,0:0.0092%]
[INFO] ** service:[0.0048200000000000005:99.9942%,-211.73542999999998:0.004%,-211.08818:0.0006%,-186.44547:0.0004%,-211.08346:0.0004%,-186.43601999999998:0.0002%,-202.75898:0.0002%]
[INFO] ** s_port:[1.45442:26.1304%,-0.32151:20.8246%,-1.27613:18.226%,-0.23351:17.5866%,-0.33484:17.2244%,-71.33197:0.004%,-6.49859:0.0008%,-71.14931:0.0006%,-0.24151:0.0004%,-64.19493:0.0004%,-71.14798:0.0004%,-68.79874000000001:0.0002%,-1.81611:0.0002%,1.47576:0.0002%,-1.27347:0.0002%,-61.95768:0.0002%,-1.02014:0.0002%,-1.2708:0.0002%]
[INFO] ** classification:[normal:97.1716%,Single Stage Single Point:2.8284%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2165526       7       0       0       0]
 [ 204612       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2265526       7       0       0       0]
 [ 204612       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2365526       7       0       0       0]
 [ 204612       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2465526       7       0       0       0]
 [ 204612       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 1 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.279461999720335
tp :  85857.0
fp :  14143.0
tn :  385857.0
fn :  14143.0
accuracy :  0.9434279799461365
precision :  0.8585699796676636
recall :  0.8585699796676636
auc :  0.9116121530532837

y_eval {0: 85858, 1: 14142}
pred {0: 99999, 1: 1}
[INFO] confusion matrix for file 
[[85857     1     0     0     0]
 [14142     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2551383       8       0       0       0]
 [ 218754       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-01_151435_117.log.part13_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1365 (0.273%)
[INFO] ** orig:[0:99.9986%,2:0.0014%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.998%,3:0.002%]
[INFO] ** i/f_dir:[1:99.998%,0:0.002%]
[INFO] ** src:[22:38.1186%,9:26.0918%,7:18.2288%,1:17.558%,21:0.0018%,14:0.0006%,15:0.0004%]
[INFO] ** dst:[21:43.3702%,10:20.8392%,8:18.2288%,9:17.5578%,15:0.002%,22:0.0012%,24:0.0004%,18:0.0002%,6:0.0002%]
[INFO] ** proto:[0:99.9976%,1:0.002%,2:0.0004%]
[INFO] ** appi_name:[21:99.9976%,30:0.002%,31:0.0002%,22:0.0002%]
[INFO] ** proxy_src_ip:[18:38.1186%,20:26.0918%,13:18.2288%,6:17.558%,17:0.002%,16:0.0004%,7:0.0004%]
[INFO] ** modbus_function_code:[0.02961:99.9976%,-33.760870000000004:0.0024%]
[INFO] ** modbus_function_description:[7:49.9998%,11:49.9978%,0:0.0024%]
[INFO] ** modbus_transaction_id:65534 (13.1068%)
[INFO] ** scada_tag:[3:26.0906%,1:20.839%,5:18.2282%,4:17.5572%,2:17.2792%,0:0.0058%]
[INFO] ** service:[0.0048200000000000005:99.9976%,-211.73542999999998:0.002%,-186.43601999999998:0.0002%,-211.08818:0.0002%]
[INFO] ** s_port:[1.45442:26.0908%,-0.32151:20.8392%,-1.27613:18.2284%,-0.23351:17.5576%,-0.33484:17.2794%,-71.33197:0.002%,1.45709:0.0006%,-1.27347:0.0004%,-1.02014:0.0004%,-0.24950999999999998:0.0002%,1.46509:0.0002%,1.47576:0.0002%,4.42897:0.0002%,-0.24151:0.0002%,-71.14931:0.0002%]
[INFO] ** classification:[normal:87.5394%,Single Stage Single Point:12.4606%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 1 0 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  7.570993858337403
tp :  53028.0
fp :  46972.0
tn :  353028.0
fn :  46972.0
accuracy :  0.8121117949485779
precision :  0.5302799940109253
recall :  0.5302799940109253
auc :  0.7064250111579895

y_eval {0: 53028, 1: 46972}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53028     0     0     0     0]
 [46972     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2604411       8       0       0       0]
 [ 265726       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.471065935707092
tp :  84669.0
fp :  15331.0
tn :  384669.0
fn :  15331.0
accuracy :  0.9386759996414185
precision :  0.8466899991035461
recall :  0.8466899991035461
auc :  0.904181182384491

y_eval {0: 84669, 1: 15331}
pred {0: 100000}
[INFO] confusion matrix for file 
[[84669     0     0     0     0]
 [15331     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2689080       8       0       0       0]
 [ 281057       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2789080       8       0       0       0]
 [ 281057       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2889080       8       0       0       0]
 [ 281057       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2989080       8       0       0       0]
 [ 281057       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-01_203011_118.log.part06_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1366 (0.2732%)
[INFO] ** orig:[0:99.9988%,2:0.0008%,1:0.0004%]
[INFO] ** type:[0:99.9986%,1:0.001%,2:0.0004%]
[INFO] ** i/f_name:[2:99.998%,3:0.002%]
[INFO] ** i/f_dir:[1:99.9982%,0:0.0018%]
[INFO] ** src:[22:38.138%,9:26.0904%,7:18.1762%,1:17.5892%,10:0.0018%,11:0.0016%,14:0.0012%,21:0.0008%,15:0.0006%,4:0.0002%]
[INFO] ** dst:[21:43.3838%,10:20.845%,8:18.1758%,9:17.589%,15:0.002%,22:0.0014%,6:0.0014%,25:0.0004%,24:0.0004%,18:0.0004%,7:0.0004%]
[INFO] ** proto:[0:99.9954%,2:0.0026%,1:0.002%]
[INFO] ** appi_name:[21:99.9944%,30:0.002%,26:0.0008%,22:0.0006%,31:0.0004%,27:0.0004%,15:0.0004%,0:0.0004%,24:0.0002%,16:0.0002%,5:0.0002%]
[INFO] ** proxy_src_ip:[18:38.138%,20:26.0904%,13:18.1762%,6:17.5892%,17:0.002%,11:0.0018%,10:0.0016%,16:0.0006%,21:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9944%,-33.760870000000004:0.0052%,0.9188299999999999:0.0004%]
[INFO] ** modbus_function_description:[7:49.998%,11:49.9964%,0:0.0052%,15:0.0004%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.0894%,1:20.8438%,5:18.1758%,4:17.5888%,2:17.294%,0:0.0082%]
[INFO] ** service:[0.0048200000000000005:99.9954%,-211.73542999999998:0.002%,-211.08346:0.0008%,-211.08818:0.0006%,-186.44547:0.0004%,-186.43601999999998:0.0004%,-202.75898:0.0004%]
[INFO] ** s_port:[1.45442:26.0898%,-0.32151:20.844%,-1.27613:18.1758%,-0.23351:17.589%,-0.33484:17.294%,-71.33197:0.002%,-6.46392:0.0008%,-71.14798:0.0008%,1.45709:0.0006%,-71.14931:0.0006%,-1.02014:0.0006%,-1.27347:0.0004%,-68.79874000000001:0.0004%,-64.19493:0.0004%,-1.81611:0.0004%,-6.49859:0.0002%,-0.24151:0.0002%]
[INFO] ** classification:[normal:90.7904%,Single Stage Multi Point:5.7378%,Single Stage Single Point:3.4718%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3089080       8       0       0       0]
 [ 281057       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3189080       8       0       0       0]
 [ 281057       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3289080       8       0       0       0]
 [ 281057       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.7979410055160523
tp :  82641.0
fp :  17359.0
tn :  382641.0
fn :  17359.0
accuracy :  0.9305639863014221
precision :  0.8264099955558777
recall :  0.8264099955558777
auc :  0.8915062546730042

y_eval {0: 82641, 1: 17359}
pred {0: 100000}
[INFO] confusion matrix for file 
[[82641     0     0     0     0]
 [17359     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[3371721       8       0       0       0]
 [ 298416       1       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 2 2] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  4.62412169456482
tp :  71311.0
fp :  28689.0
tn :  371311.0
fn :  28689.0
accuracy :  0.8852440714836121
precision :  0.7131100296974182
recall :  0.7131100296974182
auc :  0.8206937313079834

y_eval {0: 71311, 2: 28689}
pred {0: 100000}
[INFO] confusion matrix for file 
[[71311     0     0     0     0]
 [    0     0     0     0     0]
 [28689     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[3443032       8       0       0       0]
 [ 298416       1       0       0       0]
 [  55741       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-01_203011_118.log.part07_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1366 (0.2732%)
[INFO] ** orig:[0:99.9996%,2:0.0004%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.9994%,3:0.0006%]
[INFO] ** i/f_dir:[1:99.9994%,0:0.0006%]
[INFO] ** src:[22:38.0718%,9:26.1174%,7:18.2344%,1:17.5754%,21:0.0008%,14:0.0002%]
[INFO] ** dst:[21:43.3758%,10:20.813%,8:18.2342%,9:17.5754%,15:0.0006%,22:0.0004%,24:0.0002%,18:0.0002%,6:0.0002%]
[INFO] ** proto:[0:99.999%,1:0.0006%,2:0.0004%]
[INFO] ** appi_name:[21:99.999%,30:0.0006%,31:0.0002%,22:0.0002%]
[INFO] ** proxy_src_ip:[18:38.0718%,20:26.1174%,13:18.2344%,6:17.5754%,17:0.0006%,7:0.0004%]
[INFO] ** modbus_function_code:[0.02961:99.999%,-33.760870000000004:0.001%]
[INFO] ** modbus_function_description:[7:49.9996%,11:49.9994%,0:0.001%]
[INFO] ** modbus_transaction_id:65301 (13.0602%)
[INFO] ** scada_tag:[3:26.1164%,1:20.813%,5:18.2338%,4:17.575%,2:17.2586%,0:0.0032%]
[INFO] ** service:[0.0048200000000000005:99.999%,-211.73542999999998:0.0006%,-186.43601999999998:0.0002%,-211.08818:0.0002%]
[INFO] ** s_port:[1.45442:26.1168%,-0.32151:20.813%,-1.27613:18.234%,-0.23351:17.5752%,-0.33484:17.2588%,-71.33197:0.0006%,-1.27347:0.0002%,1.45709:0.0002%,1.46509:0.0002%,1.47576:0.0002%,4.42897:0.0002%,-0.24151:0.0002%,-71.14931:0.0002%,-1.2708:0.0002%]
[INFO] ** classification:[normal:89.2092%,Single Stage Multi Point:10.7908%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [2 0 0 ... 2 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  7.571155036926269
tp :  53027.0
fp :  46973.0
tn :  353027.0
fn :  46973.0
accuracy :  0.8121080994606018
precision :  0.530269980430603
recall :  0.530269980430603
auc :  0.7064187526702881

y_eval {0: 53027, 2: 46973}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53027     0     0     0     0]
 [    0     0     0     0     0]
 [46973     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[3496059       8       0       0       0]
 [ 298416       1       0       0       0]
 [ 102714       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 2 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.125204651451111
tp :  93019.0
fp :  6981.0
tn :  393019.0
fn :  6981.0
accuracy :  0.9720759987831116
precision :  0.9301900267601013
recall :  0.9301900267601013
auc :  0.9563688039779663

y_eval {0: 93019, 2: 6981}
pred {0: 100000}
[INFO] confusion matrix for file 
[[93019     0     0     0     0]
 [    0     0     0     0     0]
 [ 6981     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[3589078       8       0       0       0]
 [ 298416       1       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3689078       8       0       0       0]
 [ 298416       1       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3789078       8       0       0       0]
 [ 298416       1       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3889078       8       0       0       0]
 [ 298416       1       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-02_014558_119.log.part06_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1366 (0.2732%)
[INFO] ** orig:[0:99.997%,2:0.003%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.9964%,3:0.0036%]
[INFO] ** i/f_dir:[1:99.9964%,0:0.0036%]
[INFO] ** src:[22:38.0288%,9:26.1242%,7:18.2114%,1:17.6294%,21:0.003%,2:0.0008%,14:0.0006%,3:0.0006%,15:0.0004%,4:0.0004%,11:0.0002%,8:0.0002%]
[INFO] ** dst:[21:43.357%,10:20.7952%,8:18.2116%,9:17.629%,15:0.0036%,22:0.0012%,16:0.0008%,19:0.0004%,17:0.0004%,6:0.0004%,26:0.0002%,24:0.0002%]
[INFO] ** proto:[0:99.9958%,1:0.0036%,2:0.0006%]
[INFO] ** appi_name:[21:99.9942%,30:0.0036%,17:0.0008%,22:0.0004%,28:0.0002%,26:0.0002%,23:0.0002%,18:0.0002%,7:0.0002%]
[INFO] ** proxy_src_ip:[18:38.0288%,20:26.1242%,13:18.2114%,6:17.6294%,17:0.0036%,14:0.0008%,1:0.0006%,21:0.0004%,16:0.0004%,10:0.0002%,0:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9942%,-33.760870000000004:0.0058%]
[INFO] ** modbus_function_description:[7:49.9974%,11:49.9968%,0:0.0058%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.123%,1:20.7952%,5:18.211%,4:17.6288%,2:17.2336%,0:0.0084%]
[INFO] ** service:[0.0048200000000000005:99.9942%,-211.73542999999998:0.0036%,-205.44247:0.0008%,-211.07873999999998:0.0004%,-211.08818:0.0004%,-211.09762999999998:0.0002%,-211.08346:0.0002%,-185.9872:0.0002%]
[INFO] ** s_port:[1.45442:26.1234%,-0.32151:20.7952%,-1.27613:18.2112%,-0.23351:17.629%,-0.33484:17.2336%,-71.33197:0.0036%,1.45709:0.0006%,9.89942:0.0004%,-1.02014:0.0004%,-71.14931:0.0004%,-58.035180000000004:0.0002%,-5.1466400000000005:0.0002%,-0.24151:0.0002%,-5.08665:0.0002%,1.46509:0.0002%,-71.14798:0.0002%,-0.24950999999999998:0.0002%,2.05573:0.0002%,-43.76509:0.0002%,-1.27347:0.0002%,-58.032509999999995:0.0002%]
[INFO] ** classification:[normal:81.41%,Single Stage Single Point:18.59%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 1 0 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  5.2548229221344
tp :  67398.0
fp :  32602.0
tn :  367398.0
fn :  32602.0
accuracy :  0.869592010974884
precision :  0.6739799976348877
recall :  0.6739799976348877
auc :  0.7962374687194824

y_eval {0: 67398, 1: 32602}
pred {0: 100000}
[INFO] confusion matrix for file 
[[67398     0     0     0     0]
 [32602     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[3956476       8       0       0       0]
 [ 331018       1       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 1 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  7.567125480651855
tp :  53052.0
fp :  46948.0
tn :  353052.0
fn :  46948.0
accuracy :  0.812208354473114
precision :  0.5305200219154358
recall :  0.5305200219154358
auc :  0.7065749764442444

y_eval {0: 53052, 1: 46948}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53052     0     0     0     0]
 [46948     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[4009528       8       0       0       0]
 [ 377966       1       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.159825474357605
tp :  86600.0
fp :  13400.0
tn :  386600.0
fn :  13400.0
accuracy :  0.946399986743927
precision :  0.8659999966621399
recall :  0.8659999966621399
auc :  0.9162499308586121

y_eval {0: 86600, 1: 13400}
pred {0: 100000}
[INFO] confusion matrix for file 
[[86600     0     0     0     0]
 [13400     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[4096128       8       0       0       0]
 [ 391366       1       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4196128       8       0       0       0]
 [ 391366       1       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4296128       8       0       0       0]
 [ 391366       1       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-02_121729_121.log.part12_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1368 (0.2736%)
[INFO] ** orig:[0:99.9986%,1:0.0008%,2:0.0006%]
[INFO] ** type:[0:99.9984%,1:0.0014%,2:0.0002%]
[INFO] ** i/f_name:[2:99.9978%,3:0.0022%]
[INFO] ** i/f_dir:[1:99.998%,0:0.002%]
[INFO] ** src:[22:38.1136%,9:26.1176%,7:18.2158%,1:17.5472%,14:0.0016%,11:0.0014%,10:0.001%,21:0.0006%,15:0.0004%,2:0.0004%,4:0.0002%,3:0.0002%]
[INFO] ** dst:[21:43.4022%,10:20.8284%,8:18.2156%,9:17.547%,15:0.0022%,22:0.002%,6:0.0008%,26:0.0004%,25:0.0004%,19:0.0004%,24:0.0002%,18:0.0002%,7:0.0002%]
[INFO] ** proto:[0:99.996%,1:0.0022%,2:0.0018%]
[INFO] ** appi_name:[21:99.9946%,30:0.0022%,22:0.0006%,26:0.0004%,0:0.0004%,31:0.0002%,27:0.0002%,24:0.0002%,23:0.0002%,18:0.0002%,16:0.0002%,15:0.0002%,14:0.0002%,5:0.0002%]
[INFO] ** proxy_src_ip:[18:38.1136%,20:26.1176%,13:18.2158%,6:17.5472%,17:0.0022%,10:0.0014%,11:0.001%,16:0.0004%,14:0.0004%,21:0.0002%,1:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9946%,-33.760870000000004:0.0052%,0.9188299999999999:0.0002%]
[INFO] ** modbus_function_description:[7:49.9984%,11:49.9962%,0:0.0052%,15:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.1164%,1:20.8284%,5:18.2154%,4:17.5466%,2:17.285%,0:0.0082%]
[INFO] ** service:[0.0048200000000000005:99.9954%,-211.73542999999998:0.0022%,-211.08818:0.0006%,-186.44547:0.0004%,-211.08346:0.0004%,-211.07873999999998:0.0004%,-186.42657:0.0002%,-186.43601999999998:0.0002%,-202.75898:0.0002%]
[INFO] ** s_port:[1.45442:26.1168%,-0.32151:20.8284%,-1.27613:18.2154%,-0.23351:17.5468%,-0.33484:17.2852%,-71.33197:0.0022%,-10.59042:0.0008%,-71.14931:0.0006%,-64.19493:0.0004%,-1.02014:0.0004%,-0.24151:0.0004%,-71.14798:0.0004%,1.45709:0.0004%,10.54739:0.0004%,1.47576:0.0002%,1.46509:0.0002%,-1.27347:0.0002%,-68.79874000000001:0.0002%,13.34061:0.0002%,-1.2708:0.0002%,15.264529999999999:0.0002%]
[INFO] ** classification:[normal:99.9996%,Single Stage Multi Point:0.0004%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  4.961995184421539e-05
tp :  99999.0
fp :  1.0
tn :  399999.0
fn :  1.0
accuracy :  0.9999960064888
precision :  0.9999899864196777
recall :  0.9999899864196777
auc :  1.0

y_eval {0: 100000}
pred {0: 99999, 1: 1}
[INFO] confusion matrix for file 
[[99999     1     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[4396127       9       0       0       0]
 [ 391366       1       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  4.703879356384277e-05
tp :  99999.0
fp :  1.0
tn :  399999.0
fn :  1.0
accuracy :  0.9999960064888
precision :  0.9999899864196777
recall :  0.9999899864196777
auc :  1.0

y_eval {0: 100000}
pred {0: 99999, 1: 1}
[INFO] confusion matrix for file 
[[99999     1     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[4496126      10       0       0       0]
 [ 391366       1       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4596126      10       0       0       0]
 [ 391366       1       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4696126      10       0       0       0]
 [ 391366       1       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00032248108386993406
tp :  99998.0
fp :  2.0
tn :  399998.0
fn :  2.0
accuracy :  0.9999920129776001
precision :  0.9999799728393555
recall :  0.9999799728393555
auc :  0.9999874830245972

y_eval {0: 99998, 2: 2}
pred {0: 100000}
[INFO] confusion matrix for file 
[[99998     0     0     0     0]
 [    0     0     0     0     0]
 [    2     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[4796124      10       0       0       0]
 [ 391366       1       0       0       0]
 [ 109697       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-02_121729_121.log.part13_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1368 (0.2736%)
[INFO] ** orig:[0:99.9996%,2:0.0004%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.9994%,3:0.0006%]
[INFO] ** i/f_dir:[1:99.9994%,0:0.0006%]
[INFO] ** src:[22:38.162%,9:26.1664%,7:18.0742%,1:17.5958%,21:0.0008%,17:0.0002%,15:0.0002%,14:0.0002%,8:0.0002%]
[INFO] ** dst:[21:43.4352%,10:20.8932%,8:18.0744%,9:17.5952%,22:0.0006%,18:0.0006%,15:0.0006%,6:0.0002%]
[INFO] ** proto:[0:99.9986%,2:0.0008%,1:0.0006%]
[INFO] ** appi_name:[21:99.9986%,31:0.0006%,30:0.0006%,22:0.0002%]
[INFO] ** proxy_src_ip:[18:38.162%,20:26.1664%,13:18.0742%,6:17.5958%,17:0.0006%,7:0.0004%,16:0.0002%,2:0.0002%,0:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9986%,-33.760870000000004:0.0014%]
[INFO] ** modbus_function_description:[7:49.9998%,11:49.9988%,0:0.0014%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.166%,1:20.893%,5:18.0738%,4:17.5948%,2:17.2688%,0:0.0036%]
[INFO] ** service:[0.0048200000000000005:99.9986%,-211.73542999999998:0.0006%,-186.43601999999998:0.0006%,-211.08818:0.0002%]
[INFO] ** s_port:[1.45442:26.1662%,-0.32151:20.8932%,-1.27613:18.074%,-0.23351:17.5952%,-0.33484:17.2688%,-71.33197:0.0006%,15.43653:0.0004%,-0.24151:0.0004%,-0.24950999999999998:0.0002%,1.46509:0.0002%,4.42897:0.0002%,-71.14931:0.0002%,-1.02014:0.0002%,-1.2708:0.0002%]
[INFO] ** classification:[normal:92.8338%,Multi Stage Single Point:7.1662%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4896124      10       0       0       0]
 [ 391366       1       0       0       0]
 [ 109697       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.815864733695984
tp :  88734.0
fp :  11266.0
tn :  388734.0
fn :  11266.0
accuracy :  0.954935610294342
precision :  0.8873400092124939
recall :  0.8873400092124939
auc :  0.9295876026153564

y_eval {0: 88734, 3: 11266}
pred {0: 100000}
[INFO] confusion matrix for file 
[[88734     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [11266     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[4984858      10       0       0       0]
 [ 391366       1       0       0       0]
 [ 109697       0       0       0       0]
 [  11266       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.2193340223312379
tp :  92435.0
fp :  7565.0
tn :  392435.0
fn :  7565.0
accuracy :  0.9697398543357849
precision :  0.9243500232696533
recall :  0.9243500232696533
auc :  0.9527187943458557

y_eval {0: 92435, 3: 7565}
pred {0: 100000}
[INFO] confusion matrix for file 
[[92435     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [ 7565     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[5077293      10       0       0       0]
 [ 391366       1       0       0       0]
 [ 109697       0       0       0       0]
 [  18831       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5177293      10       0       0       0]
 [ 391366       1       0       0       0]
 [ 109697       0       0       0       0]
 [  18831       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.7401124589920043
tp :  82999.0
fp :  17001.0
tn :  382999.0
fn :  17001.0
accuracy :  0.9319958686828613
precision :  0.829990029335022
recall :  0.829990029335022
auc :  0.893749475479126

y_eval {0: 83000, 3: 17000}
pred {0: 99999, 1: 1}
[INFO] confusion matrix for file 
[[82999     1     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [17000     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[5260292      11       0       0       0]
 [ 391366       1       0       0       0]
 [ 109697       0       0       0       0]
 [  35831       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-02_121729_121.log.part14_sorted-labeled.csv
[INFO] process dataset, shape: (439824, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (439824, 17)

[INFO] analyzing data
[INFO] 439824 rows
[INFO] ** unixtime:1201 (0.27306%)
[INFO] ** orig:[0:99.99955%,2:0.00045%]
[INFO] ** type:[0:99.99977%,1:0.00023%]
[INFO] ** i/f_name:[2:99.99864%,3:0.00136%]
[INFO] ** i/f_dir:[1:99.99886%,0:0.00114%]
[INFO] ** src:[22:38.09456%,9:26.09703%,7:18.22161%,1:17.58408%,14:0.00091%,21:0.00068%,15:0.00068%,4:0.00023%,3:0.00023%]
[INFO] ** dst:[21:43.35416%,10:20.83674%,8:18.22115%,9:17.58385%,22:0.00159%,15:0.00136%,24:0.00045%,25:0.00023%,6:0.00023%,2:0.00023%]
[INFO] ** proto:[0:99.99818%,1:0.00136%,2:0.00045%]
[INFO] ** appi_name:[21:99.99795%,30:0.00136%,26:0.00023%,8:0.00023%,0:0.00023%]
[INFO] ** proxy_src_ip:[18:38.09456%,20:26.09703%,13:18.22161%,6:17.58408%,17:0.00136%,16:0.00068%,21:0.00023%,7:0.00023%,1:0.00023%]
[INFO] ** modbus_function_code:[0.02961:99.99795%,-33.760870000000004:0.00205%]
[INFO] ** modbus_function_description:[7:49.99955%,11:49.99841%,0:0.00205%]
[INFO] ** modbus_transaction_id:65536 (14.90051%)
[INFO] ** scada_tag:[3:26.09612%,1:20.83652%,5:18.22092%,4:17.5834%,2:17.25758%,0:0.00546%]
[INFO] ** service:[0.0048200000000000005:99.99795%,-211.73542999999998:0.00136%,-186.44547:0.00023%,-211.08346:0.00023%,-211.35747999999998:0.00023%]
[INFO] ** s_port:[1.45442:26.09635%,-0.32151:20.83674%,-1.27613:18.22115%,-0.23351:17.58362%,-0.33484:17.25781%,-71.33197:0.00136%,-1.02014:0.00068%,-1.27347:0.00045%,1.45709:0.00045%,-0.24151:0.00045%,-71.14798:0.00023%,1.47576:0.00023%,-64.19493:0.00023%,-1.2708:0.00023%]
[INFO] ** classification:[normal:93.34597%,Single Stage Single Point:4.48861%,Multi Stage Single Point:2.16541%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [3 0 0 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.131295860671997
tp :  86777.0
fp :  13223.0
tn :  386777.0
fn :  13223.0
accuracy :  0.9471081495285034
precision :  0.8677700161933899
recall :  0.8677700161933899
auc :  0.9173561930656433

y_eval {0: 86777, 1: 3699, 3: 9524}
pred {0: 100000}
[INFO] confusion matrix for file 
[[86777     0     0     0     0]
 [ 3699     0     0     0     0]
 [    0     0     0     0     0]
 [ 9524     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[5347069      11       0       0       0]
 [ 395065       1       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.585826151847839
tp :  83957.0
fp :  16043.0
tn :  383957.0
fn :  16043.0
accuracy :  0.9358279705047607
precision :  0.8395699858665466
recall :  0.8395699858665466
auc :  0.8997312784194946

y_eval {0: 83957, 1: 16043}
pred {0: 100000}
[INFO] confusion matrix for file 
[[83957     0     0     0     0]
 [16043     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[5431026      11       0       0       0]
 [ 411108       1       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5531026      11       0       0       0]
 [ 411108       1       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5631026      11       0       0       0]
 [ 411108       1       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/439824
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-02_172943_122.log.part03_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1376 (0.2752%)
[INFO] ** orig:[0:99.9976%,2:0.002%,1:0.0004%]
[INFO] ** type:[0:99.9988%,1:0.001%,2:0.0002%]
[INFO] ** i/f_name:[2:99.9944%,3:0.0056%]
[INFO] ** i/f_dir:[1:99.9946%,0:0.0054%]
[INFO] ** src:[22:38.2234%,9:26.124%,7:18.075%,1:17.571%,14:0.0036%,21:0.0022%,2:0.0004%,11:0.0002%,10:0.0002%]
[INFO] ** dst:[21:43.4342%,10:20.913%,8:18.0748%,9:17.5708%,15:0.0056%,22:0.0006%,25:0.0004%,24:0.0002%,18:0.0002%,7:0.0002%]
[INFO] ** proto:[0:99.9936%,1:0.0056%,2:0.0008%]
[INFO] ** appi_name:[21:99.9934%,30:0.0056%,0:0.0004%,31:0.0002%,27:0.0002%,15:0.0002%]
[INFO] ** proxy_src_ip:[18:38.2234%,20:26.124%,13:18.075%,6:17.571%,17:0.0056%,14:0.0004%,11:0.0002%,10:0.0002%,7:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9934%,-33.760870000000004:0.0064%,0.9188299999999999:0.0002%]
[INFO] ** modbus_function_description:[7:49.997%,11:49.9964%,0:0.0064%,15:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.1234%,1:20.9128%,5:18.0748%,4:17.5704%,2:17.3102%,0:0.0084%]
[INFO] ** service:[0.0048200000000000005:99.9936%,-211.73542999999998:0.0056%,-186.44547:0.0004%,-186.43601999999998:0.0002%,-202.75898:0.0002%]
[INFO] ** s_port:[1.45442:26.1238%,-0.32151:20.913%,-1.27613:18.0748%,-0.23351:17.5706%,-0.33484:17.3104%,-71.33197:0.0056%,-0.24151:0.0004%,-64.19493:0.0004%,-1.27347:0.0002%,-10.59042:0.0002%,11.862:0.0002%,1.47576:0.0002%,13.431270000000001:0.0002%]
[INFO] ** classification:[normal:94.9296%,Single Stage Single Point:5.0704%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5731026      11       0       0       0]
 [ 411108       1       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5831026      11       0       0       0]
 [ 411108       1       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5931026      11       0       0       0]
 [ 411108       1       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  4.8439854383468625e-05
tp :  99999.0
fp :  1.0
tn :  399999.0
fn :  1.0
accuracy :  0.9999960064888
precision :  0.9999899864196777
recall :  0.9999899864196777
auc :  1.0

y_eval {0: 100000}
pred {0: 99999, 1: 1}
[INFO] confusion matrix for file 
[[99999     1     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6031025      12       0       0       0]
 [ 411108       1       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  4.08626042137146
tp :  74648.0
fp :  25352.0
tn :  374648.0
fn :  25352.0
accuracy :  0.898591935634613
precision :  0.7464799880981445
recall :  0.7464799880981445
auc :  0.8415499925613403

y_eval {0: 74648, 1: 25352}
pred {0: 100000}
[INFO] confusion matrix for file 
[[74648     0     0     0     0]
 [25352     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6105673      12       0       0       0]
 [ 436460       1       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-02_172943_122.log.part04_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1377 (0.2754%)
[INFO] ** orig:[0:99.995%,2:0.005%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.9944%,3:0.0056%]
[INFO] ** i/f_dir:[1:99.9944%,0:0.0056%]
[INFO] ** src:[22:38.203%,9:26.1368%,7:18.1014%,1:17.5508%,21:0.005%,3:0.0008%,15:0.0006%,14:0.0006%,4:0.0004%,2:0.0004%,8:0.0002%]
[INFO] ** dst:[21:43.4462%,10:20.893%,8:18.1012%,9:17.5504%,15:0.0056%,22:0.0016%,16:0.0008%,6:0.0006%,17:0.0004%,24:0.0002%]
[INFO] ** proto:[0:99.9938%,1:0.0056%,2:0.0006%]
[INFO] ** appi_name:[21:99.9926%,30:0.0056%,17:0.0008%,26:0.0004%,28:0.0002%,22:0.0002%,7:0.0002%]
[INFO] ** proxy_src_ip:[18:38.203%,20:26.1368%,13:18.1014%,6:17.5508%,17:0.0056%,1:0.0008%,16:0.0006%,21:0.0004%,14:0.0004%,0:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9926%,-33.760870000000004:0.0074%]
[INFO] ** modbus_function_description:[7:49.9972%,11:49.9954%,0:0.0074%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.1358%,1:20.8928%,5:18.1008%,4:17.55%,2:17.31%,0:0.0106%]
[INFO] ** service:[0.0048200000000000005:99.9926%,-211.73542999999998:0.0056%,-205.44247:0.0008%,-211.08346:0.0004%,-211.09762999999998:0.0002%,-185.9872:0.0002%,-211.08818:0.0002%]
[INFO] ** s_port:[1.45442:26.136%,-0.32151:20.893%,-1.27613:18.101%,-0.23351:17.5502%,-0.33484:17.31%,-71.33197:0.0056%,1.45709:0.0006%,-1.02014:0.0006%,-71.14798:0.0004%,-0.24151:0.0004%,-5.1466400000000005:0.0002%,-58.035180000000004:0.0002%,-1.2708:0.0002%,-71.14931:0.0002%,1.47576:0.0002%,-1.27347:0.0002%,-5.08665:0.0002%,-0.24950999999999998:0.0002%,2.05573:0.0002%,-43.76509:0.0002%,-58.032509999999995:0.0002%]
[INFO] ** classification:[normal:64.3482%,Single Stage Single Point:35.6518%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  5.728855824279785
tp :  64457.0
fp :  35543.0
tn :  364457.0
fn :  35543.0
accuracy :  0.8578283786773682
precision :  0.644569993019104
recall :  0.644569993019104
auc :  0.7778562307357788

y_eval {0: 64457, 1: 35543}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64457     0     0     0     0]
 [35543     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6170130      12       0       0       0]
 [ 472003       1       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  5.707741105651856
tp :  64588.0
fp :  35412.0
tn :  364588.0
fn :  35412.0
accuracy :  0.8583521246910095
precision :  0.6458799839019775
recall :  0.6458799839019775
auc :  0.7786750197410583

y_eval {0: 64588, 1: 35412}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64588     0     0     0     0]
 [35412     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6234718      12       0       0       0]
 [ 507415       1       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  5.758029588317871
tp :  64276.0
fp :  35724.0
tn :  364276.0
fn :  35724.0
accuracy :  0.8571043610572815
precision :  0.6427599787712097
recall :  0.6427599787712097
auc :  0.7767249941825867

y_eval {0: 64276, 1: 35724}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64276     0     0     0     0]
 [35724     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6298994      12       0       0       0]
 [ 543139       1       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 1 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  5.7572236785888675
tp :  64281.0
fp :  35719.0
tn :  364281.0
fn :  35719.0
accuracy :  0.8571242690086365
precision :  0.6428099870681763
recall :  0.6428099870681763
auc :  0.776756227016449

y_eval {0: 64281, 1: 35719}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64281     0     0     0     0]
 [35719     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6363275      12       0       0       0]
 [ 578858       1       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 0 ... 1 1 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  5.780111391448974
tp :  64139.0
fp :  35861.0
tn :  364139.0
fn :  35861.0
accuracy :  0.8565559983253479
precision :  0.6413900256156921
recall :  0.6413900256156921
auc :  0.775868833065033

y_eval {0: 64139, 1: 35861}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64139     0     0     0     0]
 [35861     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6427414      12       0       0       0]
 [ 614719       1       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-02_172943_122.log.part05_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1367 (0.2734%)
[INFO] ** orig:[0:99.9992%,2:0.0008%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.9984%,3:0.0016%]
[INFO] ** i/f_dir:[1:99.9984%,0:0.0016%]
[INFO] ** src:[22:38.0648%,9:26.1164%,7:18.2044%,1:17.6118%,21:0.001%,14:0.0008%,3:0.0004%,2:0.0004%]
[INFO] ** dst:[21:43.368%,10:20.8128%,8:18.2044%,9:17.6114%,15:0.0016%,22:0.0006%,16:0.0004%,24:0.0002%,18:0.0002%,6:0.0002%,2:0.0002%]
[INFO] ** proto:[0:99.998%,1:0.0016%,2:0.0004%]
[INFO] ** appi_name:[21:99.9974%,30:0.0016%,7:0.0006%,31:0.0002%,22:0.0002%]
[INFO] ** proxy_src_ip:[18:38.0648%,20:26.1164%,13:18.2044%,6:17.6118%,17:0.0016%,14:0.0004%,1:0.0004%,7:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9974%,-33.760870000000004:0.0026%]
[INFO] ** modbus_function_description:[7:49.9992%,11:49.9982%,0:0.0026%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.1154%,1:20.8126%,5:18.204%,4:17.6112%,2:17.2518%,0:0.005%]
[INFO] ** service:[0.0048200000000000005:99.9974%,-211.73542999999998:0.0016%,-211.09762999999998:0.0006%,-186.43601999999998:0.0002%,-211.08818:0.0002%]
[INFO] ** s_port:[1.45442:26.1158%,-0.32151:20.8128%,-1.27613:18.204%,-0.23351:17.6114%,-0.33484:17.252%,-71.33197:0.0016%,1.45709:0.0004%,-1.2708:0.0002%,-71.14931:0.0002%,-0.24151:0.0002%,-2.02544:0.0002%,1.46509:0.0002%,10.73138:0.0002%,-0.24950999999999998:0.0002%,14.88321:0.0002%,-1.27347:0.0002%,-2.81074:0.0002%]
[INFO] ** classification:[normal:97.0224%,Single Stage Single Point:2.9776%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.3996626028060914
tp :  85112.0
fp :  14888.0
tn :  385112.0
fn :  14888.0
accuracy :  0.9404480457305908
precision :  0.8511199951171875
recall :  0.8511199951171875
auc :  0.9069499969482422

y_eval {0: 85112, 1: 14888}
pred {0: 100000}
[INFO] confusion matrix for file 
[[85112     0     0     0     0]
 [14888     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6512526      12       0       0       0]
 [ 629607       1       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[6612526      12       0       0       0]
 [ 629607       1       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[6712526      12       0       0       0]
 [ 629607       1       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[6812526      12       0       0       0]
 [ 629607       1       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1920928955078125e-07
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]Using TensorFlow backend.

[INFO] confusion matrix after adding it to total:
[[6912526      12       0       0       0]
 [ 629607       1       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
--- 223.89509630203247 seconds ---
