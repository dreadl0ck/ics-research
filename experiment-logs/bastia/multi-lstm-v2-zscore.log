2020-02-08 06:31:52.910869: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-08 06:31:52.922640: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb1a90c56a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-08 06:31:52.922672: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow backend.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
2020-02-08 06:31:58.560463: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-08 06:31:58.583304: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 06:31:58.593827: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 06:31:58.690775: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-08 06:31:58.698320: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-08 06:31:58.706157: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 06:31:58.713532: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 06:31:58.748111: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-08 06:32:02.077747: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-08 06:32:02.084523: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 06:32:02.087752: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 06:32:02.115171: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-08 06:32:02.117282: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-08 06:32:02.119534: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 06:32:02.121799: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 06:32:02.134121: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
=================================================
        TRAINING v0.4.2 (binaryClasses)
=================================================
Date: 2020-02-08 06:31:52.906566
[INFO] input_shape (32, 16)
[INFO] LSTM first and last layer neurons: 2
[INFO] adding core layer 0
wrapLayerSize 2
coreLayerSize 4
numCoreLayers 1
outputLayerActivation sigmoid
output_dim 2
loss binary_crossentropy
optimizer adam
[INFO] created DNN
[33m[INFO] epoch 1/3[0m
[33m[INFO] loading file 1-2/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 5s - loss: 0.6742 - tp: 78645.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 1355.0000 - accuracy: 0.9915 - precision: 1.0000 - recall: 0.9831 - auc: 0.9897 - val_loss: 0.6547 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-2-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6367 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6183 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-2-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6021 - tp: 79766.0000 - fp: 234.0000 - tn: 79766.0000 - fn: 234.0000 - accuracy: 0.9971 - precision: 0.9971 - recall: 0.9971 - auc: 0.9963 - val_loss: 0.6928 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 10606.0000 - val_fn: 9394.0000 - val_accuracy: 0.5303 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.5303
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-2-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6929 - tp: 42447.0000 - fp: 37553.0000 - tn: 42447.0000 - fn: 37553.0000 - accuracy: 0.5306 - precision: 0.5306 - recall: 0.5306 - auc: 0.5304 - val_loss: 0.6927 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 10626.0000 - val_fn: 9374.0000 - val_accuracy: 0.5313 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.5313
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-2-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6928 - tp: 42438.0000 - fp: 37562.0000 - tn: 42438.0000 - fn: 37562.0000 - accuracy: 0.5305 - precision: 0.5305 - recall: 0.5305 - auc: 0.5299 - val_loss: 0.6928 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 10603.0000 - val_fn: 9397.0000 - val_accuracy: 0.5301 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-2-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6926 - tp: 42435.0000 - fp: 37565.0000 - tn: 42435.0000 - fn: 37565.0000 - accuracy: 0.5304 - precision: 0.5304 - recall: 0.5304 - auc: 0.5304 - val_loss: 0.6928 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 10589.0000 - val_fn: 9411.0000 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.5294
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-2-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6145 - tp: 67619.0000 - fp: 12381.0000 - tn: 67619.0000 - fn: 12381.0000 - accuracy: 0.8452 - precision: 0.8452 - recall: 0.8452 - auc: 0.8448 - val_loss: 0.5601 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-2-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.5742 - tp: 72432.0000 - fp: 7568.0000 - tn: 72432.0000 - fn: 7568.0000 - accuracy: 0.9054 - precision: 0.9054 - recall: 0.9054 - auc: 0.9074 - val_loss: 0.6991 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 10593.0000 - val_fn: 9407.0000 - val_accuracy: 0.5296 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.5296
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-2-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6994 - tp: 42321.0000 - fp: 37679.0000 - tn: 42321.0000 - fn: 37679.0000 - accuracy: 0.5290 - precision: 0.5290 - recall: 0.5290 - auc: 0.5290 - val_loss: 0.6986 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 10602.0000 - val_fn: 9398.0000 - val_accuracy: 0.5301 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-2-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.5792 - tp: 67360.0000 - fp: 12640.0000 - tn: 67360.0000 - fn: 12640.0000 - accuracy: 0.8420 - precision: 0.8420 - recall: 0.8420 - auc: 0.8402 - val_loss: 0.5044 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-2-batch-900000-1000000
[33m[INFO] loading file 3-4/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6877 - tp: 45236.0000 - fp: 34764.0000 - tn: 45236.0000 - fn: 34764.0000 - accuracy: 0.5655 - precision: 0.5655 - recall: 0.5655 - auc: 0.5655 - val_loss: 0.7030 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 10571.0000 - val_fn: 9429.0000 - val_accuracy: 0.5286 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.5286
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-4-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6204 - tp: 57751.0000 - fp: 22249.0000 - tn: 57751.0000 - fn: 22249.0000 - accuracy: 0.7219 - precision: 0.7219 - recall: 0.7219 - auc: 0.7220 - val_loss: 0.4934 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-4-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.4746 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4535 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-4-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.4354 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4174 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-4-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.4020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3867 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-4-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.3733 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3599 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-4-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.3480 - tp: 79999.0000 - fp: 1.0000 - tn: 79999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3361 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-4-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.3256 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3149 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-4-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.4161 - tp: 71528.0000 - fp: 8472.0000 - tn: 71528.0000 - fn: 8472.0000 - accuracy: 0.8941 - precision: 0.8941 - recall: 0.8941 - auc: 0.8943 - val_loss: 0.9374 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 7806.0000 - val_fn: 12194.0000 - val_accuracy: 0.3903 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.3903
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-4-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6032 - tp: 56887.0000 - fp: 23113.0000 - tn: 56887.0000 - fn: 23113.0000 - accuracy: 0.7111 - precision: 0.7111 - recall: 0.7111 - auc: 0.7111 - val_loss: 0.3028 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-4-batch-900000-1000000
[33m[INFO] loading file 5-6/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.5307 - tp: 62445.0000 - fp: 17555.0000 - tn: 62445.0000 - fn: 17555.0000 - accuracy: 0.7806 - precision: 0.7806 - recall: 0.7806 - auc: 0.7806 - val_loss: 0.6759 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 12842.0000 - val_fn: 7158.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6421
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-6-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6756 - tp: 51316.0000 - fp: 28684.0000 - tn: 51316.0000 - fn: 28684.0000 - accuracy: 0.6414 - precision: 0.6414 - recall: 0.6414 - auc: 0.6414 - val_loss: 0.4577 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 17052.0000 - val_fn: 2948.0000 - val_accuracy: 0.8526 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.8526
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-6-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2989 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2884 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-6-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.2789 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2692 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-6-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2607 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2520 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-6-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.2444 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2366 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-6-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.2297 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2226 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-6-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2163 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2099 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-6-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.2042 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5297 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 15632.0000 - val_fn: 4368.0000 - val_accuracy: 0.7816 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.7816
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-6-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.7414 - tp: 51195.0000 - fp: 28805.0000 - tn: 51195.0000 - fn: 28805.0000 - accuracy: 0.6399 - precision: 0.6399 - recall: 0.6399 - auc: 0.6403 - val_loss: 0.7385 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 12768.0000 - val_fn: 7232.0000 - val_accuracy: 0.6384 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.6384
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-6-batch-900000-1000000
[33m[INFO] loading file 7-8/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7310 - tp: 51210.0000 - fp: 28790.0000 - tn: 51210.0000 - fn: 28790.0000 - accuracy: 0.6401 - precision: 0.6401 - recall: 0.6401 - auc: 0.6402 - val_loss: 0.7259 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 12803.0000 - val_fn: 7197.0000 - val_accuracy: 0.6402 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.6402
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-8-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7192 - tp: 51338.0000 - fp: 28662.0000 - tn: 51338.0000 - fn: 28662.0000 - accuracy: 0.6417 - precision: 0.6417 - recall: 0.6417 - auc: 0.6420 - val_loss: 0.7130 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 12860.0000 - val_fn: 7140.0000 - val_accuracy: 0.6430 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.6430
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-8-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.4774 - tp: 65370.0000 - fp: 14630.0000 - tn: 65370.0000 - fn: 14630.0000 - accuracy: 0.8171 - precision: 0.8171 - recall: 0.8171 - auc: 0.8156 - val_loss: 0.2295 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-8-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2234 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2160 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-8-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.2092 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2024 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-8-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.1963 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1901 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-8-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.1846 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1790 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-8-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.1740 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1689 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-8-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.3123 - tp: 73166.0000 - fp: 6834.0000 - tn: 73166.0000 - fn: 6834.0000 - accuracy: 0.9146 - precision: 0.9146 - recall: 0.9146 - auc: 0.9146 - val_loss: 0.4772 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 16368.0000 - val_fn: 3632.0000 - val_accuracy: 0.8184 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.8184
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-8-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.4764 - tp: 65505.0000 - fp: 14495.0000 - tn: 65505.0000 - fn: 14495.0000 - accuracy: 0.8188 - precision: 0.8188 - recall: 0.8188 - auc: 0.8188 - val_loss: 0.4757 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 16383.0000 - val_fn: 3617.0000 - val_accuracy: 0.8191 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.8191
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-8-batch-900000-1000000
[33m[INFO] loading file 9-10/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.4805 - tp: 65300.0000 - fp: 14700.0000 - tn: 65300.0000 - fn: 14700.0000 - accuracy: 0.8163 - precision: 0.8163 - recall: 0.8163 - auc: 0.8162 - val_loss: 0.4838 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 16283.0000 - val_fn: 3717.0000 - val_accuracy: 0.8141 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.8141
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-10-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1868 - tp: 78936.0000 - fp: 1064.0000 - tn: 78936.0000 - fn: 1064.0000 - accuracy: 0.9867 - precision: 0.9867 - recall: 0.9867 - auc: 0.9870 - val_loss: 0.1593 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-10-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1547 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1500 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-10-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.1457 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1414 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-10-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.1376 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1336 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-10-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1301 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1265 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-10-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1249 - tp: 79936.0000 - fp: 64.0000 - tn: 79936.0000 - fn: 64.0000 - accuracy: 0.9992 - precision: 0.9992 - recall: 0.9992 - auc: 0.9993 - val_loss: 0.8572 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 12843.0000 - val_fn: 7157.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6422
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-10-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7158 - tp: 56672.0000 - fp: 23328.0000 - tn: 56672.0000 - fn: 23328.0000 - accuracy: 0.7084 - precision: 0.7084 - recall: 0.7084 - auc: 0.7083 - val_loss: 0.1281 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-10-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1264 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1231 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-10-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1199 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1166 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-10-batch-900000-1000000
[33m[INFO] loading file 11-12/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1137 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1107 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-12-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1080 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1052 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-12-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1026 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1000 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-12-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0977 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0953 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-12-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0931 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0908 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-12-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0888 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0867 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-12-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0847 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4884 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 16689.0000 - val_fn: 3311.0000 - val_accuracy: 0.8345 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8345
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-12-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.9453 - tp: 51328.0000 - fp: 28672.0000 - tn: 51328.0000 - fn: 28672.0000 - accuracy: 0.6416 - precision: 0.6416 - recall: 0.6416 - auc: 0.6415 - val_loss: 0.5818 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 15792.0000 - val_fn: 4208.0000 - val_accuracy: 0.7896 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.7896
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-12-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0934 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0915 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-12-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0895 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0874 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-12-batch-900000-1000000
[33m[INFO] loading file 13-14/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0855 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0836 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-14-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0818 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0800 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-14-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0783 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6999 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 15075.0000 - val_fn: 4925.0000 - val_accuracy: 0.7538 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.7537
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-14-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.9677 - tp: 51313.0000 - fp: 28687.0000 - tn: 51313.0000 - fn: 28687.0000 - accuracy: 0.6414 - precision: 0.6414 - recall: 0.6414 - auc: 0.6409 - val_loss: 0.9405 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 12876.0000 - val_fn: 7124.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-14-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.9262 - tp: 51356.0000 - fp: 28644.0000 - tn: 51356.0000 - fn: 28644.0000 - accuracy: 0.6420 - precision: 0.6420 - recall: 0.6420 - auc: 0.6418 - val_loss: 0.9044 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 12867.0000 - val_fn: 7133.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-14-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.5876 - tp: 62543.0000 - fp: 17457.0000 - tn: 62543.0000 - fn: 17457.0000 - accuracy: 0.7818 - precision: 0.7818 - recall: 0.7818 - auc: 0.7809 - val_loss: 0.1062 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-14-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.1049 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1025 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-14-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.1001 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0977 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-14-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0955 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0933 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-14-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0912 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0891 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-14-batch-900000-1000000
[33m[INFO] loading file 15-16/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (939690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0872 - tp: 79998.0000 - fp: 2.0000 - tn: 79998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0852 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-16-batch-0-100000
[INFO] processing batch 100000-200000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0834 - tp: 79998.0000 - fp: 2.0000 - tn: 79998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0815 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-16-batch-100000-200000
[INFO] processing batch 200000-300000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0798 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0780 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-16-batch-200000-300000
[INFO] processing batch 300000-400000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.0764 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1503 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 11586.0000 - val_fn: 8414.0000 - val_accuracy: 0.5793 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.5793
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-16-batch-300000-400000
[INFO] processing batch 400000-500000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 1.2398 - tp: 42561.0000 - fp: 37439.0000 - tn: 42561.0000 - fn: 37439.0000 - accuracy: 0.5320 - precision: 0.5320 - recall: 0.5320 - auc: 0.5320 - val_loss: 1.2029 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 10627.0000 - val_fn: 9373.0000 - val_accuracy: 0.5314 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.5314
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-16-batch-400000-500000
[INFO] processing batch 500000-600000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 1.1712 - tp: 42492.0000 - fp: 37508.0000 - tn: 42492.0000 - fn: 37508.0000 - accuracy: 0.5311 - precision: 0.5311 - recall: 0.5311 - auc: 0.5311 - val_loss: 1.1402 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 10618.0000 - val_fn: 9382.0000 - val_accuracy: 0.5309 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.5309
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-16-batch-500000-600000
[INFO] processing batch 600000-700000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6938 - tp: 58381.0000 - fp: 21619.0000 - tn: 58381.0000 - fn: 21619.0000 - accuracy: 0.7298 - precision: 0.7298 - recall: 0.7298 - auc: 0.7326 - val_loss: 0.1124 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-16-batch-600000-700000
[INFO] processing batch 700000-800000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.1113 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1091 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-16-batch-700000-800000
[INFO] processing batch 800000-900000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.1069 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1046 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-16-batch-800000-900000
[INFO] processing batch 900000-1000000/939690
[33m[INFO] loading file 17-18/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1025 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1003 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-18-batch-0-100000
[INFO] processing batch 100000-200000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0983 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0962 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-18-batch-100000-200000
[INFO] processing batch 200000-300000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0943 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0923 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-18-batch-200000-300000
[INFO] processing batch 300000-400000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.4247 - tp: 68607.0000 - fp: 11393.0000 - tn: 68607.0000 - fn: 11393.0000 - accuracy: 0.8576 - precision: 0.8576 - recall: 0.8576 - auc: 0.8576 - val_loss: 0.5147 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 16369.0000 - val_fn: 3631.0000 - val_accuracy: 0.8184 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.8184
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-18-batch-300000-400000
[INFO] processing batch 400000-500000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.5114 - tp: 65526.0000 - fp: 14474.0000 - tn: 65526.0000 - fn: 14474.0000 - accuracy: 0.8191 - precision: 0.8191 - recall: 0.8191 - auc: 0.8193 - val_loss: 0.2517 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 18648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9324 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9324
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-18-batch-400000-500000
[INFO] processing batch 500000-600000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.3216 - tp: 72130.0000 - fp: 7870.0000 - tn: 72130.0000 - fn: 7870.0000 - accuracy: 0.9016 - precision: 0.9016 - recall: 0.9016 - auc: 0.9016 - val_loss: 0.9635 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 12369.0000 - val_fn: 7631.0000 - val_accuracy: 0.6184 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.6184
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-18-batch-500000-600000
[INFO] processing batch 600000-700000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.9413 - tp: 49699.0000 - fp: 30301.0000 - tn: 49699.0000 - fn: 30301.0000 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - auc: 0.6215 - val_loss: 0.9292 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 12357.0000 - val_fn: 7643.0000 - val_accuracy: 0.6179 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.6179
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-18-batch-600000-700000
[INFO] processing batch 700000-800000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.9090 - tp: 49541.0000 - fp: 30459.0000 - tn: 49541.0000 - fn: 30459.0000 - accuracy: 0.6193 - precision: 0.6193 - recall: 0.6193 - auc: 0.6194 - val_loss: 0.8907 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 12397.0000 - val_fn: 7603.0000 - val_accuracy: 0.6198 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.6199
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-18-batch-700000-800000
[INFO] processing batch 800000-900000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2637 - tp: 74509.0000 - fp: 5491.0000 - tn: 74509.0000 - fn: 5491.0000 - accuracy: 0.9314 - precision: 0.9314 - recall: 0.9314 - auc: 0.9314 - val_loss: 0.1247 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-18-batch-800000-900000
[INFO] processing batch 900000-1000000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1218 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1187 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-18-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039690
[33m[INFO] loading file 19-20/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1158 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1128 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-20-batch-0-100000
[INFO] processing batch 100000-200000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1101 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1073 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-20-batch-100000-200000
[INFO] processing batch 200000-300000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1022 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-20-batch-200000-300000
[INFO] processing batch 300000-400000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.3997 - tp: 69321.0000 - fp: 10679.0000 - tn: 69321.0000 - fn: 10679.0000 - accuracy: 0.8665 - precision: 0.8665 - recall: 0.8665 - auc: 0.8665 - val_loss: 1.4472 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 7882.0000 - val_fn: 12118.0000 - val_accuracy: 0.3941 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.3941
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-20-batch-300000-400000
[INFO] processing batch 400000-500000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 1.4073 - tp: 31237.0000 - fp: 48763.0000 - tn: 31237.0000 - fn: 48763.0000 - accuracy: 0.3905 - precision: 0.3905 - recall: 0.3905 - auc: 0.3901 - val_loss: 0.1251 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-20-batch-400000-500000
[INFO] processing batch 500000-600000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.1253 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1746 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 19491.0000 - val_fn: 509.0000 - val_accuracy: 0.9746 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9746
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-20-batch-500000-600000
[INFO] processing batch 600000-700000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.4931 - tp: 65427.0000 - fp: 14573.0000 - tn: 65427.0000 - fn: 14573.0000 - accuracy: 0.8178 - precision: 0.8178 - recall: 0.8178 - auc: 0.8178 - val_loss: 0.4923 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 16357.0000 - val_fn: 3643.0000 - val_accuracy: 0.8178 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.8178
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-20-batch-600000-700000
[INFO] processing batch 700000-800000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.4933 - tp: 65351.0000 - fp: 14649.0000 - tn: 65351.0000 - fn: 14649.0000 - accuracy: 0.8169 - precision: 0.8169 - recall: 0.8169 - auc: 0.8169 - val_loss: 0.4891 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 16371.0000 - val_fn: 3629.0000 - val_accuracy: 0.8185 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.8185
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-20-batch-700000-800000
[INFO] processing batch 800000-900000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.2265 - tp: 76024.0000 - fp: 3976.0000 - tn: 76024.0000 - fn: 3976.0000 - accuracy: 0.9503 - precision: 0.9503 - recall: 0.9503 - auc: 0.9503 - val_loss: 0.1254 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-20-batch-800000-900000
[INFO] processing batch 900000-1000000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.1227 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1196 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-20-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039690
[33m[INFO] loading file 21-22/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.1168 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1139 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-22-batch-0-100000
[INFO] processing batch 100000-200000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1113 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1086 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-22-batch-100000-200000
[INFO] processing batch 200000-300000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1061 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1036 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-22-batch-200000-300000
[INFO] processing batch 300000-400000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1013 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0989 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-22-batch-300000-400000
[INFO] processing batch 400000-500000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0967 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0945 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-22-batch-400000-500000
[INFO] processing batch 500000-600000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.8081 - tp: 55006.0000 - fp: 24994.0000 - tn: 55006.0000 - fn: 24994.0000 - accuracy: 0.6876 - precision: 0.6876 - recall: 0.6876 - auc: 0.6833 - val_loss: 1.1444 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 10612.0000 - val_fn: 9388.0000 - val_accuracy: 0.5306 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.5306
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-22-batch-500000-600000
[INFO] processing batch 600000-700000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 1.1170 - tp: 42398.0000 - fp: 37602.0000 - tn: 42398.0000 - fn: 37602.0000 - accuracy: 0.5300 - precision: 0.5300 - recall: 0.5300 - auc: 0.5298 - val_loss: 1.0944 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 10527.0000 - val_fn: 9473.0000 - val_accuracy: 0.5264 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.5264
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-22-batch-600000-700000
[INFO] processing batch 700000-800000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 1.0622 - tp: 42369.0000 - fp: 37631.0000 - tn: 42369.0000 - fn: 37631.0000 - accuracy: 0.5296 - precision: 0.5296 - recall: 0.5296 - auc: 0.5300 - val_loss: 1.0341 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 10623.0000 - val_fn: 9377.0000 - val_accuracy: 0.5311 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.5311
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-22-batch-700000-800000
[INFO] processing batch 800000-900000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 1.0137 - tp: 42452.0000 - fp: 37548.0000 - tn: 42452.0000 - fn: 37548.0000 - accuracy: 0.5307 - precision: 0.5307 - recall: 0.5307 - auc: 0.5316 - val_loss: 0.9935 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 10601.0000 - val_fn: 9399.0000 - val_accuracy: 0.5300 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-22-batch-800000-900000
[INFO] processing batch 900000-1000000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.9755 - tp: 42382.0000 - fp: 37618.0000 - tn: 42382.0000 - fn: 37618.0000 - accuracy: 0.5298 - precision: 0.5298 - recall: 0.5298 - auc: 0.5293 - val_loss: 0.9556 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 10612.0000 - val_fn: 9388.0000 - val_accuracy: 0.5306 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.5306
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-22-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039687
[33m[INFO] loading file 23-24/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7441 - tp: 52270.0000 - fp: 27730.0000 - tn: 52270.0000 - fn: 27730.0000 - accuracy: 0.6534 - precision: 0.6534 - recall: 0.6534 - auc: 0.6520 - val_loss: 0.1845 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-24-batch-0-100000
[INFO] processing batch 100000-200000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1816 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1768 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-24-batch-100000-200000
[INFO] processing batch 200000-300000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1722 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1676 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-24-batch-200000-300000
[INFO] processing batch 300000-400000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1633 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1590 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-24-batch-300000-400000
[INFO] processing batch 400000-500000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1551 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1511 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-24-batch-400000-500000
[INFO] processing batch 500000-600000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1474 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1437 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-24-batch-500000-600000
[INFO] processing batch 600000-700000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1403 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1368 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-24-batch-600000-700000
[INFO] processing batch 700000-800000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1337 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1304 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-24-batch-700000-800000
[INFO] processing batch 800000-900000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1275 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1244 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-24-batch-800000-900000
[INFO] processing batch 900000-1000000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2322 - tp: 75698.0000 - fp: 4302.0000 - tn: 75698.0000 - fn: 4302.0000 - accuracy: 0.9462 - precision: 0.9462 - recall: 0.9462 - auc: 0.9441 - val_loss: 0.8477 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 12912.0000 - val_fn: 7088.0000 - val_accuracy: 0.6456 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.6456
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-24-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039687
[33m[INFO] loading file 25-26/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.8425 - tp: 51502.0000 - fp: 28498.0000 - tn: 51502.0000 - fn: 28498.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6441 - val_loss: 0.8339 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 12842.0000 - val_fn: 7158.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6421
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-26-batch-0-100000
[INFO] processing batch 100000-200000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.8202 - tp: 51479.0000 - fp: 28521.0000 - tn: 51479.0000 - fn: 28521.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6438 - val_loss: 0.8069 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 12894.0000 - val_fn: 7106.0000 - val_accuracy: 0.6447 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.6447
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-26-batch-100000-200000
[INFO] processing batch 200000-300000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7996 - tp: 51470.0000 - fp: 28530.0000 - tn: 51470.0000 - fn: 28530.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6431 - val_loss: 0.7912 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 12850.0000 - val_fn: 7150.0000 - val_accuracy: 0.6425 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.6425
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-26-batch-200000-300000
[INFO] processing batch 300000-400000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7802 - tp: 51503.0000 - fp: 28497.0000 - tn: 51503.0000 - fn: 28497.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6442 - val_loss: 0.7741 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 12843.0000 - val_fn: 7157.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6422
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-26-batch-300000-400000
[INFO] processing batch 400000-500000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7642 - tp: 51468.0000 - fp: 28532.0000 - tn: 51468.0000 - fn: 28532.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6438 - val_loss: 0.7562 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 12868.0000 - val_fn: 7132.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-26-batch-400000-500000
[INFO] processing batch 500000-600000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7482 - tp: 51523.0000 - fp: 28477.0000 - tn: 51523.0000 - fn: 28477.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6446 - val_loss: 0.7423 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 12867.0000 - val_fn: 7133.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-26-batch-500000-600000
[INFO] processing batch 600000-700000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7340 - tp: 51579.0000 - fp: 28421.0000 - tn: 51579.0000 - fn: 28421.0000 - accuracy: 0.6447 - precision: 0.6447 - recall: 0.6447 - auc: 0.6449 - val_loss: 0.7300 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 12864.0000 - val_fn: 7136.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-26-batch-600000-700000
[INFO] processing batch 700000-800000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7244 - tp: 51462.0000 - fp: 28538.0000 - tn: 51462.0000 - fn: 28538.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6432 - val_loss: 0.7156 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 12911.0000 - val_fn: 7089.0000 - val_accuracy: 0.6456 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.6456
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-26-batch-700000-800000
[INFO] processing batch 800000-900000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7131 - tp: 51506.0000 - fp: 28494.0000 - tn: 51506.0000 - fn: 28494.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6438 - val_loss: 0.7042 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 12936.0000 - val_fn: 7064.0000 - val_accuracy: 0.6468 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.6468
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-26-batch-800000-900000
[INFO] processing batch 900000-1000000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.7044 - tp: 51474.0000 - fp: 28526.0000 - tn: 51474.0000 - fn: 28526.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6431 - val_loss: 0.6952 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 12945.0000 - val_fn: 7055.0000 - val_accuracy: 0.6472 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.6472
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-26-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039687
[33m[INFO] loading file 27-28/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (979817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6970 - tp: 51419.0000 - fp: 28581.0000 - tn: 51419.0000 - fn: 28581.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6428 - val_loss: 0.6947 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 12829.0000 - val_fn: 7171.0000 - val_accuracy: 0.6414 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.6414
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-28-batch-0-100000
[INFO] processing batch 100000-200000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6889 - tp: 51485.0000 - fp: 28515.0000 - tn: 51485.0000 - fn: 28515.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6434 - val_loss: 0.6828 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 12918.0000 - val_fn: 7082.0000 - val_accuracy: 0.6459 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.6459
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-28-batch-100000-200000
[INFO] processing batch 200000-300000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6813 - tp: 51583.0000 - fp: 28417.0000 - tn: 51583.0000 - fn: 28417.0000 - accuracy: 0.6448 - precision: 0.6448 - recall: 0.6448 - auc: 0.6451 - val_loss: 0.6803 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 12863.0000 - val_fn: 7137.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6431
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-28-batch-200000-300000
[INFO] processing batch 300000-400000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6785 - tp: 51396.0000 - fp: 28604.0000 - tn: 51396.0000 - fn: 28604.0000 - accuracy: 0.6424 - precision: 0.6424 - recall: 0.6424 - auc: 0.6418 - val_loss: 0.6759 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 12851.0000 - val_fn: 7149.0000 - val_accuracy: 0.6425 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.6425
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-28-batch-300000-400000
[INFO] processing batch 400000-500000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6728 - tp: 51479.0000 - fp: 28521.0000 - tn: 51479.0000 - fn: 28521.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6430 - val_loss: 0.6706 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 12871.0000 - val_fn: 7129.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-28-batch-400000-500000
[INFO] processing batch 500000-600000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6698 - tp: 51397.0000 - fp: 28603.0000 - tn: 51397.0000 - fn: 28603.0000 - accuracy: 0.6425 - precision: 0.6425 - recall: 0.6425 - auc: 0.6423 - val_loss: 0.6674 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 12861.0000 - val_fn: 7139.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6430
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-28-batch-500000-600000
[INFO] processing batch 600000-700000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6657 - tp: 51458.0000 - fp: 28542.0000 - tn: 51458.0000 - fn: 28542.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6437 - val_loss: 0.6640 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 12868.0000 - val_fn: 7132.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-28-batch-600000-700000
[INFO] processing batch 700000-800000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6629 - tp: 51459.0000 - fp: 28541.0000 - tn: 51459.0000 - fn: 28541.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6430 - val_loss: 0.6599 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 12903.0000 - val_fn: 7097.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6451
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-28-batch-700000-800000
[INFO] processing batch 800000-900000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6599 - tp: 51525.0000 - fp: 28475.0000 - tn: 51525.0000 - fn: 28475.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6440 - val_loss: 0.6600 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 12854.0000 - val_fn: 7146.0000 - val_accuracy: 0.6427 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.6427
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-28-batch-800000-900000
[INFO] processing batch 900000-1000000/979817
[33m[INFO] loading file 29-30/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6586 - tp: 51460.0000 - fp: 28540.0000 - tn: 51460.0000 - fn: 28540.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6431 - val_loss: 0.6581 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-30-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6564 - tp: 51527.0000 - fp: 28473.0000 - tn: 51527.0000 - fn: 28473.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6445 - val_loss: 0.6570 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 12849.0000 - val_fn: 7151.0000 - val_accuracy: 0.6424 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.6424
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-30-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6556 - tp: 51484.0000 - fp: 28516.0000 - tn: 51484.0000 - fn: 28516.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6437 - val_loss: 0.6527 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 12931.0000 - val_fn: 7069.0000 - val_accuracy: 0.6465 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.6465
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-30-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6539 - tp: 51556.0000 - fp: 28444.0000 - tn: 51556.0000 - fn: 28444.0000 - accuracy: 0.6445 - precision: 0.6445 - recall: 0.6445 - auc: 0.6444 - val_loss: 0.6547 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-30-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51488.0000 - fp: 28512.0000 - tn: 51488.0000 - fn: 28512.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6434 - val_loss: 0.6533 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 12875.0000 - val_fn: 7125.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-30-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51529.0000 - fp: 28471.0000 - tn: 51529.0000 - fn: 28471.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6434 - val_loss: 0.6533 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 12860.0000 - val_fn: 7140.0000 - val_accuracy: 0.6430 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.6430
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-30-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6530 - tp: 51450.0000 - fp: 28550.0000 - tn: 51450.0000 - fn: 28550.0000 - accuracy: 0.6431 - precision: 0.6431 - recall: 0.6431 - auc: 0.6431 - val_loss: 0.6530 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 12855.0000 - val_fn: 7145.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-30-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6523 - tp: 51488.0000 - fp: 28512.0000 - tn: 51488.0000 - fn: 28512.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6527 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 12856.0000 - val_fn: 7144.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-30-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51529.0000 - fp: 28471.0000 - tn: 51529.0000 - fn: 28471.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6441 - val_loss: 0.6517 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 12877.0000 - val_fn: 7123.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-30-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51550.0000 - fp: 28450.0000 - tn: 51550.0000 - fn: 28450.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6441 - val_loss: 0.6518 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 12870.0000 - val_fn: 7130.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-30-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 31-32/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51494.0000 - fp: 28506.0000 - tn: 51494.0000 - fn: 28506.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6500 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 12921.0000 - val_fn: 7079.0000 - val_accuracy: 0.6460 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.6460
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-32-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51524.0000 - fp: 28476.0000 - tn: 51524.0000 - fn: 28476.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6438 - val_loss: 0.6506 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 12902.0000 - val_fn: 7098.0000 - val_accuracy: 0.6451 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.6451
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-32-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51428.0000 - fp: 28572.0000 - tn: 51428.0000 - fn: 28572.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6428 - val_loss: 0.6514 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 12874.0000 - val_fn: 7126.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-32-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51479.0000 - fp: 28521.0000 - tn: 51479.0000 - fn: 28521.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6510 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 12886.0000 - val_fn: 7114.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-32-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 51508.0000 - fn: 28492.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6507 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 12893.0000 - val_fn: 7107.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-32-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6514 - tp: 51484.0000 - fp: 28516.0000 - tn: 51484.0000 - fn: 28516.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6436 - val_loss: 0.6508 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 12889.0000 - val_fn: 7111.0000 - val_accuracy: 0.6445 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.6445
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-32-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6510 - tp: 51531.0000 - fp: 28469.0000 - tn: 51531.0000 - fn: 28469.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6441 - val_loss: 0.6513 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 12875.0000 - val_fn: 7125.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-32-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51576.0000 - fp: 28424.0000 - tn: 51576.0000 - fn: 28424.0000 - accuracy: 0.6447 - precision: 0.6447 - recall: 0.6447 - auc: 0.6447 - val_loss: 0.6508 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 12890.0000 - val_fn: 7110.0000 - val_accuracy: 0.6445 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.6445
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-32-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51489.0000 - fp: 28511.0000 - tn: 51489.0000 - fn: 28511.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 12864.0000 - val_fn: 7136.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-32-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6516 - tp: 51449.0000 - fp: 28551.0000 - tn: 51449.0000 - fn: 28551.0000 - accuracy: 0.6431 - precision: 0.6431 - recall: 0.6431 - auc: 0.6431 - val_loss: 0.6515 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 12867.0000 - val_fn: 7133.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-32-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 33-34/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 51508.0000 - fn: 28492.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 12875.0000 - val_fn: 7125.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-34-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51518.0000 - fp: 28482.0000 - tn: 51518.0000 - fn: 28482.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6440 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 12864.0000 - val_fn: 7136.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-34-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51404.0000 - fp: 28596.0000 - tn: 51404.0000 - fn: 28596.0000 - accuracy: 0.6425 - precision: 0.6425 - recall: 0.6425 - auc: 0.6425 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 12862.0000 - val_fn: 7138.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6431
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-34-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6508 - tp: 51552.0000 - fp: 28448.0000 - tn: 51552.0000 - fn: 28448.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6444 - val_loss: 0.6509 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 12886.0000 - val_fn: 7114.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-34-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51594.0000 - fp: 28406.0000 - tn: 51594.0000 - fn: 28406.0000 - accuracy: 0.6449 - precision: 0.6449 - recall: 0.6449 - auc: 0.6449 - val_loss: 0.6496 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 12929.0000 - val_fn: 7071.0000 - val_accuracy: 0.6464 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.6465
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-34-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6512 - tp: 51505.0000 - fp: 28495.0000 - tn: 51505.0000 - fn: 28495.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6438 - val_loss: 0.6522 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 12842.0000 - val_fn: 7158.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6421
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-34-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51470.0000 - fp: 28530.0000 - tn: 51470.0000 - fn: 28530.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6434 - val_loss: 0.6515 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 12865.0000 - val_fn: 7135.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-34-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6506 - tp: 51588.0000 - fp: 28412.0000 - tn: 51588.0000 - fn: 28412.0000 - accuracy: 0.6449 - precision: 0.6449 - recall: 0.6449 - auc: 0.6449 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 12876.0000 - val_fn: 7124.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-34-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51408.0000 - fp: 28592.0000 - tn: 51408.0000 - fn: 28592.0000 - accuracy: 0.6426 - precision: 0.6426 - recall: 0.6426 - auc: 0.6426 - val_loss: 0.6524 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 12834.0000 - val_fn: 7166.0000 - val_accuracy: 0.6417 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.6417
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-34-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51422.0000 - fp: 28578.0000 - tn: 51422.0000 - fn: 28578.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6428 - val_loss: 0.6512 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 12877.0000 - val_fn: 7123.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-34-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 35-36/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51520.0000 - fp: 28480.0000 - tn: 51520.0000 - fn: 28480.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6440 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-36-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51486.0000 - fp: 28514.0000 - tn: 51486.0000 - fn: 28514.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 12876.0000 - val_fn: 7124.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-36-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51498.0000 - fp: 28502.0000 - tn: 51498.0000 - fn: 28502.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 12892.0000 - val_fn: 7108.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-36-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51521.0000 - fp: 28479.0000 - tn: 51521.0000 - fn: 28479.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6440 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 12855.0000 - val_fn: 7145.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-36-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51570.0000 - fp: 28430.0000 - tn: 51570.0000 - fn: 28430.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6513 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 12872.0000 - val_fn: 7128.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-36-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51498.0000 - fp: 28502.0000 - tn: 51498.0000 - fn: 28502.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6513 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 12874.0000 - val_fn: 7126.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-36-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6502 - tp: 51644.0000 - fp: 28356.0000 - tn: 51644.0000 - fn: 28356.0000 - accuracy: 0.6456 - precision: 0.6456 - recall: 0.6456 - auc: 0.6456 - val_loss: 0.6506 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 12895.0000 - val_fn: 7105.0000 - val_accuracy: 0.6447 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.6447
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-36-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51397.0000 - fp: 28603.0000 - tn: 51397.0000 - fn: 28603.0000 - accuracy: 0.6425 - precision: 0.6425 - recall: 0.6425 - auc: 0.6425 - val_loss: 0.6495 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 12933.0000 - val_fn: 7067.0000 - val_accuracy: 0.6467 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.6467
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-36-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51415.0000 - fp: 28585.0000 - tn: 51415.0000 - fn: 28585.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6416 - val_loss: 0.6511 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 12878.0000 - val_fn: 7122.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-36-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6512 - tp: 51498.0000 - fp: 28502.0000 - tn: 51498.0000 - fn: 28502.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6436 - val_loss: 0.6518 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 12856.0000 - val_fn: 7144.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-36-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 37-38/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51413.0000 - fp: 28587.0000 - tn: 51413.0000 - fn: 28587.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6427 - val_loss: 0.6519 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 12854.0000 - val_fn: 7146.0000 - val_accuracy: 0.6427 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.6427
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-38-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6516 - tp: 51456.0000 - fp: 28544.0000 - tn: 51456.0000 - fn: 28544.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6432 - val_loss: 0.6504 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 12903.0000 - val_fn: 7097.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6451
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-38-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51565.0000 - fp: 28435.0000 - tn: 51565.0000 - fn: 28435.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6450 - val_loss: 0.6513 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 12871.0000 - val_fn: 7129.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-38-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51512.0000 - fp: 28488.0000 - tn: 51512.0000 - fn: 28488.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6508 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 12888.0000 - val_fn: 7112.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-38-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51528.0000 - fp: 28472.0000 - tn: 51528.0000 - fn: 28472.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6441 - val_loss: 0.6505 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 12899.0000 - val_fn: 7101.0000 - val_accuracy: 0.6449 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.6449
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-38-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51513.0000 - fp: 28487.0000 - tn: 51513.0000 - fn: 28487.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6496 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 12931.0000 - val_fn: 7069.0000 - val_accuracy: 0.6465 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.6465
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-38-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51589.0000 - fp: 28411.0000 - tn: 51589.0000 - fn: 28411.0000 - accuracy: 0.6449 - precision: 0.6449 - recall: 0.6449 - auc: 0.6449 - val_loss: 0.6522 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 12842.0000 - val_fn: 7158.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6421
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-38-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51481.0000 - fp: 28519.0000 - tn: 51481.0000 - fn: 28519.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-38-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51549.0000 - fp: 28451.0000 - tn: 51549.0000 - fn: 28451.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6444 - val_loss: 0.6505 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 12898.0000 - val_fn: 7102.0000 - val_accuracy: 0.6449 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.6449
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-38-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 51550.0000 - fn: 28450.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6444 - val_loss: 0.6515 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 12866.0000 - val_fn: 7134.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-38-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 39-40/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51486.0000 - fp: 28514.0000 - tn: 51486.0000 - fn: 28514.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6521 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 12847.0000 - val_fn: 7153.0000 - val_accuracy: 0.6424 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-40-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51597.0000 - fp: 28403.0000 - tn: 51597.0000 - fn: 28403.0000 - accuracy: 0.6450 - precision: 0.6450 - recall: 0.6450 - auc: 0.6450 - val_loss: 0.6502 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 12910.0000 - val_fn: 7090.0000 - val_accuracy: 0.6455 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.6455
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-40-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6503 - tp: 51631.0000 - fp: 28369.0000 - tn: 51631.0000 - fn: 28369.0000 - accuracy: 0.6454 - precision: 0.6454 - recall: 0.6454 - auc: 0.6454 - val_loss: 0.6507 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 12894.0000 - val_fn: 7106.0000 - val_accuracy: 0.6447 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.6447
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-40-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 51493.0000 - fn: 28507.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 12869.0000 - val_fn: 7131.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-40-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51488.0000 - fp: 28512.0000 - tn: 51488.0000 - fn: 28512.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 12875.0000 - val_fn: 7125.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-40-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51418.0000 - fp: 28582.0000 - tn: 51418.0000 - fn: 28582.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6428 - val_loss: 0.6522 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 12843.0000 - val_fn: 7157.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6422
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-40-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51491.0000 - fp: 28509.0000 - tn: 51491.0000 - fn: 28509.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 12862.0000 - val_fn: 7138.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6431
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-40-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51556.0000 - fp: 28444.0000 - tn: 51556.0000 - fn: 28444.0000 - accuracy: 0.6445 - precision: 0.6445 - recall: 0.6445 - auc: 0.6445 - val_loss: 0.6500 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 12916.0000 - val_fn: 7084.0000 - val_accuracy: 0.6458 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.6458
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-40-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51505.0000 - fp: 28495.0000 - tn: 51505.0000 - fn: 28495.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6438 - val_loss: 0.6523 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 12838.0000 - val_fn: 7162.0000 - val_accuracy: 0.6419 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.6419
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-40-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51432.0000 - fp: 28568.0000 - tn: 51432.0000 - fn: 28568.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6429 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 12850.0000 - val_fn: 7150.0000 - val_accuracy: 0.6425 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.6425
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-40-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 41-42/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 51427.0000 - fn: 28573.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6425 - val_loss: 0.6516 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 12861.0000 - val_fn: 7139.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6430
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-42-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51515.0000 - fp: 28485.0000 - tn: 51515.0000 - fn: 28485.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6441 - val_loss: 0.6514 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 12868.0000 - val_fn: 7132.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-42-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 51452.0000 - fn: 28548.0000 - accuracy: 0.6431 - precision: 0.6431 - recall: 0.6431 - auc: 0.6431 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 12876.0000 - val_fn: 7124.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-42-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51587.0000 - fp: 28413.0000 - tn: 51587.0000 - fn: 28413.0000 - accuracy: 0.6448 - precision: 0.6448 - recall: 0.6448 - auc: 0.6447 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 12860.0000 - val_fn: 7140.0000 - val_accuracy: 0.6430 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.6430
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-42-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6507 - tp: 51566.0000 - fp: 28434.0000 - tn: 51566.0000 - fn: 28434.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6494 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 12937.0000 - val_fn: 7063.0000 - val_accuracy: 0.6468 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.6468
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-42-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6515 - tp: 51459.0000 - fp: 28541.0000 - tn: 51459.0000 - fn: 28541.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6432 - val_loss: 0.6527 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 12826.0000 - val_fn: 7174.0000 - val_accuracy: 0.6413 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.6413
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-42-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51511.0000 - fp: 28489.0000 - tn: 51511.0000 - fn: 28489.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6510 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 12882.0000 - val_fn: 7118.0000 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.6441
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-42-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51499.0000 - fp: 28501.0000 - tn: 51499.0000 - fn: 28501.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6519 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 12853.0000 - val_fn: 7147.0000 - val_accuracy: 0.6427 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.6427
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-42-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51494.0000 - fp: 28506.0000 - tn: 51494.0000 - fn: 28506.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6500 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 12917.0000 - val_fn: 7083.0000 - val_accuracy: 0.6459 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.6459
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-42-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51584.0000 - fp: 28416.0000 - tn: 51584.0000 - fn: 28416.0000 - accuracy: 0.6448 - precision: 0.6448 - recall: 0.6448 - auc: 0.6448 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 12875.0000 - val_fn: 7125.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-42-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 43-44/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 51591.0000 - fn: 28409.0000 - accuracy: 0.6449 - precision: 0.6449 - recall: 0.6449 - auc: 0.6449 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 12873.0000 - val_fn: 7127.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-44-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51529.0000 - fp: 28471.0000 - tn: 51529.0000 - fn: 28471.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6441 - val_loss: 0.6527 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 12824.0000 - val_fn: 7176.0000 - val_accuracy: 0.6412 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.6412
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-44-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6521 - tp: 51387.0000 - fp: 28613.0000 - tn: 51387.0000 - fn: 28613.0000 - accuracy: 0.6423 - precision: 0.6423 - recall: 0.6423 - auc: 0.6421 - val_loss: 0.6506 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 12896.0000 - val_fn: 7104.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-44-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51518.0000 - fp: 28482.0000 - tn: 51518.0000 - fn: 28482.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6445 - val_loss: 0.6522 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 12844.0000 - val_fn: 7156.0000 - val_accuracy: 0.6422 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.6422
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-44-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 51591.0000 - fn: 28409.0000 - accuracy: 0.6449 - precision: 0.6449 - recall: 0.6449 - auc: 0.6449 - val_loss: 0.6489 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 12952.0000 - val_fn: 7048.0000 - val_accuracy: 0.6476 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.6476
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-44-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 51452.0000 - fn: 28548.0000 - accuracy: 0.6431 - precision: 0.6431 - recall: 0.6431 - auc: 0.6431 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 12855.0000 - val_fn: 7145.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-44-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 51497.0000 - fn: 28503.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6438 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-44-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51543.0000 - fp: 28457.0000 - tn: 51543.0000 - fn: 28457.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6443 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-44-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 51427.0000 - fn: 28573.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6424 - val_loss: 0.6508 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 12891.0000 - val_fn: 7109.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-44-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6510 - tp: 51537.0000 - fp: 28463.0000 - tn: 51537.0000 - fn: 28463.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6445 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 12863.0000 - val_fn: 7137.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6431
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-44-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 45-46/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6503 - tp: 51620.0000 - fp: 28380.0000 - tn: 51620.0000 - fn: 28380.0000 - accuracy: 0.6453 - precision: 0.6453 - recall: 0.6453 - auc: 0.6453 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 12869.0000 - val_fn: 7131.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-46-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51538.0000 - fp: 28462.0000 - tn: 51538.0000 - fn: 28462.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6509 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 12885.0000 - val_fn: 7115.0000 - val_accuracy: 0.6442 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.6442
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-46-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51564.0000 - fp: 28436.0000 - tn: 51564.0000 - fn: 28436.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6504 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 12904.0000 - val_fn: 7096.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-46-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51590.0000 - fp: 28410.0000 - tn: 51590.0000 - fn: 28410.0000 - accuracy: 0.6449 - precision: 0.6449 - recall: 0.6449 - auc: 0.6449 - val_loss: 0.6522 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 12844.0000 - val_fn: 7156.0000 - val_accuracy: 0.6422 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.6422
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-46-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51395.0000 - fp: 28605.0000 - tn: 51395.0000 - fn: 28605.0000 - accuracy: 0.6424 - precision: 0.6424 - recall: 0.6424 - auc: 0.6417 - val_loss: 0.6506 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 12896.0000 - val_fn: 7104.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-46-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51525.0000 - fp: 28475.0000 - tn: 51525.0000 - fn: 28475.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6436 - val_loss: 0.6501 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 12913.0000 - val_fn: 7087.0000 - val_accuracy: 0.6457 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.6457
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-46-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51464.0000 - fp: 28536.0000 - tn: 51464.0000 - fn: 28536.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6428 - val_loss: 0.6510 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 12883.0000 - val_fn: 7117.0000 - val_accuracy: 0.6442 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.6442
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-46-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51532.0000 - fp: 28468.0000 - tn: 51532.0000 - fn: 28468.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6440 - val_loss: 0.6509 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 12885.0000 - val_fn: 7115.0000 - val_accuracy: 0.6442 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.6442
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-46-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51502.0000 - fp: 28498.0000 - tn: 51502.0000 - fn: 28498.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6438 - val_loss: 0.6496 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 12929.0000 - val_fn: 7071.0000 - val_accuracy: 0.6464 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.6465
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-46-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51569.0000 - fp: 28431.0000 - tn: 51569.0000 - fn: 28431.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 12873.0000 - val_fn: 7127.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-46-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 47-48/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51601.0000 - fp: 28399.0000 - tn: 51601.0000 - fn: 28399.0000 - accuracy: 0.6450 - precision: 0.6450 - recall: 0.6450 - auc: 0.6450 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 12892.0000 - val_fn: 7108.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-48-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51559.0000 - fp: 28441.0000 - tn: 51559.0000 - fn: 28441.0000 - accuracy: 0.6445 - precision: 0.6445 - recall: 0.6445 - auc: 0.6445 - val_loss: 0.6514 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 12871.0000 - val_fn: 7129.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-48-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 51468.0000 - fn: 28532.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6434 - val_loss: 0.6528 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 12822.0000 - val_fn: 7178.0000 - val_accuracy: 0.6411 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.6411
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-48-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 51493.0000 - fn: 28507.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6511 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 12881.0000 - val_fn: 7119.0000 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.6441
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-48-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51492.0000 - fp: 28508.0000 - tn: 51492.0000 - fn: 28508.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6434 - val_loss: 0.6502 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 12909.0000 - val_fn: 7091.0000 - val_accuracy: 0.6454 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.6454
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-48-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51525.0000 - fp: 28475.0000 - tn: 51525.0000 - fn: 28475.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6441 - val_loss: 0.6526 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 12830.0000 - val_fn: 7170.0000 - val_accuracy: 0.6415 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.6415
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-48-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 51497.0000 - fn: 28503.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6431 - val_loss: 0.6511 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 12879.0000 - val_fn: 7121.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-48-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51547.0000 - fp: 28453.0000 - tn: 51547.0000 - fn: 28453.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6443 - val_loss: 0.6502 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 12911.0000 - val_fn: 7089.0000 - val_accuracy: 0.6456 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.6456
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-48-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51566.0000 - fp: 28434.0000 - tn: 51566.0000 - fn: 28434.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 12863.0000 - val_fn: 7137.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6431
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-48-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6504 - tp: 51606.0000 - fp: 28394.0000 - tn: 51606.0000 - fn: 28394.0000 - accuracy: 0.6451 - precision: 0.6451 - recall: 0.6451 - auc: 0.6451 - val_loss: 0.6503 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 12905.0000 - val_fn: 7095.0000 - val_accuracy: 0.6453 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.6453
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-48-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 49-50/50 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51532.0000 - fp: 28468.0000 - tn: 51532.0000 - fn: 28468.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6515 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 12865.0000 - val_fn: 7135.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-50-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51430.0000 - fp: 28570.0000 - tn: 51430.0000 - fn: 28570.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6422 - val_loss: 0.6498 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 12924.0000 - val_fn: 7076.0000 - val_accuracy: 0.6462 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.6462
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-50-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51469.0000 - fp: 28531.0000 - tn: 51469.0000 - fn: 28531.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6432 - val_loss: 0.6526 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 12829.0000 - val_fn: 7171.0000 - val_accuracy: 0.6414 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.6414
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-50-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51492.0000 - fp: 28508.0000 - tn: 51492.0000 - fn: 28508.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6437 - val_loss: 0.6498 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 12922.0000 - val_fn: 7078.0000 - val_accuracy: 0.6461 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.6461
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-50-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51495.0000 - fp: 28505.0000 - tn: 51495.0000 - fn: 28505.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6508 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 12890.0000 - val_fn: 7110.0000 - val_accuracy: 0.6445 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.6445
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-50-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51422.0000 - fp: 28578.0000 - tn: 51422.0000 - fn: 28578.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6423 - val_loss: 0.6528 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 12823.0000 - val_fn: 7177.0000 - val_accuracy: 0.6411 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.6411
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-50-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51482.0000 - fp: 28518.0000 - tn: 51482.0000 - fn: 28518.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6428 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 12892.0000 - val_fn: 7108.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-50-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51433.0000 - fp: 28567.0000 - tn: 51433.0000 - fn: 28567.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6427 - val_loss: 0.6520 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 12849.0000 - val_fn: 7151.0000 - val_accuracy: 0.6424 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.6424
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-50-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51461.0000 - fp: 28539.0000 - tn: 51461.0000 - fn: 28539.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6435 - val_loss: 0.6508 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 12889.0000 - val_fn: 7111.0000 - val_accuracy: 0.6445 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.6445
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-50-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51467.0000 - fp: 28533.0000 - tn: 51467.0000 - fn: 28533.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6429 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-50-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[LOSS] 0.6517612545013428[0m
[33m[INFO] epoch 2/3[0m
[33m[INFO] loading file 1-2/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.3747 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3229 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-2-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2944 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2695 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-2-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2555 - tp: 79766.0000 - fp: 234.0000 - tn: 79766.0000 - fn: 234.0000 - accuracy: 0.9971 - precision: 0.9971 - recall: 0.9971 - auc: 0.9965 - val_loss: 0.8584 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 10606.0000 - val_fn: 9394.0000 - val_accuracy: 0.5303 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.5303
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-2-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.8458 - tp: 42447.0000 - fp: 37553.0000 - tn: 42447.0000 - fn: 37553.0000 - accuracy: 0.5306 - precision: 0.5306 - recall: 0.5306 - auc: 0.5309 - val_loss: 0.8269 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 10626.0000 - val_fn: 9374.0000 - val_accuracy: 0.5313 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.5313
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-2-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.8128 - tp: 42438.0000 - fp: 37562.0000 - tn: 42438.0000 - fn: 37562.0000 - accuracy: 0.5305 - precision: 0.5305 - recall: 0.5305 - auc: 0.5312 - val_loss: 0.7988 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 10603.0000 - val_fn: 9397.0000 - val_accuracy: 0.5301 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-2-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7869 - tp: 42435.0000 - fp: 37565.0000 - tn: 42435.0000 - fn: 37565.0000 - accuracy: 0.5304 - precision: 0.5304 - recall: 0.5304 - auc: 0.5300 - val_loss: 0.7767 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 10589.0000 - val_fn: 9411.0000 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.5294
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-2-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.4705 - tp: 67619.0000 - fp: 12381.0000 - tn: 67619.0000 - fn: 12381.0000 - accuracy: 0.8452 - precision: 0.8452 - recall: 0.8452 - auc: 0.8464 - val_loss: 0.3110 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-2-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.3995 - tp: 72432.0000 - fp: 7568.0000 - tn: 72432.0000 - fn: 7568.0000 - accuracy: 0.9054 - precision: 0.9054 - recall: 0.9054 - auc: 0.9037 - val_loss: 0.8034 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 10593.0000 - val_fn: 9407.0000 - val_accuracy: 0.5296 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.5296
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-2-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7965 - tp: 42321.0000 - fp: 37679.0000 - tn: 42321.0000 - fn: 37679.0000 - accuracy: 0.5290 - precision: 0.5290 - recall: 0.5290 - auc: 0.5292 - val_loss: 0.7844 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 10602.0000 - val_fn: 9398.0000 - val_accuracy: 0.5301 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-2-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.4694 - tp: 67360.0000 - fp: 12640.0000 - tn: 67360.0000 - fn: 12640.0000 - accuracy: 0.8420 - precision: 0.8420 - recall: 0.8420 - auc: 0.8414 - val_loss: 0.3018 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-2-batch-900000-1000000
[33m[INFO] loading file 3-4/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7501 - tp: 45236.0000 - fp: 34764.0000 - tn: 45236.0000 - fn: 34764.0000 - accuracy: 0.5655 - precision: 0.5655 - recall: 0.5655 - auc: 0.5652 - val_loss: 0.7789 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 10571.0000 - val_fn: 9429.0000 - val_accuracy: 0.5286 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.5286
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-4-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.5912 - tp: 57751.0000 - fp: 22249.0000 - tn: 57751.0000 - fn: 22249.0000 - accuracy: 0.7219 - precision: 0.7219 - recall: 0.7219 - auc: 0.7219 - val_loss: 0.3239 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-4-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.3095 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2922 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-4-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2778 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2637 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-4-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2521 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2406 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-4-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2308 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2212 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-4-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2129 - tp: 79999.0000 - fp: 1.0000 - tn: 79999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2046 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-4-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1974 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1902 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-4-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.3545 - tp: 71528.0000 - fp: 8472.0000 - tn: 71528.0000 - fn: 8472.0000 - accuracy: 0.8941 - precision: 0.8941 - recall: 0.8941 - auc: 0.8948 - val_loss: 1.1586 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 7806.0000 - val_fn: 12194.0000 - val_accuracy: 0.3903 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.3903
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-4-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6436 - tp: 56887.0000 - fp: 23113.0000 - tn: 56887.0000 - fn: 23113.0000 - accuracy: 0.7111 - precision: 0.7111 - recall: 0.7111 - auc: 0.7154 - val_loss: 0.1921 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-4-batch-900000-1000000
[33m[INFO] loading file 5-6/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.5321 - tp: 62445.0000 - fp: 17555.0000 - tn: 62445.0000 - fn: 17555.0000 - accuracy: 0.7806 - precision: 0.7806 - recall: 0.7806 - auc: 0.7798 - val_loss: 0.7429 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 12842.0000 - val_fn: 7158.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6421
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-6-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7379 - tp: 51316.0000 - fp: 28684.0000 - tn: 51316.0000 - fn: 28684.0000 - accuracy: 0.6414 - precision: 0.6414 - recall: 0.6414 - auc: 0.6415 - val_loss: 0.4244 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 17052.0000 - val_fn: 2948.0000 - val_accuracy: 0.8526 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.8526
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-6-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2056 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1978 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-6-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1906 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1834 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-6-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1771 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1708 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-6-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1652 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1596 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-6-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1547 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1497 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-6-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1453 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1408 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-6-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1368 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5592 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 15632.0000 - val_fn: 4368.0000 - val_accuracy: 0.7816 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.7816
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-6-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.8269 - tp: 51195.0000 - fp: 28805.0000 - tn: 51195.0000 - fn: 28805.0000 - accuracy: 0.6399 - precision: 0.6399 - recall: 0.6399 - auc: 0.6395 - val_loss: 0.8173 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 12768.0000 - val_fn: 7232.0000 - val_accuracy: 0.6384 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.6384
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-6-batch-900000-1000000
[33m[INFO] loading file 7-8/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.8028 - tp: 51210.0000 - fp: 28790.0000 - tn: 51210.0000 - fn: 28790.0000 - accuracy: 0.6401 - precision: 0.6401 - recall: 0.6401 - auc: 0.6394 - val_loss: 0.7914 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 12803.0000 - val_fn: 7197.0000 - val_accuracy: 0.6402 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.6402
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-8-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7789 - tp: 51338.0000 - fp: 28662.0000 - tn: 51338.0000 - fn: 28662.0000 - accuracy: 0.6417 - precision: 0.6417 - recall: 0.6417 - auc: 0.6416 - val_loss: 0.7671 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 12860.0000 - val_fn: 7140.0000 - val_accuracy: 0.6430 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.6430
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-8-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.4774 - tp: 65370.0000 - fp: 14630.0000 - tn: 65370.0000 - fn: 14630.0000 - accuracy: 0.8171 - precision: 0.8171 - recall: 0.8171 - auc: 0.8138 - val_loss: 0.1769 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-8-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1723 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1665 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-8-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.1612 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1558 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-8-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.1511 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1463 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-8-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.1421 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1377 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-8-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1339 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1299 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-8-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2982 - tp: 73166.0000 - fp: 6834.0000 - tn: 73166.0000 - fn: 6834.0000 - accuracy: 0.9146 - precision: 0.9146 - recall: 0.9146 - auc: 0.9130 - val_loss: 0.4900 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 16368.0000 - val_fn: 3632.0000 - val_accuracy: 0.8184 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.8184
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-8-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.4885 - tp: 65505.0000 - fp: 14495.0000 - tn: 65505.0000 - fn: 14495.0000 - accuracy: 0.8188 - precision: 0.8188 - recall: 0.8188 - auc: 0.8186 - val_loss: 0.4869 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 16383.0000 - val_fn: 3617.0000 - val_accuracy: 0.8191 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.8191
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-8-batch-900000-1000000
[33m[INFO] loading file 9-10/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.4917 - tp: 65300.0000 - fp: 14700.0000 - tn: 65300.0000 - fn: 14700.0000 - accuracy: 0.8163 - precision: 0.8163 - recall: 0.8163 - auc: 0.8162 - val_loss: 0.4948 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 16283.0000 - val_fn: 3717.0000 - val_accuracy: 0.8141 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.8141
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-10-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1579 - tp: 78936.0000 - fp: 1064.0000 - tn: 78936.0000 - fn: 1064.0000 - accuracy: 0.9867 - precision: 0.9867 - recall: 0.9867 - auc: 0.9867 - val_loss: 0.1282 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-10-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.1244 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-10-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.1170 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1135 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-10-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.1103 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1071 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-10-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1042 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1013 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-10-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1005 - tp: 79936.0000 - fp: 64.0000 - tn: 79936.0000 - fn: 64.0000 - accuracy: 0.9992 - precision: 0.9992 - recall: 0.9992 - auc: 0.9992 - val_loss: 0.9172 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 12843.0000 - val_fn: 7157.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6422
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-10-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7572 - tp: 56672.0000 - fp: 23328.0000 - tn: 56672.0000 - fn: 23328.0000 - accuracy: 0.7084 - precision: 0.7084 - recall: 0.7084 - auc: 0.7080 - val_loss: 0.1053 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-10-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1041 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-10-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0989 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0962 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-10-batch-900000-1000000
[33m[INFO] loading file 11-12/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0938 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0913 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-12-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0891 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0868 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-12-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0847 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0826 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-12-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0806 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0786 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-12-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0768 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0750 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-12-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0733 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0716 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-12-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0700 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5068 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 16689.0000 - val_fn: 3311.0000 - val_accuracy: 0.8345 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8345
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-12-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.9976 - tp: 51328.0000 - fp: 28672.0000 - tn: 51328.0000 - fn: 28672.0000 - accuracy: 0.6416 - precision: 0.6416 - recall: 0.6416 - auc: 0.6420 - val_loss: 0.6037 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 15792.0000 - val_fn: 4208.0000 - val_accuracy: 0.7896 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.7896
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-12-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.0795 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0779 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-12-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0763 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0746 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-12-batch-900000-1000000
[33m[INFO] loading file 13-14/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0731 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0715 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-14-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0700 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0685 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-14-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0671 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7282 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 15075.0000 - val_fn: 4925.0000 - val_accuracy: 0.7538 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.7537
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-14-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 1.0107 - tp: 51313.0000 - fp: 28687.0000 - tn: 51313.0000 - fn: 28687.0000 - accuracy: 0.6414 - precision: 0.6414 - recall: 0.6414 - auc: 0.6413 - val_loss: 0.9798 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 12876.0000 - val_fn: 7124.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-14-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.9631 - tp: 51356.0000 - fp: 28644.0000 - tn: 51356.0000 - fn: 28644.0000 - accuracy: 0.6420 - precision: 0.6420 - recall: 0.6420 - auc: 0.6422 - val_loss: 0.9386 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 12867.0000 - val_fn: 7133.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-14-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6032 - tp: 62543.0000 - fp: 17457.0000 - tn: 62543.0000 - fn: 17457.0000 - accuracy: 0.7818 - precision: 0.7818 - recall: 0.7818 - auc: 0.7817 - val_loss: 0.0948 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-14-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0937 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0917 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-14-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0898 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0877 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-14-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0859 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0840 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-14-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0822 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0804 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-14-batch-900000-1000000
[33m[INFO] loading file 15-16/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (939690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0788 - tp: 79998.0000 - fp: 2.0000 - tn: 79998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0770 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-16-batch-0-100000
[INFO] processing batch 100000-200000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0755 - tp: 79998.0000 - fp: 2.0000 - tn: 79998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0738 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-16-batch-100000-200000
[INFO] processing batch 200000-300000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0724 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0708 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-16-batch-200000-300000
[INFO] processing batch 300000-400000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0694 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1848 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 11586.0000 - val_fn: 8414.0000 - val_accuracy: 0.5793 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.5793
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-16-batch-300000-400000
[INFO] processing batch 400000-500000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 1.2767 - tp: 42561.0000 - fp: 37439.0000 - tn: 42561.0000 - fn: 37439.0000 - accuracy: 0.5320 - precision: 0.5320 - recall: 0.5320 - auc: 0.5323 - val_loss: 1.2375 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 10627.0000 - val_fn: 9373.0000 - val_accuracy: 0.5314 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.5314
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-16-batch-400000-500000
[INFO] processing batch 500000-600000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 1.2040 - tp: 42492.0000 - fp: 37508.0000 - tn: 42492.0000 - fn: 37508.0000 - accuracy: 0.5311 - precision: 0.5311 - recall: 0.5311 - auc: 0.5311 - val_loss: 1.1716 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 10618.0000 - val_fn: 9382.0000 - val_accuracy: 0.5309 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.5309
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-16-batch-500000-600000
[INFO] processing batch 600000-700000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7078 - tp: 58381.0000 - fp: 21619.0000 - tn: 58381.0000 - fn: 21619.0000 - accuracy: 0.7298 - precision: 0.7298 - recall: 0.7298 - auc: 0.7301 - val_loss: 0.1043 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-16-batch-600000-700000
[INFO] processing batch 700000-800000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1034 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-16-batch-700000-800000
[INFO] processing batch 800000-900000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0995 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0975 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-16-batch-800000-900000
[INFO] processing batch 900000-1000000/939690
[33m[INFO] loading file 17-18/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0957 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0937 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-18-batch-0-100000
[INFO] processing batch 100000-200000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0919 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0901 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-18-batch-100000-200000
[INFO] processing batch 200000-300000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0884 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0867 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-18-batch-200000-300000
[INFO] processing batch 300000-400000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.4283 - tp: 68607.0000 - fp: 11393.0000 - tn: 68607.0000 - fn: 11393.0000 - accuracy: 0.8576 - precision: 0.8576 - recall: 0.8576 - auc: 0.8576 - val_loss: 0.5207 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 16369.0000 - val_fn: 3631.0000 - val_accuracy: 0.8184 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.8184
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-18-batch-300000-400000
[INFO] processing batch 400000-500000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.5171 - tp: 65526.0000 - fp: 14474.0000 - tn: 65526.0000 - fn: 14474.0000 - accuracy: 0.8191 - precision: 0.8191 - recall: 0.8191 - auc: 0.8191 - val_loss: 0.2503 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 18648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9324 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9324
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-18-batch-400000-500000
[INFO] processing batch 500000-600000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.3220 - tp: 72130.0000 - fp: 7870.0000 - tn: 72130.0000 - fn: 7870.0000 - accuracy: 0.9016 - precision: 0.9016 - recall: 0.9016 - auc: 0.9016 - val_loss: 0.9802 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 12369.0000 - val_fn: 7631.0000 - val_accuracy: 0.6184 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.6184
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-18-batch-500000-600000
[INFO] processing batch 600000-700000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.9571 - tp: 49699.0000 - fp: 30301.0000 - tn: 49699.0000 - fn: 30301.0000 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - auc: 0.6210 - val_loss: 0.9446 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 12357.0000 - val_fn: 7643.0000 - val_accuracy: 0.6179 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.6179
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-18-batch-600000-700000
[INFO] processing batch 700000-800000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.9236 - tp: 49541.0000 - fp: 30459.0000 - tn: 49541.0000 - fn: 30459.0000 - accuracy: 0.6193 - precision: 0.6193 - recall: 0.6193 - auc: 0.6191 - val_loss: 0.9045 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 12397.0000 - val_fn: 7603.0000 - val_accuracy: 0.6198 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.6199
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-18-batch-700000-800000
[INFO] processing batch 800000-900000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2613 - tp: 74509.0000 - fp: 5491.0000 - tn: 74509.0000 - fn: 5491.0000 - accuracy: 0.9314 - precision: 0.9314 - recall: 0.9314 - auc: 0.9314 - val_loss: 0.1189 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-18-batch-800000-900000
[INFO] processing batch 900000-1000000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1164 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1135 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-18-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039690
[33m[INFO] loading file 19-20/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1109 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1081 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-20-batch-0-100000
[INFO] processing batch 100000-200000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1056 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1031 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-20-batch-100000-200000
[INFO] processing batch 200000-300000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1007 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0983 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-20-batch-200000-300000
[INFO] processing batch 300000-400000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.4012 - tp: 69321.0000 - fp: 10679.0000 - tn: 69321.0000 - fn: 10679.0000 - accuracy: 0.8665 - precision: 0.8665 - recall: 0.8665 - auc: 0.8665 - val_loss: 1.4667 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 7882.0000 - val_fn: 12118.0000 - val_accuracy: 0.3941 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.3941
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-20-batch-300000-400000
[INFO] processing batch 400000-500000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 1.4263 - tp: 31237.0000 - fp: 48763.0000 - tn: 31237.0000 - fn: 48763.0000 - accuracy: 0.3905 - precision: 0.3905 - recall: 0.3905 - auc: 0.3900 - val_loss: 0.1208 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-20-batch-400000-500000
[INFO] processing batch 500000-600000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1210 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1715 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 19491.0000 - val_fn: 509.0000 - val_accuracy: 0.9746 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9746
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-20-batch-500000-600000
[INFO] processing batch 600000-700000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.4955 - tp: 65427.0000 - fp: 14573.0000 - tn: 65427.0000 - fn: 14573.0000 - accuracy: 0.8178 - precision: 0.8178 - recall: 0.8178 - auc: 0.8178 - val_loss: 0.4945 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 16357.0000 - val_fn: 3643.0000 - val_accuracy: 0.8178 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.8178
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-20-batch-600000-700000
[INFO] processing batch 700000-800000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.4955 - tp: 65351.0000 - fp: 14649.0000 - tn: 65351.0000 - fn: 14649.0000 - accuracy: 0.8169 - precision: 0.8169 - recall: 0.8169 - auc: 0.8170 - val_loss: 0.4912 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 16371.0000 - val_fn: 3629.0000 - val_accuracy: 0.8185 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.8185
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-20-batch-700000-800000
[INFO] processing batch 800000-900000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2243 - tp: 76024.0000 - fp: 3976.0000 - tn: 76024.0000 - fn: 3976.0000 - accuracy: 0.9503 - precision: 0.9503 - recall: 0.9503 - auc: 0.9493 - val_loss: 0.1218 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-20-batch-800000-900000
[INFO] processing batch 900000-1000000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1192 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1163 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-20-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039690
[33m[INFO] loading file 21-22/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1136 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1109 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-22-batch-0-100000
[INFO] processing batch 100000-200000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1084 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1058 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-22-batch-100000-200000
[INFO] processing batch 200000-300000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1034 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1010 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-22-batch-200000-300000
[INFO] processing batch 300000-400000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0988 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0966 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-22-batch-300000-400000
[INFO] processing batch 400000-500000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0945 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0923 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-22-batch-400000-500000
[INFO] processing batch 500000-600000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.8133 - tp: 55006.0000 - fp: 24994.0000 - tn: 55006.0000 - fn: 24994.0000 - accuracy: 0.6876 - precision: 0.6876 - recall: 0.6876 - auc: 0.6873 - val_loss: 1.1529 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 10612.0000 - val_fn: 9388.0000 - val_accuracy: 0.5306 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.5306
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-22-batch-500000-600000
[INFO] processing batch 600000-700000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 1.1253 - tp: 42398.0000 - fp: 37602.0000 - tn: 42398.0000 - fn: 37602.0000 - accuracy: 0.5300 - precision: 0.5300 - recall: 0.5300 - auc: 0.5298 - val_loss: 1.1024 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 10527.0000 - val_fn: 9473.0000 - val_accuracy: 0.5264 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.5264
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-22-batch-600000-700000
[INFO] processing batch 700000-800000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 1.0698 - tp: 42369.0000 - fp: 37631.0000 - tn: 42369.0000 - fn: 37631.0000 - accuracy: 0.5296 - precision: 0.5296 - recall: 0.5296 - auc: 0.5300 - val_loss: 1.0414 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 10623.0000 - val_fn: 9377.0000 - val_accuracy: 0.5311 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.5311
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-22-batch-700000-800000
[INFO] processing batch 800000-900000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 1.0208 - tp: 42452.0000 - fp: 37548.0000 - tn: 42452.0000 - fn: 37548.0000 - accuracy: 0.5307 - precision: 0.5307 - recall: 0.5307 - auc: 0.5312 - val_loss: 1.0004 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 10601.0000 - val_fn: 9399.0000 - val_accuracy: 0.5300 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-22-batch-800000-900000
[INFO] processing batch 900000-1000000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.9821 - tp: 42382.0000 - fp: 37618.0000 - tn: 42382.0000 - fn: 37618.0000 - accuracy: 0.5298 - precision: 0.5298 - recall: 0.5298 - auc: 0.5300 - val_loss: 0.9619 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 10612.0000 - val_fn: 9388.0000 - val_accuracy: 0.5306 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.5306
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-22-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039687
[33m[INFO] loading file 23-24/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7478 - tp: 52270.0000 - fp: 27730.0000 - tn: 52270.0000 - fn: 27730.0000 - accuracy: 0.6534 - precision: 0.6534 - recall: 0.6534 - auc: 0.6530 - val_loss: 0.1811 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-24-batch-0-100000
[INFO] processing batch 100000-200000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1785 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1739 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-24-batch-100000-200000
[INFO] processing batch 200000-300000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1695 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1650 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-24-batch-200000-300000
[INFO] processing batch 300000-400000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1609 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1567 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-24-batch-300000-400000
[INFO] processing batch 400000-500000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1529 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1490 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-24-batch-400000-500000
[INFO] processing batch 500000-600000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1454 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1418 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-24-batch-500000-600000
[INFO] processing batch 600000-700000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1385 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1351 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-24-batch-600000-700000
[INFO] processing batch 700000-800000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1320 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1289 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-24-batch-700000-800000
[INFO] processing batch 800000-900000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1260 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1230 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-24-batch-800000-900000
[INFO] processing batch 900000-1000000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2314 - tp: 75698.0000 - fp: 4302.0000 - tn: 75698.0000 - fn: 4302.0000 - accuracy: 0.9462 - precision: 0.9462 - recall: 0.9462 - auc: 0.9466 - val_loss: 0.8506 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 12912.0000 - val_fn: 7088.0000 - val_accuracy: 0.6456 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.6456
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-24-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039687
[33m[INFO] loading file 25-26/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.8452 - tp: 51502.0000 - fp: 28498.0000 - tn: 51502.0000 - fn: 28498.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6434 - val_loss: 0.8365 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 12842.0000 - val_fn: 7158.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6421
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-26-batch-0-100000
[INFO] processing batch 100000-200000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.8227 - tp: 51479.0000 - fp: 28521.0000 - tn: 51479.0000 - fn: 28521.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6432 - val_loss: 0.8092 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 12894.0000 - val_fn: 7106.0000 - val_accuracy: 0.6447 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.6447
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-26-batch-100000-200000
[INFO] processing batch 200000-300000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.8018 - tp: 51470.0000 - fp: 28530.0000 - tn: 51470.0000 - fn: 28530.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6440 - val_loss: 0.7934 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 12850.0000 - val_fn: 7150.0000 - val_accuracy: 0.6425 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.6425
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-26-batch-200000-300000
[INFO] processing batch 300000-400000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7822 - tp: 51503.0000 - fp: 28497.0000 - tn: 51503.0000 - fn: 28497.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6428 - val_loss: 0.7761 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 12843.0000 - val_fn: 7157.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6422
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-26-batch-300000-400000
[INFO] processing batch 400000-500000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7661 - tp: 51468.0000 - fp: 28532.0000 - tn: 51468.0000 - fn: 28532.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6433 - val_loss: 0.7580 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 12868.0000 - val_fn: 7132.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-26-batch-400000-500000
[INFO] processing batch 500000-600000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7500 - tp: 51523.0000 - fp: 28477.0000 - tn: 51523.0000 - fn: 28477.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6440 - val_loss: 0.7439 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 12867.0000 - val_fn: 7133.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-26-batch-500000-600000
[INFO] processing batch 600000-700000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7355 - tp: 51579.0000 - fp: 28421.0000 - tn: 51579.0000 - fn: 28421.0000 - accuracy: 0.6447 - precision: 0.6447 - recall: 0.6447 - auc: 0.6448 - val_loss: 0.7315 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 12864.0000 - val_fn: 7136.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-26-batch-600000-700000
[INFO] processing batch 700000-800000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7258 - tp: 51462.0000 - fp: 28538.0000 - tn: 51462.0000 - fn: 28538.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6429 - val_loss: 0.7169 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 12911.0000 - val_fn: 7089.0000 - val_accuracy: 0.6456 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.6456
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-26-batch-700000-800000
[INFO] processing batch 800000-900000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7144 - tp: 51506.0000 - fp: 28494.0000 - tn: 51506.0000 - fn: 28494.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6437 - val_loss: 0.7054 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 12936.0000 - val_fn: 7064.0000 - val_accuracy: 0.6468 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.6468
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-26-batch-800000-900000
[INFO] processing batch 900000-1000000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7055 - tp: 51474.0000 - fp: 28526.0000 - tn: 51474.0000 - fn: 28526.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6433 - val_loss: 0.6962 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 12945.0000 - val_fn: 7055.0000 - val_accuracy: 0.6472 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.6472
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-26-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039687
[33m[INFO] loading file 27-28/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (979817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6981 - tp: 51419.0000 - fp: 28581.0000 - tn: 51419.0000 - fn: 28581.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6430 - val_loss: 0.6957 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 12829.0000 - val_fn: 7171.0000 - val_accuracy: 0.6414 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.6414
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-28-batch-0-100000
[INFO] processing batch 100000-200000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6898 - tp: 51485.0000 - fp: 28515.0000 - tn: 51485.0000 - fn: 28515.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6432 - val_loss: 0.6837 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 12918.0000 - val_fn: 7082.0000 - val_accuracy: 0.6459 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.6459
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-28-batch-100000-200000
[INFO] processing batch 200000-300000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6821 - tp: 51583.0000 - fp: 28417.0000 - tn: 51583.0000 - fn: 28417.0000 - accuracy: 0.6448 - precision: 0.6448 - recall: 0.6448 - auc: 0.6448 - val_loss: 0.6810 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 12863.0000 - val_fn: 7137.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6431
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-28-batch-200000-300000
[INFO] processing batch 300000-400000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6792 - tp: 51396.0000 - fp: 28604.0000 - tn: 51396.0000 - fn: 28604.0000 - accuracy: 0.6424 - precision: 0.6424 - recall: 0.6424 - auc: 0.6426 - val_loss: 0.6765 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 12851.0000 - val_fn: 7149.0000 - val_accuracy: 0.6425 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.6425
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-28-batch-300000-400000
[INFO] processing batch 400000-500000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6734 - tp: 51479.0000 - fp: 28521.0000 - tn: 51479.0000 - fn: 28521.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6437 - val_loss: 0.6712 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 12871.0000 - val_fn: 7129.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-28-batch-400000-500000
[INFO] processing batch 500000-600000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6704 - tp: 51397.0000 - fp: 28603.0000 - tn: 51397.0000 - fn: 28603.0000 - accuracy: 0.6425 - precision: 0.6425 - recall: 0.6425 - auc: 0.6426 - val_loss: 0.6679 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 12861.0000 - val_fn: 7139.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6430
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-28-batch-500000-600000
[INFO] processing batch 600000-700000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6662 - tp: 51458.0000 - fp: 28542.0000 - tn: 51458.0000 - fn: 28542.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6430 - val_loss: 0.6644 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 12868.0000 - val_fn: 7132.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-28-batch-600000-700000
[INFO] processing batch 700000-800000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6633 - tp: 51459.0000 - fp: 28541.0000 - tn: 51459.0000 - fn: 28541.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6440 - val_loss: 0.6603 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 12903.0000 - val_fn: 7097.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6451
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-28-batch-700000-800000
[INFO] processing batch 800000-900000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6602 - tp: 51525.0000 - fp: 28475.0000 - tn: 51525.0000 - fn: 28475.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6442 - val_loss: 0.6603 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 12854.0000 - val_fn: 7146.0000 - val_accuracy: 0.6427 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.6427
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-28-batch-800000-900000
[INFO] processing batch 900000-1000000/979817
[33m[INFO] loading file 29-30/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6589 - tp: 51460.0000 - fp: 28540.0000 - tn: 51460.0000 - fn: 28540.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6434 - val_loss: 0.6584 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-30-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6566 - tp: 51527.0000 - fp: 28473.0000 - tn: 51527.0000 - fn: 28473.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6440 - val_loss: 0.6572 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 12849.0000 - val_fn: 7151.0000 - val_accuracy: 0.6424 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.6424
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-30-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6558 - tp: 51484.0000 - fp: 28516.0000 - tn: 51484.0000 - fn: 28516.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6437 - val_loss: 0.6529 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 12931.0000 - val_fn: 7069.0000 - val_accuracy: 0.6465 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.6465
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-30-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6540 - tp: 51556.0000 - fp: 28444.0000 - tn: 51556.0000 - fn: 28444.0000 - accuracy: 0.6445 - precision: 0.6445 - recall: 0.6445 - auc: 0.6448 - val_loss: 0.6548 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-30-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6539 - tp: 51488.0000 - fp: 28512.0000 - tn: 51488.0000 - fn: 28512.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6440 - val_loss: 0.6534 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 12875.0000 - val_fn: 7125.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-30-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51529.0000 - fp: 28471.0000 - tn: 51529.0000 - fn: 28471.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6440 - val_loss: 0.6534 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 12860.0000 - val_fn: 7140.0000 - val_accuracy: 0.6430 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.6430
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-30-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51450.0000 - fp: 28550.0000 - tn: 51450.0000 - fn: 28550.0000 - accuracy: 0.6431 - precision: 0.6431 - recall: 0.6431 - auc: 0.6430 - val_loss: 0.6531 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 12855.0000 - val_fn: 7145.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-30-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6523 - tp: 51488.0000 - fp: 28512.0000 - tn: 51488.0000 - fn: 28512.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6437 - val_loss: 0.6527 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 12856.0000 - val_fn: 7144.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-30-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51529.0000 - fp: 28471.0000 - tn: 51529.0000 - fn: 28471.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6441 - val_loss: 0.6518 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 12877.0000 - val_fn: 7123.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-30-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6513 - tp: 51550.0000 - fp: 28450.0000 - tn: 51550.0000 - fn: 28450.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6446 - val_loss: 0.6518 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 12870.0000 - val_fn: 7130.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-30-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 31-32/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51494.0000 - fp: 28506.0000 - tn: 51494.0000 - fn: 28506.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6500 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 12921.0000 - val_fn: 7079.0000 - val_accuracy: 0.6460 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.6460
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-32-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51524.0000 - fp: 28476.0000 - tn: 51524.0000 - fn: 28476.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6441 - val_loss: 0.6506 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 12902.0000 - val_fn: 7098.0000 - val_accuracy: 0.6451 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.6451
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-32-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51428.0000 - fp: 28572.0000 - tn: 51428.0000 - fn: 28572.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6432 - val_loss: 0.6514 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 12874.0000 - val_fn: 7126.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-32-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6515 - tp: 51479.0000 - fp: 28521.0000 - tn: 51479.0000 - fn: 28521.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6510 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 12886.0000 - val_fn: 7114.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-32-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 51508.0000 - fn: 28492.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6507 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 12893.0000 - val_fn: 7107.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-32-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51484.0000 - fp: 28516.0000 - tn: 51484.0000 - fn: 28516.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6431 - val_loss: 0.6508 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 12889.0000 - val_fn: 7111.0000 - val_accuracy: 0.6445 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.6445
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-32-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51531.0000 - fp: 28469.0000 - tn: 51531.0000 - fn: 28469.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6441 - val_loss: 0.6513 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 12875.0000 - val_fn: 7125.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-32-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6507 - tp: 51576.0000 - fp: 28424.0000 - tn: 51576.0000 - fn: 28424.0000 - accuracy: 0.6447 - precision: 0.6447 - recall: 0.6447 - auc: 0.6447 - val_loss: 0.6508 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 12890.0000 - val_fn: 7110.0000 - val_accuracy: 0.6445 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.6445
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-32-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6513 - tp: 51489.0000 - fp: 28511.0000 - tn: 51489.0000 - fn: 28511.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 12864.0000 - val_fn: 7136.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-32-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6516 - tp: 51449.0000 - fp: 28551.0000 - tn: 51449.0000 - fn: 28551.0000 - accuracy: 0.6431 - precision: 0.6431 - recall: 0.6431 - auc: 0.6431 - val_loss: 0.6515 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 12867.0000 - val_fn: 7133.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-32-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 33-34/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 51508.0000 - fn: 28492.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 12875.0000 - val_fn: 7125.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-34-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51518.0000 - fp: 28482.0000 - tn: 51518.0000 - fn: 28482.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6440 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 12864.0000 - val_fn: 7136.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-34-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51404.0000 - fp: 28596.0000 - tn: 51404.0000 - fn: 28596.0000 - accuracy: 0.6425 - precision: 0.6425 - recall: 0.6425 - auc: 0.6425 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 12862.0000 - val_fn: 7138.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6431
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-34-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51552.0000 - fp: 28448.0000 - tn: 51552.0000 - fn: 28448.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6444 - val_loss: 0.6509 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 12886.0000 - val_fn: 7114.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-34-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51594.0000 - fp: 28406.0000 - tn: 51594.0000 - fn: 28406.0000 - accuracy: 0.6449 - precision: 0.6449 - recall: 0.6449 - auc: 0.6449 - val_loss: 0.6496 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 12929.0000 - val_fn: 7071.0000 - val_accuracy: 0.6464 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.6465
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-34-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51505.0000 - fp: 28495.0000 - tn: 51505.0000 - fn: 28495.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6438 - val_loss: 0.6522 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 12842.0000 - val_fn: 7158.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6421
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-34-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51470.0000 - fp: 28530.0000 - tn: 51470.0000 - fn: 28530.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6434 - val_loss: 0.6515 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 12865.0000 - val_fn: 7135.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-34-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51588.0000 - fp: 28412.0000 - tn: 51588.0000 - fn: 28412.0000 - accuracy: 0.6449 - precision: 0.6449 - recall: 0.6449 - auc: 0.6449 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 12876.0000 - val_fn: 7124.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-34-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51408.0000 - fp: 28592.0000 - tn: 51408.0000 - fn: 28592.0000 - accuracy: 0.6426 - precision: 0.6426 - recall: 0.6426 - auc: 0.6426 - val_loss: 0.6524 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 12834.0000 - val_fn: 7166.0000 - val_accuracy: 0.6417 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.6417
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-34-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51422.0000 - fp: 28578.0000 - tn: 51422.0000 - fn: 28578.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6428 - val_loss: 0.6512 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 12877.0000 - val_fn: 7123.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-34-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 35-36/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51520.0000 - fp: 28480.0000 - tn: 51520.0000 - fn: 28480.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6440 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-36-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51486.0000 - fp: 28514.0000 - tn: 51486.0000 - fn: 28514.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 12876.0000 - val_fn: 7124.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-36-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6512 - tp: 51498.0000 - fp: 28502.0000 - tn: 51498.0000 - fn: 28502.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 12892.0000 - val_fn: 7108.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-36-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51521.0000 - fp: 28479.0000 - tn: 51521.0000 - fn: 28479.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6440 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 12855.0000 - val_fn: 7145.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-36-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51570.0000 - fp: 28430.0000 - tn: 51570.0000 - fn: 28430.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6513 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 12872.0000 - val_fn: 7128.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-36-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51498.0000 - fp: 28502.0000 - tn: 51498.0000 - fn: 28502.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6513 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 12874.0000 - val_fn: 7126.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-36-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6502 - tp: 51644.0000 - fp: 28356.0000 - tn: 51644.0000 - fn: 28356.0000 - accuracy: 0.6456 - precision: 0.6456 - recall: 0.6456 - auc: 0.6456 - val_loss: 0.6506 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 12895.0000 - val_fn: 7105.0000 - val_accuracy: 0.6447 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.6447
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-36-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51397.0000 - fp: 28603.0000 - tn: 51397.0000 - fn: 28603.0000 - accuracy: 0.6425 - precision: 0.6425 - recall: 0.6425 - auc: 0.6425 - val_loss: 0.6495 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 12933.0000 - val_fn: 7067.0000 - val_accuracy: 0.6467 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.6467
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-36-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51415.0000 - fp: 28585.0000 - tn: 51415.0000 - fn: 28585.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6426 - val_loss: 0.6511 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 12878.0000 - val_fn: 7122.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-36-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51498.0000 - fp: 28502.0000 - tn: 51498.0000 - fn: 28502.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6518 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 12856.0000 - val_fn: 7144.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-36-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 37-38/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51413.0000 - fp: 28587.0000 - tn: 51413.0000 - fn: 28587.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6427 - val_loss: 0.6519 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 12854.0000 - val_fn: 7146.0000 - val_accuracy: 0.6427 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.6427
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-38-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51456.0000 - fp: 28544.0000 - tn: 51456.0000 - fn: 28544.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6425 - val_loss: 0.6504 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 12903.0000 - val_fn: 7097.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6451
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-38-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51565.0000 - fp: 28435.0000 - tn: 51565.0000 - fn: 28435.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6447 - val_loss: 0.6513 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 12871.0000 - val_fn: 7129.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-38-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51512.0000 - fp: 28488.0000 - tn: 51512.0000 - fn: 28488.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6508 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 12888.0000 - val_fn: 7112.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-38-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51528.0000 - fp: 28472.0000 - tn: 51528.0000 - fn: 28472.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6441 - val_loss: 0.6505 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 12899.0000 - val_fn: 7101.0000 - val_accuracy: 0.6449 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.6449
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-38-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51513.0000 - fp: 28487.0000 - tn: 51513.0000 - fn: 28487.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6496 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 12931.0000 - val_fn: 7069.0000 - val_accuracy: 0.6465 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.6465
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-38-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51589.0000 - fp: 28411.0000 - tn: 51589.0000 - fn: 28411.0000 - accuracy: 0.6449 - precision: 0.6449 - recall: 0.6449 - auc: 0.6449 - val_loss: 0.6522 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 12842.0000 - val_fn: 7158.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6421
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-38-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51481.0000 - fp: 28519.0000 - tn: 51481.0000 - fn: 28519.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-38-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51549.0000 - fp: 28451.0000 - tn: 51549.0000 - fn: 28451.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6444 - val_loss: 0.6505 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 12898.0000 - val_fn: 7102.0000 - val_accuracy: 0.6449 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.6449
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-38-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 51550.0000 - fn: 28450.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6444 - val_loss: 0.6515 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 12866.0000 - val_fn: 7134.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-38-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 39-40/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51486.0000 - fp: 28514.0000 - tn: 51486.0000 - fn: 28514.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6521 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 12847.0000 - val_fn: 7153.0000 - val_accuracy: 0.6424 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-40-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51597.0000 - fp: 28403.0000 - tn: 51597.0000 - fn: 28403.0000 - accuracy: 0.6450 - precision: 0.6450 - recall: 0.6450 - auc: 0.6450 - val_loss: 0.6502 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 12910.0000 - val_fn: 7090.0000 - val_accuracy: 0.6455 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.6455
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-40-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6503 - tp: 51631.0000 - fp: 28369.0000 - tn: 51631.0000 - fn: 28369.0000 - accuracy: 0.6454 - precision: 0.6454 - recall: 0.6454 - auc: 0.6454 - val_loss: 0.6507 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 12894.0000 - val_fn: 7106.0000 - val_accuracy: 0.6447 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.6447
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-40-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 51493.0000 - fn: 28507.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 12869.0000 - val_fn: 7131.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-40-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51488.0000 - fp: 28512.0000 - tn: 51488.0000 - fn: 28512.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 12875.0000 - val_fn: 7125.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-40-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51418.0000 - fp: 28582.0000 - tn: 51418.0000 - fn: 28582.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6420 - val_loss: 0.6522 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 12843.0000 - val_fn: 7157.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6422
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-40-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51491.0000 - fp: 28509.0000 - tn: 51491.0000 - fn: 28509.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 12862.0000 - val_fn: 7138.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6431
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-40-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51556.0000 - fp: 28444.0000 - tn: 51556.0000 - fn: 28444.0000 - accuracy: 0.6445 - precision: 0.6445 - recall: 0.6445 - auc: 0.6443 - val_loss: 0.6500 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 12916.0000 - val_fn: 7084.0000 - val_accuracy: 0.6458 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.6458
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-40-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51505.0000 - fp: 28495.0000 - tn: 51505.0000 - fn: 28495.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6438 - val_loss: 0.6523 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 12838.0000 - val_fn: 7162.0000 - val_accuracy: 0.6419 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.6419
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-40-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51432.0000 - fp: 28568.0000 - tn: 51432.0000 - fn: 28568.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6429 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 12850.0000 - val_fn: 7150.0000 - val_accuracy: 0.6425 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.6425
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-40-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 41-42/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 51427.0000 - fn: 28573.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6427 - val_loss: 0.6516 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 12861.0000 - val_fn: 7139.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6430
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-42-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51515.0000 - fp: 28485.0000 - tn: 51515.0000 - fn: 28485.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6436 - val_loss: 0.6514 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 12868.0000 - val_fn: 7132.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-42-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 51452.0000 - fn: 28548.0000 - accuracy: 0.6431 - precision: 0.6431 - recall: 0.6431 - auc: 0.6426 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 12876.0000 - val_fn: 7124.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-42-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51587.0000 - fp: 28413.0000 - tn: 51587.0000 - fn: 28413.0000 - accuracy: 0.6448 - precision: 0.6448 - recall: 0.6448 - auc: 0.6448 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 12860.0000 - val_fn: 7140.0000 - val_accuracy: 0.6430 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.6430
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-42-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51566.0000 - fp: 28434.0000 - tn: 51566.0000 - fn: 28434.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6494 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 12937.0000 - val_fn: 7063.0000 - val_accuracy: 0.6468 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.6468
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-42-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51459.0000 - fp: 28541.0000 - tn: 51459.0000 - fn: 28541.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6432 - val_loss: 0.6527 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 12826.0000 - val_fn: 7174.0000 - val_accuracy: 0.6413 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.6413
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-42-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51511.0000 - fp: 28489.0000 - tn: 51511.0000 - fn: 28489.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6436 - val_loss: 0.6510 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 12882.0000 - val_fn: 7118.0000 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.6441
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-42-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51499.0000 - fp: 28501.0000 - tn: 51499.0000 - fn: 28501.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6434 - val_loss: 0.6519 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 12853.0000 - val_fn: 7147.0000 - val_accuracy: 0.6427 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.6427
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-42-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51494.0000 - fp: 28506.0000 - tn: 51494.0000 - fn: 28506.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6500 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 12917.0000 - val_fn: 7083.0000 - val_accuracy: 0.6459 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.6459
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-42-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51584.0000 - fp: 28416.0000 - tn: 51584.0000 - fn: 28416.0000 - accuracy: 0.6448 - precision: 0.6448 - recall: 0.6448 - auc: 0.6450 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 12875.0000 - val_fn: 7125.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-42-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 43-44/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 51591.0000 - fn: 28409.0000 - accuracy: 0.6449 - precision: 0.6449 - recall: 0.6449 - auc: 0.6449 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 12873.0000 - val_fn: 7127.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-44-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51529.0000 - fp: 28471.0000 - tn: 51529.0000 - fn: 28471.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6441 - val_loss: 0.6528 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 12824.0000 - val_fn: 7176.0000 - val_accuracy: 0.6412 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.6412
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-44-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51387.0000 - fp: 28613.0000 - tn: 51387.0000 - fn: 28613.0000 - accuracy: 0.6423 - precision: 0.6423 - recall: 0.6423 - auc: 0.6420 - val_loss: 0.6506 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 12896.0000 - val_fn: 7104.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-44-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51518.0000 - fp: 28482.0000 - tn: 51518.0000 - fn: 28482.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6444 - val_loss: 0.6521 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 12844.0000 - val_fn: 7156.0000 - val_accuracy: 0.6422 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.6422
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-44-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 51591.0000 - fn: 28409.0000 - accuracy: 0.6449 - precision: 0.6449 - recall: 0.6449 - auc: 0.6449 - val_loss: 0.6489 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 12952.0000 - val_fn: 7048.0000 - val_accuracy: 0.6476 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.6476
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-44-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 51452.0000 - fn: 28548.0000 - accuracy: 0.6431 - precision: 0.6431 - recall: 0.6431 - auc: 0.6428 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 12855.0000 - val_fn: 7145.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-44-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 51497.0000 - fn: 28503.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6434 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-44-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51543.0000 - fp: 28457.0000 - tn: 51543.0000 - fn: 28457.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6444 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-44-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 51427.0000 - fn: 28573.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6427 - val_loss: 0.6508 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 12891.0000 - val_fn: 7109.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-44-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51537.0000 - fp: 28463.0000 - tn: 51537.0000 - fn: 28463.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6451 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 12863.0000 - val_fn: 7137.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6431
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-44-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 45-46/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6503 - tp: 51620.0000 - fp: 28380.0000 - tn: 51620.0000 - fn: 28380.0000 - accuracy: 0.6453 - precision: 0.6453 - recall: 0.6453 - auc: 0.6453 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 12869.0000 - val_fn: 7131.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-46-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51538.0000 - fp: 28462.0000 - tn: 51538.0000 - fn: 28462.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6509 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 12885.0000 - val_fn: 7115.0000 - val_accuracy: 0.6442 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.6442
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-46-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51564.0000 - fp: 28436.0000 - tn: 51564.0000 - fn: 28436.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6504 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 12904.0000 - val_fn: 7096.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-46-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51590.0000 - fp: 28410.0000 - tn: 51590.0000 - fn: 28410.0000 - accuracy: 0.6449 - precision: 0.6449 - recall: 0.6449 - auc: 0.6449 - val_loss: 0.6522 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 12844.0000 - val_fn: 7156.0000 - val_accuracy: 0.6422 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.6422
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-46-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51395.0000 - fp: 28605.0000 - tn: 51395.0000 - fn: 28605.0000 - accuracy: 0.6424 - precision: 0.6424 - recall: 0.6424 - auc: 0.6421 - val_loss: 0.6506 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 12896.0000 - val_fn: 7104.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-46-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51525.0000 - fp: 28475.0000 - tn: 51525.0000 - fn: 28475.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6440 - val_loss: 0.6501 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 12913.0000 - val_fn: 7087.0000 - val_accuracy: 0.6457 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.6457
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-46-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51464.0000 - fp: 28536.0000 - tn: 51464.0000 - fn: 28536.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6427 - val_loss: 0.6510 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 12883.0000 - val_fn: 7117.0000 - val_accuracy: 0.6442 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.6442
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-46-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51532.0000 - fp: 28468.0000 - tn: 51532.0000 - fn: 28468.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6509 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 12885.0000 - val_fn: 7115.0000 - val_accuracy: 0.6442 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.6442
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-46-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51502.0000 - fp: 28498.0000 - tn: 51502.0000 - fn: 28498.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6438 - val_loss: 0.6496 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 12929.0000 - val_fn: 7071.0000 - val_accuracy: 0.6464 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.6465
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-46-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51569.0000 - fp: 28431.0000 - tn: 51569.0000 - fn: 28431.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6445 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 12873.0000 - val_fn: 7127.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-46-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 47-48/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51601.0000 - fp: 28399.0000 - tn: 51601.0000 - fn: 28399.0000 - accuracy: 0.6450 - precision: 0.6450 - recall: 0.6450 - auc: 0.6450 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 12892.0000 - val_fn: 7108.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-48-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51559.0000 - fp: 28441.0000 - tn: 51559.0000 - fn: 28441.0000 - accuracy: 0.6445 - precision: 0.6445 - recall: 0.6445 - auc: 0.6445 - val_loss: 0.6514 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 12871.0000 - val_fn: 7129.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-48-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 51468.0000 - fn: 28532.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6434 - val_loss: 0.6528 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 12822.0000 - val_fn: 7178.0000 - val_accuracy: 0.6411 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.6411
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-48-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 51493.0000 - fn: 28507.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6435 - val_loss: 0.6511 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 12881.0000 - val_fn: 7119.0000 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.6441
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-48-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51492.0000 - fp: 28508.0000 - tn: 51492.0000 - fn: 28508.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6434 - val_loss: 0.6502 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 12909.0000 - val_fn: 7091.0000 - val_accuracy: 0.6454 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.6454
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-48-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51525.0000 - fp: 28475.0000 - tn: 51525.0000 - fn: 28475.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6441 - val_loss: 0.6526 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 12830.0000 - val_fn: 7170.0000 - val_accuracy: 0.6415 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.6415
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-48-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 51497.0000 - fn: 28503.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6433 - val_loss: 0.6511 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 12879.0000 - val_fn: 7121.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-48-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51547.0000 - fp: 28453.0000 - tn: 51547.0000 - fn: 28453.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6439 - val_loss: 0.6502 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 12911.0000 - val_fn: 7089.0000 - val_accuracy: 0.6456 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.6456
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-48-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6507 - tp: 51566.0000 - fp: 28434.0000 - tn: 51566.0000 - fn: 28434.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 12863.0000 - val_fn: 7137.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6431
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-48-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6504 - tp: 51606.0000 - fp: 28394.0000 - tn: 51606.0000 - fn: 28394.0000 - accuracy: 0.6451 - precision: 0.6451 - recall: 0.6451 - auc: 0.6451 - val_loss: 0.6503 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 12905.0000 - val_fn: 7095.0000 - val_accuracy: 0.6453 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.6453
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-48-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 49-50/50 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51532.0000 - fp: 28468.0000 - tn: 51532.0000 - fn: 28468.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6515 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 12865.0000 - val_fn: 7135.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-50-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51430.0000 - fp: 28570.0000 - tn: 51430.0000 - fn: 28570.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6426 - val_loss: 0.6498 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 12924.0000 - val_fn: 7076.0000 - val_accuracy: 0.6462 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.6462
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-50-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51469.0000 - fp: 28531.0000 - tn: 51469.0000 - fn: 28531.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6433 - val_loss: 0.6526 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 12829.0000 - val_fn: 7171.0000 - val_accuracy: 0.6414 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.6414
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-50-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51492.0000 - fp: 28508.0000 - tn: 51492.0000 - fn: 28508.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6498 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 12922.0000 - val_fn: 7078.0000 - val_accuracy: 0.6461 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.6461
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-50-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51495.0000 - fp: 28505.0000 - tn: 51495.0000 - fn: 28505.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6434 - val_loss: 0.6508 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 12890.0000 - val_fn: 7110.0000 - val_accuracy: 0.6445 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.6445
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-50-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51422.0000 - fp: 28578.0000 - tn: 51422.0000 - fn: 28578.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6430 - val_loss: 0.6528 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 12823.0000 - val_fn: 7177.0000 - val_accuracy: 0.6411 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.6411
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-50-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6514 - tp: 51482.0000 - fp: 28518.0000 - tn: 51482.0000 - fn: 28518.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6431 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 12892.0000 - val_fn: 7108.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-50-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51433.0000 - fp: 28567.0000 - tn: 51433.0000 - fn: 28567.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6429 - val_loss: 0.6520 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 12849.0000 - val_fn: 7151.0000 - val_accuracy: 0.6424 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.6424
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-50-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51461.0000 - fp: 28539.0000 - tn: 51461.0000 - fn: 28539.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6435 - val_loss: 0.6508 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 12889.0000 - val_fn: 7111.0000 - val_accuracy: 0.6445 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.6445
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-50-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51467.0000 - fp: 28533.0000 - tn: 51467.0000 - fn: 28533.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6427 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-50-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[LOSS] 0.6517621237754821[0m
[33m[INFO] epoch 3/3[0m
[33m[INFO] loading file 1-2/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.3742 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3226 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-2-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2941 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2692 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-2-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2552 - tp: 79766.0000 - fp: 234.0000 - tn: 79766.0000 - fn: 234.0000 - accuracy: 0.9971 - precision: 0.9971 - recall: 0.9971 - auc: 0.9971 - val_loss: 0.8588 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 10606.0000 - val_fn: 9394.0000 - val_accuracy: 0.5303 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.5303
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-2-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.8461 - tp: 42447.0000 - fp: 37553.0000 - tn: 42447.0000 - fn: 37553.0000 - accuracy: 0.5306 - precision: 0.5306 - recall: 0.5306 - auc: 0.5310 - val_loss: 0.8272 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 10626.0000 - val_fn: 9374.0000 - val_accuracy: 0.5313 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.5313
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-2-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.8131 - tp: 42438.0000 - fp: 37562.0000 - tn: 42438.0000 - fn: 37562.0000 - accuracy: 0.5305 - precision: 0.5305 - recall: 0.5305 - auc: 0.5299 - val_loss: 0.7990 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 10603.0000 - val_fn: 9397.0000 - val_accuracy: 0.5301 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-2-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7871 - tp: 42435.0000 - fp: 37565.0000 - tn: 42435.0000 - fn: 37565.0000 - accuracy: 0.5304 - precision: 0.5304 - recall: 0.5304 - auc: 0.5300 - val_loss: 0.7769 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 10589.0000 - val_fn: 9411.0000 - val_accuracy: 0.5294 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.5294
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-2-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.4704 - tp: 67619.0000 - fp: 12381.0000 - tn: 67619.0000 - fn: 12381.0000 - accuracy: 0.8452 - precision: 0.8452 - recall: 0.8452 - auc: 0.8437 - val_loss: 0.3108 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-2-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.3995 - tp: 72432.0000 - fp: 7568.0000 - tn: 72432.0000 - fn: 7568.0000 - accuracy: 0.9054 - precision: 0.9054 - recall: 0.9054 - auc: 0.9055 - val_loss: 0.8033 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 10593.0000 - val_fn: 9407.0000 - val_accuracy: 0.5296 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.5296
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-2-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7965 - tp: 42321.0000 - fp: 37679.0000 - tn: 42321.0000 - fn: 37679.0000 - accuracy: 0.5290 - precision: 0.5290 - recall: 0.5290 - auc: 0.5293 - val_loss: 0.7843 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 10602.0000 - val_fn: 9398.0000 - val_accuracy: 0.5301 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-2-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.4694 - tp: 67360.0000 - fp: 12640.0000 - tn: 67360.0000 - fn: 12640.0000 - accuracy: 0.8420 - precision: 0.8420 - recall: 0.8420 - auc: 0.8401 - val_loss: 0.3018 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-2-batch-900000-1000000
[33m[INFO] loading file 3-4/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7503 - tp: 45236.0000 - fp: 34764.0000 - tn: 45236.0000 - fn: 34764.0000 - accuracy: 0.5655 - precision: 0.5655 - recall: 0.5655 - auc: 0.5661 - val_loss: 0.7792 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 10571.0000 - val_fn: 9429.0000 - val_accuracy: 0.5286 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.5286
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-4-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.5912 - tp: 57751.0000 - fp: 22249.0000 - tn: 57751.0000 - fn: 22249.0000 - accuracy: 0.7219 - precision: 0.7219 - recall: 0.7219 - auc: 0.7212 - val_loss: 0.3238 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-4-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.3096 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2923 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-4-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2778 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2638 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-4-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2521 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2406 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-4-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2309 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2212 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-4-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2129 - tp: 79999.0000 - fp: 1.0000 - tn: 79999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2046 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-4-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1974 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1902 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-4-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.3545 - tp: 71528.0000 - fp: 8472.0000 - tn: 71528.0000 - fn: 8472.0000 - accuracy: 0.8941 - precision: 0.8941 - recall: 0.8941 - auc: 0.8935 - val_loss: 1.1585 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 7806.0000 - val_fn: 12194.0000 - val_accuracy: 0.3903 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.3903
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-4-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6437 - tp: 56887.0000 - fp: 23113.0000 - tn: 56887.0000 - fn: 23113.0000 - accuracy: 0.7111 - precision: 0.7111 - recall: 0.7111 - auc: 0.7108 - val_loss: 0.1921 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-4-batch-900000-1000000
[33m[INFO] loading file 5-6/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.5321 - tp: 62445.0000 - fp: 17555.0000 - tn: 62445.0000 - fn: 17555.0000 - accuracy: 0.7806 - precision: 0.7806 - recall: 0.7806 - auc: 0.7810 - val_loss: 0.7432 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 12842.0000 - val_fn: 7158.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6421
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-6-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7381 - tp: 51316.0000 - fp: 28684.0000 - tn: 51316.0000 - fn: 28684.0000 - accuracy: 0.6414 - precision: 0.6414 - recall: 0.6414 - auc: 0.6421 - val_loss: 0.4244 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 17052.0000 - val_fn: 2948.0000 - val_accuracy: 0.8526 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.8526
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-6-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2055 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1977 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-6-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1905 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1832 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-6-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1770 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1706 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-6-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1651 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1595 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-6-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1546 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1496 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-6-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1451 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1406 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-6-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1366 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5593 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 15632.0000 - val_fn: 4368.0000 - val_accuracy: 0.7816 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.7816
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-6-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.8271 - tp: 51195.0000 - fp: 28805.0000 - tn: 51195.0000 - fn: 28805.0000 - accuracy: 0.6399 - precision: 0.6399 - recall: 0.6399 - auc: 0.6402 - val_loss: 0.8175 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 12768.0000 - val_fn: 7232.0000 - val_accuracy: 0.6384 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.6384
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-6-batch-900000-1000000
[33m[INFO] loading file 7-8/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.8029 - tp: 51210.0000 - fp: 28790.0000 - tn: 51210.0000 - fn: 28790.0000 - accuracy: 0.6401 - precision: 0.6401 - recall: 0.6401 - auc: 0.6402 - val_loss: 0.7915 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 12803.0000 - val_fn: 7197.0000 - val_accuracy: 0.6402 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.6402
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-8-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7790 - tp: 51338.0000 - fp: 28662.0000 - tn: 51338.0000 - fn: 28662.0000 - accuracy: 0.6417 - precision: 0.6417 - recall: 0.6417 - auc: 0.6413 - val_loss: 0.7671 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 12860.0000 - val_fn: 7140.0000 - val_accuracy: 0.6430 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.6430
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-8-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.4774 - tp: 65370.0000 - fp: 14630.0000 - tn: 65370.0000 - fn: 14630.0000 - accuracy: 0.8171 - precision: 0.8171 - recall: 0.8171 - auc: 0.8164 - val_loss: 0.1769 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-8-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1723 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1665 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-8-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1612 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1559 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-8-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1512 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1464 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-8-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1421 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1378 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-8-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1339 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1300 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-8-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2982 - tp: 73166.0000 - fp: 6834.0000 - tn: 73166.0000 - fn: 6834.0000 - accuracy: 0.9146 - precision: 0.9146 - recall: 0.9146 - auc: 0.9150 - val_loss: 0.4900 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 16368.0000 - val_fn: 3632.0000 - val_accuracy: 0.8184 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.8184
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-8-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.4885 - tp: 65505.0000 - fp: 14495.0000 - tn: 65505.0000 - fn: 14495.0000 - accuracy: 0.8188 - precision: 0.8188 - recall: 0.8188 - auc: 0.8185 - val_loss: 0.4869 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 16383.0000 - val_fn: 3617.0000 - val_accuracy: 0.8191 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.8191
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-8-batch-900000-1000000
[33m[INFO] loading file 9-10/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.4917 - tp: 65300.0000 - fp: 14700.0000 - tn: 65300.0000 - fn: 14700.0000 - accuracy: 0.8163 - precision: 0.8163 - recall: 0.8163 - auc: 0.8162 - val_loss: 0.4948 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 16283.0000 - val_fn: 3717.0000 - val_accuracy: 0.8141 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.8141
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-10-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1579 - tp: 78936.0000 - fp: 1064.0000 - tn: 78936.0000 - fn: 1064.0000 - accuracy: 0.9867 - precision: 0.9867 - recall: 0.9867 - auc: 0.9865 - val_loss: 0.1282 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-10-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1244 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-10-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1170 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1135 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-10-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1103 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1071 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-10-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1042 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1013 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-10-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.1005 - tp: 79936.0000 - fp: 64.0000 - tn: 79936.0000 - fn: 64.0000 - accuracy: 0.9992 - precision: 0.9992 - recall: 0.9992 - auc: 0.9992 - val_loss: 0.9172 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 12843.0000 - val_fn: 7157.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6422
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-10-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.7572 - tp: 56672.0000 - fp: 23328.0000 - tn: 56672.0000 - fn: 23328.0000 - accuracy: 0.7084 - precision: 0.7084 - recall: 0.7084 - auc: 0.7067 - val_loss: 0.1053 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-10-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.1042 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-10-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0989 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0962 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-10-batch-900000-1000000
[33m[INFO] loading file 11-12/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0938 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0913 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-12-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0891 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0868 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-12-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0847 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0826 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-12-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0807 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0787 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-12-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.0769 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0750 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-12-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0733 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0716 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-12-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.0700 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5068 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 16689.0000 - val_fn: 3311.0000 - val_accuracy: 0.8345 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8345
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-12-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.9975 - tp: 51328.0000 - fp: 28672.0000 - tn: 51328.0000 - fn: 28672.0000 - accuracy: 0.6416 - precision: 0.6416 - recall: 0.6416 - auc: 0.6416 - val_loss: 0.6036 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 15792.0000 - val_fn: 4208.0000 - val_accuracy: 0.7896 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.7896
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-12-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0795 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0780 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-12-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.0763 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0746 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-12-batch-900000-1000000
[33m[INFO] loading file 13-14/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1000000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.0731 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0715 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-14-batch-0-100000
[INFO] processing batch 100000-200000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.0700 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0685 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-14-batch-100000-200000
[INFO] processing batch 200000-300000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 5s - loss: 0.0671 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7281 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 15075.0000 - val_fn: 4925.0000 - val_accuracy: 0.7538 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.7537
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-14-batch-200000-300000
[INFO] processing batch 300000-400000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 5s - loss: 1.0106 - tp: 51313.0000 - fp: 28687.0000 - tn: 51313.0000 - fn: 28687.0000 - accuracy: 0.6414 - precision: 0.6414 - recall: 0.6414 - auc: 0.6414 - val_loss: 0.9797 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 12876.0000 - val_fn: 7124.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-14-batch-300000-400000
[INFO] processing batch 400000-500000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 5s - loss: 0.9631 - tp: 51356.0000 - fp: 28644.0000 - tn: 51356.0000 - fn: 28644.0000 - accuracy: 0.6420 - precision: 0.6420 - recall: 0.6420 - auc: 0.6412 - val_loss: 0.9386 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 12867.0000 - val_fn: 7133.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-14-batch-400000-500000
[INFO] processing batch 500000-600000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 5s - loss: 0.6031 - tp: 62543.0000 - fp: 17457.0000 - tn: 62543.0000 - fn: 17457.0000 - accuracy: 0.7818 - precision: 0.7818 - recall: 0.7818 - auc: 0.7840 - val_loss: 0.0948 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-14-batch-500000-600000
[INFO] processing batch 600000-700000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.0937 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0917 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-14-batch-600000-700000
[INFO] processing batch 700000-800000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.0898 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0877 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-14-batch-700000-800000
[INFO] processing batch 800000-900000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.0859 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0840 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-14-batch-800000-900000
[INFO] processing batch 900000-1000000/1000000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0822 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0804 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-14-batch-900000-1000000
[33m[INFO] loading file 15-16/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (939690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0788 - tp: 79998.0000 - fp: 2.0000 - tn: 79998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0770 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-16-batch-0-100000
[INFO] processing batch 100000-200000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0755 - tp: 79998.0000 - fp: 2.0000 - tn: 79998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0738 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-16-batch-100000-200000
[INFO] processing batch 200000-300000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0724 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0708 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-16-batch-200000-300000
[INFO] processing batch 300000-400000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0694 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1848 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 11586.0000 - val_fn: 8414.0000 - val_accuracy: 0.5793 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.5793
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-16-batch-300000-400000
[INFO] processing batch 400000-500000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 1.2767 - tp: 42561.0000 - fp: 37439.0000 - tn: 42561.0000 - fn: 37439.0000 - accuracy: 0.5320 - precision: 0.5320 - recall: 0.5320 - auc: 0.5326 - val_loss: 1.2375 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 10627.0000 - val_fn: 9373.0000 - val_accuracy: 0.5314 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.5314
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-16-batch-400000-500000
[INFO] processing batch 500000-600000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 1.2040 - tp: 42492.0000 - fp: 37508.0000 - tn: 42492.0000 - fn: 37508.0000 - accuracy: 0.5311 - precision: 0.5311 - recall: 0.5311 - auc: 0.5305 - val_loss: 1.1716 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 10618.0000 - val_fn: 9382.0000 - val_accuracy: 0.5309 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.5309
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-16-batch-500000-600000
[INFO] processing batch 600000-700000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7078 - tp: 58381.0000 - fp: 21619.0000 - tn: 58381.0000 - fn: 21619.0000 - accuracy: 0.7298 - precision: 0.7298 - recall: 0.7298 - auc: 0.7264 - val_loss: 0.1042 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-16-batch-600000-700000
[INFO] processing batch 700000-800000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1033 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1014 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-16-batch-700000-800000
[INFO] processing batch 800000-900000/939690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.0994 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0974 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-16-batch-800000-900000
[INFO] processing batch 900000-1000000/939690
[33m[INFO] loading file 17-18/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0955 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0936 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-18-batch-0-100000
[INFO] processing batch 100000-200000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0918 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0900 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-18-batch-100000-200000
[INFO] processing batch 200000-300000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0883 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0866 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-18-batch-200000-300000
[INFO] processing batch 300000-400000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.4284 - tp: 68607.0000 - fp: 11393.0000 - tn: 68607.0000 - fn: 11393.0000 - accuracy: 0.8576 - precision: 0.8576 - recall: 0.8576 - auc: 0.8576 - val_loss: 0.5208 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 16369.0000 - val_fn: 3631.0000 - val_accuracy: 0.8184 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.8184
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-18-batch-300000-400000
[INFO] processing batch 400000-500000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.5172 - tp: 65526.0000 - fp: 14474.0000 - tn: 65526.0000 - fn: 14474.0000 - accuracy: 0.8191 - precision: 0.8191 - recall: 0.8191 - auc: 0.8186 - val_loss: 0.2502 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 18648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9324 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9324
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-18-batch-400000-500000
[INFO] processing batch 500000-600000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.3221 - tp: 72130.0000 - fp: 7870.0000 - tn: 72130.0000 - fn: 7870.0000 - accuracy: 0.9016 - precision: 0.9016 - recall: 0.9016 - auc: 0.9016 - val_loss: 0.9806 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 12369.0000 - val_fn: 7631.0000 - val_accuracy: 0.6184 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.6184
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-18-batch-500000-600000
[INFO] processing batch 600000-700000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.9575 - tp: 49699.0000 - fp: 30301.0000 - tn: 49699.0000 - fn: 30301.0000 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - auc: 0.6218 - val_loss: 0.9448 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 12357.0000 - val_fn: 7643.0000 - val_accuracy: 0.6179 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.6179
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-18-batch-600000-700000
[INFO] processing batch 700000-800000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.9238 - tp: 49541.0000 - fp: 30459.0000 - tn: 49541.0000 - fn: 30459.0000 - accuracy: 0.6193 - precision: 0.6193 - recall: 0.6193 - auc: 0.6187 - val_loss: 0.9048 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 12397.0000 - val_fn: 7603.0000 - val_accuracy: 0.6198 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.6199
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-18-batch-700000-800000
[INFO] processing batch 800000-900000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2613 - tp: 74509.0000 - fp: 5491.0000 - tn: 74509.0000 - fn: 5491.0000 - accuracy: 0.9314 - precision: 0.9314 - recall: 0.9314 - auc: 0.9314 - val_loss: 0.1188 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-18-batch-800000-900000
[INFO] processing batch 900000-1000000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1162 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1133 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-18-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039690
[33m[INFO] loading file 19-20/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1107 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1079 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-20-batch-0-100000
[INFO] processing batch 100000-200000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1055 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-20-batch-100000-200000
[INFO] processing batch 200000-300000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1006 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0982 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-20-batch-200000-300000
[INFO] processing batch 300000-400000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.4013 - tp: 69321.0000 - fp: 10679.0000 - tn: 69321.0000 - fn: 10679.0000 - accuracy: 0.8665 - precision: 0.8665 - recall: 0.8665 - auc: 0.8665 - val_loss: 1.4680 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 7882.0000 - val_fn: 12118.0000 - val_accuracy: 0.3941 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.3941
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-20-batch-300000-400000
[INFO] processing batch 400000-500000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 1.4277 - tp: 31237.0000 - fp: 48763.0000 - tn: 31237.0000 - fn: 48763.0000 - accuracy: 0.3905 - precision: 0.3905 - recall: 0.3905 - auc: 0.3906 - val_loss: 0.1205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-20-batch-400000-500000
[INFO] processing batch 500000-600000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1207 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1712 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 19491.0000 - val_fn: 509.0000 - val_accuracy: 0.9746 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9746
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-20-batch-500000-600000
[INFO] processing batch 600000-700000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.4957 - tp: 65427.0000 - fp: 14573.0000 - tn: 65427.0000 - fn: 14573.0000 - accuracy: 0.8178 - precision: 0.8178 - recall: 0.8178 - auc: 0.8178 - val_loss: 0.4947 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 16357.0000 - val_fn: 3643.0000 - val_accuracy: 0.8178 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.8178
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-20-batch-600000-700000
[INFO] processing batch 700000-800000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.4957 - tp: 65351.0000 - fp: 14649.0000 - tn: 65351.0000 - fn: 14649.0000 - accuracy: 0.8169 - precision: 0.8169 - recall: 0.8169 - auc: 0.8172 - val_loss: 0.4913 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 16371.0000 - val_fn: 3629.0000 - val_accuracy: 0.8185 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.8185
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-20-batch-700000-800000
[INFO] processing batch 800000-900000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2242 - tp: 76024.0000 - fp: 3976.0000 - tn: 76024.0000 - fn: 3976.0000 - accuracy: 0.9503 - precision: 0.9503 - recall: 0.9503 - auc: 0.9493 - val_loss: 0.1215 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-20-batch-800000-900000
[INFO] processing batch 900000-1000000/1039690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1189 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1160 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-20-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039690
[33m[INFO] loading file 21-22/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1134 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1106 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-22-batch-0-100000
[INFO] processing batch 100000-200000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1081 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1056 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-22-batch-100000-200000
[INFO] processing batch 200000-300000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1032 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1008 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-22-batch-200000-300000
[INFO] processing batch 300000-400000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0986 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0964 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-22-batch-300000-400000
[INFO] processing batch 400000-500000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.0943 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0922 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-22-batch-400000-500000
[INFO] processing batch 500000-600000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.8137 - tp: 55006.0000 - fp: 24994.0000 - tn: 55006.0000 - fn: 24994.0000 - accuracy: 0.6876 - precision: 0.6876 - recall: 0.6876 - auc: 0.6899 - val_loss: 1.1538 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 10612.0000 - val_fn: 9388.0000 - val_accuracy: 0.5306 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.5306
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-22-batch-500000-600000
[INFO] processing batch 600000-700000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 1.1263 - tp: 42398.0000 - fp: 37602.0000 - tn: 42398.0000 - fn: 37602.0000 - accuracy: 0.5300 - precision: 0.5300 - recall: 0.5300 - auc: 0.5295 - val_loss: 1.1033 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 10527.0000 - val_fn: 9473.0000 - val_accuracy: 0.5264 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.5264
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-22-batch-600000-700000
[INFO] processing batch 700000-800000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 1.0707 - tp: 42369.0000 - fp: 37631.0000 - tn: 42369.0000 - fn: 37631.0000 - accuracy: 0.5296 - precision: 0.5296 - recall: 0.5296 - auc: 0.5295 - val_loss: 1.0423 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 10623.0000 - val_fn: 9377.0000 - val_accuracy: 0.5311 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.5311
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-22-batch-700000-800000
[INFO] processing batch 800000-900000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 1.0216 - tp: 42452.0000 - fp: 37548.0000 - tn: 42452.0000 - fn: 37548.0000 - accuracy: 0.5307 - precision: 0.5307 - recall: 0.5307 - auc: 0.5301 - val_loss: 1.0011 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 10601.0000 - val_fn: 9399.0000 - val_accuracy: 0.5300 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-22-batch-800000-900000
[INFO] processing batch 900000-1000000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.9827 - tp: 42382.0000 - fp: 37618.0000 - tn: 42382.0000 - fn: 37618.0000 - accuracy: 0.5298 - precision: 0.5298 - recall: 0.5298 - auc: 0.5296 - val_loss: 0.9625 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 10612.0000 - val_fn: 9388.0000 - val_accuracy: 0.5306 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.5306
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-22-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039687
[33m[INFO] loading file 23-24/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7481 - tp: 52270.0000 - fp: 27730.0000 - tn: 52270.0000 - fn: 27730.0000 - accuracy: 0.6534 - precision: 0.6534 - recall: 0.6534 - auc: 0.6570 - val_loss: 0.1808 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-24-batch-0-100000
[INFO] processing batch 100000-200000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1781 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1735 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-24-batch-100000-200000
[INFO] processing batch 200000-300000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1691 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1646 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-24-batch-200000-300000
[INFO] processing batch 300000-400000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1605 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1563 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-24-batch-300000-400000
[INFO] processing batch 400000-500000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1525 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1486 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-24-batch-400000-500000
[INFO] processing batch 500000-600000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1451 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1415 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-24-batch-500000-600000
[INFO] processing batch 600000-700000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1382 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1348 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-24-batch-600000-700000
[INFO] processing batch 700000-800000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1317 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1286 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-24-batch-700000-800000
[INFO] processing batch 800000-900000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.1257 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 80000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1227 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 20000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-24-batch-800000-900000
[INFO] processing batch 900000-1000000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.2313 - tp: 75698.0000 - fp: 4302.0000 - tn: 75698.0000 - fn: 4302.0000 - accuracy: 0.9462 - precision: 0.9462 - recall: 0.9462 - auc: 0.9462 - val_loss: 0.8511 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 12912.0000 - val_fn: 7088.0000 - val_accuracy: 0.6456 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.6456
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-24-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039687
[33m[INFO] loading file 25-26/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1039687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.8458 - tp: 51502.0000 - fp: 28498.0000 - tn: 51502.0000 - fn: 28498.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6433 - val_loss: 0.8371 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 12842.0000 - val_fn: 7158.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6421
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-26-batch-0-100000
[INFO] processing batch 100000-200000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.8232 - tp: 51479.0000 - fp: 28521.0000 - tn: 51479.0000 - fn: 28521.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6437 - val_loss: 0.8098 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 12894.0000 - val_fn: 7106.0000 - val_accuracy: 0.6447 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.6447
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-26-batch-100000-200000
[INFO] processing batch 200000-300000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.8023 - tp: 51470.0000 - fp: 28530.0000 - tn: 51470.0000 - fn: 28530.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6434 - val_loss: 0.7939 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 12850.0000 - val_fn: 7150.0000 - val_accuracy: 0.6425 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.6425
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-26-batch-200000-300000
[INFO] processing batch 300000-400000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7827 - tp: 51503.0000 - fp: 28497.0000 - tn: 51503.0000 - fn: 28497.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6442 - val_loss: 0.7765 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 12843.0000 - val_fn: 7157.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6422
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-26-batch-300000-400000
[INFO] processing batch 400000-500000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7665 - tp: 51468.0000 - fp: 28532.0000 - tn: 51468.0000 - fn: 28532.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6431 - val_loss: 0.7584 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 12868.0000 - val_fn: 7132.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-26-batch-400000-500000
[INFO] processing batch 500000-600000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7503 - tp: 51523.0000 - fp: 28477.0000 - tn: 51523.0000 - fn: 28477.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6441 - val_loss: 0.7442 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 12867.0000 - val_fn: 7133.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-26-batch-500000-600000
[INFO] processing batch 600000-700000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7359 - tp: 51579.0000 - fp: 28421.0000 - tn: 51579.0000 - fn: 28421.0000 - accuracy: 0.6447 - precision: 0.6447 - recall: 0.6447 - auc: 0.6443 - val_loss: 0.7318 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 12864.0000 - val_fn: 7136.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-26-batch-600000-700000
[INFO] processing batch 700000-800000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7261 - tp: 51462.0000 - fp: 28538.0000 - tn: 51462.0000 - fn: 28538.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6429 - val_loss: 0.7172 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 12911.0000 - val_fn: 7089.0000 - val_accuracy: 0.6456 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.6456
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-26-batch-700000-800000
[INFO] processing batch 800000-900000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7146 - tp: 51506.0000 - fp: 28494.0000 - tn: 51506.0000 - fn: 28494.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6438 - val_loss: 0.7056 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 12936.0000 - val_fn: 7064.0000 - val_accuracy: 0.6468 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.6468
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-26-batch-800000-900000
[INFO] processing batch 900000-1000000/1039687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.7057 - tp: 51474.0000 - fp: 28526.0000 - tn: 51474.0000 - fn: 28526.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6434 - val_loss: 0.6964 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 12945.0000 - val_fn: 7055.0000 - val_accuracy: 0.6472 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.6472
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-26-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1039687
[33m[INFO] loading file 27-28/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (979817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6982 - tp: 51419.0000 - fp: 28581.0000 - tn: 51419.0000 - fn: 28581.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6425 - val_loss: 0.6959 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 12829.0000 - val_fn: 7171.0000 - val_accuracy: 0.6414 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.6414
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-28-batch-0-100000
[INFO] processing batch 100000-200000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6899 - tp: 51485.0000 - fp: 28515.0000 - tn: 51485.0000 - fn: 28515.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6435 - val_loss: 0.6838 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 12918.0000 - val_fn: 7082.0000 - val_accuracy: 0.6459 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.6459
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-28-batch-100000-200000
[INFO] processing batch 200000-300000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6822 - tp: 51583.0000 - fp: 28417.0000 - tn: 51583.0000 - fn: 28417.0000 - accuracy: 0.6448 - precision: 0.6448 - recall: 0.6448 - auc: 0.6443 - val_loss: 0.6811 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 12863.0000 - val_fn: 7137.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6431
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-28-batch-200000-300000
[INFO] processing batch 300000-400000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6793 - tp: 51396.0000 - fp: 28604.0000 - tn: 51396.0000 - fn: 28604.0000 - accuracy: 0.6424 - precision: 0.6424 - recall: 0.6424 - auc: 0.6423 - val_loss: 0.6767 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 12851.0000 - val_fn: 7149.0000 - val_accuracy: 0.6425 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.6425
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-28-batch-300000-400000
[INFO] processing batch 400000-500000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6735 - tp: 51479.0000 - fp: 28521.0000 - tn: 51479.0000 - fn: 28521.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6437 - val_loss: 0.6713 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 12871.0000 - val_fn: 7129.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-28-batch-400000-500000
[INFO] processing batch 500000-600000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6704 - tp: 51397.0000 - fp: 28603.0000 - tn: 51397.0000 - fn: 28603.0000 - accuracy: 0.6425 - precision: 0.6425 - recall: 0.6425 - auc: 0.6423 - val_loss: 0.6680 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 12861.0000 - val_fn: 7139.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6430
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-28-batch-500000-600000
[INFO] processing batch 600000-700000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6662 - tp: 51458.0000 - fp: 28542.0000 - tn: 51458.0000 - fn: 28542.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6439 - val_loss: 0.6645 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 12868.0000 - val_fn: 7132.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-28-batch-600000-700000
[INFO] processing batch 700000-800000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6633 - tp: 51459.0000 - fp: 28541.0000 - tn: 51459.0000 - fn: 28541.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6430 - val_loss: 0.6603 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 12903.0000 - val_fn: 7097.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6451
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-28-batch-700000-800000
[INFO] processing batch 800000-900000/979817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6602 - tp: 51525.0000 - fp: 28475.0000 - tn: 51525.0000 - fn: 28475.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6446 - val_loss: 0.6603 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 12854.0000 - val_fn: 7146.0000 - val_accuracy: 0.6427 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.6427
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-28-batch-800000-900000
[INFO] processing batch 900000-1000000/979817
[33m[INFO] loading file 29-30/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6590 - tp: 51460.0000 - fp: 28540.0000 - tn: 51460.0000 - fn: 28540.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6434 - val_loss: 0.6584 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-30-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6567 - tp: 51527.0000 - fp: 28473.0000 - tn: 51527.0000 - fn: 28473.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6440 - val_loss: 0.6573 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 12849.0000 - val_fn: 7151.0000 - val_accuracy: 0.6424 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.6424
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-30-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6558 - tp: 51484.0000 - fp: 28516.0000 - tn: 51484.0000 - fn: 28516.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6443 - val_loss: 0.6529 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 12931.0000 - val_fn: 7069.0000 - val_accuracy: 0.6465 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.6465
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-30-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6541 - tp: 51556.0000 - fp: 28444.0000 - tn: 51556.0000 - fn: 28444.0000 - accuracy: 0.6445 - precision: 0.6445 - recall: 0.6445 - auc: 0.6441 - val_loss: 0.6548 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-30-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6539 - tp: 51488.0000 - fp: 28512.0000 - tn: 51488.0000 - fn: 28512.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6437 - val_loss: 0.6534 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 12875.0000 - val_fn: 7125.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-30-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51529.0000 - fp: 28471.0000 - tn: 51529.0000 - fn: 28471.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6441 - val_loss: 0.6534 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 12860.0000 - val_fn: 7140.0000 - val_accuracy: 0.6430 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.6430
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-30-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51450.0000 - fp: 28550.0000 - tn: 51450.0000 - fn: 28550.0000 - accuracy: 0.6431 - precision: 0.6431 - recall: 0.6431 - auc: 0.6429 - val_loss: 0.6531 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 12855.0000 - val_fn: 7145.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-30-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51488.0000 - fp: 28512.0000 - tn: 51488.0000 - fn: 28512.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6527 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 12856.0000 - val_fn: 7144.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-30-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51529.0000 - fp: 28471.0000 - tn: 51529.0000 - fn: 28471.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6442 - val_loss: 0.6518 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 12877.0000 - val_fn: 7123.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-30-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51550.0000 - fp: 28450.0000 - tn: 51550.0000 - fn: 28450.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6444 - val_loss: 0.6518 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 12870.0000 - val_fn: 7130.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-30-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 31-32/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51494.0000 - fp: 28506.0000 - tn: 51494.0000 - fn: 28506.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6501 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 12921.0000 - val_fn: 7079.0000 - val_accuracy: 0.6460 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.6460
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-32-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51524.0000 - fp: 28476.0000 - tn: 51524.0000 - fn: 28476.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6441 - val_loss: 0.6506 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 12902.0000 - val_fn: 7098.0000 - val_accuracy: 0.6451 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.6451
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-32-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51428.0000 - fp: 28572.0000 - tn: 51428.0000 - fn: 28572.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6430 - val_loss: 0.6514 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 12874.0000 - val_fn: 7126.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-32-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6515 - tp: 51479.0000 - fp: 28521.0000 - tn: 51479.0000 - fn: 28521.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6510 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 12886.0000 - val_fn: 7114.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-32-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 51508.0000 - fn: 28492.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6507 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 12893.0000 - val_fn: 7107.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-32-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51484.0000 - fp: 28516.0000 - tn: 51484.0000 - fn: 28516.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6430 - val_loss: 0.6508 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 12889.0000 - val_fn: 7111.0000 - val_accuracy: 0.6445 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.6445
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-32-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51531.0000 - fp: 28469.0000 - tn: 51531.0000 - fn: 28469.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6441 - val_loss: 0.6513 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 12875.0000 - val_fn: 7125.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-32-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51576.0000 - fp: 28424.0000 - tn: 51576.0000 - fn: 28424.0000 - accuracy: 0.6447 - precision: 0.6447 - recall: 0.6447 - auc: 0.6447 - val_loss: 0.6508 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 12890.0000 - val_fn: 7110.0000 - val_accuracy: 0.6445 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.6445
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-32-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51489.0000 - fp: 28511.0000 - tn: 51489.0000 - fn: 28511.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 12864.0000 - val_fn: 7136.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-32-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51449.0000 - fp: 28551.0000 - tn: 51449.0000 - fn: 28551.0000 - accuracy: 0.6431 - precision: 0.6431 - recall: 0.6431 - auc: 0.6431 - val_loss: 0.6515 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 12867.0000 - val_fn: 7133.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-32-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 33-34/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 51508.0000 - fn: 28492.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 12875.0000 - val_fn: 7125.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-34-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51518.0000 - fp: 28482.0000 - tn: 51518.0000 - fn: 28482.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6440 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 12864.0000 - val_fn: 7136.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-34-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51404.0000 - fp: 28596.0000 - tn: 51404.0000 - fn: 28596.0000 - accuracy: 0.6425 - precision: 0.6425 - recall: 0.6425 - auc: 0.6425 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 12862.0000 - val_fn: 7138.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6431
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-34-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51552.0000 - fp: 28448.0000 - tn: 51552.0000 - fn: 28448.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6444 - val_loss: 0.6509 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 12886.0000 - val_fn: 7114.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-34-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51594.0000 - fp: 28406.0000 - tn: 51594.0000 - fn: 28406.0000 - accuracy: 0.6449 - precision: 0.6449 - recall: 0.6449 - auc: 0.6449 - val_loss: 0.6496 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 12929.0000 - val_fn: 7071.0000 - val_accuracy: 0.6464 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.6465
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-34-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51505.0000 - fp: 28495.0000 - tn: 51505.0000 - fn: 28495.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6438 - val_loss: 0.6522 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 12842.0000 - val_fn: 7158.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6421
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-34-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51470.0000 - fp: 28530.0000 - tn: 51470.0000 - fn: 28530.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6434 - val_loss: 0.6515 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 12865.0000 - val_fn: 7135.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-34-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51588.0000 - fp: 28412.0000 - tn: 51588.0000 - fn: 28412.0000 - accuracy: 0.6449 - precision: 0.6449 - recall: 0.6449 - auc: 0.6449 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 12876.0000 - val_fn: 7124.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-34-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51408.0000 - fp: 28592.0000 - tn: 51408.0000 - fn: 28592.0000 - accuracy: 0.6426 - precision: 0.6426 - recall: 0.6426 - auc: 0.6426 - val_loss: 0.6524 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 12834.0000 - val_fn: 7166.0000 - val_accuracy: 0.6417 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.6417
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-34-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51422.0000 - fp: 28578.0000 - tn: 51422.0000 - fn: 28578.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6428 - val_loss: 0.6512 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 12877.0000 - val_fn: 7123.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-34-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 35-36/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51520.0000 - fp: 28480.0000 - tn: 51520.0000 - fn: 28480.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6440 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-36-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51486.0000 - fp: 28514.0000 - tn: 51486.0000 - fn: 28514.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 12876.0000 - val_fn: 7124.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-36-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51498.0000 - fp: 28502.0000 - tn: 51498.0000 - fn: 28502.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 12892.0000 - val_fn: 7108.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-36-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51521.0000 - fp: 28479.0000 - tn: 51521.0000 - fn: 28479.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6440 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 12855.0000 - val_fn: 7145.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-36-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51570.0000 - fp: 28430.0000 - tn: 51570.0000 - fn: 28430.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6513 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 12872.0000 - val_fn: 7128.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-36-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51498.0000 - fp: 28502.0000 - tn: 51498.0000 - fn: 28502.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6513 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 12874.0000 - val_fn: 7126.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-36-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6502 - tp: 51644.0000 - fp: 28356.0000 - tn: 51644.0000 - fn: 28356.0000 - accuracy: 0.6456 - precision: 0.6456 - recall: 0.6456 - auc: 0.6456 - val_loss: 0.6506 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 12895.0000 - val_fn: 7105.0000 - val_accuracy: 0.6447 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.6447
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-36-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51397.0000 - fp: 28603.0000 - tn: 51397.0000 - fn: 28603.0000 - accuracy: 0.6425 - precision: 0.6425 - recall: 0.6425 - auc: 0.6425 - val_loss: 0.6495 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 12933.0000 - val_fn: 7067.0000 - val_accuracy: 0.6467 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.6467
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-36-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6519 - tp: 51415.0000 - fp: 28585.0000 - tn: 51415.0000 - fn: 28585.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6427 - val_loss: 0.6511 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 12878.0000 - val_fn: 7122.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-36-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51498.0000 - fp: 28502.0000 - tn: 51498.0000 - fn: 28502.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6518 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 12856.0000 - val_fn: 7144.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-36-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 37-38/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51413.0000 - fp: 28587.0000 - tn: 51413.0000 - fn: 28587.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6423 - val_loss: 0.6518 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 12854.0000 - val_fn: 7146.0000 - val_accuracy: 0.6427 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.6427
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-38-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6516 - tp: 51456.0000 - fp: 28544.0000 - tn: 51456.0000 - fn: 28544.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6428 - val_loss: 0.6504 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 12903.0000 - val_fn: 7097.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6451
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-38-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51565.0000 - fp: 28435.0000 - tn: 51565.0000 - fn: 28435.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6445 - val_loss: 0.6513 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 12871.0000 - val_fn: 7129.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-38-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51512.0000 - fp: 28488.0000 - tn: 51512.0000 - fn: 28488.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6508 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 12888.0000 - val_fn: 7112.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-38-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51528.0000 - fp: 28472.0000 - tn: 51528.0000 - fn: 28472.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6441 - val_loss: 0.6505 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 12899.0000 - val_fn: 7101.0000 - val_accuracy: 0.6449 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.6449
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-38-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6511 - tp: 51513.0000 - fp: 28487.0000 - tn: 51513.0000 - fn: 28487.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6496 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 12931.0000 - val_fn: 7069.0000 - val_accuracy: 0.6465 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.6465
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-38-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51589.0000 - fp: 28411.0000 - tn: 51589.0000 - fn: 28411.0000 - accuracy: 0.6449 - precision: 0.6449 - recall: 0.6449 - auc: 0.6449 - val_loss: 0.6522 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 12842.0000 - val_fn: 7158.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6421
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-38-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6514 - tp: 51481.0000 - fp: 28519.0000 - tn: 51481.0000 - fn: 28519.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-38-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51549.0000 - fp: 28451.0000 - tn: 51549.0000 - fn: 28451.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6444 - val_loss: 0.6505 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 12898.0000 - val_fn: 7102.0000 - val_accuracy: 0.6449 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.6449
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-38-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 51550.0000 - fn: 28450.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6444 - val_loss: 0.6515 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 12866.0000 - val_fn: 7134.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-38-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 39-40/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1079817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51486.0000 - fp: 28514.0000 - tn: 51486.0000 - fn: 28514.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6521 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 12847.0000 - val_fn: 7153.0000 - val_accuracy: 0.6424 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-40-batch-0-100000
[INFO] processing batch 100000-200000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51597.0000 - fp: 28403.0000 - tn: 51597.0000 - fn: 28403.0000 - accuracy: 0.6450 - precision: 0.6450 - recall: 0.6450 - auc: 0.6450 - val_loss: 0.6502 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 12910.0000 - val_fn: 7090.0000 - val_accuracy: 0.6455 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.6455
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-40-batch-100000-200000
[INFO] processing batch 200000-300000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6503 - tp: 51631.0000 - fp: 28369.0000 - tn: 51631.0000 - fn: 28369.0000 - accuracy: 0.6454 - precision: 0.6454 - recall: 0.6454 - auc: 0.6454 - val_loss: 0.6507 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 12894.0000 - val_fn: 7106.0000 - val_accuracy: 0.6447 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.6447
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-40-batch-200000-300000
[INFO] processing batch 300000-400000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 51493.0000 - fn: 28507.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 12869.0000 - val_fn: 7131.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-40-batch-300000-400000
[INFO] processing batch 400000-500000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6513 - tp: 51488.0000 - fp: 28512.0000 - tn: 51488.0000 - fn: 28512.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 12875.0000 - val_fn: 7125.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-40-batch-400000-500000
[INFO] processing batch 500000-600000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51418.0000 - fp: 28582.0000 - tn: 51418.0000 - fn: 28582.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6420 - val_loss: 0.6522 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 12843.0000 - val_fn: 7157.0000 - val_accuracy: 0.6421 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.6422
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-40-batch-500000-600000
[INFO] processing batch 600000-700000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51491.0000 - fp: 28509.0000 - tn: 51491.0000 - fn: 28509.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6434 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 12862.0000 - val_fn: 7138.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6431
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-40-batch-600000-700000
[INFO] processing batch 700000-800000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6508 - tp: 51556.0000 - fp: 28444.0000 - tn: 51556.0000 - fn: 28444.0000 - accuracy: 0.6445 - precision: 0.6445 - recall: 0.6445 - auc: 0.6445 - val_loss: 0.6500 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 12916.0000 - val_fn: 7084.0000 - val_accuracy: 0.6458 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.6458
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-40-batch-700000-800000
[INFO] processing batch 800000-900000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 4s - loss: 0.6512 - tp: 51505.0000 - fp: 28495.0000 - tn: 51505.0000 - fn: 28495.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6438 - val_loss: 0.6523 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 12838.0000 - val_fn: 7162.0000 - val_accuracy: 0.6419 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.6419
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-40-batch-800000-900000
[INFO] processing batch 900000-1000000/1079817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51432.0000 - fp: 28568.0000 - tn: 51432.0000 - fn: 28568.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6429 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 12850.0000 - val_fn: 7150.0000 - val_accuracy: 0.6425 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.6425
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-40-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1079817
[33m[INFO] loading file 41-42/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 51427.0000 - fn: 28573.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6428 - val_loss: 0.6516 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 12861.0000 - val_fn: 7139.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6430
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-42-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51515.0000 - fp: 28485.0000 - tn: 51515.0000 - fn: 28485.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6436 - val_loss: 0.6514 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 12868.0000 - val_fn: 7132.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-42-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 51452.0000 - fn: 28548.0000 - accuracy: 0.6431 - precision: 0.6431 - recall: 0.6431 - auc: 0.6429 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 12876.0000 - val_fn: 7124.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-42-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51587.0000 - fp: 28413.0000 - tn: 51587.0000 - fn: 28413.0000 - accuracy: 0.6448 - precision: 0.6448 - recall: 0.6448 - auc: 0.6449 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 12860.0000 - val_fn: 7140.0000 - val_accuracy: 0.6430 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.6430
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-42-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51566.0000 - fp: 28434.0000 - tn: 51566.0000 - fn: 28434.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6494 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 12937.0000 - val_fn: 7063.0000 - val_accuracy: 0.6468 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.6468
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-42-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51459.0000 - fp: 28541.0000 - tn: 51459.0000 - fn: 28541.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6432 - val_loss: 0.6527 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 12826.0000 - val_fn: 7174.0000 - val_accuracy: 0.6413 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.6413
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-42-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51511.0000 - fp: 28489.0000 - tn: 51511.0000 - fn: 28489.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6510 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 12882.0000 - val_fn: 7118.0000 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.6441
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-42-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51499.0000 - fp: 28501.0000 - tn: 51499.0000 - fn: 28501.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6519 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 12853.0000 - val_fn: 7147.0000 - val_accuracy: 0.6427 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.6427
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-42-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51494.0000 - fp: 28506.0000 - tn: 51494.0000 - fn: 28506.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6433 - val_loss: 0.6500 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 12917.0000 - val_fn: 7083.0000 - val_accuracy: 0.6459 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.6459
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-42-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51584.0000 - fp: 28416.0000 - tn: 51584.0000 - fn: 28416.0000 - accuracy: 0.6448 - precision: 0.6448 - recall: 0.6448 - auc: 0.6448 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 12875.0000 - val_fn: 7125.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-42-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 43-44/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 51591.0000 - fn: 28409.0000 - accuracy: 0.6449 - precision: 0.6449 - recall: 0.6449 - auc: 0.6449 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 12873.0000 - val_fn: 7127.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-44-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51529.0000 - fp: 28471.0000 - tn: 51529.0000 - fn: 28471.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6441 - val_loss: 0.6527 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 12824.0000 - val_fn: 7176.0000 - val_accuracy: 0.6412 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.6412
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-44-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51387.0000 - fp: 28613.0000 - tn: 51387.0000 - fn: 28613.0000 - accuracy: 0.6423 - precision: 0.6423 - recall: 0.6423 - auc: 0.6421 - val_loss: 0.6506 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 12896.0000 - val_fn: 7104.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-44-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51518.0000 - fp: 28482.0000 - tn: 51518.0000 - fn: 28482.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6437 - val_loss: 0.6521 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 12844.0000 - val_fn: 7156.0000 - val_accuracy: 0.6422 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.6422
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-44-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 51591.0000 - fn: 28409.0000 - accuracy: 0.6449 - precision: 0.6449 - recall: 0.6449 - auc: 0.6446 - val_loss: 0.6489 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 12952.0000 - val_fn: 7048.0000 - val_accuracy: 0.6476 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.6476
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-44-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 51452.0000 - fn: 28548.0000 - accuracy: 0.6431 - precision: 0.6431 - recall: 0.6431 - auc: 0.6427 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 12855.0000 - val_fn: 7145.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-44-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 51497.0000 - fn: 28503.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6432 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-44-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51543.0000 - fp: 28457.0000 - tn: 51543.0000 - fn: 28457.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6443 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-44-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 51427.0000 - fn: 28573.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6423 - val_loss: 0.6508 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 12891.0000 - val_fn: 7109.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-44-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51537.0000 - fp: 28463.0000 - tn: 51537.0000 - fn: 28463.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 12863.0000 - val_fn: 7137.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6431
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-44-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 45-46/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6503 - tp: 51620.0000 - fp: 28380.0000 - tn: 51620.0000 - fn: 28380.0000 - accuracy: 0.6453 - precision: 0.6453 - recall: 0.6453 - auc: 0.6453 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 12869.0000 - val_fn: 7131.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-46-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51538.0000 - fp: 28462.0000 - tn: 51538.0000 - fn: 28462.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6509 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 12885.0000 - val_fn: 7115.0000 - val_accuracy: 0.6442 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.6442
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-46-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51564.0000 - fp: 28436.0000 - tn: 51564.0000 - fn: 28436.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6443 - val_loss: 0.6504 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 12904.0000 - val_fn: 7096.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-46-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51590.0000 - fp: 28410.0000 - tn: 51590.0000 - fn: 28410.0000 - accuracy: 0.6449 - precision: 0.6449 - recall: 0.6449 - auc: 0.6449 - val_loss: 0.6522 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 12844.0000 - val_fn: 7156.0000 - val_accuracy: 0.6422 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.6422
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-46-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51395.0000 - fp: 28605.0000 - tn: 51395.0000 - fn: 28605.0000 - accuracy: 0.6424 - precision: 0.6424 - recall: 0.6424 - auc: 0.6415 - val_loss: 0.6506 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 12896.0000 - val_fn: 7104.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-46-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51525.0000 - fp: 28475.0000 - tn: 51525.0000 - fn: 28475.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6444 - val_loss: 0.6501 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 12913.0000 - val_fn: 7087.0000 - val_accuracy: 0.6457 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.6457
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-46-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51464.0000 - fp: 28536.0000 - tn: 51464.0000 - fn: 28536.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6430 - val_loss: 0.6510 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 12883.0000 - val_fn: 7117.0000 - val_accuracy: 0.6442 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.6442
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-46-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51532.0000 - fp: 28468.0000 - tn: 51532.0000 - fn: 28468.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6437 - val_loss: 0.6509 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 12885.0000 - val_fn: 7115.0000 - val_accuracy: 0.6442 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.6442
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-46-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51502.0000 - fp: 28498.0000 - tn: 51502.0000 - fn: 28498.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6438 - val_loss: 0.6496 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 12929.0000 - val_fn: 7071.0000 - val_accuracy: 0.6464 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.6465
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-46-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51569.0000 - fp: 28431.0000 - tn: 51569.0000 - fn: 28431.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6444 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 12873.0000 - val_fn: 7127.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-46-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 47-48/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51601.0000 - fp: 28399.0000 - tn: 51601.0000 - fn: 28399.0000 - accuracy: 0.6450 - precision: 0.6450 - recall: 0.6450 - auc: 0.6448 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 12892.0000 - val_fn: 7108.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-48-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51559.0000 - fp: 28441.0000 - tn: 51559.0000 - fn: 28441.0000 - accuracy: 0.6445 - precision: 0.6445 - recall: 0.6445 - auc: 0.6445 - val_loss: 0.6514 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 12871.0000 - val_fn: 7129.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-48-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 51468.0000 - fn: 28532.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6434 - val_loss: 0.6528 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 12822.0000 - val_fn: 7178.0000 - val_accuracy: 0.6411 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.6411
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-48-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 51493.0000 - fn: 28507.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6431 - val_loss: 0.6511 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 12881.0000 - val_fn: 7119.0000 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.6441
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-48-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51492.0000 - fp: 28508.0000 - tn: 51492.0000 - fn: 28508.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6431 - val_loss: 0.6502 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 12909.0000 - val_fn: 7091.0000 - val_accuracy: 0.6454 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.6454
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-48-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51525.0000 - fp: 28475.0000 - tn: 51525.0000 - fn: 28475.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6441 - val_loss: 0.6526 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 12830.0000 - val_fn: 7170.0000 - val_accuracy: 0.6415 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.6415
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-48-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 51497.0000 - fn: 28503.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6435 - val_loss: 0.6511 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 12879.0000 - val_fn: 7121.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-48-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51547.0000 - fp: 28453.0000 - tn: 51547.0000 - fn: 28453.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6443 - val_loss: 0.6502 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 12911.0000 - val_fn: 7089.0000 - val_accuracy: 0.6456 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.6456
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-48-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51566.0000 - fp: 28434.0000 - tn: 51566.0000 - fn: 28434.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 12863.0000 - val_fn: 7137.0000 - val_accuracy: 0.6431 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.6431
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-48-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6504 - tp: 51606.0000 - fp: 28394.0000 - tn: 51606.0000 - fn: 28394.0000 - accuracy: 0.6451 - precision: 0.6451 - recall: 0.6451 - auc: 0.6451 - val_loss: 0.6503 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 12905.0000 - val_fn: 7095.0000 - val_accuracy: 0.6453 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.6453
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-48-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[INFO] loading file 49-50/50 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (1019975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[INFO] processing batch 0-100000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51532.0000 - fp: 28468.0000 - tn: 51532.0000 - fn: 28468.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6515 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 12865.0000 - val_fn: 7135.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-50-batch-0-100000
[INFO] processing batch 100000-200000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51430.0000 - fp: 28570.0000 - tn: 51430.0000 - fn: 28570.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6431 - val_loss: 0.6498 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 12924.0000 - val_fn: 7076.0000 - val_accuracy: 0.6462 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.6462
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-50-batch-100000-200000
[INFO] processing batch 200000-300000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51469.0000 - fp: 28531.0000 - tn: 51469.0000 - fn: 28531.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6433 - val_loss: 0.6526 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 12829.0000 - val_fn: 7171.0000 - val_accuracy: 0.6414 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.6414
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-50-batch-200000-300000
[INFO] processing batch 300000-400000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51492.0000 - fp: 28508.0000 - tn: 51492.0000 - fn: 28508.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6433 - val_loss: 0.6498 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 12922.0000 - val_fn: 7078.0000 - val_accuracy: 0.6461 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.6461
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-50-batch-300000-400000
[INFO] processing batch 400000-500000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51495.0000 - fp: 28505.0000 - tn: 51495.0000 - fn: 28505.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6430 - val_loss: 0.6508 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 12890.0000 - val_fn: 7110.0000 - val_accuracy: 0.6445 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.6445
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-50-batch-400000-500000
[INFO] processing batch 500000-600000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51422.0000 - fp: 28578.0000 - tn: 51422.0000 - fn: 28578.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6427 - val_loss: 0.6528 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 12823.0000 - val_fn: 7177.0000 - val_accuracy: 0.6411 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.6411
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-50-batch-500000-600000
[INFO] processing batch 600000-700000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51482.0000 - fp: 28518.0000 - tn: 51482.0000 - fn: 28518.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6434 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 12892.0000 - val_fn: 7108.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-50-batch-600000-700000
[INFO] processing batch 700000-800000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51433.0000 - fp: 28567.0000 - tn: 51433.0000 - fn: 28567.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6426 - val_loss: 0.6520 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 12849.0000 - val_fn: 7151.0000 - val_accuracy: 0.6424 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.6424
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-50-batch-700000-800000
[INFO] processing batch 800000-900000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51461.0000 - fp: 28539.0000 - tn: 51461.0000 - fn: 28539.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6433 - val_loss: 0.6508 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 12889.0000 - val_fn: 7111.0000 - val_accuracy: 0.6445 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.6445
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-50-batch-800000-900000
[INFO] processing batch 900000-1000000/1019975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 2500 samples, validate on 625 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51467.0000 - fp: 28533.0000 - tn: 51467.0000 - fn: 28533.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6428 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 12857.0000 - val_fn: 7143.0000 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.6428
train.py:189: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version
of pandas will change to not sort by default.

To accept the future behavior, pass 'sort=False'.

To retain the current behavior and silence the warning, pass 'sort=True'.

  df = pd.concat(df_from_each_file, ignore_index=True)
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-50-batch-900000-1000000
[INFO] processing batch 1000000-1100000/1019975
[33m[LOSS] 0.6517613738059997[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6517613738059997  <  0.001
--- 2757.629835128784 seconds ---
2020-02-08 07:17:54.953067: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-08 07:17:54.965759: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f87c7403110 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-08 07:17:54.965791: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow backend.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
2020-02-08 07:17:58.362582: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-08 07:17:58.368287: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 07:17:58.371018: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 07:17:58.394032: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-08 07:17:58.395794: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-08 07:17:58.397706: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 07:17:58.399622: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-08 07:17:58.408858: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
=================================================
        SCORING v0.4.2 (binaryClasses)
=================================================
Date: 2020-02-08 07:17:54.948897
[INFO] input_shape (32, 16)
[INFO] LSTM first and last layer neurons: 2
[INFO] adding core layer 0
wrapLayerSize 2
coreLayerSize 4
numCoreLayers 1
outputLayerActivation sigmoid
output_dim 2
loss binary_crossentropy
optimizer adam
[INFO] created DNN
loading weights: checkpoints/*
loading file checkpoints/lstm-epoch-003-files-8-10-batch-900000-1000000
[33m[INFO] model summary:[0m
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 32, 2)             152       
_________________________________________________________________
dropout_1 (Dropout)          (None, 32, 2)             0         
_________________________________________________________________
lstm_2 (LSTM)                (None, 32, 4)             112       
_________________________________________________________________
dropout_2 (Dropout)          (None, 32, 4)             0         
_________________________________________________________________
lstm_3 (LSTM)                (None, 32, 2)             56        
_________________________________________________________________
dropout_3 (Dropout)          (None, 32, 2)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 32, 1)             3         
_________________________________________________________________
dropout_4 (Dropout)          (None, 32, 1)             0         
_________________________________________________________________
dense_2 (Dense)              (None, 32, 2)             4         
=================================================================
Total params: 327
Trainable params: 327
Non-trainable params: 0
_________________________________________________________________
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2015-12-31_130240_112.log.part10_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1364 (0.2728%)
[INFO] ** orig:[0.0:99.9992%,-1.0:0.0008%]
[INFO] ** type:[1.0:99.9984%,0.0:0.0014%,-1.0:0.0002%]
[INFO] ** i/f_name:[-1.0:99.9984%,0.0:0.0016%]
[INFO] ** i/f_dir:[-0.7071067812:99.9986%,0.7071067812:0.0014%]
[INFO] ** src:[-1.3652730819:38.114%,1.3652730819:26.0964%,0.5251050315:18.2424%,-0.5251050315:17.543%,-1.1552310693:0.0016%,-1.5753150944999998:0.0012%,-0.9451890567:0.001%,0.10502100630000001:0.0004%]
[INFO] ** dst:[-1.0302443927:43.3686%,1.4048787174000001:20.8412%,1.2175615551:18.2422%,0.0936585812:17.5434%,-0.6556100681:0.0016%,-1.5921958797:0.0014%,-0.4682929058:0.0006%,0.28097574350000004:0.0004%,-0.0936585812:0.0002%,-0.8429272304000001:0.0002%,-1.4048787174000001:0.0002%]
[INFO] ** proto:[0.0:99.997%,-1.0:0.0016%,1.0:0.0014%]
[INFO] ** appi_name:[-1.6378460497:99.9962%,-1.5118578919999999:0.0016%,1.3858697344:0.0004%,-1.3858697344:0.0004%,0.37796447299999997:0.0002%,-0.5039526307:0.0002%,-0.25197631530000003:0.0002%,-0.6299407883:0.0002%,0.25197631530000003:0.0002%,1.5118578919999999:0.0002%,-0.37796447299999997:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.114%,-1.5753150944999998:26.0964%,1.3652730819:18.2424%,-0.3150630189:17.543%,0.10502100630000001:0.0016%,-1.1552310693:0.0012%,-1.3652730819:0.001%,0.3150630189:0.0004%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9962%,-176.7993450566:0.0036%,4.6584169229:0.0002%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.9988%,-1.3363062096:49.9974%,-0.2672612419:0.0036%,0.2672612419:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:26.0954%,0.2672612419:20.841%,0.8017837256999999:18.242%,-1.3363062096:17.5424%,-0.2672612419:17.2726%,-0.8017837256999999:0.0066%]
[INFO] ** service:[0.0054950911:99.997%,-185.27759935790002:0.0016%,-184.7070904767:0.0004%,-163.1476425417:0.0004%,-163.13937429709998:0.0002%,-184.7112245991:0.0002%,-177.4227669367:0.0002%]
[INFO] ** s_port:[1.4631574735:26.0956%,-0.2976951931:20.8412%,-1.2442195994:18.242%,-0.2104457366:17.5424%,-0.3109148077:17.2728%,-70.70536262659999:0.0016%,-9.4443465444:0.0008%,-0.2183775054:0.0006%,-70.522931945:0.0004%,-0.9904029989:0.0004%,-63.6289029238:0.0004%,1.4658013963999998:0.0004%,-1.2389317536:0.0002%,-68.19363585:0.0002%,-3.1729613716000005:0.0002%,-70.5242539064:0.0002%,-1.2415756765000001:0.0002%,1.4843088569:0.0002%,1.4737331652:0.0002%]
[INFO] ** classification:[normal:79.7796%,Single Stage Single Point:20.2204%]
[INFO] columns with count within 2-10 {'orig': 2, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'src': 8, 'proto': 3, 'proxy_src_ip': 8, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 7, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 1 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.9156020136833191
tp :  64261.0
fp :  35739.0
tn :  64261.0
fn :  35739.0
accuracy :  0.6426100134849548
precision :  0.6426100134849548
recall :  0.6426100134849548
auc :  0.6426100730895996

y_eval {0: 64261, 1: 35739}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64261     0]
 [35739     0]]
[INFO] confusion matrix after adding it to total:
[[64261     0]
 [35739     0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 1 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.9162898084259034
tp :  64231.0
fp :  35769.0
tn :  64231.0
fn :  35769.0
accuracy :  0.6423100233078003
precision :  0.6423100233078003
recall :  0.6423100233078003
auc :  0.6423100233078003

y_eval {0: 64231, 1: 35769}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64231     0]
 [35769     0]]
[INFO] confusion matrix after adding it to total:
[[128492      0]
 [ 71508      0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.7747153851842881
tp :  70406.0
fp :  29594.0
tn :  70406.0
fn :  29594.0
accuracy :  0.7040600180625916
precision :  0.7040600180625916
recall :  0.7040600180625916
auc :  0.7040599584579468

y_eval {0: 70406, 1: 29594}
pred {0: 100000}
[INFO] confusion matrix for file 
[[70406     0]
 [29594     0]]
[INFO] confusion matrix after adding it to total:
[[198898      0]
 [101102      0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[298898      0]
 [101102      0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[398898      0]
 [101102      0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2015-12-31_181648_113.log.part08_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1370 (0.274%)
[INFO] ** orig:[0.0:99.9948%,1.0:0.0052%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[-1.0:99.9948%,0.0:0.0052%]
[INFO] ** i/f_dir:[-0.7071067812:99.9948%,0.7071067812:0.0052%]
[INFO] ** src:[-1.3652730819:38.4402%,1.3652730819:25.9738%,0.5251050315:18.1202%,-0.5251050315:17.4598%,0.9451890567:0.0052%,-0.7351470441:0.0004%,0.10502100630000001:0.0002%,-1.5753150944999998:0.0002%]
[INFO] ** dst:[-1.0302443927:43.345%,1.4048787174000001:21.0682%,1.2175615551:18.1202%,0.0936585812:17.4594%,-0.6556100681:0.0052%,-1.5921958797:0.0012%,0.8429272304000001:0.0004%,-0.8429272304000001:0.0002%,1.5921958797:0.0002%]
[INFO] ** proto:[0.0:99.9946%,-1.0:0.0052%,1.0:0.0002%]
[INFO] ** appi_name:[-1.6378460497:99.9942%,-1.5118578919999999:0.0052%,-0.1259881577:0.0002%,-0.25197631530000003:0.0002%,-1.133893419:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.4402%,-1.5753150944999998:25.9738%,1.3652730819:18.1202%,-0.3150630189:17.4598%,0.10502100630000001:0.0052%,0.9451890567:0.0004%,-1.1552310693:0.0002%,0.3150630189:0.0002%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9942%,-176.7993450566:0.0058%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.998%,-1.3363062096:49.9962%,-0.2672612419:0.0058%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:25.9726%,0.2672612419:21.0682%,0.8017837256999999:18.1198%,-1.3363062096:17.459%,-0.2672612419:17.3718%,-0.8017837256999999:0.0086%]
[INFO] ** service:[0.0054950911:99.9942%,-185.27759935790002:0.0052%,-184.7029563544:0.0004%,-184.7112245991:0.0002%]
[INFO] ** s_port:[1.4631574735:25.973%,-0.2976951931:21.0682%,-1.2442195994:18.12%,-0.2104457366:17.4592%,-0.3109148077:17.372%,-70.70536262659999:0.0052%,-0.2183775054:0.0006%,8.3333911883:0.0004%,1.4658013963999998:0.0004%,-0.9904029989:0.0002%,-1.2415756765000001:0.0002%,-70.5242539064:0.0002%,1.4843088569:0.0002%,1.4737331652:0.0002%]
[INFO] ** classification:[normal:80.1196%,Multi Stage Multi Point:14.47%,Single Stage Multi Point:5.4104%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 8, 'dst': 9, 'proto': 3, 'appi_name': 5, 'proxy_src_ip': 8, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 4, 'classification': 3}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.7164343028020859
tp :  72948.0
fp :  27052.0
tn :  72948.0
fn :  27052.0
accuracy :  0.7294800281524658
precision :  0.7294800281524658
recall :  0.7294800281524658
auc :  0.7294800281524658

y_eval {0: 72948, 1: 27052}
pred {0: 100000}
[INFO] confusion matrix for file 
[[72948     0]
 [27052     0]]
[INFO] confusion matrix after adding it to total:
[[471846      0]
 [128154      0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[571846      0]
 [128154      0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[671846      0]
 [128154      0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.6746614507293701
tp :  74770.0
fp :  25230.0
tn :  74770.0
fn :  25230.0
accuracy :  0.7476999759674072
precision :  0.7476999759674072
recall :  0.7476999759674072
auc :  0.7476999163627625

y_eval {0: 74770, 1: 25230}
pred {0: 100000}
[INFO] confusion matrix for file 
[[74770     0]
 [25230     0]]
[INFO] confusion matrix after adding it to total:
[[746616      0]
 [153384      0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.176533950958252
tp :  52880.0
fp :  47120.0
tn :  52880.0
fn :  47120.0
accuracy :  0.5288000106811523
precision :  0.5288000106811523
recall :  0.5288000106811523
auc :  0.5288000106811523

y_eval {0: 52880, 1: 47120}
pred {0: 100000}
[INFO] confusion matrix for file 
[[52880     0]
 [47120     0]]
[INFO] confusion matrix after adding it to total:
[[799496      0]
 [200504      0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2015-12-31_181648_113.log.part09_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1359 (0.2718%)
[INFO] ** orig:[0.0:99.9966%,1.0:0.0034%]
[INFO] ** type:[1.0:99.9996%,0.0:0.0004%]
[INFO] ** i/f_name:[-1.0:99.9938%,0.0:0.0062%]
[INFO] ** i/f_dir:[-0.7071067812:99.9942%,0.7071067812:0.0058%]
[INFO] ** src:[-1.3652730819:38.4204%,1.3652730819:25.9634%,0.5251050315:18.123%,-0.5251050315:17.486%,0.9451890567:0.0034%,-1.1552310693:0.0028%,0.10502100630000001:0.0006%,-0.7351470441:0.0004%]
[INFO] ** dst:[-1.0302443927:43.3316%,1.4048787174000001:21.0518%,1.2175615551:18.123%,0.0936585812:17.486%,-0.6556100681:0.0062%,-1.5921958797:0.0008%,-0.0936585812:0.0002%,-0.8429272304000001:0.0002%,-1.4048787174000001:0.0002%]
[INFO] ** proto:[0.0:99.9934%,-1.0:0.0062%,1.0:0.0004%]
[INFO] ** appi_name:[-1.6378460497:99.9934%,-1.5118578919999999:0.0062%,-0.6299407883:0.0002%,1.5118578919999999:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.4204%,-1.5753150944999998:25.9634%,1.3652730819:18.123%,-0.3150630189:17.486%,0.10502100630000001:0.0062%,0.3150630189:0.0006%,0.9451890567:0.0004%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9934%,-176.7993450566:0.0066%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.9972%,-1.3363062096:49.9962%,-0.2672612419:0.0066%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:25.9624%,0.2672612419:21.0518%,0.8017837256999999:18.1226%,-1.3363062096:17.4856%,-0.2672612419:17.3686%,-0.8017837256999999:0.009%]
[INFO] ** service:[0.0054950911:99.9934%,-185.27759935790002:0.0062%,-163.13937429709998:0.0002%,-177.4227669367:0.0002%]
[INFO] ** s_port:[1.4631574735:25.9628%,-0.2976951931:21.0518%,-1.2442195994:18.1226%,-0.2104457366:17.4858%,-0.3109148077:17.3686%,-70.70536262659999:0.0062%,-0.9904029989:0.0006%,13.3383372811:0.0002%,-1.2415756765000001:0.0002%,-1.2389317536:0.0002%,-0.22630927420000002:0.0002%,1.4843088569:0.0002%,11.782388641099999:0.0002%,1.4737331652:0.0002%,1.4658013963999998:0.0002%]
[INFO] ** classification:[normal:73.9096%,Multi Stage Multi Point:26.0904%]
[INFO] columns with count within 2-10 {'orig': 2, 'type': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 8, 'dst': 9, 'proto': 3, 'appi_name': 4, 'proxy_src_ip': 7, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 4, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 1 1 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1743558814620971
tp :  52975.0
fp :  47025.0
tn :  52975.0
fn :  47025.0
accuracy :  0.5297499895095825
precision :  0.5297499895095825
recall :  0.5297499895095825
auc :  0.5297499895095825

y_eval {0: 52975, 1: 47025}
pred {0: 100000}
[INFO] confusion matrix for file 
[[52975     0]
 [47025     0]]
[INFO] confusion matrix after adding it to total:
[[852471      0]
 [247529      0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 1 ... 0 1 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1731178226089478
tp :  53029.0
fp :  46971.0
tn :  53029.0
fn :  46971.0
accuracy :  0.5302900075912476
precision :  0.5302900075912476
recall :  0.5302900075912476
auc :  0.5302900075912476

y_eval {0: 53029, 1: 46971}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53029     0]
 [46971     0]]
[INFO] confusion matrix after adding it to total:
[[905500      0]
 [294500      0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 1 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.9320402018499374
tp :  63544.0
fp :  36456.0
tn :  63544.0
fn :  36456.0
accuracy :  0.6354399919509888
precision :  0.6354399919509888
recall :  0.6354399919509888
auc :  0.6354399919509888

y_eval {0: 63544, 1: 36456}
pred {0: 100000}
[INFO] confusion matrix for file 
[[63544     0]
 [36456     0]]
[INFO] confusion matrix after adding it to total:
[[969044      0]
 [330956      0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[1069044       0]
 [ 330956       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[1169044       0]
 [ 330956       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2015-12-31_233049_114.log.part11_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1361 (0.2722%)
[INFO] ** orig:[0.0:99.9996%,1.0:0.0004%]
[INFO] ** type:[1.0:99.9994%,0.0:0.0004%,-1.0:0.0002%]
[INFO] ** i/f_name:[-1.0:99.9968%,0.0:0.0032%]
[INFO] ** i/f_dir:[-0.7071067812:99.9972%,0.7071067812:0.0028%]
[INFO] ** src:[-1.3652730819:38.4512%,1.3652730819:25.9642%,0.5251050315:18.089%,-0.5251050315:17.4908%,-1.1552310693:0.0028%,-1.5753150944999998:0.0008%,0.10502100630000001:0.0004%,-0.7351470441:0.0004%,0.9451890567:0.0004%]
[INFO] ** dst:[-1.0302443927:43.3436%,1.4048787174000001:21.0714%,1.2175615551:18.0896%,0.0936585812:17.4906%,-0.6556100681:0.0032%,-1.5921958797:0.001%,-0.0936585812:0.0002%,-0.8429272304000001:0.0002%,-1.4048787174000001:0.0002%]
[INFO] ** proto:[0.0:99.9964%,-1.0:0.0032%,1.0:0.0004%]
[INFO] ** appi_name:[-1.6378460497:99.9956%,-1.5118578919999999:0.0032%,-0.37796447299999997:0.0002%,-0.5039526307:0.0002%,0.25197631530000003:0.0002%,0.37796447299999997:0.0002%,-0.6299407883:0.0002%,1.5118578919999999:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.4512%,-1.5753150944999998:25.9642%,1.3652730819:18.089%,-0.3150630189:17.4908%,0.10502100630000001:0.0032%,-1.1552310693:0.0008%,0.3150630189:0.0004%,0.9451890567:0.0004%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9956%,-176.7993450566:0.0042%,4.6584169229:0.0002%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.999%,-1.3363062096:49.9966%,-0.2672612419:0.0042%,0.2672612419:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:25.9632%,0.2672612419:21.0714%,0.8017837256999999:18.0886%,-1.3363062096:17.4902%,-0.2672612419:17.3796%,-0.8017837256999999:0.007%]
[INFO] ** service:[0.0054950911:99.9964%,-185.27759935790002:0.0032%,-163.13937429709998:0.0002%,-177.4227669367:0.0002%]
[INFO] ** s_port:[1.4631574735:25.9636%,-0.2976951931:21.0714%,-1.2442195994:18.0886%,-0.2104457366:17.4904%,-0.3109148077:17.3798%,-70.70536262659999:0.0032%,6.2539458095:0.0008%,-0.9904029989:0.0004%,1.4658013963999998:0.0004%,13.3383372811:0.0002%,-1.2415756765000001:0.0002%,-0.2183775054:0.0002%,-1.2389317536:0.0002%,-0.22630927420000002:0.0002%,1.4843088569:0.0002%,11.782388641099999:0.0002%]
[INFO] ** classification:[normal:95.0874%,Single Stage Single Point:4.9126%]
[INFO] columns with count within 2-10 {'orig': 2, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'src': 9, 'dst': 9, 'proto': 3, 'appi_name': 8, 'proxy_src_ip': 8, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 4, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[1269044       0]
 [ 330956       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[1369044       0]
 [ 330956       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.26497861483573915
tp :  92639.0
fp :  7361.0
tn :  92639.0
fn :  7361.0
accuracy :  0.9263899922370911
precision :  0.9263899922370911
recall :  0.9263899922370911
auc :  0.9263899326324463

y_eval {0: 92639, 1: 7361}
pred {0: 100000}
[INFO] confusion matrix for file 
[[92639     0]
 [ 7361     0]]
[INFO] confusion matrix after adding it to total:
[[1461683       0]
 [ 338317       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.49060360295772554
tp :  82798.0
fp :  17202.0
tn :  82798.0
fn :  17202.0
accuracy :  0.8279799818992615
precision :  0.8279799818992615
recall :  0.8279799818992615
auc :  0.8279799818992615

y_eval {0: 82798, 1: 17202}
pred {0: 100000}
[INFO] confusion matrix for file 
[[82798     0]
 [17202     0]]
[INFO] confusion matrix after adding it to total:
[[1544481       0]
 [ 355519       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[1644481       0]
 [ 355519       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-01_151435_117.log.part03_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1365 (0.273%)
[INFO] ** orig:[0.0:99.9976%,1.0:0.0024%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[-1.0:99.9966%,0.0:0.0034%]
[INFO] ** i/f_dir:[-0.7071067812:99.9966%,0.7071067812:0.0034%]
[INFO] ** src:[-1.3652730819:38.1462%,1.3652730819:26.099%,0.5251050315:18.1904%,-0.5251050315:17.5592%,0.9451890567:0.0028%,-1.1552310693:0.001%,1.5753150944999998:0.0006%,0.10502100630000001:0.0004%,-0.7351470441:0.0004%]
[INFO] ** dst:[-1.0302443927:43.376%,1.4048787174000001:20.8688%,1.2175615551:18.1902%,0.0936585812:17.5592%,-0.6556100681:0.0034%,-1.5921958797:0.0008%,-0.0936585812:0.0004%,0.4682929058:0.0004%,-0.4682929058:0.0004%,-0.8429272304000001:0.0002%,-0.28097574350000004:0.0002%]
[INFO] ** proto:[0.0:99.9958%,-1.0:0.0034%,1.0:0.0008%]
[INFO] ** appi_name:[-1.6378460497:99.9952%,-1.5118578919999999:0.0034%,0.1259881577:0.0006%,-0.6299407883:0.0004%,-1.3858697344:0.0002%,-0.25197631530000003:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.1462%,-1.5753150944999998:26.099%,1.3652730819:18.1904%,-0.3150630189:17.5592%,0.10502100630000001:0.0034%,0.7351470441:0.0006%,-0.10502100630000001:0.0004%,0.3150630189:0.0004%,0.9451890567:0.0004%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9952%,-176.7993450566:0.0048%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.9978%,-1.3363062096:49.9974%,-0.2672612419:0.0048%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:26.0982%,0.2672612419:20.8688%,0.8017837256999999:18.19%,-1.3363062096:17.5588%,-0.2672612419:17.2772%,-0.8017837256999999:0.007%]
[INFO] ** service:[0.0054950911:99.9952%,-185.27759935790002:0.0034%,-184.71949284369998:0.0006%,-163.13937429709998:0.0004%,-184.7070904767:0.0002%,-184.7112245991:0.0002%]
[INFO] ** s_port:[1.4631574735:26.0986%,-0.2976951931:20.8688%,-1.2442195994:18.1902%,-0.2104457366:17.559%,-0.3109148077:17.2774%,-70.70536262659999:0.0034%,-0.9904029989:0.0004%,1.4843088569:0.0002%,-0.7550938587:0.0002%,9.1265680651:0.0002%,-70.522931945:0.0002%,-70.5242539064:0.0002%,-2.8821298501:0.0002%,-4.818803391:0.0002%,-0.2183775054:0.0002%,-1.2415756765000001:0.0002%,4.4124534938:0.0002%,1.4658013963999998:0.0002%]
[INFO] ** classification:[normal:84.2104%,Single Stage Single Point:15.7896%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 9, 'proto': 3, 'appi_name': 6, 'proxy_src_ip': 9, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 6, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.7677914141273499
tp :  70708.0
fp :  29292.0
tn :  70708.0
fn :  29292.0
accuracy :  0.7070800065994263
precision :  0.7070800065994263
recall :  0.7070800065994263
auc :  0.7070800065994263

y_eval {0: 70708, 1: 29292}
pred {0: 100000}
[INFO] confusion matrix for file 
[[70708     0]
 [29292     0]]
[INFO] confusion matrix after adding it to total:
[[1715189       0]
 [ 384811       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 1 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.9166566468048095
tp :  64215.0
fp :  35785.0
tn :  64215.0
fn :  35785.0
accuracy :  0.6421499848365784
precision :  0.6421499848365784
recall :  0.6421499848365784
auc :  0.6421500444412231

y_eval {0: 64215, 1: 35785}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64215     0]
 [35785     0]]
[INFO] confusion matrix after adding it to total:
[[1779404       0]
 [ 420596       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.4142335989141464
tp :  86129.0
fp :  13871.0
tn :  86129.0
fn :  13871.0
accuracy :  0.8612899780273438
precision :  0.8612899780273438
recall :  0.8612899780273438
auc :  0.8612899780273438

y_eval {0: 86129, 1: 13871}
pred {0: 100000}
[INFO] confusion matrix for file 
[[86129     0]
 [13871     0]]
[INFO] confusion matrix after adding it to total:
[[1865533       0]
 [ 434467       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[1965533       0]
 [ 434467       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[2065533       0]
 [ 434467       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-01_151435_117.log.part12_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1377 (0.2754%)
[INFO] ** orig:[0.0:99.9964%,1.0:0.0036%]
[INFO] ** type:[1.0:99.9994%,0.0:0.0004%,-1.0:0.0002%]
[INFO] ** i/f_name:[-1.0:99.996%,0.0:0.004%]
[INFO] ** i/f_dir:[-0.7071067812:99.9964%,0.7071067812:0.0036%]
[INFO] ** src:[-1.3652730819:38.049%,1.3652730819:26.1306%,0.5251050315:18.2264%,-0.5251050315:17.587%,0.9451890567:0.0036%,-1.5753150944999998:0.0014%,-0.9451890567:0.001%,-1.1552310693:0.0004%,0.10502100630000001:0.0002%,0.3150630189:0.0002%,-0.3150630189:0.0002%]
[INFO] ** dst:[-1.0302443927:43.355%,1.4048787174000001:20.8256%,1.2175615551:18.226%,0.0936585812:17.5868%,-0.6556100681:0.004%,-0.4682929058:0.001%,-1.5921958797:0.0006%,0.28097574350000004:0.0004%,-0.0936585812:0.0002%,-0.8429272304000001:0.0002%,-1.4048787174000001:0.0002%]
[INFO] ** proto:[0.0:99.9942%,-1.0:0.004%,1.0:0.0018%]
[INFO] ** appi_name:[-1.6378460497:99.9932%,-1.5118578919999999:0.004%,-0.25197631530000003:0.0006%,-1.3858697344:0.0004%,1.3858697344:0.0004%,0.37796447299999997:0.0002%,-1.0079052614:0.0002%,-0.6299407883:0.0002%,0.25197631530000003:0.0002%,1.5118578919999999:0.0002%,-0.37796447299999997:0.0002%,-0.5039526307:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.049%,-1.5753150944999998:26.1306%,1.3652730819:18.2264%,-0.3150630189:17.587%,0.10502100630000001:0.004%,-1.1552310693:0.0014%,-1.3652730819:0.001%,0.3150630189:0.0002%,1.5753150944999998:0.0002%,-0.5251050315:0.0002%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9932%,-176.7993450566:0.0066%,4.6584169229:0.0002%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.9974%,-1.3363062096:49.9958%,-0.2672612419:0.0066%,0.2672612419:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:26.13%,0.2672612419:20.8244%,0.8017837256999999:18.2258%,-1.3363062096:17.5864%,-0.2672612419:17.2242%,-0.8017837256999999:0.0092%]
[INFO] ** service:[0.0054950911:99.9942%,-185.27759935790002:0.004%,-184.7112245991:0.0006%,-184.7070904767:0.0004%,-163.1476425417:0.0004%,-163.13937429709998:0.0002%,-177.4227669367:0.0002%]
[INFO] ** s_port:[1.4631574735:26.1304%,-0.2976951931:20.8246%,-1.2442195994:18.226%,-0.2104457366:17.5866%,-0.3109148077:17.2244%,-70.70536262659999:0.004%,-6.4223426437:0.0008%,-70.5242539064:0.0006%,-0.2183775054:0.0004%,-63.6289029238:0.0004%,-70.522931945:0.0004%,-1.2415756765000001:0.0002%,-61.4106515916:0.0002%,-1.2389317536:0.0002%,-68.19363585:0.0002%,-1.7796139913:0.0002%,1.4843088569:0.0002%,-0.9904029989:0.0002%]
[INFO] ** classification:[normal:97.1716%,Single Stage Single Point:2.8284%]
[INFO] columns with count within 2-10 {'orig': 2, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'proto': 3, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 7, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[2165533       0]
 [ 434467       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[2265533       0]
 [ 434467       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[2365533       0]
 [ 434467       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[2465533       0]
 [ 434467       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 1 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.4204466346359253
tp :  85858.0
fp :  14142.0
tn :  85858.0
fn :  14142.0
accuracy :  0.8585799932479858
precision :  0.8585799932479858
recall :  0.8585799932479858
auc :  0.8585799932479858

y_eval {0: 85858, 1: 14142}
pred {0: 100000}
[INFO] confusion matrix for file 
[[85858     0]
 [14142     0]]
[INFO] confusion matrix after adding it to total:
[[2551391       0]
 [ 448609       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-01_151435_117.log.part13_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1365 (0.273%)
[INFO] ** orig:[0.0:99.9986%,1.0:0.0014%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[-1.0:99.998%,0.0:0.002%]
[INFO] ** i/f_dir:[-0.7071067812:99.998%,0.7071067812:0.002%]
[INFO] ** src:[-1.3652730819:38.1186%,1.3652730819:26.0918%,0.5251050315:18.2288%,-0.5251050315:17.558%,0.9451890567:0.0018%,-1.1552310693:0.0006%,0.10502100630000001:0.0004%]
[INFO] ** dst:[-1.0302443927:43.3702%,1.4048787174000001:20.8392%,1.2175615551:18.2288%,0.0936585812:17.5578%,-0.6556100681:0.002%,-1.5921958797:0.0012%,-0.8429272304000001:0.0004%,-0.0936585812:0.0002%,-0.4682929058:0.0002%]
[INFO] ** proto:[0.0:99.9976%,-1.0:0.002%,1.0:0.0004%]
[INFO] ** appi_name:[-1.6378460497:99.9976%,-1.5118578919999999:0.002%,-0.25197631530000003:0.0002%,-0.6299407883:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.1186%,-1.5753150944999998:26.0918%,1.3652730819:18.2288%,-0.3150630189:17.558%,0.10502100630000001:0.002%,-0.10502100630000001:0.0004%,0.3150630189:0.0004%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9976%,-176.7993450566:0.0024%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.9998%,-1.3363062096:49.9978%,-0.2672612419:0.0024%]
[INFO] ** modbus_transaction_id:65534 (13.1068%)
[INFO] ** scada_tag:[1.3363062096:26.0906%,0.2672612419:20.839%,0.8017837256999999:18.2282%,-1.3363062096:17.5572%,-0.2672612419:17.2792%,-0.8017837256999999:0.0058%]
[INFO] ** service:[0.0054950911:99.9976%,-185.27759935790002:0.002%,-163.13937429709998:0.0002%,-184.7112245991:0.0002%]
[INFO] ** s_port:[1.4631574735:26.0908%,-0.2976951931:20.8392%,-1.2442195994:18.2284%,-0.2104457366:17.5576%,-0.3109148077:17.2794%,-70.70536262659999:0.002%,1.4658013963999998:0.0006%,-0.9904029989:0.0004%,-1.2415756765000001:0.0004%,4.4124534938:0.0002%,-0.2183775054:0.0002%,-0.22630927420000002:0.0002%,-70.5242539064:0.0002%,1.4843088569:0.0002%,1.4737331652:0.0002%]
[INFO] ** classification:[normal:87.5394%,Single Stage Single Point:12.4606%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 7, 'dst': 9, 'proto': 3, 'appi_name': 4, 'proxy_src_ip': 7, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 4, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 1 0 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1731407569885255
tp :  53028.0
fp :  46972.0
tn :  53028.0
fn :  46972.0
accuracy :  0.5302799940109253
precision :  0.5302799940109253
recall :  0.5302799940109253
auc :  0.5302799940109253

y_eval {0: 53028, 1: 46972}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53028     0]
 [46972     0]]
[INFO] confusion matrix after adding it to total:
[[2604419       0]
 [ 495581       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.4477068610906601
tp :  84669.0
fp :  15331.0
tn :  84669.0
fn :  15331.0
accuracy :  0.8466899991035461
precision :  0.8466899991035461
recall :  0.8466899991035461
auc :  0.8466899991035461

y_eval {0: 84669, 1: 15331}
pred {0: 100000}
[INFO] confusion matrix for file 
[[84669     0]
 [15331     0]]
[INFO] confusion matrix after adding it to total:
[[2689088       0]
 [ 510912       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[2789088       0]
 [ 510912       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[2889088       0]
 [ 510912       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[2989088       0]
 [ 510912       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-01_203011_118.log.part06_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1366 (0.2732%)
[INFO] ** orig:[0.0:99.9988%,1.0:0.0008%,-1.0:0.0004%]
[INFO] ** type:[1.0:99.9986%,0.0:0.001%,-1.0:0.0004%]
[INFO] ** i/f_name:[-1.0:99.998%,0.0:0.002%]
[INFO] ** i/f_dir:[-0.7071067812:99.9982%,0.7071067812:0.0018%]
[INFO] ** src:[-1.3652730819:38.138%,1.3652730819:26.0904%,0.5251050315:18.1762%,-0.5251050315:17.5892%,-0.9451890567:0.0018%,-1.5753150944999998:0.0016%,-1.1552310693:0.0012%,0.9451890567:0.0008%,0.10502100630000001:0.0006%,-0.3150630189:0.0002%]
[INFO] ** dst:[-1.0302443927:43.3838%,1.4048787174000001:20.845%,1.2175615551:18.1758%,0.0936585812:17.589%,-0.6556100681:0.002%,-1.5921958797:0.0014%,-0.4682929058:0.0014%,-0.0936585812:0.0004%,-0.8429272304000001:0.0004%,-1.4048787174000001:0.0004%,0.28097574350000004:0.0004%]
[INFO] ** proto:[0.0:99.9954%,1.0:0.0026%,-1.0:0.002%]
[INFO] ** appi_name:[-1.6378460497:99.9944%,-1.5118578919999999:0.002%,-1.3858697344:0.0008%,-0.25197631530000003:0.0006%,-0.5039526307:0.0004%,-0.6299407883:0.0004%,1.3858697344:0.0004%,1.5118578919999999:0.0004%,0.37796447299999997:0.0002%,0.25197631530000003:0.0002%,-0.37796447299999997:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.138%,-1.5753150944999998:26.0904%,1.3652730819:18.1762%,-0.3150630189:17.5892%,0.10502100630000001:0.002%,-1.3652730819:0.0018%,-1.1552310693:0.0016%,0.3150630189:0.0006%,1.5753150944999998:0.0002%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9944%,-176.7993450566:0.0052%,4.6584169229:0.0004%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.998%,-1.3363062096:49.9964%,-0.2672612419:0.0052%,0.2672612419:0.0004%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:26.0894%,0.2672612419:20.8438%,0.8017837256999999:18.1758%,-1.3363062096:17.5888%,-0.2672612419:17.294%,-0.8017837256999999:0.0082%]
[INFO] ** service:[0.0054950911:99.9954%,-185.27759935790002:0.002%,-184.7070904767:0.0008%,-184.7112245991:0.0006%,-163.13937429709998:0.0004%,-163.1476425417:0.0004%,-177.4227669367:0.0004%]
[INFO] ** s_port:[1.4631574735:26.0898%,-0.2976951931:20.844%,-1.2442195994:18.1758%,-0.2104457366:17.589%,-0.3109148077:17.294%,-70.70536262659999:0.002%,-6.3879716457:0.0008%,-70.522931945:0.0008%,-70.5242539064:0.0006%,-0.9904029989:0.0006%,1.4658013963999998:0.0006%,-1.2415756765000001:0.0004%,-68.19363585:0.0004%,-63.6289029238:0.0004%,-1.7796139913:0.0004%,-0.2183775054:0.0002%,-6.4223426437:0.0002%]
[INFO] ** classification:[normal:90.7904%,Single Stage Multi Point:5.7378%,Single Stage Single Point:3.4718%]
[INFO] columns with count within 2-10 {'orig': 3, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'proto': 3, 'proxy_src_ip': 9, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 7, 'classification': 3}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[3089088       0]
 [ 510912       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[3189088       0]
 [ 510912       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[3289088       0]
 [ 510912       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.4942028652715683
tp :  82641.0
fp :  17359.0
tn :  82641.0
fn :  17359.0
accuracy :  0.8264099955558777
precision :  0.8264099955558777
recall :  0.8264099955558777
auc :  0.8264100551605225

y_eval {0: 82641, 1: 17359}
pred {0: 100000}
[INFO] confusion matrix for file 
[[82641     0]
 [17359     0]]
[INFO] confusion matrix after adding it to total:
[[3371729       0]
 [ 528271       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 1 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.7539660131072998
tp :  71311.0
fp :  28689.0
tn :  71311.0
fn :  28689.0
accuracy :  0.7131100296974182
precision :  0.7131100296974182
recall :  0.7131100296974182
auc :  0.7131099700927734

y_eval {0: 71311, 1: 28689}
pred {0: 100000}
[INFO] confusion matrix for file 
[[71311     0]
 [28689     0]]
[INFO] confusion matrix after adding it to total:
[[3443040       0]
 [ 556960       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-01_203011_118.log.part07_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1366 (0.2732%)
[INFO] ** orig:[0.0:99.9996%,1.0:0.0004%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[-1.0:99.9994%,0.0:0.0006%]
[INFO] ** i/f_dir:[-0.7071067812:99.9994%,0.7071067812:0.0006%]
[INFO] ** src:[-1.3652730819:38.0718%,1.3652730819:26.1174%,0.5251050315:18.2344%,-0.5251050315:17.5754%,0.9451890567:0.0008%,-1.1552310693:0.0002%]
[INFO] ** dst:[-1.0302443927:43.3758%,1.4048787174000001:20.813%,1.2175615551:18.2342%,0.0936585812:17.5754%,-0.6556100681:0.0006%,-1.5921958797:0.0004%,-0.0936585812:0.0002%,-0.8429272304000001:0.0002%,-0.4682929058:0.0002%]
[INFO] ** proto:[0.0:99.999%,-1.0:0.0006%,1.0:0.0004%]
[INFO] ** appi_name:[-1.6378460497:99.999%,-1.5118578919999999:0.0006%,-0.25197631530000003:0.0002%,-0.6299407883:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.0718%,-1.5753150944999998:26.1174%,1.3652730819:18.2344%,-0.3150630189:17.5754%,0.10502100630000001:0.0006%,-0.10502100630000001:0.0004%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.999%,-176.7993450566:0.001%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.9996%,-1.3363062096:49.9994%,-0.2672612419:0.001%]
[INFO] ** modbus_transaction_id:65301 (13.0602%)
[INFO] ** scada_tag:[1.3363062096:26.1164%,0.2672612419:20.813%,0.8017837256999999:18.2338%,-1.3363062096:17.575%,-0.2672612419:17.2586%,-0.8017837256999999:0.0032%]
[INFO] ** service:[0.0054950911:99.999%,-185.27759935790002:0.0006%,-163.13937429709998:0.0002%,-184.7112245991:0.0002%]
[INFO] ** s_port:[1.4631574735:26.1168%,-0.2976951931:20.813%,-1.2442195994:18.234%,-0.2104457366:17.5752%,-0.3109148077:17.2588%,-70.70536262659999:0.0006%,4.4124534938:0.0002%,-1.2415756765000001:0.0002%,-0.2183775054:0.0002%,-1.2389317536:0.0002%,-70.5242539064:0.0002%,1.4843088569:0.0002%,1.4737331652:0.0002%,1.4658013963999998:0.0002%]
[INFO] ** classification:[normal:89.2092%,Single Stage Multi Point:10.7908%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 6, 'dst': 9, 'proto': 3, 'appi_name': 4, 'proxy_src_ip': 6, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 4, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 0 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.173163677368164
tp :  53027.0
fp :  46973.0
tn :  53027.0
fn :  46973.0
accuracy :  0.530269980430603
precision :  0.530269980430603
recall :  0.530269980430603
auc :  0.530269980430603

y_eval {0: 53027, 1: 46973}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53027     0]
 [46973     0]]
[INFO] confusion matrix after adding it to total:
[[3496067       0]
 [ 603933       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.2562662416601181
tp :  93019.0
fp :  6981.0
tn :  93019.0
fn :  6981.0
accuracy :  0.9301900267601013
precision :  0.9301900267601013
recall :  0.9301900267601013
auc :  0.9301899671554565

y_eval {0: 93019, 1: 6981}
pred {0: 100000}
[INFO] confusion matrix for file 
[[93019     0]
 [ 6981     0]]
[INFO] confusion matrix after adding it to total:
[[3589086       0]
 [ 610914       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[3689086       0]
 [ 610914       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[3789086       0]
 [ 610914       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[3889086       0]
 [ 610914       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-02_014558_119.log.part06_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1366 (0.2732%)
[INFO] ** orig:[0.0:99.997%,1.0:0.003%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[-1.0:99.9964%,0.0:0.0036%]
[INFO] ** i/f_dir:[-0.7071067812:99.9964%,0.7071067812:0.0036%]
[INFO] ** src:[-1.3652730819:38.0288%,1.3652730819:26.1242%,0.5251050315:18.2114%,-0.5251050315:17.6294%,0.9451890567:0.003%,-0.7351470441:0.0008%,-1.1552310693:0.0006%,1.5753150944999998:0.0006%,0.10502100630000001:0.0004%,-0.3150630189:0.0004%,-1.5753150944999998:0.0002%,0.3150630189:0.0002%]
[INFO] ** dst:[-1.0302443927:43.357%,1.4048787174000001:20.7952%,1.2175615551:18.2116%,0.0936585812:17.629%,-0.6556100681:0.0036%,-1.5921958797:0.0012%,0.4682929058:0.0008%,0.6556100681:0.0004%,0.8429272304000001:0.0004%,-0.4682929058:0.0004%,-0.8429272304000001:0.0002%,1.5921958797:0.0002%]
[INFO] ** proto:[0.0:99.9958%,-1.0:0.0036%,1.0:0.0006%]
[INFO] ** appi_name:[-1.6378460497:99.9942%,-1.5118578919999999:0.0036%,0.8819171037000001:0.0008%,-0.25197631530000003:0.0004%,-0.1259881577:0.0002%,-1.3858697344:0.0002%,-1.2598815767:0.0002%,-1.133893419:0.0002%,0.1259881577:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.0288%,-1.5753150944999998:26.1242%,1.3652730819:18.2114%,-0.3150630189:17.6294%,0.10502100630000001:0.0036%,0.9451890567:0.0008%,0.7351470441:0.0006%,0.3150630189:0.0004%,1.5753150944999998:0.0004%,-1.1552310693:0.0002%,-0.5251050315:0.0002%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9942%,-176.7993450566:0.0058%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.9974%,-1.3363062096:49.9968%,-0.2672612419:0.0058%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:26.123%,0.2672612419:20.7952%,0.8017837256999999:18.211%,-1.3363062096:17.6288%,-0.2672612419:17.2336%,-0.8017837256999999:0.0084%]
[INFO] ** service:[0.0054950911:99.9942%,-185.27759935790002:0.0036%,-179.7709484184:0.0008%,-184.7112245991:0.0004%,-184.7029563544:0.0004%,-184.71949284369998:0.0002%,-162.746632676:0.0002%,-184.7070904767:0.0002%]
[INFO] ** s_port:[1.4631574735:26.1234%,-0.2976951931:20.7952%,-1.2442195994:18.2112%,-0.2104457366:17.629%,-0.3109148077:17.2336%,-70.70536262659999:0.0036%,1.4658013963999998:0.0006%,9.8364613699:0.0004%,-0.9904029989:0.0004%,-70.5242539064:0.0004%,-5.0223854561:0.0002%,-57.521440972200004:0.0002%,-1.2415756765000001:0.0002%,-0.2183775054:0.0002%,-0.22630927420000002:0.0002%,-57.518797049300005:0.0002%,-70.522931945:0.0002%,2.0593620926:0.0002%,-5.0818737219:0.0002%,1.4737331652:0.0002%,-43.372487451000005:0.0002%]
[INFO] ** classification:[normal:81.41%,Single Stage Single Point:18.59%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'proto': 3, 'appi_name': 9, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 8, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 1 0 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.8436794605255127
tp :  67398.0
fp :  32602.0
tn :  67398.0
fn :  32602.0
accuracy :  0.6739799976348877
precision :  0.6739799976348877
recall :  0.6739799976348877
auc :  0.6739799976348877

y_eval {0: 67398, 1: 32602}
pred {0: 100000}
[INFO] confusion matrix for file 
[[67398     0]
 [32602     0]]
[INFO] confusion matrix after adding it to total:
[[3956484       0]
 [ 643516       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 1 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1725905136108399
tp :  53052.0
fp :  46948.0
tn :  53052.0
fn :  46948.0
accuracy :  0.5305200219154358
precision :  0.5305200219154358
recall :  0.5305200219154358
auc :  0.530519962310791

y_eval {0: 53052, 1: 46948}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53052     0]
 [46948     0]]
[INFO] confusion matrix after adding it to total:
[[4009536       0]
 [ 690464       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.4034347886419296
tp :  86600.0
fp :  13400.0
tn :  86600.0
fn :  13400.0
accuracy :  0.8659999966621399
precision :  0.8659999966621399
recall :  0.8659999966621399
auc :  0.8659999966621399

y_eval {0: 86600, 1: 13400}
pred {0: 100000}
[INFO] confusion matrix for file 
[[86600     0]
 [13400     0]]
[INFO] confusion matrix after adding it to total:
[[4096136       0]
 [ 703864       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[4196136       0]
 [ 703864       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[4296136       0]
 [ 703864       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-02_121729_121.log.part12_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1368 (0.2736%)
[INFO] ** orig:[0.0:99.9986%,-1.0:0.0008%,1.0:0.0006%]
[INFO] ** type:[1.0:99.9984%,0.0:0.0014%,-1.0:0.0002%]
[INFO] ** i/f_name:[-1.0:99.9978%,0.0:0.0022%]
[INFO] ** i/f_dir:[-0.7071067812:99.998%,0.7071067812:0.002%]
[INFO] ** src:[-1.3652730819:38.1136%,1.3652730819:26.1176%,0.5251050315:18.2158%,-0.5251050315:17.5472%,-1.1552310693:0.0016%,-1.5753150944999998:0.0014%,-0.9451890567:0.001%,0.9451890567:0.0006%,0.10502100630000001:0.0004%,-0.7351470441:0.0004%,1.5753150944999998:0.0002%,-0.3150630189:0.0002%]
[INFO] ** dst:[-1.0302443927:43.4022%,1.4048787174000001:20.8284%,1.2175615551:18.2156%,0.0936585812:17.547%,-0.6556100681:0.0022%,-1.5921958797:0.002%,-0.4682929058:0.0008%,0.8429272304000001:0.0004%,1.5921958797:0.0004%,0.28097574350000004:0.0004%,-0.0936585812:0.0002%,-1.4048787174000001:0.0002%,-0.8429272304000001:0.0002%]
[INFO] ** proto:[0.0:99.996%,-1.0:0.0022%,1.0:0.0018%]
[INFO] ** appi_name:[-1.6378460497:99.9946%,-1.5118578919999999:0.0022%,-0.25197631530000003:0.0006%,1.3858697344:0.0004%,-1.3858697344:0.0004%,0.37796447299999997:0.0002%,-0.1259881577:0.0002%,-0.5039526307:0.0002%,-0.6299407883:0.0002%,0.25197631530000003:0.0002%,1.6378460497:0.0002%,-1.133893419:0.0002%,1.5118578919999999:0.0002%,-0.37796447299999997:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.1136%,-1.5753150944999998:26.1176%,1.3652730819:18.2158%,-0.3150630189:17.5472%,0.10502100630000001:0.0022%,-1.1552310693:0.0014%,-1.3652730819:0.001%,0.3150630189:0.0004%,0.9451890567:0.0004%,0.7351470441:0.0002%,1.5753150944999998:0.0002%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9946%,-176.7993450566:0.0052%,4.6584169229:0.0002%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.9984%,-1.3363062096:49.9962%,-0.2672612419:0.0052%,0.2672612419:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:26.1164%,0.2672612419:20.8284%,0.8017837256999999:18.2154%,-1.3363062096:17.5466%,-0.2672612419:17.285%,-0.8017837256999999:0.0082%]
[INFO] ** service:[0.0054950911:99.9954%,-185.27759935790002:0.0022%,-184.7112245991:0.0006%,-184.7070904767:0.0004%,-163.1476425417:0.0004%,-184.7029563544:0.0004%,-163.13110605239999:0.0002%,-163.13937429709998:0.0002%,-177.4227669367:0.0002%]
[INFO] ** s_port:[1.4631574735:26.1168%,-0.2976951931:20.8284%,-1.2442195994:18.2154%,-0.2104457366:17.5468%,-0.3109148077:17.2852%,-70.70536262659999:0.0022%,-10.479442368700001:0.0008%,-70.5242539064:0.0006%,-63.6289029238:0.0004%,-0.2183775054:0.0004%,-70.522931945:0.0004%,-0.9904029989:0.0004%,1.4658013963999998:0.0004%,10.4789346401:0.0004%,-68.19363585:0.0002%,-1.2389317536:0.0002%,13.2484439018:0.0002%,1.4843088569:0.0002%,15.1560342905:0.0002%,-1.2415756765000001:0.0002%,1.4737331652:0.0002%]
[INFO] ** classification:[normal:99.9996%,Single Stage Multi Point:0.0004%]
[INFO] columns with count within 2-10 {'orig': 3, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'proto': 3, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 9, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[4396136       0]
 [ 703864       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[4496136       0]
 [ 703864       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[4596136       0]
 [ 703864       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[4696136       0]
 [ 703864       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.0962585473394394
tp :  99998.0
fp :  2.0
tn :  99998.0
fn :  2.0
accuracy :  0.9999799728393555
precision :  0.9999799728393555
recall :  0.9999799728393555
auc :  0.9999799728393555

y_eval {0: 99998, 1: 2}
pred {0: 100000}
[INFO] confusion matrix for file 
[[99998     0]
 [    2     0]]
[INFO] confusion matrix after adding it to total:
[[4796134       0]
 [ 703866       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-02_121729_121.log.part13_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1368 (0.2736%)
[INFO] ** orig:[0.0:99.9996%,1.0:0.0004%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[-1.0:99.9994%,0.0:0.0006%]
[INFO] ** i/f_dir:[-0.7071067812:99.9994%,0.7071067812:0.0006%]
[INFO] ** src:[-1.3652730819:38.162%,1.3652730819:26.1664%,0.5251050315:18.0742%,-0.5251050315:17.5958%,0.9451890567:0.0008%,0.10502100630000001:0.0002%,-1.1552310693:0.0002%,0.7351470441:0.0002%,0.3150630189:0.0002%]
[INFO] ** dst:[-1.0302443927:43.4352%,1.4048787174000001:20.8932%,1.2175615551:18.0744%,0.0936585812:17.5952%,-0.0936585812:0.0006%,-1.5921958797:0.0006%,-0.6556100681:0.0006%,-0.4682929058:0.0002%]
[INFO] ** proto:[0.0:99.9986%,1.0:0.0008%,-1.0:0.0006%]
[INFO] ** appi_name:[-1.6378460497:99.9986%,-1.5118578919999999:0.0006%,-0.6299407883:0.0006%,-0.25197631530000003:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.162%,-1.5753150944999998:26.1664%,1.3652730819:18.0742%,-0.3150630189:17.5958%,0.10502100630000001:0.0006%,-0.10502100630000001:0.0004%,0.3150630189:0.0002%,-0.7351470441:0.0002%,-0.5251050315:0.0002%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9986%,-176.7993450566:0.0014%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.9998%,-1.3363062096:49.9988%,-0.2672612419:0.0014%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:26.166%,0.2672612419:20.893%,0.8017837256999999:18.0738%,-1.3363062096:17.5948%,-0.2672612419:17.2688%,-0.8017837256999999:0.0036%]
[INFO] ** service:[0.0054950911:99.9986%,-185.27759935790002:0.0006%,-163.13937429709998:0.0006%,-184.7112245991:0.0002%]
[INFO] ** s_port:[1.4631574735:26.1662%,-0.2976951931:20.8932%,-1.2442195994:18.074%,-0.2104457366:17.5952%,-0.3109148077:17.2688%,-70.70536262659999:0.0006%,-0.2183775054:0.0004%,15.3265673191:0.0004%,-0.9904029989:0.0002%,4.4124534938:0.0002%,-1.2389317536:0.0002%,-0.22630927420000002:0.0002%,-70.5242539064:0.0002%,1.4737331652:0.0002%]
[INFO] ** classification:[normal:92.8338%,Multi Stage Single Point:7.1662%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 9, 'dst': 8, 'proto': 3, 'appi_name': 4, 'proxy_src_ip': 9, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 4, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[4896134       0]
 [ 703866       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.35450869733810425
tp :  88734.0
fp :  11266.0
tn :  88734.0
fn :  11266.0
accuracy :  0.8873400092124939
precision :  0.8873400092124939
recall :  0.8873400092124939
auc :  0.8873400092124939

y_eval {0: 88734, 1: 11266}
pred {0: 100000}
[INFO] confusion matrix for file 
[[88734     0]
 [11266     0]]
[INFO] confusion matrix after adding it to total:
[[4984868       0]
 [ 715132       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.2696557358312607
tp :  92435.0
fp :  7565.0
tn :  92435.0
fn :  7565.0
accuracy :  0.9243500232696533
precision :  0.9243500232696533
recall :  0.9243500232696533
auc :  0.9243500232696533

y_eval {0: 92435, 1: 7565}
pred {0: 100000}
[INFO] confusion matrix for file 
[[92435     0]
 [ 7565     0]]
[INFO] confusion matrix after adding it to total:
[[5077303       0]
 [ 722697       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[5177303       0]
 [ 722697       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.4859723412322998
tp :  83000.0
fp :  17000.0
tn :  83000.0
fn :  17000.0
accuracy :  0.8299999833106995
precision :  0.8299999833106995
recall :  0.8299999833106995
auc :  0.8299999833106995

y_eval {0: 83000, 1: 17000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[83000     0]
 [17000     0]]
[INFO] confusion matrix after adding it to total:
[[5260303       0]
 [ 739697       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-02_121729_121.log.part14_sorted-labeled.csv
[INFO] process dataset, shape: (439824, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (439824, 17)

[INFO] analyzing data
[INFO] 439824 rows
[INFO] ** unixtime:1201 (0.27306%)
[INFO] ** orig:[0.0:99.99955%,1.0:0.00045%]
[INFO] ** type:[1.0:99.99977%,0.0:0.00023%]
[INFO] ** i/f_name:[-1.0:99.99864%,0.0:0.00136%]
[INFO] ** i/f_dir:[-0.7071067812:99.99886%,0.7071067812:0.00114%]
[INFO] ** src:[-1.3652730819:38.09456%,1.3652730819:26.09703%,0.5251050315:18.22161%,-0.5251050315:17.58408%,-1.1552310693:0.00091%,0.10502100630000001:0.00068%,0.9451890567:0.00068%,1.5753150944999998:0.00023%,-0.3150630189:0.00023%]
[INFO] ** dst:[-1.0302443927:43.35416%,1.4048787174000001:20.83674%,1.2175615551:18.22115%,0.0936585812:17.58385%,-1.5921958797:0.00159%,-0.6556100681:0.00136%,-0.8429272304000001:0.00045%,-0.28097574350000004:0.00023%,-0.4682929058:0.00023%,0.28097574350000004:0.00023%]
[INFO] ** proto:[0.0:99.99818%,-1.0:0.00136%,1.0:0.00045%]
[INFO] ** appi_name:[-1.6378460497:99.99795%,-1.5118578919999999:0.00136%,-1.3858697344:0.00023%,1.3858697344:0.00023%,0.7559289459999999:0.00023%]
[INFO] ** proxy_src_ip:[0.5251050315:38.09456%,-1.5753150944999998:26.09703%,1.3652730819:18.22161%,-0.3150630189:17.58408%,0.10502100630000001:0.00136%,0.3150630189:0.00068%,-0.10502100630000001:0.00023%,0.7351470441:0.00023%,1.5753150944999998:0.00023%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.99795%,-176.7993450566:0.00205%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.99955%,-1.3363062096:49.99841%,-0.2672612419:0.00205%]
[INFO] ** modbus_transaction_id:65536 (14.90051%)
[INFO] ** scada_tag:[1.3363062096:26.09612%,0.2672612419:20.83652%,0.8017837256999999:18.22092%,-1.3363062096:17.5834%,-0.2672612419:17.25758%,-0.8017837256999999:0.00546%]
[INFO] ** service:[0.0054950911:99.99795%,-185.27759935790002:0.00136%,-184.94686957169998:0.00023%,-184.7070904767:0.00023%,-163.1476425417:0.00023%]
[INFO] ** s_port:[1.4631574735:26.09635%,-0.2976951931:20.83674%,-1.2442195994:18.22115%,-0.2104457366:17.58362%,-0.3109148077:17.25781%,-70.70536262659999:0.00136%,-0.9904029989:0.00068%,-1.2415756765000001:0.00045%,-0.2183775054:0.00045%,1.4658013963999998:0.00045%,-63.6289029238:0.00023%,-1.2389317536:0.00023%,1.4843088569:0.00023%,-70.522931945:0.00023%]
[INFO] ** classification:[normal:93.34597%,Single Stage Single Point:4.48861%,Multi Stage Single Point:2.16541%]
[INFO] columns with count within 2-10 {'orig': 2, 'type': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 9, 'proto': 3, 'appi_name': 5, 'proxy_src_ip': 9, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 5, 'classification': 3}
[INFO] processing batch 0-100000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 0 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.399376915512085
tp :  86777.0
fp :  13223.0
tn :  86777.0
fn :  13223.0
accuracy :  0.8677700161933899
precision :  0.8677700161933899
recall :  0.8677700161933899
auc :  0.8677700161933899

y_eval {0: 86777, 1: 13223}
pred {0: 100000}
[INFO] confusion matrix for file 
[[86777     0]
 [13223     0]]
[INFO] confusion matrix after adding it to total:
[[5347080       0]
 [ 752920       0]]
[INFO] processing batch 100000-200000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.46403116582393644
tp :  83957.0
fp :  16043.0
tn :  83957.0
fn :  16043.0
accuracy :  0.8395699858665466
precision :  0.8395699858665466
recall :  0.8395699858665466
auc :  0.8395699858665466

y_eval {0: 83957, 1: 16043}
pred {0: 100000}
[INFO] confusion matrix for file 
[[83957     0]
 [16043     0]]
[INFO] confusion matrix after adding it to total:
[[5431037       0]
 [ 768963       0]]
[INFO] processing batch 200000-300000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[5531037       0]
 [ 768963       0]]
[INFO] processing batch 300000-400000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[5631037       0]
 [ 768963       0]]
[INFO] processing batch 400000-500000/439824
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-02_172943_122.log.part03_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1376 (0.2752%)
[INFO] ** orig:[0.0:99.9976%,1.0:0.002%,-1.0:0.0004%]
[INFO] ** type:[1.0:99.9988%,0.0:0.001%,-1.0:0.0002%]
[INFO] ** i/f_name:[-1.0:99.9944%,0.0:0.0056%]
[INFO] ** i/f_dir:[-0.7071067812:99.9946%,0.7071067812:0.0054%]
[INFO] ** src:[-1.3652730819:38.2234%,1.3652730819:26.124%,0.5251050315:18.075%,-0.5251050315:17.571%,-1.1552310693:0.0036%,0.9451890567:0.0022%,-0.7351470441:0.0004%,-1.5753150944999998:0.0002%,-0.9451890567:0.0002%]
[INFO] ** dst:[-1.0302443927:43.4342%,1.4048787174000001:20.913%,1.2175615551:18.0748%,0.0936585812:17.5708%,-0.6556100681:0.0056%,-1.5921958797:0.0006%,0.28097574350000004:0.0004%,-0.0936585812:0.0002%,-0.8429272304000001:0.0002%,-1.4048787174000001:0.0002%]
[INFO] ** proto:[0.0:99.9936%,-1.0:0.0056%,1.0:0.0008%]
[INFO] ** appi_name:[-1.6378460497:99.9934%,-1.5118578919999999:0.0056%,1.3858697344:0.0004%,-0.5039526307:0.0002%,-0.6299407883:0.0002%,1.5118578919999999:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.2234%,-1.5753150944999998:26.124%,1.3652730819:18.075%,-0.3150630189:17.571%,0.10502100630000001:0.0056%,0.9451890567:0.0004%,-1.1552310693:0.0002%,-0.10502100630000001:0.0002%,-1.3652730819:0.0002%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9934%,-176.7993450566:0.0064%,4.6584169229:0.0002%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.997%,-1.3363062096:49.9964%,-0.2672612419:0.0064%,0.2672612419:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:26.1234%,0.2672612419:20.9128%,0.8017837256999999:18.0748%,-1.3363062096:17.5704%,-0.2672612419:17.3102%,-0.8017837256999999:0.0084%]
[INFO] ** service:[0.0054950911:99.9936%,-185.27759935790002:0.0056%,-163.1476425417:0.0004%,-163.13937429709998:0.0002%,-177.4227669367:0.0002%]
[INFO] ** s_port:[1.4631574735:26.1238%,-0.2976951931:20.913%,-1.2442195994:18.0748%,-0.2104457366:17.5706%,-0.3109148077:17.3104%,-70.70536262659999:0.0056%,-63.6289029238:0.0004%,-0.2183775054:0.0004%,13.3383372811:0.0002%,-1.2415756765000001:0.0002%,1.4843088569:0.0002%,11.782388641099999:0.0002%,-10.479442368700001:0.0002%]
[INFO] ** classification:[normal:94.9296%,Single Stage Single Point:5.0704%]
[INFO] columns with count within 2-10 {'orig': 3, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'src': 9, 'proto': 3, 'appi_name': 6, 'proxy_src_ip': 9, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 5, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[5731037       0]
 [ 768963       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[5831037       0]
 [ 768963       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[5931037       0]
 [ 768963       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[6031037       0]
 [ 768963       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.6774588956260681
tp :  74648.0
fp :  25352.0
tn :  74648.0
fn :  25352.0
accuracy :  0.7464799880981445
precision :  0.7464799880981445
recall :  0.7464799880981445
auc :  0.7464799880981445

y_eval {0: 74648, 1: 25352}
pred {0: 100000}
[INFO] confusion matrix for file 
[[74648     0]
 [25352     0]]
[INFO] confusion matrix after adding it to total:
[[6105685       0]
 [ 794315       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-02_172943_122.log.part04_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1377 (0.2754%)
[INFO] ** orig:[0.0:99.995%,1.0:0.005%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[-1.0:99.9944%,0.0:0.0056%]
[INFO] ** i/f_dir:[-0.7071067812:99.9944%,0.7071067812:0.0056%]
[INFO] ** src:[-1.3652730819:38.203%,1.3652730819:26.1368%,0.5251050315:18.1014%,-0.5251050315:17.5508%,0.9451890567:0.005%,1.5753150944999998:0.0008%,0.10502100630000001:0.0006%,-1.1552310693:0.0006%,-0.7351470441:0.0004%,-0.3150630189:0.0004%,0.3150630189:0.0002%]
[INFO] ** dst:[-1.0302443927:43.4462%,1.4048787174000001:20.893%,1.2175615551:18.1012%,0.0936585812:17.5504%,-0.6556100681:0.0056%,-1.5921958797:0.0016%,0.4682929058:0.0008%,-0.4682929058:0.0006%,0.6556100681:0.0004%,-0.8429272304000001:0.0002%]
[INFO] ** proto:[0.0:99.9938%,-1.0:0.0056%,1.0:0.0006%]
[INFO] ** appi_name:[-1.6378460497:99.9926%,-1.5118578919999999:0.0056%,0.8819171037000001:0.0008%,-1.3858697344:0.0004%,0.1259881577:0.0002%,-0.25197631530000003:0.0002%,-1.2598815767:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.203%,-1.5753150944999998:26.1368%,1.3652730819:18.1014%,-0.3150630189:17.5508%,0.10502100630000001:0.0056%,0.7351470441:0.0008%,0.3150630189:0.0006%,1.5753150944999998:0.0004%,0.9451890567:0.0004%,-0.5251050315:0.0002%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9926%,-176.7993450566:0.0074%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.9972%,-1.3363062096:49.9954%,-0.2672612419:0.0074%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:26.1358%,0.2672612419:20.8928%,0.8017837256999999:18.1008%,-1.3363062096:17.55%,-0.2672612419:17.31%,-0.8017837256999999:0.0106%]
[INFO] ** service:[0.0054950911:99.9926%,-185.27759935790002:0.0056%,-179.7709484184:0.0008%,-184.7070904767:0.0004%,-184.71949284369998:0.0002%,-162.746632676:0.0002%,-184.7112245991:0.0002%]
[INFO] ** s_port:[1.4631574735:26.136%,-0.2976951931:20.893%,-1.2442195994:18.101%,-0.2104457366:17.5502%,-0.3109148077:17.31%,-70.70536262659999:0.0056%,-0.9904029989:0.0006%,1.4658013963999998:0.0006%,-0.2183775054:0.0004%,-70.522931945:0.0004%,-5.0223854561:0.0002%,-57.521440972200004:0.0002%,-1.2415756765000001:0.0002%,-1.2389317536:0.0002%,-0.22630927420000002:0.0002%,-70.5242539064:0.0002%,-57.518797049300005:0.0002%,1.4843088569:0.0002%,2.0593620926:0.0002%,-5.0818737219:0.0002%,-43.372487451000005:0.0002%]
[INFO] ** classification:[normal:64.3482%,Single Stage Single Point:35.6518%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'proto': 3, 'appi_name': 7, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 7, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.9111083146476746
tp :  64457.0
fp :  35543.0
tn :  64457.0
fn :  35543.0
accuracy :  0.644569993019104
precision :  0.644569993019104
recall :  0.644569993019104
auc :  0.644569993019104

y_eval {0: 64457, 1: 35543}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64457     0]
 [35543     0]]
[INFO] confusion matrix after adding it to total:
[[6170142       0]
 [ 829858       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.9081048700714112
tp :  64588.0
fp :  35412.0
tn :  64588.0
fn :  35412.0
accuracy :  0.6458799839019775
precision :  0.6458799839019775
recall :  0.6458799839019775
auc :  0.6458799839019775

y_eval {0: 64588, 1: 35412}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64588     0]
 [35412     0]]
[INFO] confusion matrix after adding it to total:
[[6234730       0]
 [ 865270       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.9152581016349792
tp :  64276.0
fp :  35724.0
tn :  64276.0
fn :  35724.0
accuracy :  0.6427599787712097
precision :  0.6427599787712097
recall :  0.6427599787712097
auc :  0.6427600383758545

y_eval {0: 64276, 1: 35724}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64276     0]
 [35724     0]]
[INFO] confusion matrix after adding it to total:
[[6299006       0]
 [ 900994       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 1 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.9151434727859497
tp :  64281.0
fp :  35719.0
tn :  64281.0
fn :  35719.0
accuracy :  0.6428099870681763
precision :  0.6428099870681763
recall :  0.6428099870681763
auc :  0.6428099870681763

y_eval {0: 64281, 1: 35719}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64281     0]
 [35719     0]]
[INFO] confusion matrix after adding it to total:
[[6363287       0]
 [ 936713       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 0 ... 1 1 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.9183991029548645
tp :  64139.0
fp :  35861.0
tn :  64139.0
fn :  35861.0
accuracy :  0.6413900256156921
precision :  0.6413900256156921
recall :  0.6413900256156921
auc :  0.6413899660110474

y_eval {0: 64139, 1: 35861}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64139     0]
 [35861     0]]
[INFO] confusion matrix after adding it to total:
[[6427426       0]
 [ 972574       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-zscore/eval/2016-01-02_172943_122.log.part05_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1367 (0.2734%)
[INFO] ** orig:[0.0:99.9992%,1.0:0.0008%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[-1.0:99.9984%,0.0:0.0016%]
[INFO] ** i/f_dir:[-0.7071067812:99.9984%,0.7071067812:0.0016%]
[INFO] ** src:[-1.3652730819:38.0648%,1.3652730819:26.1164%,0.5251050315:18.2044%,-0.5251050315:17.6118%,0.9451890567:0.001%,-1.1552310693:0.0008%,1.5753150944999998:0.0004%,-0.7351470441:0.0004%]
[INFO] ** dst:[-1.0302443927:43.368%,1.4048787174000001:20.8128%,1.2175615551:18.2044%,0.0936585812:17.6114%,-0.6556100681:0.0016%,-1.5921958797:0.0006%,0.4682929058:0.0004%,-0.0936585812:0.0002%,-0.8429272304000001:0.0002%,-0.4682929058:0.0002%,-0.28097574350000004:0.0002%]
[INFO] ** proto:[0.0:99.998%,-1.0:0.0016%,1.0:0.0004%]
[INFO] ** appi_name:[-1.6378460497:99.9974%,-1.5118578919999999:0.0016%,0.1259881577:0.0006%,-0.25197631530000003:0.0002%,-0.6299407883:0.0002%]
[INFO] ** proxy_src_ip:[0.5251050315:38.0648%,-1.5753150944999998:26.1164%,1.3652730819:18.2044%,-0.3150630189:17.6118%,0.10502100630000001:0.0016%,0.7351470441:0.0004%,0.9451890567:0.0004%,-0.10502100630000001:0.0002%]
[INFO] ** modbus_function_code:[0.005653795200000001:99.9974%,-176.7993450566:0.0026%]
[INFO] ** modbus_function_description:[-0.8017837256999999:49.9992%,-1.3363062096:49.9982%,-0.2672612419:0.0026%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.3363062096:26.1154%,0.2672612419:20.8126%,0.8017837256999999:18.204%,-1.3363062096:17.6112%,-0.2672612419:17.2518%,-0.8017837256999999:0.005%]
[INFO] ** service:[0.0054950911:99.9974%,-185.27759935790002:0.0016%,-184.71949284369998:0.0006%,-163.13937429709998:0.0002%,-184.7112245991:0.0002%]
[INFO] ** s_port:[1.4631574735:26.1158%,-0.2976951931:20.8128%,-1.2442195994:18.204%,-0.2104457366:17.6114%,-0.3109148077:17.252%,-70.70536262659999:0.0016%,1.4658013963999998:0.0004%,10.6613653218:0.0002%,-2.7657972414999996:0.0002%,-1.9871619406999999:0.0002%,-70.5242539064:0.0002%,-1.2389317536:0.0002%,-0.2183775054:0.0002%,-1.2415756765000001:0.0002%,1.4737331652:0.0002%,14.7779533126:0.0002%,-0.22630927420000002:0.0002%]
[INFO] ** classification:[normal:97.0224%,Single Stage Single Point:2.9776%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 8, 'proto': 3, 'appi_name': 5, 'proxy_src_ip': 8, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 5, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.43755039983272553
tp :  85112.0
fp :  14888.0
tn :  85112.0
fn :  14888.0
accuracy :  0.8511199951171875
precision :  0.8511199951171875
recall :  0.8511199951171875
auc :  0.8511199951171875

y_eval {0: 85112, 1: 14888}
pred {0: 100000}
[INFO] confusion matrix for file 
[[85112     0]
 [14888     0]]
[INFO] confusion matrix after adding it to total:
[[6512538       0]
 [ 987462       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[6612538       0]
 [ 987462       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[6712538       0]
 [ 987462       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[6812538       0]
 [ 987462       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09621269361019134
tp :  100000.0
fp :  0.0
tn :  100000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[6912538       0]
 [ 987462       0]]
--- 215.34554600715637 seconds ---
