2020-02-09 15:07:14.058004: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-02-09 15:07:14.058159: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-02-09 15:07:14.058174: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-02-09 15:07:14.858662: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-02-09 15:07:14.858690: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-02-09 15:07:14.858718: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (bastia): /proc/driver/nvidia/version does not exist
2020-02-09 15:07:14.858916: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-09 15:07:14.868122: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2112050000 Hz
2020-02-09 15:07:14.869604: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55949f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-09 15:07:14.869653: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow backend.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
2020-02-09 15:12:50.702490: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-09 15:12:50.736363: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 15:12:50.749393: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 15:12:50.860592: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-09 15:12:50.867385: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-09 15:12:50.876724: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 15:12:50.885586: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 15:12:50.910020: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-09 15:13:03.685352: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-09 15:13:03.691455: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 15:13:03.694398: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 15:13:03.715238: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-09 15:13:03.716706: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-09 15:13:03.718828: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 15:13:03.720822: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 15:13:03.727215: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
=================================================
        TRAINING v0.4.5 (binary)
=================================================
Date: 2020-02-09 15:07:14.852570
------------DNN info-------------
dnnBatchSize 16
wrapLayerSize 8
coreLayerSize 32
numCoreLayers 3
outputLayerActivation sigmoid
output_dim 2
loss binary_crossentropy
optimizer adam
------------DNN info-------------
[INFO] input_shape (16, 107)
[INFO] LSTM first and last layer neurons: 8
[INFO] adding core layer 0
[INFO] adding core layer 1
[INFO] adding core layer 2
[INFO] created DNN
[33m[INFO] epoch 1/10[0m
[33m[INFO] loading file 1-50/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (24819975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] Shape when encoding dataset: (24819975, 17)
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
missing -1
len(df.columns) 108
numFeatures 107
[INFO] Shape AFTER encoding dataset: (24819975, 108)
[INFO] processing batch 0-256000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 16s - loss: 0.6075 - tp: 191599.0000 - fp: 117.0000 - tn: 191883.0000 - fn: 401.0000 - accuracy: 0.9987 - precision: 0.9994 - recall: 0.9979 - auc: 0.9996 - val_loss: 0.5293 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-0-256000
[INFO] processing batch 256000-512000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6776 - tp: 112918.0000 - fp: 79082.0000 - tn: 112918.0000 - fn: 79082.0000 - accuracy: 0.5881 - precision: 0.5881 - recall: 0.5881 - auc: 0.5881 - val_loss: 0.6987 - val_tp: 33927.0000 - val_fp: 30073.0000 - val_tn: 33927.0000 - val_fn: 30073.0000 - val_accuracy: 0.5301 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-256000-512000
[INFO] processing batch 512000-768000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6201 - tp: 138284.0000 - fp: 53716.0000 - tn: 138284.0000 - fn: 53716.0000 - accuracy: 0.7202 - precision: 0.7202 - recall: 0.7202 - auc: 0.7200 - val_loss: 0.4807 - val_tp: 62058.0000 - val_fp: 1942.0000 - val_tn: 62058.0000 - val_fn: 1942.0000 - val_accuracy: 0.9697 - val_precision: 0.9697 - val_recall: 0.9697 - val_auc: 0.9697
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-512000-768000
[INFO] processing batch 768000-1024000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6689 - tp: 117250.0000 - fp: 74750.0000 - tn: 117250.0000 - fn: 74750.0000 - accuracy: 0.6107 - precision: 0.6107 - recall: 0.6107 - auc: 0.6100 - val_loss: 0.5395 - val_tp: 55591.0000 - val_fp: 8409.0000 - val_tn: 55591.0000 - val_fn: 8409.0000 - val_accuracy: 0.8686 - val_precision: 0.8686 - val_recall: 0.8686 - val_auc: 0.8686
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-768000-1024000
[INFO] processing batch 1024000-1280000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6207 - tp: 133967.0000 - fp: 58033.0000 - tn: 133967.0000 - fn: 58033.0000 - accuracy: 0.6977 - precision: 0.6977 - recall: 0.6977 - auc: 0.6998 - val_loss: 0.4249 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-1024000-1280000
[INFO] processing batch 1280000-1536000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.3312 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2628 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-1280000-1536000
[INFO] processing batch 1536000-1792000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.2224 - tp: 191999.0000 - fp: 1.0000 - tn: 191999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1890 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-1536000-1792000
[INFO] processing batch 1792000-2048000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.5449 - tp: 148221.0000 - fp: 43779.0000 - tn: 148221.0000 - fn: 43779.0000 - accuracy: 0.7720 - precision: 0.7720 - recall: 0.7720 - auc: 0.7714 - val_loss: 0.3453 - val_tp: 57941.0000 - val_fp: 6059.0000 - val_tn: 57941.0000 - val_fn: 6059.0000 - val_accuracy: 0.9053 - val_precision: 0.9053 - val_recall: 0.9053 - val_auc: 0.9053
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-1792000-2048000
[INFO] processing batch 2048000-2304000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.5873 - tp: 141714.0000 - fp: 50286.0000 - tn: 141714.0000 - fn: 50286.0000 - accuracy: 0.7381 - precision: 0.7381 - recall: 0.7381 - auc: 0.7392 - val_loss: 0.2352 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-2048000-2304000
[INFO] processing batch 2304000-2560000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1947 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1607 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-2304000-2560000
[INFO] processing batch 2560000-2816000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1384 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1193 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-2560000-2816000
[INFO] processing batch 2816000-3072000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.5721 - tp: 148720.0000 - fp: 43280.0000 - tn: 148720.0000 - fn: 43280.0000 - accuracy: 0.7746 - precision: 0.7746 - recall: 0.7746 - auc: 0.7758 - val_loss: 0.8041 - val_tp: 40961.0000 - val_fp: 23039.0000 - val_tn: 40961.0000 - val_fn: 23039.0000 - val_accuracy: 0.6400 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.6400
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-2816000-3072000
[INFO] processing batch 3072000-3328000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6900 - tp: 131495.0000 - fp: 60505.0000 - tn: 131495.0000 - fn: 60505.0000 - accuracy: 0.6849 - precision: 0.6849 - recall: 0.6849 - auc: 0.6846 - val_loss: 0.2165 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-3072000-3328000
[INFO] processing batch 3328000-3584000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1803 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1492 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-3328000-3584000
[INFO] processing batch 3584000-3840000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1286 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1110 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-3584000-3840000
[INFO] processing batch 3840000-4096000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.4896 - tp: 157534.0000 - fp: 34466.0000 - tn: 157534.0000 - fn: 34466.0000 - accuracy: 0.8205 - precision: 0.8205 - recall: 0.8205 - auc: 0.8205 - val_loss: 0.4928 - val_tp: 52219.0000 - val_fp: 11781.0000 - val_tn: 52219.0000 - val_fn: 11781.0000 - val_accuracy: 0.8159 - val_precision: 0.8159 - val_recall: 0.8159 - val_auc: 0.8159
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-3840000-4096000
[INFO] processing batch 4096000-4352000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1344 - tp: 190188.0000 - fp: 1812.0000 - tn: 190188.0000 - fn: 1812.0000 - accuracy: 0.9906 - precision: 0.9906 - recall: 0.9906 - auc: 0.9906 - val_loss: 0.0989 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-4096000-4352000
[INFO] processing batch 4352000-4608000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.0864 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0755 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-4352000-4608000
[INFO] processing batch 4608000-4864000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.4700 - tp: 161451.0000 - fp: 30549.0000 - tn: 161451.0000 - fn: 30549.0000 - accuracy: 0.8409 - precision: 0.8409 - recall: 0.8409 - auc: 0.8416 - val_loss: 0.0977 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-4608000-4864000
[INFO] processing batch 4864000-5120000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.0849 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0731 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-4864000-5120000
[INFO] processing batch 5120000-5376000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.0644 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0567 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-5120000-5376000
[INFO] processing batch 5376000-5632000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.0507 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0453 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-5376000-5632000
[INFO] processing batch 5632000-5888000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.5869 - tp: 155809.0000 - fp: 36191.0000 - tn: 155809.0000 - fn: 36191.0000 - accuracy: 0.8115 - precision: 0.8115 - recall: 0.8115 - auc: 0.8109 - val_loss: 0.0759 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-5632000-5888000
[INFO] processing batch 5888000-6144000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.0679 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0598 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-5888000-6144000
[INFO] processing batch 6144000-6400000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.3168 - tp: 174156.0000 - fp: 17844.0000 - tn: 174156.0000 - fn: 17844.0000 - accuracy: 0.9071 - precision: 0.9071 - recall: 0.9071 - auc: 0.9085 - val_loss: 1.0172 - val_tp: 41108.0000 - val_fp: 22892.0000 - val_tn: 41108.0000 - val_fn: 22892.0000 - val_accuracy: 0.6423 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-6144000-6400000
[INFO] processing batch 6400000-6656000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.7339 - tp: 138766.0000 - fp: 53234.0000 - tn: 138766.0000 - fn: 53234.0000 - accuracy: 0.7227 - precision: 0.7227 - recall: 0.7227 - auc: 0.7233 - val_loss: 0.1272 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-6400000-6656000
[INFO] processing batch 6656000-6912000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1108 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0950 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-6656000-6912000
[INFO] processing batch 6912000-7168000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.0835 - tp: 191998.0000 - fp: 2.0000 - tn: 191998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0734 - val_tp: 63999.0000 - val_fp: 1.0000 - val_tn: 63999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-6912000-7168000
[INFO] processing batch 7168000-7424000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.0654 - tp: 191999.0000 - fp: 1.0000 - tn: 191999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9221 - val_tp: 44344.0000 - val_fp: 19656.0000 - val_tn: 44344.0000 - val_fn: 19656.0000 - val_accuracy: 0.6929 - val_precision: 0.6929 - val_recall: 0.6929 - val_auc: 0.6929
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-7168000-7424000
[INFO] processing batch 7424000-7680000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 1.1977 - tp: 102062.0000 - fp: 89938.0000 - tn: 102062.0000 - fn: 89938.0000 - accuracy: 0.5316 - precision: 0.5316 - recall: 0.5316 - auc: 0.5316 - val_loss: 0.5688 - val_tp: 49859.0000 - val_fp: 14141.0000 - val_tn: 49859.0000 - val_fn: 14141.0000 - val_accuracy: 0.7790 - val_precision: 0.7790 - val_recall: 0.7790 - val_auc: 0.7790
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-7424000-7680000
[INFO] processing batch 7680000-7936000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1178 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1073 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-7680000-7936000
[INFO] processing batch 7936000-8192000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.0981 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0894 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-7936000-8192000
[INFO] processing batch 8192000-8448000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.4575 - tp: 161781.0000 - fp: 30219.0000 - tn: 161781.0000 - fn: 30219.0000 - accuracy: 0.8426 - precision: 0.8426 - recall: 0.8426 - auc: 0.8430 - val_loss: 0.1249 - val_tp: 63369.0000 - val_fp: 631.0000 - val_tn: 63369.0000 - val_fn: 631.0000 - val_accuracy: 0.9901 - val_precision: 0.9901 - val_recall: 0.9901 - val_auc: 0.9901
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-8192000-8448000
[INFO] processing batch 8448000-8704000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.8322 - tp: 123282.0000 - fp: 68718.0000 - tn: 123282.0000 - fn: 68718.0000 - accuracy: 0.6421 - precision: 0.6421 - recall: 0.6421 - auc: 0.6419 - val_loss: 0.8143 - val_tp: 39692.0000 - val_fp: 24308.0000 - val_tn: 39692.0000 - val_fn: 24308.0000 - val_accuracy: 0.6202 - val_precision: 0.6202 - val_recall: 0.6202 - val_auc: 0.6202
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-8448000-8704000
[INFO] processing batch 8704000-8960000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1879 - tp: 188028.0000 - fp: 3972.0000 - tn: 188028.0000 - fn: 3972.0000 - accuracy: 0.9793 - precision: 0.9793 - recall: 0.9793 - auc: 0.9793 - val_loss: 0.1331 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-8704000-8960000
[INFO] processing batch 8960000-9216000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1174 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1034 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-8960000-9216000
[INFO] processing batch 9216000-9472000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.8600 - tp: 120440.0000 - fp: 71560.0000 - tn: 120440.0000 - fn: 71560.0000 - accuracy: 0.6273 - precision: 0.6273 - recall: 0.6273 - auc: 0.6276 - val_loss: 0.1688 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-9216000-9472000
[INFO] processing batch 9472000-9728000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.4373 - tp: 161553.0000 - fp: 30447.0000 - tn: 161553.0000 - fn: 30447.0000 - accuracy: 0.8414 - precision: 0.8414 - recall: 0.8414 - auc: 0.8414 - val_loss: 0.4474 - val_tp: 53468.0000 - val_fp: 10532.0000 - val_tn: 53468.0000 - val_fn: 10532.0000 - val_accuracy: 0.8354 - val_precision: 0.8354 - val_recall: 0.8354 - val_auc: 0.8354
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-9472000-9728000
[INFO] processing batch 9728000-9984000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1472 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1261 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-9728000-9984000
[INFO] processing batch 9984000-10240000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1106 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0971 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-9984000-10240000
[INFO] processing batch 10240000-10496000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1188 - tp: 189510.0000 - fp: 2490.0000 - tn: 189510.0000 - fn: 2490.0000 - accuracy: 0.9870 - precision: 0.9870 - recall: 0.9870 - auc: 0.9869 - val_loss: 1.2488 - val_tp: 33975.0000 - val_fp: 30025.0000 - val_tn: 33975.0000 - val_fn: 30025.0000 - val_accuracy: 0.5309 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.5309
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-10240000-10496000
[INFO] processing batch 10496000-10752000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 1.1045 - tp: 101670.0000 - fp: 90330.0000 - tn: 101670.0000 - fn: 90330.0000 - accuracy: 0.5295 - precision: 0.5295 - recall: 0.5295 - auc: 0.5295 - val_loss: 0.9851 - val_tp: 34015.0000 - val_fp: 29985.0000 - val_tn: 34015.0000 - val_fn: 29985.0000 - val_accuracy: 0.5315 - val_precision: 0.5315 - val_recall: 0.5315 - val_auc: 0.5315
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-10496000-10752000
[INFO] processing batch 10752000-11008000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.9149 - tp: 101693.0000 - fp: 90307.0000 - tn: 101693.0000 - fn: 90307.0000 - accuracy: 0.5297 - precision: 0.5297 - recall: 0.5297 - auc: 0.5295 - val_loss: 0.3830 - val_tp: 56989.0000 - val_fp: 7011.0000 - val_tn: 56989.0000 - val_fn: 7011.0000 - val_accuracy: 0.8905 - val_precision: 0.8905 - val_recall: 0.8905 - val_auc: 0.8905
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-10752000-11008000
[INFO] processing batch 11008000-11264000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.2127 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1857 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-11008000-11264000
[INFO] processing batch 11264000-11520000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1648 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1461 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-11264000-11520000
[INFO] processing batch 11520000-11776000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1310 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1173 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-11520000-11776000
[INFO] processing batch 11776000-12032000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.4989 - tp: 156412.0000 - fp: 35588.0000 - tn: 156412.0000 - fn: 35588.0000 - accuracy: 0.8146 - precision: 0.8146 - recall: 0.8146 - auc: 0.8148 - val_loss: 0.8284 - val_tp: 41134.0000 - val_fp: 22866.0000 - val_tn: 41134.0000 - val_fn: 22866.0000 - val_accuracy: 0.6427 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.6427
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-11776000-12032000
[INFO] processing batch 12032000-12288000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.7780 - tp: 123527.0000 - fp: 68473.0000 - tn: 123527.0000 - fn: 68473.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6434 - val_loss: 0.7355 - val_tp: 41219.0000 - val_fp: 22781.0000 - val_tn: 41219.0000 - val_fn: 22781.0000 - val_accuracy: 0.6440 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.6440
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-12032000-12288000
[INFO] processing batch 12288000-12544000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.7096 - tp: 123560.0000 - fp: 68440.0000 - tn: 123560.0000 - fn: 68440.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6867 - val_tp: 41268.0000 - val_fp: 22732.0000 - val_tn: 41268.0000 - val_fn: 22732.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-12288000-12544000
[INFO] processing batch 12544000-12800000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6749 - tp: 123588.0000 - fp: 68412.0000 - tn: 123588.0000 - fn: 68412.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6441 - val_loss: 0.6638 - val_tp: 41269.0000 - val_fp: 22731.0000 - val_tn: 41269.0000 - val_fn: 22731.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-12544000-12800000
[INFO] processing batch 12800000-13056000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6596 - tp: 123531.0000 - fp: 68469.0000 - tn: 123531.0000 - fn: 68469.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6437 - val_loss: 0.6555 - val_tp: 41181.0000 - val_fp: 22819.0000 - val_tn: 41181.0000 - val_fn: 22819.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-12800000-13056000
[INFO] processing batch 13056000-13312000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6534 - tp: 123615.0000 - fp: 68385.0000 - tn: 123615.0000 - fn: 68385.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6436 - val_loss: 0.6523 - val_tp: 41192.0000 - val_fp: 22808.0000 - val_tn: 41192.0000 - val_fn: 22808.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-13056000-13312000
[INFO] processing batch 13312000-13568000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6522 - tp: 123437.0000 - fp: 68563.0000 - tn: 123437.0000 - fn: 68563.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6433 - val_loss: 0.6516 - val_tp: 41179.0000 - val_fp: 22821.0000 - val_tn: 41179.0000 - val_fn: 22821.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-13312000-13568000
[INFO] processing batch 13568000-13824000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123539.0000 - fp: 68461.0000 - tn: 123539.0000 - fn: 68461.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6434 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-13568000-13824000
[INFO] processing batch 13824000-14080000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6514 - tp: 123556.0000 - fp: 68444.0000 - tn: 123556.0000 - fn: 68444.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6515 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 41173.0000 - val_fn: 22827.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-13824000-14080000
[INFO] processing batch 14080000-14336000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6510 - tp: 123681.0000 - fp: 68319.0000 - tn: 123681.0000 - fn: 68319.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6510 - val_tp: 41221.0000 - val_fp: 22779.0000 - val_tn: 41221.0000 - val_fn: 22779.0000 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.6441
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-14080000-14336000
[INFO] processing batch 14336000-14592000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123523.0000 - fp: 68477.0000 - tn: 123523.0000 - fn: 68477.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6431 - val_loss: 0.6513 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 41197.0000 - val_fn: 22803.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-14336000-14592000
[INFO] processing batch 14592000-14848000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6511 - tp: 123652.0000 - fp: 68348.0000 - tn: 123652.0000 - fn: 68348.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6439 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-14592000-14848000
[INFO] processing batch 14848000-15104000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6513 - tp: 123594.0000 - fp: 68406.0000 - tn: 123594.0000 - fn: 68406.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6512 - val_tp: 41205.0000 - val_fp: 22795.0000 - val_tn: 41205.0000 - val_fn: 22795.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-14848000-15104000
[INFO] processing batch 15104000-15360000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123629.0000 - fp: 68371.0000 - tn: 123629.0000 - fn: 68371.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6509 - val_tp: 41234.0000 - val_fp: 22766.0000 - val_tn: 41234.0000 - val_fn: 22766.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-15104000-15360000
[INFO] processing batch 15360000-15616000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6511 - tp: 123632.0000 - fp: 68368.0000 - tn: 123632.0000 - fn: 68368.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6506 - val_tp: 41266.0000 - val_fp: 22734.0000 - val_tn: 41266.0000 - val_fn: 22734.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-15360000-15616000
[INFO] processing batch 15616000-15872000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123527.0000 - fp: 68473.0000 - tn: 123527.0000 - fn: 68473.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6431 - val_loss: 0.6513 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 41197.0000 - val_fn: 22803.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-15616000-15872000
[INFO] processing batch 15872000-16128000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6514 - tp: 123531.0000 - fp: 68469.0000 - tn: 123531.0000 - fn: 68469.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6436 - val_loss: 0.6515 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 41173.0000 - val_fn: 22827.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-15872000-16128000
[INFO] processing batch 16128000-16384000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6507 - tp: 123781.0000 - fp: 68219.0000 - tn: 123781.0000 - fn: 68219.0000 - accuracy: 0.6447 - precision: 0.6447 - recall: 0.6447 - auc: 0.6447 - val_loss: 0.6513 - val_tp: 41195.0000 - val_fp: 22805.0000 - val_tn: 41195.0000 - val_fn: 22805.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-16128000-16384000
[INFO] processing batch 16384000-16640000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123621.0000 - fp: 68379.0000 - tn: 123621.0000 - fn: 68379.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6437 - val_loss: 0.6516 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 41165.0000 - val_fn: 22835.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-16384000-16640000
[INFO] processing batch 16640000-16896000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6518 - tp: 123417.0000 - fp: 68583.0000 - tn: 123417.0000 - fn: 68583.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6423 - val_loss: 0.6510 - val_tp: 41230.0000 - val_fp: 22770.0000 - val_tn: 41230.0000 - val_fn: 22770.0000 - val_accuracy: 0.6442 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.6442
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-16640000-16896000
[INFO] processing batch 16896000-17152000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6512 - tp: 123600.0000 - fp: 68400.0000 - tn: 123600.0000 - fn: 68400.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6437 - val_loss: 0.6513 - val_tp: 41198.0000 - val_fp: 22802.0000 - val_tn: 41198.0000 - val_fn: 22802.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-16896000-17152000
[INFO] processing batch 17152000-17408000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123711.0000 - fp: 68289.0000 - tn: 123711.0000 - fn: 68289.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6451 - val_loss: 0.6515 - val_tp: 41168.0000 - val_fp: 22832.0000 - val_tn: 41168.0000 - val_fn: 22832.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-17152000-17408000
[INFO] processing batch 17408000-17664000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6509 - tp: 123701.0000 - fp: 68299.0000 - tn: 123701.0000 - fn: 68299.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6443 - val_loss: 0.6520 - val_tp: 41118.0000 - val_fp: 22882.0000 - val_tn: 41118.0000 - val_fn: 22882.0000 - val_accuracy: 0.6425 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.6425
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-17408000-17664000
[INFO] processing batch 17664000-17920000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123546.0000 - fp: 68454.0000 - tn: 123546.0000 - fn: 68454.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6522 - val_tp: 41089.0000 - val_fp: 22911.0000 - val_tn: 41089.0000 - val_fn: 22911.0000 - val_accuracy: 0.6420 - val_precision: 0.6420 - val_recall: 0.6420 - val_auc: 0.6420
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-17664000-17920000
[INFO] processing batch 17920000-18176000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123681.0000 - fp: 68319.0000 - tn: 123681.0000 - fn: 68319.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6441 - val_loss: 0.6509 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 41233.0000 - val_fn: 22767.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-17920000-18176000
[INFO] processing batch 18176000-18432000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6511 - tp: 123640.0000 - fp: 68360.0000 - tn: 123640.0000 - fn: 68360.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6436 - val_loss: 0.6503 - val_tp: 41298.0000 - val_fp: 22702.0000 - val_tn: 41298.0000 - val_fn: 22702.0000 - val_accuracy: 0.6453 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.6453
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-18176000-18432000
[INFO] processing batch 18432000-18688000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6512 - tp: 123615.0000 - fp: 68385.0000 - tn: 123615.0000 - fn: 68385.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6437 - val_loss: 0.6509 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 41233.0000 - val_fn: 22767.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-18432000-18688000
[INFO] processing batch 18688000-18944000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6511 - tp: 123645.0000 - fp: 68355.0000 - tn: 123645.0000 - fn: 68355.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6436 - val_loss: 0.6514 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 41184.0000 - val_fn: 22816.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-18688000-18944000
[INFO] processing batch 18944000-19200000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6503 - tp: 123888.0000 - fp: 68112.0000 - tn: 123888.0000 - fn: 68112.0000 - accuracy: 0.6453 - precision: 0.6453 - recall: 0.6453 - auc: 0.6453 - val_loss: 0.6515 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 41169.0000 - val_fn: 22831.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-18944000-19200000
[INFO] processing batch 19200000-19456000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123500.0000 - fp: 68500.0000 - tn: 123500.0000 - fn: 68500.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6433 - val_loss: 0.6513 - val_tp: 41189.0000 - val_fp: 22811.0000 - val_tn: 41189.0000 - val_fn: 22811.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-19200000-19456000
[INFO] processing batch 19456000-19712000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6510 - tp: 123689.0000 - fp: 68311.0000 - tn: 123689.0000 - fn: 68311.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6445 - val_loss: 0.6516 - val_tp: 41166.0000 - val_fp: 22834.0000 - val_tn: 41166.0000 - val_fn: 22834.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-19456000-19712000
[INFO] processing batch 19712000-19968000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6518 - tp: 123402.0000 - fp: 68598.0000 - tn: 123402.0000 - fn: 68598.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6428 - val_loss: 0.6508 - val_tp: 41242.0000 - val_fp: 22758.0000 - val_tn: 41242.0000 - val_fn: 22758.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-19712000-19968000
[INFO] processing batch 19968000-20224000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6514 - tp: 123541.0000 - fp: 68459.0000 - tn: 123541.0000 - fn: 68459.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6434 - val_loss: 0.6509 - val_tp: 41241.0000 - val_fp: 22759.0000 - val_tn: 41241.0000 - val_fn: 22759.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-19968000-20224000
[INFO] processing batch 20224000-20480000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6511 - tp: 123640.0000 - fp: 68360.0000 - tn: 123640.0000 - fn: 68360.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6438 - val_loss: 0.6511 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 41209.0000 - val_fn: 22791.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-20224000-20480000
[INFO] processing batch 20480000-20736000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123598.0000 - fp: 68402.0000 - tn: 123598.0000 - fn: 68402.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6436 - val_loss: 0.6509 - val_tp: 41235.0000 - val_fp: 22765.0000 - val_tn: 41235.0000 - val_fn: 22765.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-20480000-20736000
[INFO] processing batch 20736000-20992000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6507 - tp: 123769.0000 - fp: 68231.0000 - tn: 123769.0000 - fn: 68231.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-20736000-20992000
[INFO] processing batch 20992000-21248000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6517 - tp: 123459.0000 - fp: 68541.0000 - tn: 123459.0000 - fn: 68541.0000 - accuracy: 0.6430 - precision: 0.6430 - recall: 0.6430 - auc: 0.6429 - val_loss: 0.6511 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 41209.0000 - val_fn: 22791.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-20992000-21248000
[INFO] processing batch 21248000-21504000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123683.0000 - fp: 68317.0000 - tn: 123683.0000 - fn: 68317.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6514 - val_tp: 41183.0000 - val_fp: 22817.0000 - val_tn: 41183.0000 - val_fn: 22817.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-21248000-21504000
[INFO] processing batch 21504000-21760000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6513 - tp: 123564.0000 - fp: 68436.0000 - tn: 123564.0000 - fn: 68436.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6432 - val_loss: 0.6507 - val_tp: 41254.0000 - val_fp: 22746.0000 - val_tn: 41254.0000 - val_fn: 22746.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-21504000-21760000
[INFO] processing batch 21760000-22016000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123717.0000 - fp: 68283.0000 - tn: 123717.0000 - fn: 68283.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6442 - val_loss: 0.6506 - val_tp: 41270.0000 - val_fp: 22730.0000 - val_tn: 41270.0000 - val_fn: 22730.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-21760000-22016000
[INFO] processing batch 22016000-22272000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123690.0000 - fp: 68310.0000 - tn: 123690.0000 - fn: 68310.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6521 - val_tp: 41104.0000 - val_fp: 22896.0000 - val_tn: 41104.0000 - val_fn: 22896.0000 - val_accuracy: 0.6423 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-22016000-22272000
[INFO] processing batch 22272000-22528000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123672.0000 - fp: 68328.0000 - tn: 123672.0000 - fn: 68328.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6436 - val_loss: 0.6508 - val_tp: 41243.0000 - val_fp: 22757.0000 - val_tn: 41243.0000 - val_fn: 22757.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-22272000-22528000
[INFO] processing batch 22528000-22784000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123623.0000 - fp: 68377.0000 - tn: 123623.0000 - fn: 68377.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6437 - val_loss: 0.6504 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 41292.0000 - val_fn: 22708.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-22528000-22784000
[INFO] processing batch 22784000-23040000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6507 - tp: 123759.0000 - fp: 68241.0000 - tn: 123759.0000 - fn: 68241.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6442 - val_loss: 0.6514 - val_tp: 41180.0000 - val_fp: 22820.0000 - val_tn: 41180.0000 - val_fn: 22820.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-22784000-23040000
[INFO] processing batch 23040000-23296000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123507.0000 - fp: 68493.0000 - tn: 123507.0000 - fn: 68493.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6434 - val_loss: 0.6507 - val_tp: 41255.0000 - val_fp: 22745.0000 - val_tn: 41255.0000 - val_fn: 22745.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-23040000-23296000
[INFO] processing batch 23296000-23552000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123601.0000 - fp: 68399.0000 - tn: 123601.0000 - fn: 68399.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6435 - val_loss: 0.6511 - val_tp: 41213.0000 - val_fp: 22787.0000 - val_tn: 41213.0000 - val_fn: 22787.0000 - val_accuracy: 0.6440 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.6440
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-23296000-23552000
[INFO] processing batch 23552000-23808000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6508 - tp: 123749.0000 - fp: 68251.0000 - tn: 123749.0000 - fn: 68251.0000 - accuracy: 0.6445 - precision: 0.6445 - recall: 0.6445 - auc: 0.6445 - val_loss: 0.6504 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 41292.0000 - val_fn: 22708.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-23552000-23808000
[INFO] processing batch 23808000-24064000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123603.0000 - fp: 68397.0000 - tn: 123603.0000 - fn: 68397.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6435 - val_loss: 0.6516 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 41165.0000 - val_fn: 22835.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-23808000-24064000
[INFO] processing batch 24064000-24320000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123599.0000 - fp: 68401.0000 - tn: 123599.0000 - fn: 68401.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6438 - val_loss: 0.6514 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 41184.0000 - val_fn: 22816.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-24064000-24320000
[INFO] processing batch 24320000-24576000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6517 - tp: 123440.0000 - fp: 68560.0000 - tn: 123440.0000 - fn: 68560.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6431 - val_loss: 0.6515 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 41169.0000 - val_fn: 22831.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-24320000-24576000
[33m[LOSS] 0.6515167264938354[0m
[33m[INFO] epoch 2/10[0m
[33m[INFO] loading file 1-50/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (24819975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] Shape when encoding dataset: (24819975, 17)
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
missing -1
len(df.columns) 108
numFeatures 107
[INFO] Shape AFTER encoding dataset: (24819975, 108)
[INFO] processing batch 0-256000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.2733 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1954 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-0-256000
[INFO] processing batch 256000-512000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.7756 - tp: 112918.0000 - fp: 79082.0000 - tn: 112918.0000 - fn: 79082.0000 - accuracy: 0.5881 - precision: 0.5881 - recall: 0.5881 - auc: 0.5893 - val_loss: 0.7957 - val_tp: 33927.0000 - val_fp: 30073.0000 - val_tn: 33927.0000 - val_fn: 30073.0000 - val_accuracy: 0.5301 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-256000-512000
[INFO] processing batch 512000-768000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5935 - tp: 138284.0000 - fp: 53716.0000 - tn: 138284.0000 - fn: 53716.0000 - accuracy: 0.7202 - precision: 0.7202 - recall: 0.7202 - auc: 0.7198 - val_loss: 0.3414 - val_tp: 62058.0000 - val_fp: 1942.0000 - val_tn: 62058.0000 - val_fn: 1942.0000 - val_accuracy: 0.9697 - val_precision: 0.9697 - val_recall: 0.9697 - val_auc: 0.9697
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-512000-768000
[INFO] processing batch 768000-1024000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6890 - tp: 117250.0000 - fp: 74750.0000 - tn: 117250.0000 - fn: 74750.0000 - accuracy: 0.6107 - precision: 0.6107 - recall: 0.6107 - auc: 0.6101 - val_loss: 0.4872 - val_tp: 55591.0000 - val_fp: 8409.0000 - val_tn: 55591.0000 - val_fn: 8409.0000 - val_accuracy: 0.8686 - val_precision: 0.8686 - val_recall: 0.8686 - val_auc: 0.8686
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-768000-1024000
[INFO] processing batch 1024000-1280000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6134 - tp: 133967.0000 - fp: 58033.0000 - tn: 133967.0000 - fn: 58033.0000 - accuracy: 0.6977 - precision: 0.6977 - recall: 0.6977 - auc: 0.6955 - val_loss: 0.3759 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-1024000-1280000
[INFO] processing batch 1280000-1536000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.2803 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2154 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-1280000-1536000
[INFO] processing batch 1536000-1792000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1803 - tp: 191999.0000 - fp: 1.0000 - tn: 191999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1518 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-1536000-1792000
[INFO] processing batch 1792000-2048000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5574 - tp: 148221.0000 - fp: 43779.0000 - tn: 148221.0000 - fn: 43779.0000 - accuracy: 0.7720 - precision: 0.7720 - recall: 0.7720 - auc: 0.7714 - val_loss: 0.3331 - val_tp: 57941.0000 - val_fp: 6059.0000 - val_tn: 57941.0000 - val_fn: 6059.0000 - val_accuracy: 0.9053 - val_precision: 0.9053 - val_recall: 0.9053 - val_auc: 0.9053
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-1792000-2048000
[INFO] processing batch 2048000-2304000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5959 - tp: 141714.0000 - fp: 50286.0000 - tn: 141714.0000 - fn: 50286.0000 - accuracy: 0.7381 - precision: 0.7381 - recall: 0.7381 - auc: 0.7384 - val_loss: 0.2187 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-2048000-2304000
[INFO] processing batch 2304000-2560000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1794 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1469 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-2304000-2560000
[INFO] processing batch 2560000-2816000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1260 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1084 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-2560000-2816000
[INFO] processing batch 2816000-3072000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5804 - tp: 148720.0000 - fp: 43280.0000 - tn: 148720.0000 - fn: 43280.0000 - accuracy: 0.7746 - precision: 0.7746 - recall: 0.7746 - auc: 0.7761 - val_loss: 0.8166 - val_tp: 40961.0000 - val_fp: 23039.0000 - val_tn: 40961.0000 - val_fn: 23039.0000 - val_accuracy: 0.6400 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.6400
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-2816000-3072000
[INFO] processing batch 3072000-3328000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6961 - tp: 131495.0000 - fp: 60505.0000 - tn: 131495.0000 - fn: 60505.0000 - accuracy: 0.6849 - precision: 0.6849 - recall: 0.6849 - auc: 0.6847 - val_loss: 0.2115 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-3072000-3328000
[INFO] processing batch 3328000-3584000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1761 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1456 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-3328000-3584000
[INFO] processing batch 3584000-3840000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1254 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1082 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-3584000-3840000
[INFO] processing batch 3840000-4096000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4911 - tp: 157534.0000 - fp: 34466.0000 - tn: 157534.0000 - fn: 34466.0000 - accuracy: 0.8205 - precision: 0.8205 - recall: 0.8205 - auc: 0.8212 - val_loss: 0.4938 - val_tp: 52219.0000 - val_fp: 11781.0000 - val_tn: 52219.0000 - val_fn: 11781.0000 - val_accuracy: 0.8159 - val_precision: 0.8159 - val_recall: 0.8159 - val_auc: 0.8159
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-3840000-4096000
[INFO] processing batch 4096000-4352000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1328 - tp: 190188.0000 - fp: 1812.0000 - tn: 190188.0000 - fn: 1812.0000 - accuracy: 0.9906 - precision: 0.9906 - recall: 0.9906 - auc: 0.9906 - val_loss: 0.0973 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-4096000-4352000
[INFO] processing batch 4352000-4608000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0850 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0743 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-4352000-4608000
[INFO] processing batch 4608000-4864000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4710 - tp: 161451.0000 - fp: 30549.0000 - tn: 161451.0000 - fn: 30549.0000 - accuracy: 0.8409 - precision: 0.8409 - recall: 0.8409 - auc: 0.8417 - val_loss: 0.0967 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-4608000-4864000
[INFO] processing batch 4864000-5120000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0841 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0724 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-4864000-5120000
[INFO] processing batch 5120000-5376000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0637 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0561 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-5120000-5376000
[INFO] processing batch 5376000-5632000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0502 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0448 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-5376000-5632000
[INFO] processing batch 5632000-5888000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5879 - tp: 155809.0000 - fp: 36191.0000 - tn: 155809.0000 - fn: 36191.0000 - accuracy: 0.8115 - precision: 0.8115 - recall: 0.8115 - auc: 0.8113 - val_loss: 0.0755 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-5632000-5888000
[INFO] processing batch 5888000-6144000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0676 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0595 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-5888000-6144000
[INFO] processing batch 6144000-6400000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.3169 - tp: 174156.0000 - fp: 17844.0000 - tn: 174156.0000 - fn: 17844.0000 - accuracy: 0.9071 - precision: 0.9071 - recall: 0.9071 - auc: 0.9075 - val_loss: 1.0182 - val_tp: 41108.0000 - val_fp: 22892.0000 - val_tn: 41108.0000 - val_fn: 22892.0000 - val_accuracy: 0.6423 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-6144000-6400000
[INFO] processing batch 6400000-6656000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.7345 - tp: 138766.0000 - fp: 53234.0000 - tn: 138766.0000 - fn: 53234.0000 - accuracy: 0.7227 - precision: 0.7227 - recall: 0.7227 - auc: 0.7226 - val_loss: 0.1267 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-6400000-6656000
[INFO] processing batch 6656000-6912000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1104 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0948 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-6656000-6912000
[INFO] processing batch 6912000-7168000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.0833 - tp: 191998.0000 - fp: 2.0000 - tn: 191998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0732 - val_tp: 63999.0000 - val_fp: 1.0000 - val_tn: 63999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-6912000-7168000
[INFO] processing batch 7168000-7424000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0653 - tp: 191999.0000 - fp: 1.0000 - tn: 191999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9225 - val_tp: 44344.0000 - val_fp: 19656.0000 - val_tn: 44344.0000 - val_fn: 19656.0000 - val_accuracy: 0.6929 - val_precision: 0.6929 - val_recall: 0.6929 - val_auc: 0.6929
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-7168000-7424000
[INFO] processing batch 7424000-7680000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 1.1982 - tp: 102062.0000 - fp: 89938.0000 - tn: 102062.0000 - fn: 89938.0000 - accuracy: 0.5316 - precision: 0.5316 - recall: 0.5316 - auc: 0.5314 - val_loss: 0.5689 - val_tp: 49859.0000 - val_fp: 14141.0000 - val_tn: 49859.0000 - val_fn: 14141.0000 - val_accuracy: 0.7790 - val_precision: 0.7790 - val_recall: 0.7790 - val_auc: 0.7790
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-7424000-7680000
[INFO] processing batch 7680000-7936000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1177 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1071 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-7680000-7936000
[INFO] processing batch 7936000-8192000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0980 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0894 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-7936000-8192000
[INFO] processing batch 8192000-8448000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4576 - tp: 161781.0000 - fp: 30219.0000 - tn: 161781.0000 - fn: 30219.0000 - accuracy: 0.8426 - precision: 0.8426 - recall: 0.8426 - auc: 0.8429 - val_loss: 0.1248 - val_tp: 63369.0000 - val_fp: 631.0000 - val_tn: 63369.0000 - val_fn: 631.0000 - val_accuracy: 0.9901 - val_precision: 0.9901 - val_recall: 0.9901 - val_auc: 0.9901
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-8192000-8448000
[INFO] processing batch 8448000-8704000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.8323 - tp: 123282.0000 - fp: 68718.0000 - tn: 123282.0000 - fn: 68718.0000 - accuracy: 0.6421 - precision: 0.6421 - recall: 0.6421 - auc: 0.6428 - val_loss: 0.8143 - val_tp: 39692.0000 - val_fp: 24308.0000 - val_tn: 39692.0000 - val_fn: 24308.0000 - val_accuracy: 0.6202 - val_precision: 0.6202 - val_recall: 0.6202 - val_auc: 0.6202
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-8448000-8704000
[INFO] processing batch 8704000-8960000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1879 - tp: 188028.0000 - fp: 3972.0000 - tn: 188028.0000 - fn: 3972.0000 - accuracy: 0.9793 - precision: 0.9793 - recall: 0.9793 - auc: 0.9795 - val_loss: 0.1331 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-8704000-8960000
[INFO] processing batch 8960000-9216000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1174 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1034 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-8960000-9216000
[INFO] processing batch 9216000-9472000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.8602 - tp: 120440.0000 - fp: 71560.0000 - tn: 120440.0000 - fn: 71560.0000 - accuracy: 0.6273 - precision: 0.6273 - recall: 0.6273 - auc: 0.6269 - val_loss: 0.1686 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-9216000-9472000
[INFO] processing batch 9472000-9728000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4373 - tp: 161553.0000 - fp: 30447.0000 - tn: 161553.0000 - fn: 30447.0000 - accuracy: 0.8414 - precision: 0.8414 - recall: 0.8414 - auc: 0.8415 - val_loss: 0.4474 - val_tp: 53468.0000 - val_fp: 10532.0000 - val_tn: 53468.0000 - val_fn: 10532.0000 - val_accuracy: 0.8354 - val_precision: 0.8354 - val_recall: 0.8354 - val_auc: 0.8354
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-9472000-9728000
[INFO] processing batch 9728000-9984000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1471 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1260 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-9728000-9984000
[INFO] processing batch 9984000-10240000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1106 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0971 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-9984000-10240000
[INFO] processing batch 10240000-10496000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1188 - tp: 189510.0000 - fp: 2490.0000 - tn: 189510.0000 - fn: 2490.0000 - accuracy: 0.9870 - precision: 0.9870 - recall: 0.9870 - auc: 0.9870 - val_loss: 1.2489 - val_tp: 33975.0000 - val_fp: 30025.0000 - val_tn: 33975.0000 - val_fn: 30025.0000 - val_accuracy: 0.5309 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.5309
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-10240000-10496000
[INFO] processing batch 10496000-10752000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 1.1044 - tp: 101670.0000 - fp: 90330.0000 - tn: 101670.0000 - fn: 90330.0000 - accuracy: 0.5295 - precision: 0.5295 - recall: 0.5295 - auc: 0.5296 - val_loss: 0.9851 - val_tp: 34015.0000 - val_fp: 29985.0000 - val_tn: 34015.0000 - val_fn: 29985.0000 - val_accuracy: 0.5315 - val_precision: 0.5315 - val_recall: 0.5315 - val_auc: 0.5315
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-10496000-10752000
[INFO] processing batch 10752000-11008000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.9149 - tp: 101693.0000 - fp: 90307.0000 - tn: 101693.0000 - fn: 90307.0000 - accuracy: 0.5297 - precision: 0.5297 - recall: 0.5297 - auc: 0.5291 - val_loss: 0.3829 - val_tp: 56989.0000 - val_fp: 7011.0000 - val_tn: 56989.0000 - val_fn: 7011.0000 - val_accuracy: 0.8905 - val_precision: 0.8905 - val_recall: 0.8905 - val_auc: 0.8905
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-10752000-11008000
[INFO] processing batch 11008000-11264000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.2127 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1857 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-11008000-11264000
[INFO] processing batch 11264000-11520000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1648 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1461 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-11264000-11520000
[INFO] processing batch 11520000-11776000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1310 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1173 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-11520000-11776000
[INFO] processing batch 11776000-12032000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4990 - tp: 156412.0000 - fp: 35588.0000 - tn: 156412.0000 - fn: 35588.0000 - accuracy: 0.8146 - precision: 0.8146 - recall: 0.8146 - auc: 0.8134 - val_loss: 0.8286 - val_tp: 41134.0000 - val_fp: 22866.0000 - val_tn: 41134.0000 - val_fn: 22866.0000 - val_accuracy: 0.6427 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.6427
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-11776000-12032000
[INFO] processing batch 12032000-12288000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.7782 - tp: 123527.0000 - fp: 68473.0000 - tn: 123527.0000 - fn: 68473.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6428 - val_loss: 0.7356 - val_tp: 41219.0000 - val_fp: 22781.0000 - val_tn: 41219.0000 - val_fn: 22781.0000 - val_accuracy: 0.6440 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.6440
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-12032000-12288000
[INFO] processing batch 12288000-12544000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.7097 - tp: 123560.0000 - fp: 68440.0000 - tn: 123560.0000 - fn: 68440.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6436 - val_loss: 0.6868 - val_tp: 41268.0000 - val_fp: 22732.0000 - val_tn: 41268.0000 - val_fn: 22732.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-12288000-12544000
[INFO] processing batch 12544000-12800000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6750 - tp: 123588.0000 - fp: 68412.0000 - tn: 123588.0000 - fn: 68412.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6439 - val_loss: 0.6638 - val_tp: 41269.0000 - val_fp: 22731.0000 - val_tn: 41269.0000 - val_fn: 22731.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-12544000-12800000
[INFO] processing batch 12800000-13056000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6596 - tp: 123531.0000 - fp: 68469.0000 - tn: 123531.0000 - fn: 68469.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6435 - val_loss: 0.6555 - val_tp: 41181.0000 - val_fp: 22819.0000 - val_tn: 41181.0000 - val_fn: 22819.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-12800000-13056000
[INFO] processing batch 13056000-13312000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6534 - tp: 123615.0000 - fp: 68385.0000 - tn: 123615.0000 - fn: 68385.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6446 - val_loss: 0.6523 - val_tp: 41192.0000 - val_fp: 22808.0000 - val_tn: 41192.0000 - val_fn: 22808.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-13056000-13312000
[INFO] processing batch 13312000-13568000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6522 - tp: 123437.0000 - fp: 68563.0000 - tn: 123437.0000 - fn: 68563.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6429 - val_loss: 0.6516 - val_tp: 41179.0000 - val_fp: 22821.0000 - val_tn: 41179.0000 - val_fn: 22821.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-13312000-13568000
[INFO] processing batch 13568000-13824000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123539.0000 - fp: 68461.0000 - tn: 123539.0000 - fn: 68461.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6435 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-13568000-13824000
[INFO] processing batch 13824000-14080000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123556.0000 - fp: 68444.0000 - tn: 123556.0000 - fn: 68444.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6515 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 41173.0000 - val_fn: 22827.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-13824000-14080000
[INFO] processing batch 14080000-14336000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123681.0000 - fp: 68319.0000 - tn: 123681.0000 - fn: 68319.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6510 - val_tp: 41221.0000 - val_fp: 22779.0000 - val_tn: 41221.0000 - val_fn: 22779.0000 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.6441
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-14080000-14336000
[INFO] processing batch 14336000-14592000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123523.0000 - fp: 68477.0000 - tn: 123523.0000 - fn: 68477.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6433 - val_loss: 0.6513 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 41197.0000 - val_fn: 22803.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-14336000-14592000
[INFO] processing batch 14592000-14848000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123652.0000 - fp: 68348.0000 - tn: 123652.0000 - fn: 68348.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6440 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-14592000-14848000
[INFO] processing batch 14848000-15104000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6513 - tp: 123594.0000 - fp: 68406.0000 - tn: 123594.0000 - fn: 68406.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6435 - val_loss: 0.6512 - val_tp: 41205.0000 - val_fp: 22795.0000 - val_tn: 41205.0000 - val_fn: 22795.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-14848000-15104000
[INFO] processing batch 15104000-15360000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6511 - tp: 123629.0000 - fp: 68371.0000 - tn: 123629.0000 - fn: 68371.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6509 - val_tp: 41234.0000 - val_fp: 22766.0000 - val_tn: 41234.0000 - val_fn: 22766.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-15104000-15360000
[INFO] processing batch 15360000-15616000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123632.0000 - fp: 68368.0000 - tn: 123632.0000 - fn: 68368.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6438 - val_loss: 0.6506 - val_tp: 41266.0000 - val_fp: 22734.0000 - val_tn: 41266.0000 - val_fn: 22734.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-15360000-15616000
[INFO] processing batch 15616000-15872000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123527.0000 - fp: 68473.0000 - tn: 123527.0000 - fn: 68473.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6432 - val_loss: 0.6513 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 41197.0000 - val_fn: 22803.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-15616000-15872000
[INFO] processing batch 15872000-16128000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123531.0000 - fp: 68469.0000 - tn: 123531.0000 - fn: 68469.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6434 - val_loss: 0.6515 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 41173.0000 - val_fn: 22827.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-15872000-16128000
[INFO] processing batch 16128000-16384000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6507 - tp: 123781.0000 - fp: 68219.0000 - tn: 123781.0000 - fn: 68219.0000 - accuracy: 0.6447 - precision: 0.6447 - recall: 0.6447 - auc: 0.6447 - val_loss: 0.6513 - val_tp: 41195.0000 - val_fp: 22805.0000 - val_tn: 41195.0000 - val_fn: 22805.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-16128000-16384000
[INFO] processing batch 16384000-16640000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123621.0000 - fp: 68379.0000 - tn: 123621.0000 - fn: 68379.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6435 - val_loss: 0.6516 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 41165.0000 - val_fn: 22835.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-16384000-16640000
[INFO] processing batch 16640000-16896000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6518 - tp: 123417.0000 - fp: 68583.0000 - tn: 123417.0000 - fn: 68583.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6430 - val_loss: 0.6510 - val_tp: 41230.0000 - val_fp: 22770.0000 - val_tn: 41230.0000 - val_fn: 22770.0000 - val_accuracy: 0.6442 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.6442
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-16640000-16896000
[INFO] processing batch 16896000-17152000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123600.0000 - fp: 68400.0000 - tn: 123600.0000 - fn: 68400.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6442 - val_loss: 0.6512 - val_tp: 41198.0000 - val_fp: 22802.0000 - val_tn: 41198.0000 - val_fn: 22802.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-16896000-17152000
[INFO] processing batch 17152000-17408000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123711.0000 - fp: 68289.0000 - tn: 123711.0000 - fn: 68289.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6442 - val_loss: 0.6515 - val_tp: 41168.0000 - val_fp: 22832.0000 - val_tn: 41168.0000 - val_fn: 22832.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-17152000-17408000
[INFO] processing batch 17408000-17664000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123701.0000 - fp: 68299.0000 - tn: 123701.0000 - fn: 68299.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6441 - val_loss: 0.6520 - val_tp: 41118.0000 - val_fp: 22882.0000 - val_tn: 41118.0000 - val_fn: 22882.0000 - val_accuracy: 0.6425 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.6425
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-17408000-17664000
[INFO] processing batch 17664000-17920000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123546.0000 - fp: 68454.0000 - tn: 123546.0000 - fn: 68454.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6434 - val_loss: 0.6523 - val_tp: 41089.0000 - val_fp: 22911.0000 - val_tn: 41089.0000 - val_fn: 22911.0000 - val_accuracy: 0.6420 - val_precision: 0.6420 - val_recall: 0.6420 - val_auc: 0.6420
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-17664000-17920000
[INFO] processing batch 17920000-18176000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123681.0000 - fp: 68319.0000 - tn: 123681.0000 - fn: 68319.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6440 - val_loss: 0.6509 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 41233.0000 - val_fn: 22767.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-17920000-18176000
[INFO] processing batch 18176000-18432000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123640.0000 - fp: 68360.0000 - tn: 123640.0000 - fn: 68360.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6443 - val_loss: 0.6503 - val_tp: 41298.0000 - val_fp: 22702.0000 - val_tn: 41298.0000 - val_fn: 22702.0000 - val_accuracy: 0.6453 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.6453
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-18176000-18432000
[INFO] processing batch 18432000-18688000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123615.0000 - fp: 68385.0000 - tn: 123615.0000 - fn: 68385.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6433 - val_loss: 0.6509 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 41233.0000 - val_fn: 22767.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-18432000-18688000
[INFO] processing batch 18688000-18944000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123645.0000 - fp: 68355.0000 - tn: 123645.0000 - fn: 68355.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6439 - val_loss: 0.6514 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 41184.0000 - val_fn: 22816.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-18688000-18944000
[INFO] processing batch 18944000-19200000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6503 - tp: 123888.0000 - fp: 68112.0000 - tn: 123888.0000 - fn: 68112.0000 - accuracy: 0.6453 - precision: 0.6453 - recall: 0.6453 - auc: 0.6452 - val_loss: 0.6515 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 41169.0000 - val_fn: 22831.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-18944000-19200000
[INFO] processing batch 19200000-19456000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6515 - tp: 123500.0000 - fp: 68500.0000 - tn: 123500.0000 - fn: 68500.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6431 - val_loss: 0.6513 - val_tp: 41189.0000 - val_fp: 22811.0000 - val_tn: 41189.0000 - val_fn: 22811.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-19200000-19456000
[INFO] processing batch 19456000-19712000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123689.0000 - fp: 68311.0000 - tn: 123689.0000 - fn: 68311.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6443 - val_loss: 0.6515 - val_tp: 41166.0000 - val_fp: 22834.0000 - val_tn: 41166.0000 - val_fn: 22834.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-19456000-19712000
[INFO] processing batch 19712000-19968000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6518 - tp: 123402.0000 - fp: 68598.0000 - tn: 123402.0000 - fn: 68598.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6428 - val_loss: 0.6509 - val_tp: 41242.0000 - val_fp: 22758.0000 - val_tn: 41242.0000 - val_fn: 22758.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-19712000-19968000
[INFO] processing batch 19968000-20224000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123541.0000 - fp: 68459.0000 - tn: 123541.0000 - fn: 68459.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6433 - val_loss: 0.6509 - val_tp: 41241.0000 - val_fp: 22759.0000 - val_tn: 41241.0000 - val_fn: 22759.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-19968000-20224000
[INFO] processing batch 20224000-20480000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123640.0000 - fp: 68360.0000 - tn: 123640.0000 - fn: 68360.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6439 - val_loss: 0.6511 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 41209.0000 - val_fn: 22791.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-20224000-20480000
[INFO] processing batch 20480000-20736000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123598.0000 - fp: 68402.0000 - tn: 123598.0000 - fn: 68402.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6435 - val_loss: 0.6509 - val_tp: 41235.0000 - val_fp: 22765.0000 - val_tn: 41235.0000 - val_fn: 22765.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-20480000-20736000
[INFO] processing batch 20736000-20992000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6507 - tp: 123769.0000 - fp: 68231.0000 - tn: 123769.0000 - fn: 68231.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-20736000-20992000
[INFO] processing batch 20992000-21248000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6517 - tp: 123459.0000 - fp: 68541.0000 - tn: 123459.0000 - fn: 68541.0000 - accuracy: 0.6430 - precision: 0.6430 - recall: 0.6430 - auc: 0.6430 - val_loss: 0.6512 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 41209.0000 - val_fn: 22791.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-20992000-21248000
[INFO] processing batch 21248000-21504000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123683.0000 - fp: 68317.0000 - tn: 123683.0000 - fn: 68317.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6439 - val_loss: 0.6514 - val_tp: 41183.0000 - val_fp: 22817.0000 - val_tn: 41183.0000 - val_fn: 22817.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-21248000-21504000
[INFO] processing batch 21504000-21760000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6513 - tp: 123564.0000 - fp: 68436.0000 - tn: 123564.0000 - fn: 68436.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6434 - val_loss: 0.6507 - val_tp: 41254.0000 - val_fp: 22746.0000 - val_tn: 41254.0000 - val_fn: 22746.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-21504000-21760000
[INFO] processing batch 21760000-22016000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123717.0000 - fp: 68283.0000 - tn: 123717.0000 - fn: 68283.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6442 - val_loss: 0.6506 - val_tp: 41270.0000 - val_fp: 22730.0000 - val_tn: 41270.0000 - val_fn: 22730.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-21760000-22016000
[INFO] processing batch 22016000-22272000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123690.0000 - fp: 68310.0000 - tn: 123690.0000 - fn: 68310.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6521 - val_tp: 41104.0000 - val_fp: 22896.0000 - val_tn: 41104.0000 - val_fn: 22896.0000 - val_accuracy: 0.6423 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-22016000-22272000
[INFO] processing batch 22272000-22528000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123672.0000 - fp: 68328.0000 - tn: 123672.0000 - fn: 68328.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6443 - val_loss: 0.6508 - val_tp: 41243.0000 - val_fp: 22757.0000 - val_tn: 41243.0000 - val_fn: 22757.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-22272000-22528000
[INFO] processing batch 22528000-22784000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123623.0000 - fp: 68377.0000 - tn: 123623.0000 - fn: 68377.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6435 - val_loss: 0.6504 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 41292.0000 - val_fn: 22708.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-22528000-22784000
[INFO] processing batch 22784000-23040000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6507 - tp: 123759.0000 - fp: 68241.0000 - tn: 123759.0000 - fn: 68241.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6448 - val_loss: 0.6514 - val_tp: 41180.0000 - val_fp: 22820.0000 - val_tn: 41180.0000 - val_fn: 22820.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-22784000-23040000
[INFO] processing batch 23040000-23296000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123507.0000 - fp: 68493.0000 - tn: 123507.0000 - fn: 68493.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6427 - val_loss: 0.6507 - val_tp: 41255.0000 - val_fp: 22745.0000 - val_tn: 41255.0000 - val_fn: 22745.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-23040000-23296000
[INFO] processing batch 23296000-23552000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6512 - tp: 123601.0000 - fp: 68399.0000 - tn: 123601.0000 - fn: 68399.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6436 - val_loss: 0.6511 - val_tp: 41213.0000 - val_fp: 22787.0000 - val_tn: 41213.0000 - val_fn: 22787.0000 - val_accuracy: 0.6440 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.6440
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-23296000-23552000
[INFO] processing batch 23552000-23808000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6508 - tp: 123749.0000 - fp: 68251.0000 - tn: 123749.0000 - fn: 68251.0000 - accuracy: 0.6445 - precision: 0.6445 - recall: 0.6445 - auc: 0.6444 - val_loss: 0.6504 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 41292.0000 - val_fn: 22708.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-23552000-23808000
[INFO] processing batch 23808000-24064000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123603.0000 - fp: 68397.0000 - tn: 123603.0000 - fn: 68397.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6436 - val_loss: 0.6516 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 41165.0000 - val_fn: 22835.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-23808000-24064000
[INFO] processing batch 24064000-24320000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123599.0000 - fp: 68401.0000 - tn: 123599.0000 - fn: 68401.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6435 - val_loss: 0.6514 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 41184.0000 - val_fn: 22816.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-24064000-24320000
[INFO] processing batch 24320000-24576000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6517 - tp: 123440.0000 - fp: 68560.0000 - tn: 123440.0000 - fn: 68560.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6431 - val_loss: 0.6515 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 41169.0000 - val_fn: 22831.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-24320000-24576000
[33m[LOSS] 0.6515183000564575[0m
[33m[INFO] epoch 3/10[0m
[33m[INFO] loading file 1-50/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (24819975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] Shape when encoding dataset: (24819975, 17)
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
missing -1
len(df.columns) 108
numFeatures 107
[INFO] Shape AFTER encoding dataset: (24819975, 108)
[INFO] processing batch 0-256000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.2752 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1967 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-0-256000
[INFO] processing batch 256000-512000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.7748 - tp: 112918.0000 - fp: 79082.0000 - tn: 112918.0000 - fn: 79082.0000 - accuracy: 0.5881 - precision: 0.5881 - recall: 0.5881 - auc: 0.5877 - val_loss: 0.7953 - val_tp: 33927.0000 - val_fp: 30073.0000 - val_tn: 33927.0000 - val_fn: 30073.0000 - val_accuracy: 0.5301 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-256000-512000
[INFO] processing batch 512000-768000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5934 - tp: 138284.0000 - fp: 53716.0000 - tn: 138284.0000 - fn: 53716.0000 - accuracy: 0.7202 - precision: 0.7202 - recall: 0.7202 - auc: 0.7222 - val_loss: 0.3419 - val_tp: 62058.0000 - val_fp: 1942.0000 - val_tn: 62058.0000 - val_fn: 1942.0000 - val_accuracy: 0.9697 - val_precision: 0.9697 - val_recall: 0.9697 - val_auc: 0.9697
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-512000-768000
[INFO] processing batch 768000-1024000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6887 - tp: 117250.0000 - fp: 74750.0000 - tn: 117250.0000 - fn: 74750.0000 - accuracy: 0.6107 - precision: 0.6107 - recall: 0.6107 - auc: 0.6114 - val_loss: 0.4876 - val_tp: 55591.0000 - val_fp: 8409.0000 - val_tn: 55591.0000 - val_fn: 8409.0000 - val_accuracy: 0.8686 - val_precision: 0.8686 - val_recall: 0.8686 - val_auc: 0.8686
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-768000-1024000
[INFO] processing batch 1024000-1280000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6134 - tp: 133967.0000 - fp: 58033.0000 - tn: 133967.0000 - fn: 58033.0000 - accuracy: 0.6977 - precision: 0.6977 - recall: 0.6977 - auc: 0.6963 - val_loss: 0.3760 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-1024000-1280000
[INFO] processing batch 1280000-1536000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.2805 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2154 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-1280000-1536000
[INFO] processing batch 1536000-1792000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1803 - tp: 191999.0000 - fp: 1.0000 - tn: 191999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1519 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-1536000-1792000
[INFO] processing batch 1792000-2048000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5573 - tp: 148221.0000 - fp: 43779.0000 - tn: 148221.0000 - fn: 43779.0000 - accuracy: 0.7720 - precision: 0.7720 - recall: 0.7720 - auc: 0.7734 - val_loss: 0.3332 - val_tp: 57941.0000 - val_fp: 6059.0000 - val_tn: 57941.0000 - val_fn: 6059.0000 - val_accuracy: 0.9053 - val_precision: 0.9053 - val_recall: 0.9053 - val_auc: 0.9053
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-1792000-2048000
[INFO] processing batch 2048000-2304000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5958 - tp: 141714.0000 - fp: 50286.0000 - tn: 141714.0000 - fn: 50286.0000 - accuracy: 0.7381 - precision: 0.7381 - recall: 0.7381 - auc: 0.7384 - val_loss: 0.2190 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-2048000-2304000
[INFO] processing batch 2304000-2560000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1796 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1470 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-2304000-2560000
[INFO] processing batch 2560000-2816000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1261 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1084 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-2560000-2816000
[INFO] processing batch 2816000-3072000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.5804 - tp: 148720.0000 - fp: 43280.0000 - tn: 148720.0000 - fn: 43280.0000 - accuracy: 0.7746 - precision: 0.7746 - recall: 0.7746 - auc: 0.7744 - val_loss: 0.8169 - val_tp: 40961.0000 - val_fp: 23039.0000 - val_tn: 40961.0000 - val_fn: 23039.0000 - val_accuracy: 0.6400 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.6400
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-2816000-3072000
[INFO] processing batch 3072000-3328000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6962 - tp: 131495.0000 - fp: 60505.0000 - tn: 131495.0000 - fn: 60505.0000 - accuracy: 0.6849 - precision: 0.6849 - recall: 0.6849 - auc: 0.6850 - val_loss: 0.2114 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-3072000-3328000
[INFO] processing batch 3328000-3584000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1760 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1455 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-3328000-3584000
[INFO] processing batch 3584000-3840000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1254 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1082 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-3584000-3840000
[INFO] processing batch 3840000-4096000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4911 - tp: 157534.0000 - fp: 34466.0000 - tn: 157534.0000 - fn: 34466.0000 - accuracy: 0.8205 - precision: 0.8205 - recall: 0.8205 - auc: 0.8206 - val_loss: 0.4938 - val_tp: 52219.0000 - val_fp: 11781.0000 - val_tn: 52219.0000 - val_fn: 11781.0000 - val_accuracy: 0.8159 - val_precision: 0.8159 - val_recall: 0.8159 - val_auc: 0.8159
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-3840000-4096000
[INFO] processing batch 4096000-4352000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1327 - tp: 190188.0000 - fp: 1812.0000 - tn: 190188.0000 - fn: 1812.0000 - accuracy: 0.9906 - precision: 0.9906 - recall: 0.9906 - auc: 0.9905 - val_loss: 0.0973 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-4096000-4352000
[INFO] processing batch 4352000-4608000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0850 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0742 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-4352000-4608000
[INFO] processing batch 4608000-4864000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4711 - tp: 161451.0000 - fp: 30549.0000 - tn: 161451.0000 - fn: 30549.0000 - accuracy: 0.8409 - precision: 0.8409 - recall: 0.8409 - auc: 0.8403 - val_loss: 0.0966 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-4608000-4864000
[INFO] processing batch 4864000-5120000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0841 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0723 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-4864000-5120000
[INFO] processing batch 5120000-5376000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0637 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0561 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-5120000-5376000
[INFO] processing batch 5376000-5632000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0502 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0448 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-5376000-5632000
[INFO] processing batch 5632000-5888000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5879 - tp: 155809.0000 - fp: 36191.0000 - tn: 155809.0000 - fn: 36191.0000 - accuracy: 0.8115 - precision: 0.8115 - recall: 0.8115 - auc: 0.8125 - val_loss: 0.0756 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-5632000-5888000
[INFO] processing batch 5888000-6144000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0676 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0596 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-5888000-6144000
[INFO] processing batch 6144000-6400000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.3169 - tp: 174156.0000 - fp: 17844.0000 - tn: 174156.0000 - fn: 17844.0000 - accuracy: 0.9071 - precision: 0.9071 - recall: 0.9071 - auc: 0.9071 - val_loss: 1.0182 - val_tp: 41108.0000 - val_fp: 22892.0000 - val_tn: 41108.0000 - val_fn: 22892.0000 - val_accuracy: 0.6423 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-6144000-6400000
[INFO] processing batch 6400000-6656000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.7349 - tp: 138766.0000 - fp: 53234.0000 - tn: 138766.0000 - fn: 53234.0000 - accuracy: 0.7227 - precision: 0.7227 - recall: 0.7227 - auc: 0.7219 - val_loss: 0.1265 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-6400000-6656000
[INFO] processing batch 6656000-6912000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1103 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0946 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-6656000-6912000
[INFO] processing batch 6912000-7168000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0832 - tp: 191998.0000 - fp: 2.0000 - tn: 191998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0731 - val_tp: 63999.0000 - val_fp: 1.0000 - val_tn: 63999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-6912000-7168000
[INFO] processing batch 7168000-7424000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0653 - tp: 191999.0000 - fp: 1.0000 - tn: 191999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9228 - val_tp: 44344.0000 - val_fp: 19656.0000 - val_tn: 44344.0000 - val_fn: 19656.0000 - val_accuracy: 0.6929 - val_precision: 0.6929 - val_recall: 0.6929 - val_auc: 0.6929
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-7168000-7424000
[INFO] processing batch 7424000-7680000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 1.1986 - tp: 102062.0000 - fp: 89938.0000 - tn: 102062.0000 - fn: 89938.0000 - accuracy: 0.5316 - precision: 0.5316 - recall: 0.5316 - auc: 0.5318 - val_loss: 0.5690 - val_tp: 49859.0000 - val_fp: 14141.0000 - val_tn: 49859.0000 - val_fn: 14141.0000 - val_accuracy: 0.7790 - val_precision: 0.7790 - val_recall: 0.7790 - val_auc: 0.7790
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-7424000-7680000
[INFO] processing batch 7680000-7936000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1176 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1071 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-7680000-7936000
[INFO] processing batch 7936000-8192000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0979 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0893 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-7936000-8192000
[INFO] processing batch 8192000-8448000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4576 - tp: 161781.0000 - fp: 30219.0000 - tn: 161781.0000 - fn: 30219.0000 - accuracy: 0.8426 - precision: 0.8426 - recall: 0.8426 - auc: 0.8430 - val_loss: 0.1248 - val_tp: 63369.0000 - val_fp: 631.0000 - val_tn: 63369.0000 - val_fn: 631.0000 - val_accuracy: 0.9901 - val_precision: 0.9901 - val_recall: 0.9901 - val_auc: 0.9901
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-8192000-8448000
[INFO] processing batch 8448000-8704000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.8323 - tp: 123282.0000 - fp: 68718.0000 - tn: 123282.0000 - fn: 68718.0000 - accuracy: 0.6421 - precision: 0.6421 - recall: 0.6421 - auc: 0.6431 - val_loss: 0.8144 - val_tp: 39692.0000 - val_fp: 24308.0000 - val_tn: 39692.0000 - val_fn: 24308.0000 - val_accuracy: 0.6202 - val_precision: 0.6202 - val_recall: 0.6202 - val_auc: 0.6202
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-8448000-8704000
[INFO] processing batch 8704000-8960000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1879 - tp: 188028.0000 - fp: 3972.0000 - tn: 188028.0000 - fn: 3972.0000 - accuracy: 0.9793 - precision: 0.9793 - recall: 0.9793 - auc: 0.9802 - val_loss: 0.1331 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-8704000-8960000
[INFO] processing batch 8960000-9216000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1174 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1034 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-8960000-9216000
[INFO] processing batch 9216000-9472000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.8600 - tp: 120440.0000 - fp: 71560.0000 - tn: 120440.0000 - fn: 71560.0000 - accuracy: 0.6273 - precision: 0.6273 - recall: 0.6273 - auc: 0.6266 - val_loss: 0.1689 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-9216000-9472000
[INFO] processing batch 9472000-9728000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.4373 - tp: 161553.0000 - fp: 30447.0000 - tn: 161553.0000 - fn: 30447.0000 - accuracy: 0.8414 - precision: 0.8414 - recall: 0.8414 - auc: 0.8415 - val_loss: 0.4474 - val_tp: 53468.0000 - val_fp: 10532.0000 - val_tn: 53468.0000 - val_fn: 10532.0000 - val_accuracy: 0.8354 - val_precision: 0.8354 - val_recall: 0.8354 - val_auc: 0.8354
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-9472000-9728000
[INFO] processing batch 9728000-9984000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1472 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1260 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-9728000-9984000
[INFO] processing batch 9984000-10240000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1106 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0971 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-9984000-10240000
[INFO] processing batch 10240000-10496000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1188 - tp: 189510.0000 - fp: 2490.0000 - tn: 189510.0000 - fn: 2490.0000 - accuracy: 0.9870 - precision: 0.9870 - recall: 0.9870 - auc: 0.9875 - val_loss: 1.2489 - val_tp: 33975.0000 - val_fp: 30025.0000 - val_tn: 33975.0000 - val_fn: 30025.0000 - val_accuracy: 0.5309 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.5309
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-10240000-10496000
[INFO] processing batch 10496000-10752000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 1.1047 - tp: 101670.0000 - fp: 90330.0000 - tn: 101670.0000 - fn: 90330.0000 - accuracy: 0.5295 - precision: 0.5295 - recall: 0.5295 - auc: 0.5297 - val_loss: 0.9853 - val_tp: 34015.0000 - val_fp: 29985.0000 - val_tn: 34015.0000 - val_fn: 29985.0000 - val_accuracy: 0.5315 - val_precision: 0.5315 - val_recall: 0.5315 - val_auc: 0.5315
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-10496000-10752000
[INFO] processing batch 10752000-11008000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.9151 - tp: 101693.0000 - fp: 90307.0000 - tn: 101693.0000 - fn: 90307.0000 - accuracy: 0.5297 - precision: 0.5297 - recall: 0.5297 - auc: 0.5292 - val_loss: 0.3829 - val_tp: 56989.0000 - val_fp: 7011.0000 - val_tn: 56989.0000 - val_fn: 7011.0000 - val_accuracy: 0.8905 - val_precision: 0.8905 - val_recall: 0.8905 - val_auc: 0.8905
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-10752000-11008000
[INFO] processing batch 11008000-11264000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.2126 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1856 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-11008000-11264000
[INFO] processing batch 11264000-11520000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1647 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1460 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-11264000-11520000
[INFO] processing batch 11520000-11776000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1309 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1172 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-11520000-11776000
[INFO] processing batch 11776000-12032000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4990 - tp: 156412.0000 - fp: 35588.0000 - tn: 156412.0000 - fn: 35588.0000 - accuracy: 0.8146 - precision: 0.8146 - recall: 0.8146 - auc: 0.8146 - val_loss: 0.8285 - val_tp: 41134.0000 - val_fp: 22866.0000 - val_tn: 41134.0000 - val_fn: 22866.0000 - val_accuracy: 0.6427 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.6427
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-11776000-12032000
[INFO] processing batch 12032000-12288000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.7781 - tp: 123527.0000 - fp: 68473.0000 - tn: 123527.0000 - fn: 68473.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6438 - val_loss: 0.7356 - val_tp: 41219.0000 - val_fp: 22781.0000 - val_tn: 41219.0000 - val_fn: 22781.0000 - val_accuracy: 0.6440 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.6440
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-12032000-12288000
[INFO] processing batch 12288000-12544000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.7096 - tp: 123560.0000 - fp: 68440.0000 - tn: 123560.0000 - fn: 68440.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6439 - val_loss: 0.6867 - val_tp: 41268.0000 - val_fp: 22732.0000 - val_tn: 41268.0000 - val_fn: 22732.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-12288000-12544000
[INFO] processing batch 12544000-12800000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6750 - tp: 123588.0000 - fp: 68412.0000 - tn: 123588.0000 - fn: 68412.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6638 - val_tp: 41269.0000 - val_fp: 22731.0000 - val_tn: 41269.0000 - val_fn: 22731.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-12544000-12800000
[INFO] processing batch 12800000-13056000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6596 - tp: 123531.0000 - fp: 68469.0000 - tn: 123531.0000 - fn: 68469.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6435 - val_loss: 0.6555 - val_tp: 41181.0000 - val_fp: 22819.0000 - val_tn: 41181.0000 - val_fn: 22819.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-12800000-13056000
[INFO] processing batch 13056000-13312000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6534 - tp: 123615.0000 - fp: 68385.0000 - tn: 123615.0000 - fn: 68385.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6444 - val_loss: 0.6523 - val_tp: 41192.0000 - val_fp: 22808.0000 - val_tn: 41192.0000 - val_fn: 22808.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-13056000-13312000
[INFO] processing batch 13312000-13568000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6522 - tp: 123437.0000 - fp: 68563.0000 - tn: 123437.0000 - fn: 68563.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6426 - val_loss: 0.6516 - val_tp: 41179.0000 - val_fp: 22821.0000 - val_tn: 41179.0000 - val_fn: 22821.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-13312000-13568000
[INFO] processing batch 13568000-13824000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123539.0000 - fp: 68461.0000 - tn: 123539.0000 - fn: 68461.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6434 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-13568000-13824000
[INFO] processing batch 13824000-14080000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123556.0000 - fp: 68444.0000 - tn: 123556.0000 - fn: 68444.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6515 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 41173.0000 - val_fn: 22827.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-13824000-14080000
[INFO] processing batch 14080000-14336000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123681.0000 - fp: 68319.0000 - tn: 123681.0000 - fn: 68319.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6510 - val_tp: 41221.0000 - val_fp: 22779.0000 - val_tn: 41221.0000 - val_fn: 22779.0000 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.6441
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-14080000-14336000
[INFO] processing batch 14336000-14592000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123523.0000 - fp: 68477.0000 - tn: 123523.0000 - fn: 68477.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6431 - val_loss: 0.6513 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 41197.0000 - val_fn: 22803.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-14336000-14592000
[INFO] processing batch 14592000-14848000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6511 - tp: 123652.0000 - fp: 68348.0000 - tn: 123652.0000 - fn: 68348.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6440 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-14592000-14848000
[INFO] processing batch 14848000-15104000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123594.0000 - fp: 68406.0000 - tn: 123594.0000 - fn: 68406.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6512 - val_tp: 41205.0000 - val_fp: 22795.0000 - val_tn: 41205.0000 - val_fn: 22795.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-14848000-15104000
[INFO] processing batch 15104000-15360000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123629.0000 - fp: 68371.0000 - tn: 123629.0000 - fn: 68371.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6509 - val_tp: 41234.0000 - val_fp: 22766.0000 - val_tn: 41234.0000 - val_fn: 22766.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-15104000-15360000
[INFO] processing batch 15360000-15616000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6511 - tp: 123632.0000 - fp: 68368.0000 - tn: 123632.0000 - fn: 68368.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6438 - val_loss: 0.6506 - val_tp: 41266.0000 - val_fp: 22734.0000 - val_tn: 41266.0000 - val_fn: 22734.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-15360000-15616000
[INFO] processing batch 15616000-15872000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123527.0000 - fp: 68473.0000 - tn: 123527.0000 - fn: 68473.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6431 - val_loss: 0.6513 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 41197.0000 - val_fn: 22803.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-15616000-15872000
[INFO] processing batch 15872000-16128000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123531.0000 - fp: 68469.0000 - tn: 123531.0000 - fn: 68469.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6425 - val_loss: 0.6515 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 41173.0000 - val_fn: 22827.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-15872000-16128000
[INFO] processing batch 16128000-16384000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6507 - tp: 123781.0000 - fp: 68219.0000 - tn: 123781.0000 - fn: 68219.0000 - accuracy: 0.6447 - precision: 0.6447 - recall: 0.6447 - auc: 0.6448 - val_loss: 0.6513 - val_tp: 41195.0000 - val_fp: 22805.0000 - val_tn: 41195.0000 - val_fn: 22805.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-16128000-16384000
[INFO] processing batch 16384000-16640000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123621.0000 - fp: 68379.0000 - tn: 123621.0000 - fn: 68379.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6516 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 41165.0000 - val_fn: 22835.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-16384000-16640000
[INFO] processing batch 16640000-16896000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6518 - tp: 123417.0000 - fp: 68583.0000 - tn: 123417.0000 - fn: 68583.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6425 - val_loss: 0.6510 - val_tp: 41230.0000 - val_fp: 22770.0000 - val_tn: 41230.0000 - val_fn: 22770.0000 - val_accuracy: 0.6442 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.6442
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-16640000-16896000
[INFO] processing batch 16896000-17152000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123600.0000 - fp: 68400.0000 - tn: 123600.0000 - fn: 68400.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6436 - val_loss: 0.6512 - val_tp: 41198.0000 - val_fp: 22802.0000 - val_tn: 41198.0000 - val_fn: 22802.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-16896000-17152000
[INFO] processing batch 17152000-17408000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123711.0000 - fp: 68289.0000 - tn: 123711.0000 - fn: 68289.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6443 - val_loss: 0.6515 - val_tp: 41168.0000 - val_fp: 22832.0000 - val_tn: 41168.0000 - val_fn: 22832.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-17152000-17408000
[INFO] processing batch 17408000-17664000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6509 - tp: 123701.0000 - fp: 68299.0000 - tn: 123701.0000 - fn: 68299.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6441 - val_loss: 0.6520 - val_tp: 41118.0000 - val_fp: 22882.0000 - val_tn: 41118.0000 - val_fn: 22882.0000 - val_accuracy: 0.6425 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.6425
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-17408000-17664000
[INFO] processing batch 17664000-17920000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123546.0000 - fp: 68454.0000 - tn: 123546.0000 - fn: 68454.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6431 - val_loss: 0.6523 - val_tp: 41089.0000 - val_fp: 22911.0000 - val_tn: 41089.0000 - val_fn: 22911.0000 - val_accuracy: 0.6420 - val_precision: 0.6420 - val_recall: 0.6420 - val_auc: 0.6420
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-17664000-17920000
[INFO] processing batch 17920000-18176000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123681.0000 - fp: 68319.0000 - tn: 123681.0000 - fn: 68319.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6440 - val_loss: 0.6509 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 41233.0000 - val_fn: 22767.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-17920000-18176000
[INFO] processing batch 18176000-18432000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123640.0000 - fp: 68360.0000 - tn: 123640.0000 - fn: 68360.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6441 - val_loss: 0.6503 - val_tp: 41298.0000 - val_fp: 22702.0000 - val_tn: 41298.0000 - val_fn: 22702.0000 - val_accuracy: 0.6453 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.6453
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-18176000-18432000
[INFO] processing batch 18432000-18688000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123615.0000 - fp: 68385.0000 - tn: 123615.0000 - fn: 68385.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6438 - val_loss: 0.6509 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 41233.0000 - val_fn: 22767.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-18432000-18688000
[INFO] processing batch 18688000-18944000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123645.0000 - fp: 68355.0000 - tn: 123645.0000 - fn: 68355.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6442 - val_loss: 0.6514 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 41184.0000 - val_fn: 22816.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-18688000-18944000
[INFO] processing batch 18944000-19200000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6503 - tp: 123888.0000 - fp: 68112.0000 - tn: 123888.0000 - fn: 68112.0000 - accuracy: 0.6453 - precision: 0.6453 - recall: 0.6453 - auc: 0.6454 - val_loss: 0.6515 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 41169.0000 - val_fn: 22831.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-18944000-19200000
[INFO] processing batch 19200000-19456000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123500.0000 - fp: 68500.0000 - tn: 123500.0000 - fn: 68500.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6434 - val_loss: 0.6513 - val_tp: 41189.0000 - val_fp: 22811.0000 - val_tn: 41189.0000 - val_fn: 22811.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-19200000-19456000
[INFO] processing batch 19456000-19712000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123689.0000 - fp: 68311.0000 - tn: 123689.0000 - fn: 68311.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6515 - val_tp: 41166.0000 - val_fp: 22834.0000 - val_tn: 41166.0000 - val_fn: 22834.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-19456000-19712000
[INFO] processing batch 19712000-19968000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6518 - tp: 123402.0000 - fp: 68598.0000 - tn: 123402.0000 - fn: 68598.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6424 - val_loss: 0.6508 - val_tp: 41242.0000 - val_fp: 22758.0000 - val_tn: 41242.0000 - val_fn: 22758.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-19712000-19968000
[INFO] processing batch 19968000-20224000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6514 - tp: 123541.0000 - fp: 68459.0000 - tn: 123541.0000 - fn: 68459.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6434 - val_loss: 0.6509 - val_tp: 41241.0000 - val_fp: 22759.0000 - val_tn: 41241.0000 - val_fn: 22759.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-19968000-20224000
[INFO] processing batch 20224000-20480000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123640.0000 - fp: 68360.0000 - tn: 123640.0000 - fn: 68360.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6436 - val_loss: 0.6511 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 41209.0000 - val_fn: 22791.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-20224000-20480000
[INFO] processing batch 20480000-20736000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123598.0000 - fp: 68402.0000 - tn: 123598.0000 - fn: 68402.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6431 - val_loss: 0.6509 - val_tp: 41235.0000 - val_fp: 22765.0000 - val_tn: 41235.0000 - val_fn: 22765.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-20480000-20736000
[INFO] processing batch 20736000-20992000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6507 - tp: 123769.0000 - fp: 68231.0000 - tn: 123769.0000 - fn: 68231.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-20736000-20992000
[INFO] processing batch 20992000-21248000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6517 - tp: 123459.0000 - fp: 68541.0000 - tn: 123459.0000 - fn: 68541.0000 - accuracy: 0.6430 - precision: 0.6430 - recall: 0.6430 - auc: 0.6428 - val_loss: 0.6512 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 41209.0000 - val_fn: 22791.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-20992000-21248000
[INFO] processing batch 21248000-21504000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6510 - tp: 123683.0000 - fp: 68317.0000 - tn: 123683.0000 - fn: 68317.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6441 - val_loss: 0.6514 - val_tp: 41183.0000 - val_fp: 22817.0000 - val_tn: 41183.0000 - val_fn: 22817.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-21248000-21504000
[INFO] processing batch 21504000-21760000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6513 - tp: 123564.0000 - fp: 68436.0000 - tn: 123564.0000 - fn: 68436.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6435 - val_loss: 0.6507 - val_tp: 41254.0000 - val_fp: 22746.0000 - val_tn: 41254.0000 - val_fn: 22746.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-21504000-21760000
[INFO] processing batch 21760000-22016000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6509 - tp: 123717.0000 - fp: 68283.0000 - tn: 123717.0000 - fn: 68283.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6441 - val_loss: 0.6506 - val_tp: 41270.0000 - val_fp: 22730.0000 - val_tn: 41270.0000 - val_fn: 22730.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-21760000-22016000
[INFO] processing batch 22016000-22272000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123690.0000 - fp: 68310.0000 - tn: 123690.0000 - fn: 68310.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6440 - val_loss: 0.6521 - val_tp: 41104.0000 - val_fp: 22896.0000 - val_tn: 41104.0000 - val_fn: 22896.0000 - val_accuracy: 0.6423 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-22016000-22272000
[INFO] processing batch 22272000-22528000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123672.0000 - fp: 68328.0000 - tn: 123672.0000 - fn: 68328.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6441 - val_loss: 0.6508 - val_tp: 41243.0000 - val_fp: 22757.0000 - val_tn: 41243.0000 - val_fn: 22757.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-22272000-22528000
[INFO] processing batch 22528000-22784000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123623.0000 - fp: 68377.0000 - tn: 123623.0000 - fn: 68377.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6438 - val_loss: 0.6504 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 41292.0000 - val_fn: 22708.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-22528000-22784000
[INFO] processing batch 22784000-23040000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6507 - tp: 123759.0000 - fp: 68241.0000 - tn: 123759.0000 - fn: 68241.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6445 - val_loss: 0.6514 - val_tp: 41180.0000 - val_fp: 22820.0000 - val_tn: 41180.0000 - val_fn: 22820.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-22784000-23040000
[INFO] processing batch 23040000-23296000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123507.0000 - fp: 68493.0000 - tn: 123507.0000 - fn: 68493.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6430 - val_loss: 0.6507 - val_tp: 41255.0000 - val_fp: 22745.0000 - val_tn: 41255.0000 - val_fn: 22745.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-23040000-23296000
[INFO] processing batch 23296000-23552000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123601.0000 - fp: 68399.0000 - tn: 123601.0000 - fn: 68399.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6439 - val_loss: 0.6511 - val_tp: 41213.0000 - val_fp: 22787.0000 - val_tn: 41213.0000 - val_fn: 22787.0000 - val_accuracy: 0.6440 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.6440
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-23296000-23552000
[INFO] processing batch 23552000-23808000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6508 - tp: 123749.0000 - fp: 68251.0000 - tn: 123749.0000 - fn: 68251.0000 - accuracy: 0.6445 - precision: 0.6445 - recall: 0.6445 - auc: 0.6447 - val_loss: 0.6504 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 41292.0000 - val_fn: 22708.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-23552000-23808000
[INFO] processing batch 23808000-24064000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123603.0000 - fp: 68397.0000 - tn: 123603.0000 - fn: 68397.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6435 - val_loss: 0.6516 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 41165.0000 - val_fn: 22835.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-23808000-24064000
[INFO] processing batch 24064000-24320000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123599.0000 - fp: 68401.0000 - tn: 123599.0000 - fn: 68401.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6435 - val_loss: 0.6514 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 41184.0000 - val_fn: 22816.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-24064000-24320000
[INFO] processing batch 24320000-24576000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6517 - tp: 123440.0000 - fp: 68560.0000 - tn: 123440.0000 - fn: 68560.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6428 - val_loss: 0.6515 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 41169.0000 - val_fn: 22831.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-24320000-24576000
[33m[LOSS] 0.6515193800926209[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6515193800926209  <  0.001
[33m[INFO] epoch 4/10[0m
[33m[INFO] loading file 1-50/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (24819975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] Shape when encoding dataset: (24819975, 17)
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
missing -1
len(df.columns) 108
numFeatures 107
[INFO] Shape AFTER encoding dataset: (24819975, 108)
[INFO] processing batch 0-256000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.2725 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1948 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-0-256000
[INFO] processing batch 256000-512000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.7762 - tp: 112918.0000 - fp: 79082.0000 - tn: 112918.0000 - fn: 79082.0000 - accuracy: 0.5881 - precision: 0.5881 - recall: 0.5881 - auc: 0.5875 - val_loss: 0.7962 - val_tp: 33927.0000 - val_fp: 30073.0000 - val_tn: 33927.0000 - val_fn: 30073.0000 - val_accuracy: 0.5301 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-256000-512000
[INFO] processing batch 512000-768000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.5935 - tp: 138284.0000 - fp: 53716.0000 - tn: 138284.0000 - fn: 53716.0000 - accuracy: 0.7202 - precision: 0.7202 - recall: 0.7202 - auc: 0.7209 - val_loss: 0.3414 - val_tp: 62058.0000 - val_fp: 1942.0000 - val_tn: 62058.0000 - val_fn: 1942.0000 - val_accuracy: 0.9697 - val_precision: 0.9697 - val_recall: 0.9697 - val_auc: 0.9697
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-512000-768000
[INFO] processing batch 768000-1024000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6890 - tp: 117250.0000 - fp: 74750.0000 - tn: 117250.0000 - fn: 74750.0000 - accuracy: 0.6107 - precision: 0.6107 - recall: 0.6107 - auc: 0.6107 - val_loss: 0.4871 - val_tp: 55591.0000 - val_fp: 8409.0000 - val_tn: 55591.0000 - val_fn: 8409.0000 - val_accuracy: 0.8686 - val_precision: 0.8686 - val_recall: 0.8686 - val_auc: 0.8686
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-768000-1024000
[INFO] processing batch 1024000-1280000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6134 - tp: 133967.0000 - fp: 58033.0000 - tn: 133967.0000 - fn: 58033.0000 - accuracy: 0.6977 - precision: 0.6977 - recall: 0.6977 - auc: 0.6977 - val_loss: 0.3753 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-1024000-1280000
[INFO] processing batch 1280000-1536000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.2796 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2148 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-1280000-1536000
[INFO] processing batch 1536000-1792000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1798 - tp: 191999.0000 - fp: 1.0000 - tn: 191999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1514 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-1536000-1792000
[INFO] processing batch 1792000-2048000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5576 - tp: 148221.0000 - fp: 43779.0000 - tn: 148221.0000 - fn: 43779.0000 - accuracy: 0.7720 - precision: 0.7720 - recall: 0.7720 - auc: 0.7706 - val_loss: 0.3329 - val_tp: 57941.0000 - val_fp: 6059.0000 - val_tn: 57941.0000 - val_fn: 6059.0000 - val_accuracy: 0.9053 - val_precision: 0.9053 - val_recall: 0.9053 - val_auc: 0.9053
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-1792000-2048000
[INFO] processing batch 2048000-2304000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5961 - tp: 141714.0000 - fp: 50286.0000 - tn: 141714.0000 - fn: 50286.0000 - accuracy: 0.7381 - precision: 0.7381 - recall: 0.7381 - auc: 0.7378 - val_loss: 0.2185 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-2048000-2304000
[INFO] processing batch 2304000-2560000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1791 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1467 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-2304000-2560000
[INFO] processing batch 2560000-2816000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1258 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1082 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-2560000-2816000
[INFO] processing batch 2816000-3072000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5806 - tp: 148720.0000 - fp: 43280.0000 - tn: 148720.0000 - fn: 43280.0000 - accuracy: 0.7746 - precision: 0.7746 - recall: 0.7746 - auc: 0.7756 - val_loss: 0.8170 - val_tp: 40961.0000 - val_fp: 23039.0000 - val_tn: 40961.0000 - val_fn: 23039.0000 - val_accuracy: 0.6400 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.6400
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-2816000-3072000
[INFO] processing batch 3072000-3328000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6962 - tp: 131495.0000 - fp: 60505.0000 - tn: 131495.0000 - fn: 60505.0000 - accuracy: 0.6849 - precision: 0.6849 - recall: 0.6849 - auc: 0.6858 - val_loss: 0.2116 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-3072000-3328000
[INFO] processing batch 3328000-3584000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1761 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1456 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-3328000-3584000
[INFO] processing batch 3584000-3840000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1254 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1082 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-3584000-3840000
[INFO] processing batch 3840000-4096000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4911 - tp: 157534.0000 - fp: 34466.0000 - tn: 157534.0000 - fn: 34466.0000 - accuracy: 0.8205 - precision: 0.8205 - recall: 0.8205 - auc: 0.8204 - val_loss: 0.4938 - val_tp: 52219.0000 - val_fp: 11781.0000 - val_tn: 52219.0000 - val_fn: 11781.0000 - val_accuracy: 0.8159 - val_precision: 0.8159 - val_recall: 0.8159 - val_auc: 0.8159
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-3840000-4096000
[INFO] processing batch 4096000-4352000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1327 - tp: 190188.0000 - fp: 1812.0000 - tn: 190188.0000 - fn: 1812.0000 - accuracy: 0.9906 - precision: 0.9906 - recall: 0.9906 - auc: 0.9907 - val_loss: 0.0973 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-4096000-4352000
[INFO] processing batch 4352000-4608000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0850 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0742 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-4352000-4608000
[INFO] processing batch 4608000-4864000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.4710 - tp: 161451.0000 - fp: 30549.0000 - tn: 161451.0000 - fn: 30549.0000 - accuracy: 0.8409 - precision: 0.8409 - recall: 0.8409 - auc: 0.8419 - val_loss: 0.0967 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-4608000-4864000
[INFO] processing batch 4864000-5120000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0842 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0724 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-4864000-5120000
[INFO] processing batch 5120000-5376000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0638 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0562 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-5120000-5376000
[INFO] processing batch 5376000-5632000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0502 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0448 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-5376000-5632000
[INFO] processing batch 5632000-5888000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.5879 - tp: 155809.0000 - fp: 36191.0000 - tn: 155809.0000 - fn: 36191.0000 - accuracy: 0.8115 - precision: 0.8115 - recall: 0.8115 - auc: 0.8116 - val_loss: 0.0756 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-5632000-5888000
[INFO] processing batch 5888000-6144000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0676 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0595 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-5888000-6144000
[INFO] processing batch 6144000-6400000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.3169 - tp: 174156.0000 - fp: 17844.0000 - tn: 174156.0000 - fn: 17844.0000 - accuracy: 0.9071 - precision: 0.9071 - recall: 0.9071 - auc: 0.9063 - val_loss: 1.0183 - val_tp: 41108.0000 - val_fp: 22892.0000 - val_tn: 41108.0000 - val_fn: 22892.0000 - val_accuracy: 0.6423 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-6144000-6400000
[INFO] processing batch 6400000-6656000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.7348 - tp: 138766.0000 - fp: 53234.0000 - tn: 138766.0000 - fn: 53234.0000 - accuracy: 0.7227 - precision: 0.7227 - recall: 0.7227 - auc: 0.7214 - val_loss: 0.1266 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-6400000-6656000
[INFO] processing batch 6656000-6912000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1102 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0946 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-6656000-6912000
[INFO] processing batch 6912000-7168000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0832 - tp: 191998.0000 - fp: 2.0000 - tn: 191998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0731 - val_tp: 63999.0000 - val_fp: 1.0000 - val_tn: 63999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-6912000-7168000
[INFO] processing batch 7168000-7424000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0652 - tp: 191999.0000 - fp: 1.0000 - tn: 191999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9230 - val_tp: 44344.0000 - val_fp: 19656.0000 - val_tn: 44344.0000 - val_fn: 19656.0000 - val_accuracy: 0.6929 - val_precision: 0.6929 - val_recall: 0.6929 - val_auc: 0.6929
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-7168000-7424000
[INFO] processing batch 7424000-7680000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 1.1989 - tp: 102062.0000 - fp: 89938.0000 - tn: 102062.0000 - fn: 89938.0000 - accuracy: 0.5316 - precision: 0.5316 - recall: 0.5316 - auc: 0.5312 - val_loss: 0.5691 - val_tp: 49859.0000 - val_fp: 14141.0000 - val_tn: 49859.0000 - val_fn: 14141.0000 - val_accuracy: 0.7790 - val_precision: 0.7790 - val_recall: 0.7790 - val_auc: 0.7790
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-7424000-7680000
[INFO] processing batch 7680000-7936000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1175 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1070 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-7680000-7936000
[INFO] processing batch 7936000-8192000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0978 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0892 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-7936000-8192000
[INFO] processing batch 8192000-8448000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4577 - tp: 161781.0000 - fp: 30219.0000 - tn: 161781.0000 - fn: 30219.0000 - accuracy: 0.8426 - precision: 0.8426 - recall: 0.8426 - auc: 0.8425 - val_loss: 0.1247 - val_tp: 63369.0000 - val_fp: 631.0000 - val_tn: 63369.0000 - val_fn: 631.0000 - val_accuracy: 0.9901 - val_precision: 0.9901 - val_recall: 0.9901 - val_auc: 0.9901
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-8192000-8448000
[INFO] processing batch 8448000-8704000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.8325 - tp: 123282.0000 - fp: 68718.0000 - tn: 123282.0000 - fn: 68718.0000 - accuracy: 0.6421 - precision: 0.6421 - recall: 0.6421 - auc: 0.6429 - val_loss: 0.8146 - val_tp: 39692.0000 - val_fp: 24308.0000 - val_tn: 39692.0000 - val_fn: 24308.0000 - val_accuracy: 0.6202 - val_precision: 0.6202 - val_recall: 0.6202 - val_auc: 0.6202
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-8448000-8704000
[INFO] processing batch 8704000-8960000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1879 - tp: 188028.0000 - fp: 3972.0000 - tn: 188028.0000 - fn: 3972.0000 - accuracy: 0.9793 - precision: 0.9793 - recall: 0.9793 - auc: 0.9791 - val_loss: 0.1330 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-8704000-8960000
[INFO] processing batch 8960000-9216000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1173 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1034 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-8960000-9216000
[INFO] processing batch 9216000-9472000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.8602 - tp: 120440.0000 - fp: 71560.0000 - tn: 120440.0000 - fn: 71560.0000 - accuracy: 0.6273 - precision: 0.6273 - recall: 0.6273 - auc: 0.6265 - val_loss: 0.1688 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-9216000-9472000
[INFO] processing batch 9472000-9728000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4373 - tp: 161553.0000 - fp: 30447.0000 - tn: 161553.0000 - fn: 30447.0000 - accuracy: 0.8414 - precision: 0.8414 - recall: 0.8414 - auc: 0.8414 - val_loss: 0.4474 - val_tp: 53468.0000 - val_fp: 10532.0000 - val_tn: 53468.0000 - val_fn: 10532.0000 - val_accuracy: 0.8354 - val_precision: 0.8354 - val_recall: 0.8354 - val_auc: 0.8354
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-9472000-9728000
[INFO] processing batch 9728000-9984000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1471 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1260 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-9728000-9984000
[INFO] processing batch 9984000-10240000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1106 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0971 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-9984000-10240000
[INFO] processing batch 10240000-10496000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1188 - tp: 189510.0000 - fp: 2490.0000 - tn: 189510.0000 - fn: 2490.0000 - accuracy: 0.9870 - precision: 0.9870 - recall: 0.9870 - auc: 0.9873 - val_loss: 1.2490 - val_tp: 33975.0000 - val_fp: 30025.0000 - val_tn: 33975.0000 - val_fn: 30025.0000 - val_accuracy: 0.5309 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.5309
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-10240000-10496000
[INFO] processing batch 10496000-10752000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 1.1046 - tp: 101670.0000 - fp: 90330.0000 - tn: 101670.0000 - fn: 90330.0000 - accuracy: 0.5295 - precision: 0.5295 - recall: 0.5295 - auc: 0.5295 - val_loss: 0.9852 - val_tp: 34015.0000 - val_fp: 29985.0000 - val_tn: 34015.0000 - val_fn: 29985.0000 - val_accuracy: 0.5315 - val_precision: 0.5315 - val_recall: 0.5315 - val_auc: 0.5315
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-10496000-10752000
[INFO] processing batch 10752000-11008000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.9150 - tp: 101693.0000 - fp: 90307.0000 - tn: 101693.0000 - fn: 90307.0000 - accuracy: 0.5297 - precision: 0.5297 - recall: 0.5297 - auc: 0.5298 - val_loss: 0.3829 - val_tp: 56989.0000 - val_fp: 7011.0000 - val_tn: 56989.0000 - val_fn: 7011.0000 - val_accuracy: 0.8905 - val_precision: 0.8905 - val_recall: 0.8905 - val_auc: 0.8905
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-10752000-11008000
[INFO] processing batch 11008000-11264000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.2127 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1857 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-11008000-11264000
[INFO] processing batch 11264000-11520000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1648 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1460 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-11264000-11520000
[INFO] processing batch 11520000-11776000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1310 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1173 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-11520000-11776000
[INFO] processing batch 11776000-12032000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4990 - tp: 156412.0000 - fp: 35588.0000 - tn: 156412.0000 - fn: 35588.0000 - accuracy: 0.8146 - precision: 0.8146 - recall: 0.8146 - auc: 0.8128 - val_loss: 0.8286 - val_tp: 41134.0000 - val_fp: 22866.0000 - val_tn: 41134.0000 - val_fn: 22866.0000 - val_accuracy: 0.6427 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.6427
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-11776000-12032000
[INFO] processing batch 12032000-12288000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.7783 - tp: 123527.0000 - fp: 68473.0000 - tn: 123527.0000 - fn: 68473.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6430 - val_loss: 0.7357 - val_tp: 41219.0000 - val_fp: 22781.0000 - val_tn: 41219.0000 - val_fn: 22781.0000 - val_accuracy: 0.6440 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.6440
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-12032000-12288000
[INFO] processing batch 12288000-12544000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.7097 - tp: 123560.0000 - fp: 68440.0000 - tn: 123560.0000 - fn: 68440.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6440 - val_loss: 0.6868 - val_tp: 41268.0000 - val_fp: 22732.0000 - val_tn: 41268.0000 - val_fn: 22732.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-12288000-12544000
[INFO] processing batch 12544000-12800000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6750 - tp: 123588.0000 - fp: 68412.0000 - tn: 123588.0000 - fn: 68412.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6639 - val_tp: 41269.0000 - val_fp: 22731.0000 - val_tn: 41269.0000 - val_fn: 22731.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-12544000-12800000
[INFO] processing batch 12800000-13056000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6596 - tp: 123531.0000 - fp: 68469.0000 - tn: 123531.0000 - fn: 68469.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6430 - val_loss: 0.6556 - val_tp: 41181.0000 - val_fp: 22819.0000 - val_tn: 41181.0000 - val_fn: 22819.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-12800000-13056000
[INFO] processing batch 13056000-13312000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6534 - tp: 123615.0000 - fp: 68385.0000 - tn: 123615.0000 - fn: 68385.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6440 - val_loss: 0.6523 - val_tp: 41192.0000 - val_fp: 22808.0000 - val_tn: 41192.0000 - val_fn: 22808.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-13056000-13312000
[INFO] processing batch 13312000-13568000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6522 - tp: 123437.0000 - fp: 68563.0000 - tn: 123437.0000 - fn: 68563.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6431 - val_loss: 0.6516 - val_tp: 41179.0000 - val_fp: 22821.0000 - val_tn: 41179.0000 - val_fn: 22821.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-13312000-13568000
[INFO] processing batch 13568000-13824000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6515 - tp: 123539.0000 - fp: 68461.0000 - tn: 123539.0000 - fn: 68461.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6440 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-13568000-13824000
[INFO] processing batch 13824000-14080000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123556.0000 - fp: 68444.0000 - tn: 123556.0000 - fn: 68444.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6515 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 41173.0000 - val_fn: 22827.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-13824000-14080000
[INFO] processing batch 14080000-14336000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123681.0000 - fp: 68319.0000 - tn: 123681.0000 - fn: 68319.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6510 - val_tp: 41221.0000 - val_fp: 22779.0000 - val_tn: 41221.0000 - val_fn: 22779.0000 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.6441
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-14080000-14336000
[INFO] processing batch 14336000-14592000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123523.0000 - fp: 68477.0000 - tn: 123523.0000 - fn: 68477.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6430 - val_loss: 0.6513 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 41197.0000 - val_fn: 22803.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-14336000-14592000
[INFO] processing batch 14592000-14848000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123652.0000 - fp: 68348.0000 - tn: 123652.0000 - fn: 68348.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6440 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-14592000-14848000
[INFO] processing batch 14848000-15104000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6513 - tp: 123594.0000 - fp: 68406.0000 - tn: 123594.0000 - fn: 68406.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6512 - val_tp: 41205.0000 - val_fp: 22795.0000 - val_tn: 41205.0000 - val_fn: 22795.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-14848000-15104000
[INFO] processing batch 15104000-15360000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123629.0000 - fp: 68371.0000 - tn: 123629.0000 - fn: 68371.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6437 - val_loss: 0.6509 - val_tp: 41234.0000 - val_fp: 22766.0000 - val_tn: 41234.0000 - val_fn: 22766.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-15104000-15360000
[INFO] processing batch 15360000-15616000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123632.0000 - fp: 68368.0000 - tn: 123632.0000 - fn: 68368.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6506 - val_tp: 41266.0000 - val_fp: 22734.0000 - val_tn: 41266.0000 - val_fn: 22734.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-15360000-15616000
[INFO] processing batch 15616000-15872000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6515 - tp: 123527.0000 - fp: 68473.0000 - tn: 123527.0000 - fn: 68473.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6433 - val_loss: 0.6513 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 41197.0000 - val_fn: 22803.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-15616000-15872000
[INFO] processing batch 15872000-16128000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123531.0000 - fp: 68469.0000 - tn: 123531.0000 - fn: 68469.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6431 - val_loss: 0.6515 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 41173.0000 - val_fn: 22827.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-15872000-16128000
[INFO] processing batch 16128000-16384000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6507 - tp: 123781.0000 - fp: 68219.0000 - tn: 123781.0000 - fn: 68219.0000 - accuracy: 0.6447 - precision: 0.6447 - recall: 0.6447 - auc: 0.6447 - val_loss: 0.6513 - val_tp: 41195.0000 - val_fp: 22805.0000 - val_tn: 41195.0000 - val_fn: 22805.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-16128000-16384000
[INFO] processing batch 16384000-16640000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6512 - tp: 123621.0000 - fp: 68379.0000 - tn: 123621.0000 - fn: 68379.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6516 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 41165.0000 - val_fn: 22835.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-16384000-16640000
[INFO] processing batch 16640000-16896000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6518 - tp: 123417.0000 - fp: 68583.0000 - tn: 123417.0000 - fn: 68583.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6430 - val_loss: 0.6510 - val_tp: 41230.0000 - val_fp: 22770.0000 - val_tn: 41230.0000 - val_fn: 22770.0000 - val_accuracy: 0.6442 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.6442
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-16640000-16896000
[INFO] processing batch 16896000-17152000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123600.0000 - fp: 68400.0000 - tn: 123600.0000 - fn: 68400.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6439 - val_loss: 0.6512 - val_tp: 41198.0000 - val_fp: 22802.0000 - val_tn: 41198.0000 - val_fn: 22802.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-16896000-17152000
[INFO] processing batch 17152000-17408000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123711.0000 - fp: 68289.0000 - tn: 123711.0000 - fn: 68289.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6443 - val_loss: 0.6515 - val_tp: 41168.0000 - val_fp: 22832.0000 - val_tn: 41168.0000 - val_fn: 22832.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-17152000-17408000
[INFO] processing batch 17408000-17664000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123701.0000 - fp: 68299.0000 - tn: 123701.0000 - fn: 68299.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6442 - val_loss: 0.6520 - val_tp: 41118.0000 - val_fp: 22882.0000 - val_tn: 41118.0000 - val_fn: 22882.0000 - val_accuracy: 0.6425 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.6425
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-17408000-17664000
[INFO] processing batch 17664000-17920000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123546.0000 - fp: 68454.0000 - tn: 123546.0000 - fn: 68454.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6433 - val_loss: 0.6523 - val_tp: 41089.0000 - val_fp: 22911.0000 - val_tn: 41089.0000 - val_fn: 22911.0000 - val_accuracy: 0.6420 - val_precision: 0.6420 - val_recall: 0.6420 - val_auc: 0.6420
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-17664000-17920000
[INFO] processing batch 17920000-18176000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123681.0000 - fp: 68319.0000 - tn: 123681.0000 - fn: 68319.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6441 - val_loss: 0.6509 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 41233.0000 - val_fn: 22767.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-17920000-18176000
[INFO] processing batch 18176000-18432000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123640.0000 - fp: 68360.0000 - tn: 123640.0000 - fn: 68360.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6441 - val_loss: 0.6503 - val_tp: 41298.0000 - val_fp: 22702.0000 - val_tn: 41298.0000 - val_fn: 22702.0000 - val_accuracy: 0.6453 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.6453
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-18176000-18432000
[INFO] processing batch 18432000-18688000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6512 - tp: 123615.0000 - fp: 68385.0000 - tn: 123615.0000 - fn: 68385.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6439 - val_loss: 0.6509 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 41233.0000 - val_fn: 22767.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-18432000-18688000
[INFO] processing batch 18688000-18944000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6511 - tp: 123645.0000 - fp: 68355.0000 - tn: 123645.0000 - fn: 68355.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6442 - val_loss: 0.6514 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 41184.0000 - val_fn: 22816.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-18688000-18944000
[INFO] processing batch 18944000-19200000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6503 - tp: 123888.0000 - fp: 68112.0000 - tn: 123888.0000 - fn: 68112.0000 - accuracy: 0.6453 - precision: 0.6453 - recall: 0.6453 - auc: 0.6453 - val_loss: 0.6515 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 41169.0000 - val_fn: 22831.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-18944000-19200000
[INFO] processing batch 19200000-19456000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123500.0000 - fp: 68500.0000 - tn: 123500.0000 - fn: 68500.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6436 - val_loss: 0.6513 - val_tp: 41189.0000 - val_fp: 22811.0000 - val_tn: 41189.0000 - val_fn: 22811.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-19200000-19456000
[INFO] processing batch 19456000-19712000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6510 - tp: 123689.0000 - fp: 68311.0000 - tn: 123689.0000 - fn: 68311.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6444 - val_loss: 0.6515 - val_tp: 41166.0000 - val_fp: 22834.0000 - val_tn: 41166.0000 - val_fn: 22834.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-19456000-19712000
[INFO] processing batch 19712000-19968000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6518 - tp: 123402.0000 - fp: 68598.0000 - tn: 123402.0000 - fn: 68598.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6426 - val_loss: 0.6508 - val_tp: 41242.0000 - val_fp: 22758.0000 - val_tn: 41242.0000 - val_fn: 22758.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-19712000-19968000
[INFO] processing batch 19968000-20224000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123541.0000 - fp: 68459.0000 - tn: 123541.0000 - fn: 68459.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6429 - val_loss: 0.6509 - val_tp: 41241.0000 - val_fp: 22759.0000 - val_tn: 41241.0000 - val_fn: 22759.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-19968000-20224000
[INFO] processing batch 20224000-20480000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123640.0000 - fp: 68360.0000 - tn: 123640.0000 - fn: 68360.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6439 - val_loss: 0.6511 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 41209.0000 - val_fn: 22791.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-20224000-20480000
[INFO] processing batch 20480000-20736000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123598.0000 - fp: 68402.0000 - tn: 123598.0000 - fn: 68402.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6435 - val_loss: 0.6509 - val_tp: 41235.0000 - val_fp: 22765.0000 - val_tn: 41235.0000 - val_fn: 22765.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-20480000-20736000
[INFO] processing batch 20736000-20992000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6507 - tp: 123769.0000 - fp: 68231.0000 - tn: 123769.0000 - fn: 68231.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-20736000-20992000
[INFO] processing batch 20992000-21248000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6517 - tp: 123459.0000 - fp: 68541.0000 - tn: 123459.0000 - fn: 68541.0000 - accuracy: 0.6430 - precision: 0.6430 - recall: 0.6430 - auc: 0.6428 - val_loss: 0.6511 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 41209.0000 - val_fn: 22791.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-20992000-21248000
[INFO] processing batch 21248000-21504000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123683.0000 - fp: 68317.0000 - tn: 123683.0000 - fn: 68317.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6438 - val_loss: 0.6514 - val_tp: 41183.0000 - val_fp: 22817.0000 - val_tn: 41183.0000 - val_fn: 22817.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-21248000-21504000
[INFO] processing batch 21504000-21760000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6513 - tp: 123564.0000 - fp: 68436.0000 - tn: 123564.0000 - fn: 68436.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6440 - val_loss: 0.6507 - val_tp: 41254.0000 - val_fp: 22746.0000 - val_tn: 41254.0000 - val_fn: 22746.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-21504000-21760000
[INFO] processing batch 21760000-22016000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123717.0000 - fp: 68283.0000 - tn: 123717.0000 - fn: 68283.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6445 - val_loss: 0.6506 - val_tp: 41270.0000 - val_fp: 22730.0000 - val_tn: 41270.0000 - val_fn: 22730.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-21760000-22016000
[INFO] processing batch 22016000-22272000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123690.0000 - fp: 68310.0000 - tn: 123690.0000 - fn: 68310.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6444 - val_loss: 0.6521 - val_tp: 41104.0000 - val_fp: 22896.0000 - val_tn: 41104.0000 - val_fn: 22896.0000 - val_accuracy: 0.6423 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-22016000-22272000
[INFO] processing batch 22272000-22528000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123672.0000 - fp: 68328.0000 - tn: 123672.0000 - fn: 68328.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6440 - val_loss: 0.6508 - val_tp: 41243.0000 - val_fp: 22757.0000 - val_tn: 41243.0000 - val_fn: 22757.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-22272000-22528000
[INFO] processing batch 22528000-22784000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123623.0000 - fp: 68377.0000 - tn: 123623.0000 - fn: 68377.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6440 - val_loss: 0.6504 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 41292.0000 - val_fn: 22708.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-22528000-22784000
[INFO] processing batch 22784000-23040000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6507 - tp: 123759.0000 - fp: 68241.0000 - tn: 123759.0000 - fn: 68241.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6514 - val_tp: 41180.0000 - val_fp: 22820.0000 - val_tn: 41180.0000 - val_fn: 22820.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-22784000-23040000
[INFO] processing batch 23040000-23296000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123507.0000 - fp: 68493.0000 - tn: 123507.0000 - fn: 68493.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6431 - val_loss: 0.6507 - val_tp: 41255.0000 - val_fp: 22745.0000 - val_tn: 41255.0000 - val_fn: 22745.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-23040000-23296000
[INFO] processing batch 23296000-23552000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6512 - tp: 123601.0000 - fp: 68399.0000 - tn: 123601.0000 - fn: 68399.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6437 - val_loss: 0.6511 - val_tp: 41213.0000 - val_fp: 22787.0000 - val_tn: 41213.0000 - val_fn: 22787.0000 - val_accuracy: 0.6440 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.6440
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-23296000-23552000
[INFO] processing batch 23552000-23808000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6508 - tp: 123749.0000 - fp: 68251.0000 - tn: 123749.0000 - fn: 68251.0000 - accuracy: 0.6445 - precision: 0.6445 - recall: 0.6445 - auc: 0.6444 - val_loss: 0.6504 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 41292.0000 - val_fn: 22708.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-23552000-23808000
[INFO] processing batch 23808000-24064000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123603.0000 - fp: 68397.0000 - tn: 123603.0000 - fn: 68397.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6431 - val_loss: 0.6516 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 41165.0000 - val_fn: 22835.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-23808000-24064000
[INFO] processing batch 24064000-24320000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123599.0000 - fp: 68401.0000 - tn: 123599.0000 - fn: 68401.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6514 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 41184.0000 - val_fn: 22816.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-24064000-24320000
[INFO] processing batch 24320000-24576000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6517 - tp: 123440.0000 - fp: 68560.0000 - tn: 123440.0000 - fn: 68560.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6426 - val_loss: 0.6515 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 41169.0000 - val_fn: 22831.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-004-files-0-50-batch-24320000-24576000
[33m[LOSS] 0.6515170283317566[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6515170283317566  <  0.001
[33m[INFO] epoch 5/10[0m
[33m[INFO] loading file 1-50/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (24819975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] Shape when encoding dataset: (24819975, 17)
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
missing -1
len(df.columns) 108
numFeatures 107
[INFO] Shape AFTER encoding dataset: (24819975, 108)
[INFO] processing batch 0-256000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.2750 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1966 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-0-256000
[INFO] processing batch 256000-512000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.7747 - tp: 112918.0000 - fp: 79082.0000 - tn: 112918.0000 - fn: 79082.0000 - accuracy: 0.5881 - precision: 0.5881 - recall: 0.5881 - auc: 0.5883 - val_loss: 0.7951 - val_tp: 33927.0000 - val_fp: 30073.0000 - val_tn: 33927.0000 - val_fn: 30073.0000 - val_accuracy: 0.5301 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-256000-512000
[INFO] processing batch 512000-768000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.5934 - tp: 138284.0000 - fp: 53716.0000 - tn: 138284.0000 - fn: 53716.0000 - accuracy: 0.7202 - precision: 0.7202 - recall: 0.7202 - auc: 0.7199 - val_loss: 0.3419 - val_tp: 62058.0000 - val_fp: 1942.0000 - val_tn: 62058.0000 - val_fn: 1942.0000 - val_accuracy: 0.9697 - val_precision: 0.9697 - val_recall: 0.9697 - val_auc: 0.9697
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-512000-768000
[INFO] processing batch 768000-1024000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6888 - tp: 117250.0000 - fp: 74750.0000 - tn: 117250.0000 - fn: 74750.0000 - accuracy: 0.6107 - precision: 0.6107 - recall: 0.6107 - auc: 0.6119 - val_loss: 0.4876 - val_tp: 55591.0000 - val_fp: 8409.0000 - val_tn: 55591.0000 - val_fn: 8409.0000 - val_accuracy: 0.8686 - val_precision: 0.8686 - val_recall: 0.8686 - val_auc: 0.8686
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-768000-1024000
[INFO] processing batch 1024000-1280000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6134 - tp: 133967.0000 - fp: 58033.0000 - tn: 133967.0000 - fn: 58033.0000 - accuracy: 0.6977 - precision: 0.6977 - recall: 0.6977 - auc: 0.6967 - val_loss: 0.3756 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-1024000-1280000
[INFO] processing batch 1280000-1536000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.2801 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2151 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-1280000-1536000
[INFO] processing batch 1536000-1792000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1801 - tp: 191999.0000 - fp: 1.0000 - tn: 191999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1516 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-1536000-1792000
[INFO] processing batch 1792000-2048000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5575 - tp: 148221.0000 - fp: 43779.0000 - tn: 148221.0000 - fn: 43779.0000 - accuracy: 0.7720 - precision: 0.7720 - recall: 0.7720 - auc: 0.7713 - val_loss: 0.3330 - val_tp: 57941.0000 - val_fp: 6059.0000 - val_tn: 57941.0000 - val_fn: 6059.0000 - val_accuracy: 0.9053 - val_precision: 0.9053 - val_recall: 0.9053 - val_auc: 0.9053
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-1792000-2048000
[INFO] processing batch 2048000-2304000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.5960 - tp: 141714.0000 - fp: 50286.0000 - tn: 141714.0000 - fn: 50286.0000 - accuracy: 0.7381 - precision: 0.7381 - recall: 0.7381 - auc: 0.7370 - val_loss: 0.2188 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-2048000-2304000
[INFO] processing batch 2304000-2560000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1792 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1467 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-2304000-2560000
[INFO] processing batch 2560000-2816000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1258 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1081 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-2560000-2816000
[INFO] processing batch 2816000-3072000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.5806 - tp: 148720.0000 - fp: 43280.0000 - tn: 148720.0000 - fn: 43280.0000 - accuracy: 0.7746 - precision: 0.7746 - recall: 0.7746 - auc: 0.7755 - val_loss: 0.8171 - val_tp: 40961.0000 - val_fp: 23039.0000 - val_tn: 40961.0000 - val_fn: 23039.0000 - val_accuracy: 0.6400 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.6400
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-2816000-3072000
[INFO] processing batch 3072000-3328000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6962 - tp: 131495.0000 - fp: 60505.0000 - tn: 131495.0000 - fn: 60505.0000 - accuracy: 0.6849 - precision: 0.6849 - recall: 0.6849 - auc: 0.6850 - val_loss: 0.2115 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-3072000-3328000
[INFO] processing batch 3328000-3584000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1760 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1455 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-3328000-3584000
[INFO] processing batch 3584000-3840000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1253 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1082 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-3584000-3840000
[INFO] processing batch 3840000-4096000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4912 - tp: 157534.0000 - fp: 34466.0000 - tn: 157534.0000 - fn: 34466.0000 - accuracy: 0.8205 - precision: 0.8205 - recall: 0.8205 - auc: 0.8202 - val_loss: 0.4938 - val_tp: 52219.0000 - val_fp: 11781.0000 - val_tn: 52219.0000 - val_fn: 11781.0000 - val_accuracy: 0.8159 - val_precision: 0.8159 - val_recall: 0.8159 - val_auc: 0.8159
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-3840000-4096000
[INFO] processing batch 4096000-4352000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1327 - tp: 190188.0000 - fp: 1812.0000 - tn: 190188.0000 - fn: 1812.0000 - accuracy: 0.9906 - precision: 0.9906 - recall: 0.9906 - auc: 0.9908 - val_loss: 0.0972 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-4096000-4352000
[INFO] processing batch 4352000-4608000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.0849 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0742 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-4352000-4608000
[INFO] processing batch 4608000-4864000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4711 - tp: 161451.0000 - fp: 30549.0000 - tn: 161451.0000 - fn: 30549.0000 - accuracy: 0.8409 - precision: 0.8409 - recall: 0.8409 - auc: 0.8407 - val_loss: 0.0966 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-4608000-4864000
[INFO] processing batch 4864000-5120000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0841 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0723 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-4864000-5120000
[INFO] processing batch 5120000-5376000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0637 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0561 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-5120000-5376000
[INFO] processing batch 5376000-5632000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0501 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0448 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-5376000-5632000
[INFO] processing batch 5632000-5888000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5881 - tp: 155809.0000 - fp: 36191.0000 - tn: 155809.0000 - fn: 36191.0000 - accuracy: 0.8115 - precision: 0.8115 - recall: 0.8115 - auc: 0.8107 - val_loss: 0.0753 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-5632000-5888000
[INFO] processing batch 5888000-6144000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.0675 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0594 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-5888000-6144000
[INFO] processing batch 6144000-6400000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.3169 - tp: 174156.0000 - fp: 17844.0000 - tn: 174156.0000 - fn: 17844.0000 - accuracy: 0.9071 - precision: 0.9071 - recall: 0.9071 - auc: 0.9083 - val_loss: 1.0186 - val_tp: 41108.0000 - val_fp: 22892.0000 - val_tn: 41108.0000 - val_fn: 22892.0000 - val_accuracy: 0.6423 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-6144000-6400000
[INFO] processing batch 6400000-6656000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.7348 - tp: 138766.0000 - fp: 53234.0000 - tn: 138766.0000 - fn: 53234.0000 - accuracy: 0.7227 - precision: 0.7227 - recall: 0.7227 - auc: 0.7220 - val_loss: 0.1266 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-6400000-6656000
[INFO] processing batch 6656000-6912000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1103 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0947 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-6656000-6912000
[INFO] processing batch 6912000-7168000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0832 - tp: 191998.0000 - fp: 2.0000 - tn: 191998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0732 - val_tp: 63999.0000 - val_fp: 1.0000 - val_tn: 63999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-6912000-7168000
[INFO] processing batch 7168000-7424000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0653 - tp: 191999.0000 - fp: 1.0000 - tn: 191999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9228 - val_tp: 44344.0000 - val_fp: 19656.0000 - val_tn: 44344.0000 - val_fn: 19656.0000 - val_accuracy: 0.6929 - val_precision: 0.6929 - val_recall: 0.6929 - val_auc: 0.6929
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-7168000-7424000
[INFO] processing batch 7424000-7680000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 1.1985 - tp: 102062.0000 - fp: 89938.0000 - tn: 102062.0000 - fn: 89938.0000 - accuracy: 0.5316 - precision: 0.5316 - recall: 0.5316 - auc: 0.5319 - val_loss: 0.5690 - val_tp: 49859.0000 - val_fp: 14141.0000 - val_tn: 49859.0000 - val_fn: 14141.0000 - val_accuracy: 0.7790 - val_precision: 0.7790 - val_recall: 0.7790 - val_auc: 0.7790
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-7424000-7680000
[INFO] processing batch 7680000-7936000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1176 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1071 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-7680000-7936000
[INFO] processing batch 7936000-8192000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0979 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0893 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-7936000-8192000
[INFO] processing batch 8192000-8448000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4576 - tp: 161781.0000 - fp: 30219.0000 - tn: 161781.0000 - fn: 30219.0000 - accuracy: 0.8426 - precision: 0.8426 - recall: 0.8426 - auc: 0.8427 - val_loss: 0.1248 - val_tp: 63369.0000 - val_fp: 631.0000 - val_tn: 63369.0000 - val_fn: 631.0000 - val_accuracy: 0.9901 - val_precision: 0.9901 - val_recall: 0.9901 - val_auc: 0.9901
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-8192000-8448000
[INFO] processing batch 8448000-8704000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.8325 - tp: 123282.0000 - fp: 68718.0000 - tn: 123282.0000 - fn: 68718.0000 - accuracy: 0.6421 - precision: 0.6421 - recall: 0.6421 - auc: 0.6412 - val_loss: 0.8147 - val_tp: 39692.0000 - val_fp: 24308.0000 - val_tn: 39692.0000 - val_fn: 24308.0000 - val_accuracy: 0.6202 - val_precision: 0.6202 - val_recall: 0.6202 - val_auc: 0.6202
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-8448000-8704000
[INFO] processing batch 8704000-8960000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1878 - tp: 188028.0000 - fp: 3972.0000 - tn: 188028.0000 - fn: 3972.0000 - accuracy: 0.9793 - precision: 0.9793 - recall: 0.9793 - auc: 0.9793 - val_loss: 0.1329 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-8704000-8960000
[INFO] processing batch 8960000-9216000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1173 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1033 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-8960000-9216000
[INFO] processing batch 9216000-9472000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.8605 - tp: 120440.0000 - fp: 71560.0000 - tn: 120440.0000 - fn: 71560.0000 - accuracy: 0.6273 - precision: 0.6273 - recall: 0.6273 - auc: 0.6247 - val_loss: 0.1684 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-9216000-9472000
[INFO] processing batch 9472000-9728000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4373 - tp: 161553.0000 - fp: 30447.0000 - tn: 161553.0000 - fn: 30447.0000 - accuracy: 0.8414 - precision: 0.8414 - recall: 0.8414 - auc: 0.8414 - val_loss: 0.4474 - val_tp: 53468.0000 - val_fp: 10532.0000 - val_tn: 53468.0000 - val_fn: 10532.0000 - val_accuracy: 0.8354 - val_precision: 0.8354 - val_recall: 0.8354 - val_auc: 0.8354
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-9472000-9728000
[INFO] processing batch 9728000-9984000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1469 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1258 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-9728000-9984000
[INFO] processing batch 9984000-10240000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1105 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0970 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-9984000-10240000
[INFO] processing batch 10240000-10496000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1187 - tp: 189510.0000 - fp: 2490.0000 - tn: 189510.0000 - fn: 2490.0000 - accuracy: 0.9870 - precision: 0.9870 - recall: 0.9870 - auc: 0.9867 - val_loss: 1.2492 - val_tp: 33975.0000 - val_fp: 30025.0000 - val_tn: 33975.0000 - val_fn: 30025.0000 - val_accuracy: 0.5309 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.5309
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-10240000-10496000
[INFO] processing batch 10496000-10752000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 1.1049 - tp: 101670.0000 - fp: 90330.0000 - tn: 101670.0000 - fn: 90330.0000 - accuracy: 0.5295 - precision: 0.5295 - recall: 0.5295 - auc: 0.5291 - val_loss: 0.9855 - val_tp: 34015.0000 - val_fp: 29985.0000 - val_tn: 34015.0000 - val_fn: 29985.0000 - val_accuracy: 0.5315 - val_precision: 0.5315 - val_recall: 0.5315 - val_auc: 0.5315
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-10496000-10752000
[INFO] processing batch 10752000-11008000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.9152 - tp: 101693.0000 - fp: 90307.0000 - tn: 101693.0000 - fn: 90307.0000 - accuracy: 0.5297 - precision: 0.5297 - recall: 0.5297 - auc: 0.5298 - val_loss: 0.3829 - val_tp: 56989.0000 - val_fp: 7011.0000 - val_tn: 56989.0000 - val_fn: 7011.0000 - val_accuracy: 0.8905 - val_precision: 0.8905 - val_recall: 0.8905 - val_auc: 0.8905
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-10752000-11008000
[INFO] processing batch 11008000-11264000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.2126 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1856 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-11008000-11264000
[INFO] processing batch 11264000-11520000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1647 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1460 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-11264000-11520000
[INFO] processing batch 11520000-11776000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1309 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1172 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-11520000-11776000
[INFO] processing batch 11776000-12032000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.4990 - tp: 156412.0000 - fp: 35588.0000 - tn: 156412.0000 - fn: 35588.0000 - accuracy: 0.8146 - precision: 0.8146 - recall: 0.8146 - auc: 0.8147 - val_loss: 0.8287 - val_tp: 41134.0000 - val_fp: 22866.0000 - val_tn: 41134.0000 - val_fn: 22866.0000 - val_accuracy: 0.6427 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.6427
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-11776000-12032000
[INFO] processing batch 12032000-12288000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.7781 - tp: 123527.0000 - fp: 68473.0000 - tn: 123527.0000 - fn: 68473.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6437 - val_loss: 0.7356 - val_tp: 41219.0000 - val_fp: 22781.0000 - val_tn: 41219.0000 - val_fn: 22781.0000 - val_accuracy: 0.6440 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.6440
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-12032000-12288000
[INFO] processing batch 12288000-12544000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.7096 - tp: 123560.0000 - fp: 68440.0000 - tn: 123560.0000 - fn: 68440.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6434 - val_loss: 0.6867 - val_tp: 41268.0000 - val_fp: 22732.0000 - val_tn: 41268.0000 - val_fn: 22732.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-12288000-12544000
[INFO] processing batch 12544000-12800000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6750 - tp: 123588.0000 - fp: 68412.0000 - tn: 123588.0000 - fn: 68412.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6440 - val_loss: 0.6638 - val_tp: 41269.0000 - val_fp: 22731.0000 - val_tn: 41269.0000 - val_fn: 22731.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-12544000-12800000
[INFO] processing batch 12800000-13056000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6596 - tp: 123531.0000 - fp: 68469.0000 - tn: 123531.0000 - fn: 68469.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6430 - val_loss: 0.6555 - val_tp: 41181.0000 - val_fp: 22819.0000 - val_tn: 41181.0000 - val_fn: 22819.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-12800000-13056000
[INFO] processing batch 13056000-13312000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6534 - tp: 123615.0000 - fp: 68385.0000 - tn: 123615.0000 - fn: 68385.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6440 - val_loss: 0.6523 - val_tp: 41192.0000 - val_fp: 22808.0000 - val_tn: 41192.0000 - val_fn: 22808.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-13056000-13312000
[INFO] processing batch 13312000-13568000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6522 - tp: 123437.0000 - fp: 68563.0000 - tn: 123437.0000 - fn: 68563.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6430 - val_loss: 0.6516 - val_tp: 41179.0000 - val_fp: 22821.0000 - val_tn: 41179.0000 - val_fn: 22821.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-13312000-13568000
[INFO] processing batch 13568000-13824000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123539.0000 - fp: 68461.0000 - tn: 123539.0000 - fn: 68461.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6431 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-13568000-13824000
[INFO] processing batch 13824000-14080000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.6514 - tp: 123556.0000 - fp: 68444.0000 - tn: 123556.0000 - fn: 68444.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6515 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 41173.0000 - val_fn: 22827.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-13824000-14080000
[INFO] processing batch 14080000-14336000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 16s - loss: 0.6510 - tp: 123681.0000 - fp: 68319.0000 - tn: 123681.0000 - fn: 68319.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6510 - val_tp: 41221.0000 - val_fp: 22779.0000 - val_tn: 41221.0000 - val_fn: 22779.0000 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.6441
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-14080000-14336000
[INFO] processing batch 14336000-14592000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123523.0000 - fp: 68477.0000 - tn: 123523.0000 - fn: 68477.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6433 - val_loss: 0.6513 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 41197.0000 - val_fn: 22803.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-14336000-14592000
[INFO] processing batch 14592000-14848000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123652.0000 - fp: 68348.0000 - tn: 123652.0000 - fn: 68348.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6439 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-14592000-14848000
[INFO] processing batch 14848000-15104000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6512 - tp: 123594.0000 - fp: 68406.0000 - tn: 123594.0000 - fn: 68406.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6434 - val_loss: 0.6512 - val_tp: 41205.0000 - val_fp: 22795.0000 - val_tn: 41205.0000 - val_fn: 22795.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-14848000-15104000
[INFO] processing batch 15104000-15360000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123629.0000 - fp: 68371.0000 - tn: 123629.0000 - fn: 68371.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6509 - val_tp: 41234.0000 - val_fp: 22766.0000 - val_tn: 41234.0000 - val_fn: 22766.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-15104000-15360000
[INFO] processing batch 15360000-15616000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123632.0000 - fp: 68368.0000 - tn: 123632.0000 - fn: 68368.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6440 - val_loss: 0.6506 - val_tp: 41266.0000 - val_fp: 22734.0000 - val_tn: 41266.0000 - val_fn: 22734.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-15360000-15616000
[INFO] processing batch 15616000-15872000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123527.0000 - fp: 68473.0000 - tn: 123527.0000 - fn: 68473.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6434 - val_loss: 0.6513 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 41197.0000 - val_fn: 22803.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-15616000-15872000
[INFO] processing batch 15872000-16128000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6514 - tp: 123531.0000 - fp: 68469.0000 - tn: 123531.0000 - fn: 68469.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6430 - val_loss: 0.6515 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 41173.0000 - val_fn: 22827.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-15872000-16128000
[INFO] processing batch 16128000-16384000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6507 - tp: 123781.0000 - fp: 68219.0000 - tn: 123781.0000 - fn: 68219.0000 - accuracy: 0.6447 - precision: 0.6447 - recall: 0.6447 - auc: 0.6445 - val_loss: 0.6513 - val_tp: 41195.0000 - val_fp: 22805.0000 - val_tn: 41195.0000 - val_fn: 22805.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-16128000-16384000
[INFO] processing batch 16384000-16640000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6512 - tp: 123621.0000 - fp: 68379.0000 - tn: 123621.0000 - fn: 68379.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6437 - val_loss: 0.6516 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 41165.0000 - val_fn: 22835.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-16384000-16640000
[INFO] processing batch 16640000-16896000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6518 - tp: 123417.0000 - fp: 68583.0000 - tn: 123417.0000 - fn: 68583.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6422 - val_loss: 0.6510 - val_tp: 41230.0000 - val_fp: 22770.0000 - val_tn: 41230.0000 - val_fn: 22770.0000 - val_accuracy: 0.6442 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.6442
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-16640000-16896000
[INFO] processing batch 16896000-17152000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123600.0000 - fp: 68400.0000 - tn: 123600.0000 - fn: 68400.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6435 - val_loss: 0.6513 - val_tp: 41198.0000 - val_fp: 22802.0000 - val_tn: 41198.0000 - val_fn: 22802.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-16896000-17152000
[INFO] processing batch 17152000-17408000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123711.0000 - fp: 68289.0000 - tn: 123711.0000 - fn: 68289.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6439 - val_loss: 0.6515 - val_tp: 41168.0000 - val_fp: 22832.0000 - val_tn: 41168.0000 - val_fn: 22832.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-17152000-17408000
[INFO] processing batch 17408000-17664000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123701.0000 - fp: 68299.0000 - tn: 123701.0000 - fn: 68299.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6444 - val_loss: 0.6520 - val_tp: 41118.0000 - val_fp: 22882.0000 - val_tn: 41118.0000 - val_fn: 22882.0000 - val_accuracy: 0.6425 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.6425
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-17408000-17664000
[INFO] processing batch 17664000-17920000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123546.0000 - fp: 68454.0000 - tn: 123546.0000 - fn: 68454.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6433 - val_loss: 0.6523 - val_tp: 41089.0000 - val_fp: 22911.0000 - val_tn: 41089.0000 - val_fn: 22911.0000 - val_accuracy: 0.6420 - val_precision: 0.6420 - val_recall: 0.6420 - val_auc: 0.6420
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-17664000-17920000
[INFO] processing batch 17920000-18176000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123681.0000 - fp: 68319.0000 - tn: 123681.0000 - fn: 68319.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6509 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 41233.0000 - val_fn: 22767.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-17920000-18176000
[INFO] processing batch 18176000-18432000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123640.0000 - fp: 68360.0000 - tn: 123640.0000 - fn: 68360.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6433 - val_loss: 0.6503 - val_tp: 41298.0000 - val_fp: 22702.0000 - val_tn: 41298.0000 - val_fn: 22702.0000 - val_accuracy: 0.6453 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.6453
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-18176000-18432000
[INFO] processing batch 18432000-18688000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123615.0000 - fp: 68385.0000 - tn: 123615.0000 - fn: 68385.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6435 - val_loss: 0.6509 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 41233.0000 - val_fn: 22767.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-18432000-18688000
[INFO] processing batch 18688000-18944000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123645.0000 - fp: 68355.0000 - tn: 123645.0000 - fn: 68355.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6439 - val_loss: 0.6514 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 41184.0000 - val_fn: 22816.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-18688000-18944000
[INFO] processing batch 18944000-19200000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6503 - tp: 123888.0000 - fp: 68112.0000 - tn: 123888.0000 - fn: 68112.0000 - accuracy: 0.6453 - precision: 0.6453 - recall: 0.6453 - auc: 0.6453 - val_loss: 0.6515 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 41169.0000 - val_fn: 22831.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-18944000-19200000
[INFO] processing batch 19200000-19456000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123500.0000 - fp: 68500.0000 - tn: 123500.0000 - fn: 68500.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6430 - val_loss: 0.6513 - val_tp: 41189.0000 - val_fp: 22811.0000 - val_tn: 41189.0000 - val_fn: 22811.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-19200000-19456000
[INFO] processing batch 19456000-19712000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123689.0000 - fp: 68311.0000 - tn: 123689.0000 - fn: 68311.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6515 - val_tp: 41166.0000 - val_fp: 22834.0000 - val_tn: 41166.0000 - val_fn: 22834.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-19456000-19712000
[INFO] processing batch 19712000-19968000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6518 - tp: 123402.0000 - fp: 68598.0000 - tn: 123402.0000 - fn: 68598.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6430 - val_loss: 0.6509 - val_tp: 41242.0000 - val_fp: 22758.0000 - val_tn: 41242.0000 - val_fn: 22758.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-19712000-19968000
[INFO] processing batch 19968000-20224000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123541.0000 - fp: 68459.0000 - tn: 123541.0000 - fn: 68459.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6433 - val_loss: 0.6509 - val_tp: 41241.0000 - val_fp: 22759.0000 - val_tn: 41241.0000 - val_fn: 22759.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-19968000-20224000
[INFO] processing batch 20224000-20480000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123640.0000 - fp: 68360.0000 - tn: 123640.0000 - fn: 68360.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6440 - val_loss: 0.6512 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 41209.0000 - val_fn: 22791.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-20224000-20480000
[INFO] processing batch 20480000-20736000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123598.0000 - fp: 68402.0000 - tn: 123598.0000 - fn: 68402.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6509 - val_tp: 41235.0000 - val_fp: 22765.0000 - val_tn: 41235.0000 - val_fn: 22765.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-20480000-20736000
[INFO] processing batch 20736000-20992000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6507 - tp: 123769.0000 - fp: 68231.0000 - tn: 123769.0000 - fn: 68231.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6445 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-20736000-20992000
[INFO] processing batch 20992000-21248000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6517 - tp: 123459.0000 - fp: 68541.0000 - tn: 123459.0000 - fn: 68541.0000 - accuracy: 0.6430 - precision: 0.6430 - recall: 0.6430 - auc: 0.6431 - val_loss: 0.6511 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 41209.0000 - val_fn: 22791.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-20992000-21248000
[INFO] processing batch 21248000-21504000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123683.0000 - fp: 68317.0000 - tn: 123683.0000 - fn: 68317.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6440 - val_loss: 0.6514 - val_tp: 41183.0000 - val_fp: 22817.0000 - val_tn: 41183.0000 - val_fn: 22817.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-21248000-21504000
[INFO] processing batch 21504000-21760000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.6513 - tp: 123564.0000 - fp: 68436.0000 - tn: 123564.0000 - fn: 68436.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6434 - val_loss: 0.6507 - val_tp: 41254.0000 - val_fp: 22746.0000 - val_tn: 41254.0000 - val_fn: 22746.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-21504000-21760000
[INFO] processing batch 21760000-22016000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123717.0000 - fp: 68283.0000 - tn: 123717.0000 - fn: 68283.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6442 - val_loss: 0.6506 - val_tp: 41270.0000 - val_fp: 22730.0000 - val_tn: 41270.0000 - val_fn: 22730.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-21760000-22016000
[INFO] processing batch 22016000-22272000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123690.0000 - fp: 68310.0000 - tn: 123690.0000 - fn: 68310.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6438 - val_loss: 0.6521 - val_tp: 41104.0000 - val_fp: 22896.0000 - val_tn: 41104.0000 - val_fn: 22896.0000 - val_accuracy: 0.6423 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-22016000-22272000
[INFO] processing batch 22272000-22528000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123672.0000 - fp: 68328.0000 - tn: 123672.0000 - fn: 68328.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6439 - val_loss: 0.6508 - val_tp: 41243.0000 - val_fp: 22757.0000 - val_tn: 41243.0000 - val_fn: 22757.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-22272000-22528000
[INFO] processing batch 22528000-22784000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123623.0000 - fp: 68377.0000 - tn: 123623.0000 - fn: 68377.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6437 - val_loss: 0.6504 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 41292.0000 - val_fn: 22708.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-22528000-22784000
[INFO] processing batch 22784000-23040000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6507 - tp: 123759.0000 - fp: 68241.0000 - tn: 123759.0000 - fn: 68241.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6514 - val_tp: 41180.0000 - val_fp: 22820.0000 - val_tn: 41180.0000 - val_fn: 22820.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-22784000-23040000
[INFO] processing batch 23040000-23296000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123507.0000 - fp: 68493.0000 - tn: 123507.0000 - fn: 68493.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6431 - val_loss: 0.6507 - val_tp: 41255.0000 - val_fp: 22745.0000 - val_tn: 41255.0000 - val_fn: 22745.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-23040000-23296000
[INFO] processing batch 23296000-23552000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123601.0000 - fp: 68399.0000 - tn: 123601.0000 - fn: 68399.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6439 - val_loss: 0.6511 - val_tp: 41213.0000 - val_fp: 22787.0000 - val_tn: 41213.0000 - val_fn: 22787.0000 - val_accuracy: 0.6440 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.6440
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-23296000-23552000
[INFO] processing batch 23552000-23808000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6508 - tp: 123749.0000 - fp: 68251.0000 - tn: 123749.0000 - fn: 68251.0000 - accuracy: 0.6445 - precision: 0.6445 - recall: 0.6445 - auc: 0.6445 - val_loss: 0.6504 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 41292.0000 - val_fn: 22708.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-23552000-23808000
[INFO] processing batch 23808000-24064000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123603.0000 - fp: 68397.0000 - tn: 123603.0000 - fn: 68397.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6436 - val_loss: 0.6516 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 41165.0000 - val_fn: 22835.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-23808000-24064000
[INFO] processing batch 24064000-24320000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123599.0000 - fp: 68401.0000 - tn: 123599.0000 - fn: 68401.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6441 - val_loss: 0.6514 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 41184.0000 - val_fn: 22816.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-24064000-24320000
[INFO] processing batch 24320000-24576000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6517 - tp: 123440.0000 - fp: 68560.0000 - tn: 123440.0000 - fn: 68560.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6427 - val_loss: 0.6515 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 41169.0000 - val_fn: 22831.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-005-files-0-50-batch-24320000-24576000
[33m[LOSS] 0.6515166039466858[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6515166039466858  <  0.001
[33m[INFO] epoch 6/10[0m
[33m[INFO] loading file 1-50/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (24819975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] Shape when encoding dataset: (24819975, 17)
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
missing -1
len(df.columns) 108
numFeatures 107
[INFO] Shape AFTER encoding dataset: (24819975, 108)
[INFO] processing batch 0-256000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.2732 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1953 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-0-256000
[INFO] processing batch 256000-512000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.7759 - tp: 112918.0000 - fp: 79082.0000 - tn: 112918.0000 - fn: 79082.0000 - accuracy: 0.5881 - precision: 0.5881 - recall: 0.5881 - auc: 0.5875 - val_loss: 0.7960 - val_tp: 33927.0000 - val_fp: 30073.0000 - val_tn: 33927.0000 - val_fn: 30073.0000 - val_accuracy: 0.5301 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-256000-512000
[INFO] processing batch 512000-768000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5935 - tp: 138284.0000 - fp: 53716.0000 - tn: 138284.0000 - fn: 53716.0000 - accuracy: 0.7202 - precision: 0.7202 - recall: 0.7202 - auc: 0.7190 - val_loss: 0.3409 - val_tp: 62058.0000 - val_fp: 1942.0000 - val_tn: 62058.0000 - val_fn: 1942.0000 - val_accuracy: 0.9697 - val_precision: 0.9697 - val_recall: 0.9697 - val_auc: 0.9697
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-512000-768000
[INFO] processing batch 768000-1024000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6891 - tp: 117250.0000 - fp: 74750.0000 - tn: 117250.0000 - fn: 74750.0000 - accuracy: 0.6107 - precision: 0.6107 - recall: 0.6107 - auc: 0.6102 - val_loss: 0.4869 - val_tp: 55591.0000 - val_fp: 8409.0000 - val_tn: 55591.0000 - val_fn: 8409.0000 - val_accuracy: 0.8686 - val_precision: 0.8686 - val_recall: 0.8686 - val_auc: 0.8686
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-768000-1024000
[INFO] processing batch 1024000-1280000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6134 - tp: 133967.0000 - fp: 58033.0000 - tn: 133967.0000 - fn: 58033.0000 - accuracy: 0.6977 - precision: 0.6977 - recall: 0.6977 - auc: 0.6976 - val_loss: 0.3751 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-1024000-1280000
[INFO] processing batch 1280000-1536000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.2796 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2148 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-1280000-1536000
[INFO] processing batch 1536000-1792000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1798 - tp: 191999.0000 - fp: 1.0000 - tn: 191999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1515 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-1536000-1792000
[INFO] processing batch 1792000-2048000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.5575 - tp: 148221.0000 - fp: 43779.0000 - tn: 148221.0000 - fn: 43779.0000 - accuracy: 0.7720 - precision: 0.7720 - recall: 0.7720 - auc: 0.7721 - val_loss: 0.3330 - val_tp: 57941.0000 - val_fp: 6059.0000 - val_tn: 57941.0000 - val_fn: 6059.0000 - val_accuracy: 0.9053 - val_precision: 0.9053 - val_recall: 0.9053 - val_auc: 0.9053
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-1792000-2048000
[INFO] processing batch 2048000-2304000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5960 - tp: 141714.0000 - fp: 50286.0000 - tn: 141714.0000 - fn: 50286.0000 - accuracy: 0.7381 - precision: 0.7381 - recall: 0.7381 - auc: 0.7371 - val_loss: 0.2185 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-2048000-2304000
[INFO] processing batch 2304000-2560000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.1792 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1467 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-2304000-2560000
[INFO] processing batch 2560000-2816000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1258 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1082 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-2560000-2816000
[INFO] processing batch 2816000-3072000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5807 - tp: 148720.0000 - fp: 43280.0000 - tn: 148720.0000 - fn: 43280.0000 - accuracy: 0.7746 - precision: 0.7746 - recall: 0.7746 - auc: 0.7731 - val_loss: 0.8173 - val_tp: 40961.0000 - val_fp: 23039.0000 - val_tn: 40961.0000 - val_fn: 23039.0000 - val_accuracy: 0.6400 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.6400
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-2816000-3072000
[INFO] processing batch 3072000-3328000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6965 - tp: 131495.0000 - fp: 60505.0000 - tn: 131495.0000 - fn: 60505.0000 - accuracy: 0.6849 - precision: 0.6849 - recall: 0.6849 - auc: 0.6838 - val_loss: 0.2111 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-3072000-3328000
[INFO] processing batch 3328000-3584000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1757 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1453 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-3328000-3584000
[INFO] processing batch 3584000-3840000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1251 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1080 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-3584000-3840000
[INFO] processing batch 3840000-4096000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4912 - tp: 157534.0000 - fp: 34466.0000 - tn: 157534.0000 - fn: 34466.0000 - accuracy: 0.8205 - precision: 0.8205 - recall: 0.8205 - auc: 0.8205 - val_loss: 0.4939 - val_tp: 52219.0000 - val_fp: 11781.0000 - val_tn: 52219.0000 - val_fn: 11781.0000 - val_accuracy: 0.8159 - val_precision: 0.8159 - val_recall: 0.8159 - val_auc: 0.8159
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-3840000-4096000
[INFO] processing batch 4096000-4352000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.1326 - tp: 190188.0000 - fp: 1812.0000 - tn: 190188.0000 - fn: 1812.0000 - accuracy: 0.9906 - precision: 0.9906 - recall: 0.9906 - auc: 0.9908 - val_loss: 0.0972 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-4096000-4352000
[INFO] processing batch 4352000-4608000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.0849 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0742 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-4352000-4608000
[INFO] processing batch 4608000-4864000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4711 - tp: 161451.0000 - fp: 30549.0000 - tn: 161451.0000 - fn: 30549.0000 - accuracy: 0.8409 - precision: 0.8409 - recall: 0.8409 - auc: 0.8413 - val_loss: 0.0966 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-4608000-4864000
[INFO] processing batch 4864000-5120000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0840 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0723 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-4864000-5120000
[INFO] processing batch 5120000-5376000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0637 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0561 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-5120000-5376000
[INFO] processing batch 5376000-5632000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0501 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0447 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-5376000-5632000
[INFO] processing batch 5632000-5888000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.5880 - tp: 155809.0000 - fp: 36191.0000 - tn: 155809.0000 - fn: 36191.0000 - accuracy: 0.8115 - precision: 0.8115 - recall: 0.8115 - auc: 0.8114 - val_loss: 0.0756 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-5632000-5888000
[INFO] processing batch 5888000-6144000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0676 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0595 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-5888000-6144000
[INFO] processing batch 6144000-6400000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.3169 - tp: 174156.0000 - fp: 17844.0000 - tn: 174156.0000 - fn: 17844.0000 - accuracy: 0.9071 - precision: 0.9071 - recall: 0.9071 - auc: 0.9081 - val_loss: 1.0187 - val_tp: 41108.0000 - val_fp: 22892.0000 - val_tn: 41108.0000 - val_fn: 22892.0000 - val_accuracy: 0.6423 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-6144000-6400000
[INFO] processing batch 6400000-6656000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.7343 - tp: 138766.0000 - fp: 53234.0000 - tn: 138766.0000 - fn: 53234.0000 - accuracy: 0.7227 - precision: 0.7227 - recall: 0.7227 - auc: 0.7241 - val_loss: 0.1270 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-6400000-6656000
[INFO] processing batch 6656000-6912000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1106 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0949 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-6656000-6912000
[INFO] processing batch 6912000-7168000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 16s - loss: 0.0834 - tp: 191998.0000 - fp: 2.0000 - tn: 191998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0733 - val_tp: 63999.0000 - val_fp: 1.0000 - val_tn: 63999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-6912000-7168000
[INFO] processing batch 7168000-7424000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0654 - tp: 191999.0000 - fp: 1.0000 - tn: 191999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9223 - val_tp: 44344.0000 - val_fp: 19656.0000 - val_tn: 44344.0000 - val_fn: 19656.0000 - val_accuracy: 0.6929 - val_precision: 0.6929 - val_recall: 0.6929 - val_auc: 0.6929
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-7168000-7424000
[INFO] processing batch 7424000-7680000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 1.1981 - tp: 102062.0000 - fp: 89938.0000 - tn: 102062.0000 - fn: 89938.0000 - accuracy: 0.5316 - precision: 0.5316 - recall: 0.5316 - auc: 0.5311 - val_loss: 0.5689 - val_tp: 49859.0000 - val_fp: 14141.0000 - val_tn: 49859.0000 - val_fn: 14141.0000 - val_accuracy: 0.7790 - val_precision: 0.7790 - val_recall: 0.7790 - val_auc: 0.7790
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-7424000-7680000
[INFO] processing batch 7680000-7936000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1177 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1072 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-7680000-7936000
[INFO] processing batch 7936000-8192000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.0980 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0894 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-7936000-8192000
[INFO] processing batch 8192000-8448000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.4576 - tp: 161781.0000 - fp: 30219.0000 - tn: 161781.0000 - fn: 30219.0000 - accuracy: 0.8426 - precision: 0.8426 - recall: 0.8426 - auc: 0.8425 - val_loss: 0.1248 - val_tp: 63369.0000 - val_fp: 631.0000 - val_tn: 63369.0000 - val_fn: 631.0000 - val_accuracy: 0.9901 - val_precision: 0.9901 - val_recall: 0.9901 - val_auc: 0.9901
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-8192000-8448000
[INFO] processing batch 8448000-8704000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.8323 - tp: 123282.0000 - fp: 68718.0000 - tn: 123282.0000 - fn: 68718.0000 - accuracy: 0.6421 - precision: 0.6421 - recall: 0.6421 - auc: 0.6429 - val_loss: 0.8144 - val_tp: 39692.0000 - val_fp: 24308.0000 - val_tn: 39692.0000 - val_fn: 24308.0000 - val_accuracy: 0.6202 - val_precision: 0.6202 - val_recall: 0.6202 - val_auc: 0.6202
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-8448000-8704000
[INFO] processing batch 8704000-8960000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1879 - tp: 188028.0000 - fp: 3972.0000 - tn: 188028.0000 - fn: 3972.0000 - accuracy: 0.9793 - precision: 0.9793 - recall: 0.9793 - auc: 0.9795 - val_loss: 0.1331 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-8704000-8960000
[INFO] processing batch 8960000-9216000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1174 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1034 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-8960000-9216000
[INFO] processing batch 9216000-9472000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.8601 - tp: 120440.0000 - fp: 71560.0000 - tn: 120440.0000 - fn: 71560.0000 - accuracy: 0.6273 - precision: 0.6273 - recall: 0.6273 - auc: 0.6264 - val_loss: 0.1687 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-9216000-9472000
[INFO] processing batch 9472000-9728000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.4373 - tp: 161553.0000 - fp: 30447.0000 - tn: 161553.0000 - fn: 30447.0000 - accuracy: 0.8414 - precision: 0.8414 - recall: 0.8414 - auc: 0.8415 - val_loss: 0.4474 - val_tp: 53468.0000 - val_fp: 10532.0000 - val_tn: 53468.0000 - val_fn: 10532.0000 - val_accuracy: 0.8354 - val_precision: 0.8354 - val_recall: 0.8354 - val_auc: 0.8354
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-9472000-9728000
[INFO] processing batch 9728000-9984000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1471 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1260 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-9728000-9984000
[INFO] processing batch 9984000-10240000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1106 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0971 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-9984000-10240000
[INFO] processing batch 10240000-10496000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1188 - tp: 189510.0000 - fp: 2490.0000 - tn: 189510.0000 - fn: 2490.0000 - accuracy: 0.9870 - precision: 0.9870 - recall: 0.9870 - auc: 0.9869 - val_loss: 1.2490 - val_tp: 33975.0000 - val_fp: 30025.0000 - val_tn: 33975.0000 - val_fn: 30025.0000 - val_accuracy: 0.5309 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.5309
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-10240000-10496000
[INFO] processing batch 10496000-10752000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 1.1045 - tp: 101670.0000 - fp: 90330.0000 - tn: 101670.0000 - fn: 90330.0000 - accuracy: 0.5295 - precision: 0.5295 - recall: 0.5295 - auc: 0.5300 - val_loss: 0.9851 - val_tp: 34015.0000 - val_fp: 29985.0000 - val_tn: 34015.0000 - val_fn: 29985.0000 - val_accuracy: 0.5315 - val_precision: 0.5315 - val_recall: 0.5315 - val_auc: 0.5315
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-10496000-10752000
[INFO] processing batch 10752000-11008000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.9149 - tp: 101693.0000 - fp: 90307.0000 - tn: 101693.0000 - fn: 90307.0000 - accuracy: 0.5297 - precision: 0.5297 - recall: 0.5297 - auc: 0.5294 - val_loss: 0.3829 - val_tp: 56989.0000 - val_fp: 7011.0000 - val_tn: 56989.0000 - val_fn: 7011.0000 - val_accuracy: 0.8905 - val_precision: 0.8905 - val_recall: 0.8905 - val_auc: 0.8905
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-10752000-11008000
[INFO] processing batch 11008000-11264000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.2127 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1857 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-11008000-11264000
[INFO] processing batch 11264000-11520000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1648 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1461 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-11264000-11520000
[INFO] processing batch 11520000-11776000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1310 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1173 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-11520000-11776000
[INFO] processing batch 11776000-12032000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4990 - tp: 156412.0000 - fp: 35588.0000 - tn: 156412.0000 - fn: 35588.0000 - accuracy: 0.8146 - precision: 0.8146 - recall: 0.8146 - auc: 0.8147 - val_loss: 0.8287 - val_tp: 41134.0000 - val_fp: 22866.0000 - val_tn: 41134.0000 - val_fn: 22866.0000 - val_accuracy: 0.6427 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.6427
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-11776000-12032000
[INFO] processing batch 12032000-12288000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.7781 - tp: 123527.0000 - fp: 68473.0000 - tn: 123527.0000 - fn: 68473.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6434 - val_loss: 0.7356 - val_tp: 41219.0000 - val_fp: 22781.0000 - val_tn: 41219.0000 - val_fn: 22781.0000 - val_accuracy: 0.6440 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.6440
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-12032000-12288000
[INFO] processing batch 12288000-12544000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.7097 - tp: 123560.0000 - fp: 68440.0000 - tn: 123560.0000 - fn: 68440.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6439 - val_loss: 0.6867 - val_tp: 41268.0000 - val_fp: 22732.0000 - val_tn: 41268.0000 - val_fn: 22732.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-12288000-12544000
[INFO] processing batch 12544000-12800000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6750 - tp: 123588.0000 - fp: 68412.0000 - tn: 123588.0000 - fn: 68412.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6438 - val_loss: 0.6639 - val_tp: 41269.0000 - val_fp: 22731.0000 - val_tn: 41269.0000 - val_fn: 22731.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-12544000-12800000
[INFO] processing batch 12800000-13056000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6596 - tp: 123531.0000 - fp: 68469.0000 - tn: 123531.0000 - fn: 68469.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6431 - val_loss: 0.6555 - val_tp: 41181.0000 - val_fp: 22819.0000 - val_tn: 41181.0000 - val_fn: 22819.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-12800000-13056000
[INFO] processing batch 13056000-13312000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6534 - tp: 123615.0000 - fp: 68385.0000 - tn: 123615.0000 - fn: 68385.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6437 - val_loss: 0.6523 - val_tp: 41192.0000 - val_fp: 22808.0000 - val_tn: 41192.0000 - val_fn: 22808.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-13056000-13312000
[INFO] processing batch 13312000-13568000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6522 - tp: 123437.0000 - fp: 68563.0000 - tn: 123437.0000 - fn: 68563.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6434 - val_loss: 0.6516 - val_tp: 41179.0000 - val_fp: 22821.0000 - val_tn: 41179.0000 - val_fn: 22821.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-13312000-13568000
[INFO] processing batch 13568000-13824000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123539.0000 - fp: 68461.0000 - tn: 123539.0000 - fn: 68461.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6436 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-13568000-13824000
[INFO] processing batch 13824000-14080000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6514 - tp: 123556.0000 - fp: 68444.0000 - tn: 123556.0000 - fn: 68444.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6515 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 41173.0000 - val_fn: 22827.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-13824000-14080000
[INFO] processing batch 14080000-14336000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6510 - tp: 123681.0000 - fp: 68319.0000 - tn: 123681.0000 - fn: 68319.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6510 - val_tp: 41221.0000 - val_fp: 22779.0000 - val_tn: 41221.0000 - val_fn: 22779.0000 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.6441
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-14080000-14336000
[INFO] processing batch 14336000-14592000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6515 - tp: 123523.0000 - fp: 68477.0000 - tn: 123523.0000 - fn: 68477.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6431 - val_loss: 0.6513 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 41197.0000 - val_fn: 22803.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-14336000-14592000
[INFO] processing batch 14592000-14848000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123652.0000 - fp: 68348.0000 - tn: 123652.0000 - fn: 68348.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6439 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-14592000-14848000
[INFO] processing batch 14848000-15104000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.6512 - tp: 123594.0000 - fp: 68406.0000 - tn: 123594.0000 - fn: 68406.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6436 - val_loss: 0.6512 - val_tp: 41205.0000 - val_fp: 22795.0000 - val_tn: 41205.0000 - val_fn: 22795.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-14848000-15104000
[INFO] processing batch 15104000-15360000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123629.0000 - fp: 68371.0000 - tn: 123629.0000 - fn: 68371.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6437 - val_loss: 0.6509 - val_tp: 41234.0000 - val_fp: 22766.0000 - val_tn: 41234.0000 - val_fn: 22766.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-15104000-15360000
[INFO] processing batch 15360000-15616000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123632.0000 - fp: 68368.0000 - tn: 123632.0000 - fn: 68368.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6506 - val_tp: 41266.0000 - val_fp: 22734.0000 - val_tn: 41266.0000 - val_fn: 22734.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-15360000-15616000
[INFO] processing batch 15616000-15872000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.6515 - tp: 123527.0000 - fp: 68473.0000 - tn: 123527.0000 - fn: 68473.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6431 - val_loss: 0.6513 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 41197.0000 - val_fn: 22803.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-15616000-15872000
[INFO] processing batch 15872000-16128000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123531.0000 - fp: 68469.0000 - tn: 123531.0000 - fn: 68469.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6428 - val_loss: 0.6515 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 41173.0000 - val_fn: 22827.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-15872000-16128000
[INFO] processing batch 16128000-16384000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6507 - tp: 123781.0000 - fp: 68219.0000 - tn: 123781.0000 - fn: 68219.0000 - accuracy: 0.6447 - precision: 0.6447 - recall: 0.6447 - auc: 0.6452 - val_loss: 0.6513 - val_tp: 41195.0000 - val_fp: 22805.0000 - val_tn: 41195.0000 - val_fn: 22805.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-16128000-16384000
[INFO] processing batch 16384000-16640000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 16s - loss: 0.6512 - tp: 123621.0000 - fp: 68379.0000 - tn: 123621.0000 - fn: 68379.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6437 - val_loss: 0.6516 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 41165.0000 - val_fn: 22835.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-16384000-16640000
[INFO] processing batch 16640000-16896000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6518 - tp: 123417.0000 - fp: 68583.0000 - tn: 123417.0000 - fn: 68583.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6427 - val_loss: 0.6510 - val_tp: 41230.0000 - val_fp: 22770.0000 - val_tn: 41230.0000 - val_fn: 22770.0000 - val_accuracy: 0.6442 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.6442
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-16640000-16896000
[INFO] processing batch 16896000-17152000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123600.0000 - fp: 68400.0000 - tn: 123600.0000 - fn: 68400.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6435 - val_loss: 0.6513 - val_tp: 41198.0000 - val_fp: 22802.0000 - val_tn: 41198.0000 - val_fn: 22802.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-16896000-17152000
[INFO] processing batch 17152000-17408000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123711.0000 - fp: 68289.0000 - tn: 123711.0000 - fn: 68289.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6442 - val_loss: 0.6515 - val_tp: 41168.0000 - val_fp: 22832.0000 - val_tn: 41168.0000 - val_fn: 22832.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-17152000-17408000
[INFO] processing batch 17408000-17664000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123701.0000 - fp: 68299.0000 - tn: 123701.0000 - fn: 68299.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6442 - val_loss: 0.6520 - val_tp: 41118.0000 - val_fp: 22882.0000 - val_tn: 41118.0000 - val_fn: 22882.0000 - val_accuracy: 0.6425 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.6425
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-17408000-17664000
[INFO] processing batch 17664000-17920000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6514 - tp: 123546.0000 - fp: 68454.0000 - tn: 123546.0000 - fn: 68454.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6433 - val_loss: 0.6523 - val_tp: 41089.0000 - val_fp: 22911.0000 - val_tn: 41089.0000 - val_fn: 22911.0000 - val_accuracy: 0.6420 - val_precision: 0.6420 - val_recall: 0.6420 - val_auc: 0.6420
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-17664000-17920000
[INFO] processing batch 17920000-18176000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123681.0000 - fp: 68319.0000 - tn: 123681.0000 - fn: 68319.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6509 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 41233.0000 - val_fn: 22767.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-17920000-18176000
[INFO] processing batch 18176000-18432000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123640.0000 - fp: 68360.0000 - tn: 123640.0000 - fn: 68360.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6435 - val_loss: 0.6503 - val_tp: 41298.0000 - val_fp: 22702.0000 - val_tn: 41298.0000 - val_fn: 22702.0000 - val_accuracy: 0.6453 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.6453
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-18176000-18432000
[INFO] processing batch 18432000-18688000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123615.0000 - fp: 68385.0000 - tn: 123615.0000 - fn: 68385.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6436 - val_loss: 0.6509 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 41233.0000 - val_fn: 22767.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-18432000-18688000
[INFO] processing batch 18688000-18944000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123645.0000 - fp: 68355.0000 - tn: 123645.0000 - fn: 68355.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6440 - val_loss: 0.6514 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 41184.0000 - val_fn: 22816.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-18688000-18944000
[INFO] processing batch 18944000-19200000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.6503 - tp: 123888.0000 - fp: 68112.0000 - tn: 123888.0000 - fn: 68112.0000 - accuracy: 0.6453 - precision: 0.6453 - recall: 0.6453 - auc: 0.6456 - val_loss: 0.6515 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 41169.0000 - val_fn: 22831.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-18944000-19200000
[INFO] processing batch 19200000-19456000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123500.0000 - fp: 68500.0000 - tn: 123500.0000 - fn: 68500.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6431 - val_loss: 0.6513 - val_tp: 41189.0000 - val_fp: 22811.0000 - val_tn: 41189.0000 - val_fn: 22811.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-19200000-19456000
[INFO] processing batch 19456000-19712000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6510 - tp: 123689.0000 - fp: 68311.0000 - tn: 123689.0000 - fn: 68311.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6515 - val_tp: 41166.0000 - val_fp: 22834.0000 - val_tn: 41166.0000 - val_fn: 22834.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-19456000-19712000
[INFO] processing batch 19712000-19968000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6518 - tp: 123402.0000 - fp: 68598.0000 - tn: 123402.0000 - fn: 68598.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6421 - val_loss: 0.6508 - val_tp: 41242.0000 - val_fp: 22758.0000 - val_tn: 41242.0000 - val_fn: 22758.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-19712000-19968000
[INFO] processing batch 19968000-20224000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123541.0000 - fp: 68459.0000 - tn: 123541.0000 - fn: 68459.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6429 - val_loss: 0.6509 - val_tp: 41241.0000 - val_fp: 22759.0000 - val_tn: 41241.0000 - val_fn: 22759.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-19968000-20224000
[INFO] processing batch 20224000-20480000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123640.0000 - fp: 68360.0000 - tn: 123640.0000 - fn: 68360.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6444 - val_loss: 0.6511 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 41209.0000 - val_fn: 22791.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-20224000-20480000
[INFO] processing batch 20480000-20736000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123598.0000 - fp: 68402.0000 - tn: 123598.0000 - fn: 68402.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6438 - val_loss: 0.6509 - val_tp: 41235.0000 - val_fp: 22765.0000 - val_tn: 41235.0000 - val_fn: 22765.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-20480000-20736000
[INFO] processing batch 20736000-20992000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6507 - tp: 123769.0000 - fp: 68231.0000 - tn: 123769.0000 - fn: 68231.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6445 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-20736000-20992000
[INFO] processing batch 20992000-21248000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6517 - tp: 123459.0000 - fp: 68541.0000 - tn: 123459.0000 - fn: 68541.0000 - accuracy: 0.6430 - precision: 0.6430 - recall: 0.6430 - auc: 0.6427 - val_loss: 0.6512 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 41209.0000 - val_fn: 22791.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-20992000-21248000
[INFO] processing batch 21248000-21504000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123683.0000 - fp: 68317.0000 - tn: 123683.0000 - fn: 68317.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6440 - val_loss: 0.6514 - val_tp: 41183.0000 - val_fp: 22817.0000 - val_tn: 41183.0000 - val_fn: 22817.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-21248000-21504000
[INFO] processing batch 21504000-21760000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6513 - tp: 123564.0000 - fp: 68436.0000 - tn: 123564.0000 - fn: 68436.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6434 - val_loss: 0.6507 - val_tp: 41254.0000 - val_fp: 22746.0000 - val_tn: 41254.0000 - val_fn: 22746.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-21504000-21760000
[INFO] processing batch 21760000-22016000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.6509 - tp: 123717.0000 - fp: 68283.0000 - tn: 123717.0000 - fn: 68283.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6445 - val_loss: 0.6506 - val_tp: 41270.0000 - val_fp: 22730.0000 - val_tn: 41270.0000 - val_fn: 22730.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-21760000-22016000
[INFO] processing batch 22016000-22272000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6510 - tp: 123690.0000 - fp: 68310.0000 - tn: 123690.0000 - fn: 68310.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6521 - val_tp: 41104.0000 - val_fp: 22896.0000 - val_tn: 41104.0000 - val_fn: 22896.0000 - val_accuracy: 0.6423 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-22016000-22272000
[INFO] processing batch 22272000-22528000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123672.0000 - fp: 68328.0000 - tn: 123672.0000 - fn: 68328.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6437 - val_loss: 0.6508 - val_tp: 41243.0000 - val_fp: 22757.0000 - val_tn: 41243.0000 - val_fn: 22757.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-22272000-22528000
[INFO] processing batch 22528000-22784000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123623.0000 - fp: 68377.0000 - tn: 123623.0000 - fn: 68377.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6435 - val_loss: 0.6504 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 41292.0000 - val_fn: 22708.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-22528000-22784000
[INFO] processing batch 22784000-23040000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6507 - tp: 123759.0000 - fp: 68241.0000 - tn: 123759.0000 - fn: 68241.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6514 - val_tp: 41180.0000 - val_fp: 22820.0000 - val_tn: 41180.0000 - val_fn: 22820.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-22784000-23040000
[INFO] processing batch 23040000-23296000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123507.0000 - fp: 68493.0000 - tn: 123507.0000 - fn: 68493.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6428 - val_loss: 0.6507 - val_tp: 41255.0000 - val_fp: 22745.0000 - val_tn: 41255.0000 - val_fn: 22745.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-23040000-23296000
[INFO] processing batch 23296000-23552000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123601.0000 - fp: 68399.0000 - tn: 123601.0000 - fn: 68399.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6433 - val_loss: 0.6511 - val_tp: 41213.0000 - val_fp: 22787.0000 - val_tn: 41213.0000 - val_fn: 22787.0000 - val_accuracy: 0.6440 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.6440
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-23296000-23552000
[INFO] processing batch 23552000-23808000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6508 - tp: 123749.0000 - fp: 68251.0000 - tn: 123749.0000 - fn: 68251.0000 - accuracy: 0.6445 - precision: 0.6445 - recall: 0.6445 - auc: 0.6445 - val_loss: 0.6504 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 41292.0000 - val_fn: 22708.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-23552000-23808000
[INFO] processing batch 23808000-24064000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123603.0000 - fp: 68397.0000 - tn: 123603.0000 - fn: 68397.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6435 - val_loss: 0.6516 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 41165.0000 - val_fn: 22835.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-23808000-24064000
[INFO] processing batch 24064000-24320000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123599.0000 - fp: 68401.0000 - tn: 123599.0000 - fn: 68401.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6435 - val_loss: 0.6514 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 41184.0000 - val_fn: 22816.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-24064000-24320000
[INFO] processing batch 24320000-24576000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6517 - tp: 123440.0000 - fp: 68560.0000 - tn: 123440.0000 - fn: 68560.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6426 - val_loss: 0.6515 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 41169.0000 - val_fn: 22831.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-006-files-0-50-batch-24320000-24576000
[33m[LOSS] 0.6515163145065308[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6515163145065308  <  0.001
[33m[INFO] epoch 7/10[0m
[33m[INFO] loading file 1-50/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (24819975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] Shape when encoding dataset: (24819975, 17)
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
missing -1
len(df.columns) 108
numFeatures 107
[INFO] Shape AFTER encoding dataset: (24819975, 108)
[INFO] processing batch 0-256000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.2739 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1958 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-0-256000
[INFO] processing batch 256000-512000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.7753 - tp: 112918.0000 - fp: 79082.0000 - tn: 112918.0000 - fn: 79082.0000 - accuracy: 0.5881 - precision: 0.5881 - recall: 0.5881 - auc: 0.5890 - val_loss: 0.7956 - val_tp: 33927.0000 - val_fp: 30073.0000 - val_tn: 33927.0000 - val_fn: 30073.0000 - val_accuracy: 0.5301 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-256000-512000
[INFO] processing batch 512000-768000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5935 - tp: 138284.0000 - fp: 53716.0000 - tn: 138284.0000 - fn: 53716.0000 - accuracy: 0.7202 - precision: 0.7202 - recall: 0.7202 - auc: 0.7193 - val_loss: 0.3419 - val_tp: 62058.0000 - val_fp: 1942.0000 - val_tn: 62058.0000 - val_fn: 1942.0000 - val_accuracy: 0.9697 - val_precision: 0.9697 - val_recall: 0.9697 - val_auc: 0.9697
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-512000-768000
[INFO] processing batch 768000-1024000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6889 - tp: 117250.0000 - fp: 74750.0000 - tn: 117250.0000 - fn: 74750.0000 - accuracy: 0.6107 - precision: 0.6107 - recall: 0.6107 - auc: 0.6102 - val_loss: 0.4872 - val_tp: 55591.0000 - val_fp: 8409.0000 - val_tn: 55591.0000 - val_fn: 8409.0000 - val_accuracy: 0.8686 - val_precision: 0.8686 - val_recall: 0.8686 - val_auc: 0.8686
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-768000-1024000
[INFO] processing batch 1024000-1280000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6134 - tp: 133967.0000 - fp: 58033.0000 - tn: 133967.0000 - fn: 58033.0000 - accuracy: 0.6977 - precision: 0.6977 - recall: 0.6977 - auc: 0.6974 - val_loss: 0.3754 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-1024000-1280000
[INFO] processing batch 1280000-1536000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.2797 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2149 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-1280000-1536000
[INFO] processing batch 1536000-1792000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1798 - tp: 191999.0000 - fp: 1.0000 - tn: 191999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1514 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-1536000-1792000
[INFO] processing batch 1792000-2048000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5575 - tp: 148221.0000 - fp: 43779.0000 - tn: 148221.0000 - fn: 43779.0000 - accuracy: 0.7720 - precision: 0.7720 - recall: 0.7720 - auc: 0.7737 - val_loss: 0.3330 - val_tp: 57941.0000 - val_fp: 6059.0000 - val_tn: 57941.0000 - val_fn: 6059.0000 - val_accuracy: 0.9053 - val_precision: 0.9053 - val_recall: 0.9053 - val_auc: 0.9053
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-1792000-2048000
[INFO] processing batch 2048000-2304000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5959 - tp: 141714.0000 - fp: 50286.0000 - tn: 141714.0000 - fn: 50286.0000 - accuracy: 0.7381 - precision: 0.7381 - recall: 0.7381 - auc: 0.7379 - val_loss: 0.2188 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-2048000-2304000
[INFO] processing batch 2304000-2560000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1793 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1468 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-2304000-2560000
[INFO] processing batch 2560000-2816000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1259 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1082 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-2560000-2816000
[INFO] processing batch 2816000-3072000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5804 - tp: 148720.0000 - fp: 43280.0000 - tn: 148720.0000 - fn: 43280.0000 - accuracy: 0.7746 - precision: 0.7746 - recall: 0.7746 - auc: 0.7771 - val_loss: 0.8169 - val_tp: 40961.0000 - val_fp: 23039.0000 - val_tn: 40961.0000 - val_fn: 23039.0000 - val_accuracy: 0.6400 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.6400
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-2816000-3072000
[INFO] processing batch 3072000-3328000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6961 - tp: 131495.0000 - fp: 60505.0000 - tn: 131495.0000 - fn: 60505.0000 - accuracy: 0.6849 - precision: 0.6849 - recall: 0.6849 - auc: 0.6845 - val_loss: 0.2115 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-3072000-3328000
[INFO] processing batch 3328000-3584000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1761 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1455 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-3328000-3584000
[INFO] processing batch 3584000-3840000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1254 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1082 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-3584000-3840000
[INFO] processing batch 3840000-4096000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4911 - tp: 157534.0000 - fp: 34466.0000 - tn: 157534.0000 - fn: 34466.0000 - accuracy: 0.8205 - precision: 0.8205 - recall: 0.8205 - auc: 0.8200 - val_loss: 0.4938 - val_tp: 52219.0000 - val_fp: 11781.0000 - val_tn: 52219.0000 - val_fn: 11781.0000 - val_accuracy: 0.8159 - val_precision: 0.8159 - val_recall: 0.8159 - val_auc: 0.8159
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-3840000-4096000
[INFO] processing batch 4096000-4352000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1327 - tp: 190188.0000 - fp: 1812.0000 - tn: 190188.0000 - fn: 1812.0000 - accuracy: 0.9906 - precision: 0.9906 - recall: 0.9906 - auc: 0.9906 - val_loss: 0.0972 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-4096000-4352000
[INFO] processing batch 4352000-4608000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.0850 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0742 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-4352000-4608000
[INFO] processing batch 4608000-4864000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4710 - tp: 161451.0000 - fp: 30549.0000 - tn: 161451.0000 - fn: 30549.0000 - accuracy: 0.8409 - precision: 0.8409 - recall: 0.8409 - auc: 0.8422 - val_loss: 0.0967 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-4608000-4864000
[INFO] processing batch 4864000-5120000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0842 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0724 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-4864000-5120000
[INFO] processing batch 5120000-5376000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0638 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0562 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-5120000-5376000
[INFO] processing batch 5376000-5632000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0502 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0448 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-5376000-5632000
[INFO] processing batch 5632000-5888000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5879 - tp: 155809.0000 - fp: 36191.0000 - tn: 155809.0000 - fn: 36191.0000 - accuracy: 0.8115 - precision: 0.8115 - recall: 0.8115 - auc: 0.8103 - val_loss: 0.0756 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-5632000-5888000
[INFO] processing batch 5888000-6144000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0675 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0594 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-5888000-6144000
[INFO] processing batch 6144000-6400000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.3169 - tp: 174156.0000 - fp: 17844.0000 - tn: 174156.0000 - fn: 17844.0000 - accuracy: 0.9071 - precision: 0.9071 - recall: 0.9071 - auc: 0.9060 - val_loss: 1.0187 - val_tp: 41108.0000 - val_fp: 22892.0000 - val_tn: 41108.0000 - val_fn: 22892.0000 - val_accuracy: 0.6423 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-6144000-6400000
[INFO] processing batch 6400000-6656000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.7346 - tp: 138766.0000 - fp: 53234.0000 - tn: 138766.0000 - fn: 53234.0000 - accuracy: 0.7227 - precision: 0.7227 - recall: 0.7227 - auc: 0.7232 - val_loss: 0.1269 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-6400000-6656000
[INFO] processing batch 6656000-6912000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1105 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0948 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-6656000-6912000
[INFO] processing batch 6912000-7168000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0833 - tp: 191998.0000 - fp: 2.0000 - tn: 191998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0732 - val_tp: 63999.0000 - val_fp: 1.0000 - val_tn: 63999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-6912000-7168000
[INFO] processing batch 7168000-7424000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0653 - tp: 191999.0000 - fp: 1.0000 - tn: 191999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9225 - val_tp: 44344.0000 - val_fp: 19656.0000 - val_tn: 44344.0000 - val_fn: 19656.0000 - val_accuracy: 0.6929 - val_precision: 0.6929 - val_recall: 0.6929 - val_auc: 0.6929
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-7168000-7424000
[INFO] processing batch 7424000-7680000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 1.1983 - tp: 102062.0000 - fp: 89938.0000 - tn: 102062.0000 - fn: 89938.0000 - accuracy: 0.5316 - precision: 0.5316 - recall: 0.5316 - auc: 0.5316 - val_loss: 0.5689 - val_tp: 49859.0000 - val_fp: 14141.0000 - val_tn: 49859.0000 - val_fn: 14141.0000 - val_accuracy: 0.7790 - val_precision: 0.7790 - val_recall: 0.7790 - val_auc: 0.7790
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-7424000-7680000
[INFO] processing batch 7680000-7936000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1177 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1071 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-7680000-7936000
[INFO] processing batch 7936000-8192000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.0980 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0894 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-7936000-8192000
[INFO] processing batch 8192000-8448000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.4576 - tp: 161781.0000 - fp: 30219.0000 - tn: 161781.0000 - fn: 30219.0000 - accuracy: 0.8426 - precision: 0.8426 - recall: 0.8426 - auc: 0.8424 - val_loss: 0.1248 - val_tp: 63369.0000 - val_fp: 631.0000 - val_tn: 63369.0000 - val_fn: 631.0000 - val_accuracy: 0.9901 - val_precision: 0.9901 - val_recall: 0.9901 - val_auc: 0.9901
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-8192000-8448000
[INFO] processing batch 8448000-8704000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.8324 - tp: 123282.0000 - fp: 68718.0000 - tn: 123282.0000 - fn: 68718.0000 - accuracy: 0.6421 - precision: 0.6421 - recall: 0.6421 - auc: 0.6417 - val_loss: 0.8145 - val_tp: 39692.0000 - val_fp: 24308.0000 - val_tn: 39692.0000 - val_fn: 24308.0000 - val_accuracy: 0.6202 - val_precision: 0.6202 - val_recall: 0.6202 - val_auc: 0.6202
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-8448000-8704000
[INFO] processing batch 8704000-8960000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1878 - tp: 188028.0000 - fp: 3972.0000 - tn: 188028.0000 - fn: 3972.0000 - accuracy: 0.9793 - precision: 0.9793 - recall: 0.9793 - auc: 0.9792 - val_loss: 0.1330 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-8704000-8960000
[INFO] processing batch 8960000-9216000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1173 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1033 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-8960000-9216000
[INFO] processing batch 9216000-9472000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.8600 - tp: 120440.0000 - fp: 71560.0000 - tn: 120440.0000 - fn: 71560.0000 - accuracy: 0.6273 - precision: 0.6273 - recall: 0.6273 - auc: 0.6286 - val_loss: 0.1688 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-9216000-9472000
[INFO] processing batch 9472000-9728000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4373 - tp: 161553.0000 - fp: 30447.0000 - tn: 161553.0000 - fn: 30447.0000 - accuracy: 0.8414 - precision: 0.8414 - recall: 0.8414 - auc: 0.8415 - val_loss: 0.4474 - val_tp: 53468.0000 - val_fp: 10532.0000 - val_tn: 53468.0000 - val_fn: 10532.0000 - val_accuracy: 0.8354 - val_precision: 0.8354 - val_recall: 0.8354 - val_auc: 0.8354
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-9472000-9728000
[INFO] processing batch 9728000-9984000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1473 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1261 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-9728000-9984000
[INFO] processing batch 9984000-10240000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1107 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0972 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-9984000-10240000
[INFO] processing batch 10240000-10496000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1189 - tp: 189510.0000 - fp: 2490.0000 - tn: 189510.0000 - fn: 2490.0000 - accuracy: 0.9870 - precision: 0.9870 - recall: 0.9870 - auc: 0.9868 - val_loss: 1.2484 - val_tp: 33975.0000 - val_fp: 30025.0000 - val_tn: 33975.0000 - val_fn: 30025.0000 - val_accuracy: 0.5309 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.5309
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-10240000-10496000
[INFO] processing batch 10496000-10752000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 1.1042 - tp: 101670.0000 - fp: 90330.0000 - tn: 101670.0000 - fn: 90330.0000 - accuracy: 0.5295 - precision: 0.5295 - recall: 0.5295 - auc: 0.5296 - val_loss: 0.9848 - val_tp: 34015.0000 - val_fp: 29985.0000 - val_tn: 34015.0000 - val_fn: 29985.0000 - val_accuracy: 0.5315 - val_precision: 0.5315 - val_recall: 0.5315 - val_auc: 0.5315
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-10496000-10752000
[INFO] processing batch 10752000-11008000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.9148 - tp: 101693.0000 - fp: 90307.0000 - tn: 101693.0000 - fn: 90307.0000 - accuracy: 0.5297 - precision: 0.5297 - recall: 0.5297 - auc: 0.5291 - val_loss: 0.3830 - val_tp: 56989.0000 - val_fp: 7011.0000 - val_tn: 56989.0000 - val_fn: 7011.0000 - val_accuracy: 0.8905 - val_precision: 0.8905 - val_recall: 0.8905 - val_auc: 0.8905
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-10752000-11008000
[INFO] processing batch 11008000-11264000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.2127 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1857 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-11008000-11264000
[INFO] processing batch 11264000-11520000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1648 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1461 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-11264000-11520000
[INFO] processing batch 11520000-11776000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1310 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1173 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-11520000-11776000
[INFO] processing batch 11776000-12032000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4989 - tp: 156412.0000 - fp: 35588.0000 - tn: 156412.0000 - fn: 35588.0000 - accuracy: 0.8146 - precision: 0.8146 - recall: 0.8146 - auc: 0.8146 - val_loss: 0.8284 - val_tp: 41134.0000 - val_fp: 22866.0000 - val_tn: 41134.0000 - val_fn: 22866.0000 - val_accuracy: 0.6427 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.6427
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-11776000-12032000
[INFO] processing batch 12032000-12288000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.7780 - tp: 123527.0000 - fp: 68473.0000 - tn: 123527.0000 - fn: 68473.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6437 - val_loss: 0.7355 - val_tp: 41219.0000 - val_fp: 22781.0000 - val_tn: 41219.0000 - val_fn: 22781.0000 - val_accuracy: 0.6440 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.6440
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-12032000-12288000
[INFO] processing batch 12288000-12544000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.7096 - tp: 123560.0000 - fp: 68440.0000 - tn: 123560.0000 - fn: 68440.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6442 - val_loss: 0.6867 - val_tp: 41268.0000 - val_fp: 22732.0000 - val_tn: 41268.0000 - val_fn: 22732.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-12288000-12544000
[INFO] processing batch 12544000-12800000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6749 - tp: 123588.0000 - fp: 68412.0000 - tn: 123588.0000 - fn: 68412.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6436 - val_loss: 0.6638 - val_tp: 41269.0000 - val_fp: 22731.0000 - val_tn: 41269.0000 - val_fn: 22731.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-12544000-12800000
[INFO] processing batch 12800000-13056000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6596 - tp: 123531.0000 - fp: 68469.0000 - tn: 123531.0000 - fn: 68469.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6432 - val_loss: 0.6555 - val_tp: 41181.0000 - val_fp: 22819.0000 - val_tn: 41181.0000 - val_fn: 22819.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-12800000-13056000
[INFO] processing batch 13056000-13312000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6534 - tp: 123615.0000 - fp: 68385.0000 - tn: 123615.0000 - fn: 68385.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6442 - val_loss: 0.6523 - val_tp: 41192.0000 - val_fp: 22808.0000 - val_tn: 41192.0000 - val_fn: 22808.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-13056000-13312000
[INFO] processing batch 13312000-13568000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.6522 - tp: 123437.0000 - fp: 68563.0000 - tn: 123437.0000 - fn: 68563.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6430 - val_loss: 0.6516 - val_tp: 41179.0000 - val_fp: 22821.0000 - val_tn: 41179.0000 - val_fn: 22821.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-13312000-13568000
[INFO] processing batch 13568000-13824000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6515 - tp: 123539.0000 - fp: 68461.0000 - tn: 123539.0000 - fn: 68461.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6432 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-13568000-13824000
[INFO] processing batch 13824000-14080000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123556.0000 - fp: 68444.0000 - tn: 123556.0000 - fn: 68444.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6515 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 41173.0000 - val_fn: 22827.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-13824000-14080000
[INFO] processing batch 14080000-14336000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123681.0000 - fp: 68319.0000 - tn: 123681.0000 - fn: 68319.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6510 - val_tp: 41221.0000 - val_fp: 22779.0000 - val_tn: 41221.0000 - val_fn: 22779.0000 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.6441
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-14080000-14336000
[INFO] processing batch 14336000-14592000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6515 - tp: 123523.0000 - fp: 68477.0000 - tn: 123523.0000 - fn: 68477.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6432 - val_loss: 0.6513 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 41197.0000 - val_fn: 22803.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-14336000-14592000
[INFO] processing batch 14592000-14848000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6511 - tp: 123652.0000 - fp: 68348.0000 - tn: 123652.0000 - fn: 68348.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6439 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-14592000-14848000
[INFO] processing batch 14848000-15104000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123594.0000 - fp: 68406.0000 - tn: 123594.0000 - fn: 68406.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6434 - val_loss: 0.6512 - val_tp: 41205.0000 - val_fp: 22795.0000 - val_tn: 41205.0000 - val_fn: 22795.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-14848000-15104000
[INFO] processing batch 15104000-15360000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6511 - tp: 123629.0000 - fp: 68371.0000 - tn: 123629.0000 - fn: 68371.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6509 - val_tp: 41234.0000 - val_fp: 22766.0000 - val_tn: 41234.0000 - val_fn: 22766.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-15104000-15360000
[INFO] processing batch 15360000-15616000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123632.0000 - fp: 68368.0000 - tn: 123632.0000 - fn: 68368.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6441 - val_loss: 0.6506 - val_tp: 41266.0000 - val_fp: 22734.0000 - val_tn: 41266.0000 - val_fn: 22734.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-15360000-15616000
[INFO] processing batch 15616000-15872000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123527.0000 - fp: 68473.0000 - tn: 123527.0000 - fn: 68473.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6435 - val_loss: 0.6513 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 41197.0000 - val_fn: 22803.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-15616000-15872000
[INFO] processing batch 15872000-16128000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6514 - tp: 123531.0000 - fp: 68469.0000 - tn: 123531.0000 - fn: 68469.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6433 - val_loss: 0.6515 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 41173.0000 - val_fn: 22827.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-15872000-16128000
[INFO] processing batch 16128000-16384000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6507 - tp: 123781.0000 - fp: 68219.0000 - tn: 123781.0000 - fn: 68219.0000 - accuracy: 0.6447 - precision: 0.6447 - recall: 0.6447 - auc: 0.6447 - val_loss: 0.6513 - val_tp: 41195.0000 - val_fp: 22805.0000 - val_tn: 41195.0000 - val_fn: 22805.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-16128000-16384000
[INFO] processing batch 16384000-16640000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123621.0000 - fp: 68379.0000 - tn: 123621.0000 - fn: 68379.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6437 - val_loss: 0.6516 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 41165.0000 - val_fn: 22835.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-16384000-16640000
[INFO] processing batch 16640000-16896000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6518 - tp: 123417.0000 - fp: 68583.0000 - tn: 123417.0000 - fn: 68583.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6428 - val_loss: 0.6510 - val_tp: 41230.0000 - val_fp: 22770.0000 - val_tn: 41230.0000 - val_fn: 22770.0000 - val_accuracy: 0.6442 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.6442
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-16640000-16896000
[INFO] processing batch 16896000-17152000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123600.0000 - fp: 68400.0000 - tn: 123600.0000 - fn: 68400.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6436 - val_loss: 0.6513 - val_tp: 41198.0000 - val_fp: 22802.0000 - val_tn: 41198.0000 - val_fn: 22802.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-16896000-17152000
[INFO] processing batch 17152000-17408000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123711.0000 - fp: 68289.0000 - tn: 123711.0000 - fn: 68289.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6444 - val_loss: 0.6515 - val_tp: 41168.0000 - val_fp: 22832.0000 - val_tn: 41168.0000 - val_fn: 22832.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-17152000-17408000
[INFO] processing batch 17408000-17664000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123701.0000 - fp: 68299.0000 - tn: 123701.0000 - fn: 68299.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6443 - val_loss: 0.6520 - val_tp: 41118.0000 - val_fp: 22882.0000 - val_tn: 41118.0000 - val_fn: 22882.0000 - val_accuracy: 0.6425 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.6425
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-17408000-17664000
[INFO] processing batch 17664000-17920000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.6514 - tp: 123546.0000 - fp: 68454.0000 - tn: 123546.0000 - fn: 68454.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6432 - val_loss: 0.6523 - val_tp: 41089.0000 - val_fp: 22911.0000 - val_tn: 41089.0000 - val_fn: 22911.0000 - val_accuracy: 0.6420 - val_precision: 0.6420 - val_recall: 0.6420 - val_auc: 0.6420
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-17664000-17920000
[INFO] processing batch 17920000-18176000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123681.0000 - fp: 68319.0000 - tn: 123681.0000 - fn: 68319.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6509 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 41233.0000 - val_fn: 22767.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-17920000-18176000
[INFO] processing batch 18176000-18432000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123640.0000 - fp: 68360.0000 - tn: 123640.0000 - fn: 68360.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6439 - val_loss: 0.6503 - val_tp: 41298.0000 - val_fp: 22702.0000 - val_tn: 41298.0000 - val_fn: 22702.0000 - val_accuracy: 0.6453 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.6453
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-18176000-18432000
[INFO] processing batch 18432000-18688000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123615.0000 - fp: 68385.0000 - tn: 123615.0000 - fn: 68385.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6438 - val_loss: 0.6509 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 41233.0000 - val_fn: 22767.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-18432000-18688000
[INFO] processing batch 18688000-18944000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123645.0000 - fp: 68355.0000 - tn: 123645.0000 - fn: 68355.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6440 - val_loss: 0.6514 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 41184.0000 - val_fn: 22816.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-18688000-18944000
[INFO] processing batch 18944000-19200000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6503 - tp: 123888.0000 - fp: 68112.0000 - tn: 123888.0000 - fn: 68112.0000 - accuracy: 0.6453 - precision: 0.6453 - recall: 0.6453 - auc: 0.6454 - val_loss: 0.6515 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 41169.0000 - val_fn: 22831.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-18944000-19200000
[INFO] processing batch 19200000-19456000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123500.0000 - fp: 68500.0000 - tn: 123500.0000 - fn: 68500.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6436 - val_loss: 0.6513 - val_tp: 41189.0000 - val_fp: 22811.0000 - val_tn: 41189.0000 - val_fn: 22811.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-19200000-19456000
[INFO] processing batch 19456000-19712000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123689.0000 - fp: 68311.0000 - tn: 123689.0000 - fn: 68311.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6515 - val_tp: 41166.0000 - val_fp: 22834.0000 - val_tn: 41166.0000 - val_fn: 22834.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-19456000-19712000
[INFO] processing batch 19712000-19968000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6518 - tp: 123402.0000 - fp: 68598.0000 - tn: 123402.0000 - fn: 68598.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6433 - val_loss: 0.6509 - val_tp: 41242.0000 - val_fp: 22758.0000 - val_tn: 41242.0000 - val_fn: 22758.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-19712000-19968000
[INFO] processing batch 19968000-20224000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6514 - tp: 123541.0000 - fp: 68459.0000 - tn: 123541.0000 - fn: 68459.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6435 - val_loss: 0.6509 - val_tp: 41241.0000 - val_fp: 22759.0000 - val_tn: 41241.0000 - val_fn: 22759.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-19968000-20224000
[INFO] processing batch 20224000-20480000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123640.0000 - fp: 68360.0000 - tn: 123640.0000 - fn: 68360.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6444 - val_loss: 0.6512 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 41209.0000 - val_fn: 22791.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-20224000-20480000
[INFO] processing batch 20480000-20736000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123598.0000 - fp: 68402.0000 - tn: 123598.0000 - fn: 68402.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6509 - val_tp: 41235.0000 - val_fp: 22765.0000 - val_tn: 41235.0000 - val_fn: 22765.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-20480000-20736000
[INFO] processing batch 20736000-20992000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6507 - tp: 123769.0000 - fp: 68231.0000 - tn: 123769.0000 - fn: 68231.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6447 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-20736000-20992000
[INFO] processing batch 20992000-21248000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6517 - tp: 123459.0000 - fp: 68541.0000 - tn: 123459.0000 - fn: 68541.0000 - accuracy: 0.6430 - precision: 0.6430 - recall: 0.6430 - auc: 0.6426 - val_loss: 0.6512 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 41209.0000 - val_fn: 22791.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-20992000-21248000
[INFO] processing batch 21248000-21504000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123683.0000 - fp: 68317.0000 - tn: 123683.0000 - fn: 68317.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6444 - val_loss: 0.6514 - val_tp: 41183.0000 - val_fp: 22817.0000 - val_tn: 41183.0000 - val_fn: 22817.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-21248000-21504000
[INFO] processing batch 21504000-21760000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6513 - tp: 123564.0000 - fp: 68436.0000 - tn: 123564.0000 - fn: 68436.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6435 - val_loss: 0.6507 - val_tp: 41254.0000 - val_fp: 22746.0000 - val_tn: 41254.0000 - val_fn: 22746.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-21504000-21760000
[INFO] processing batch 21760000-22016000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 16s - loss: 0.6509 - tp: 123717.0000 - fp: 68283.0000 - tn: 123717.0000 - fn: 68283.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6444 - val_loss: 0.6506 - val_tp: 41270.0000 - val_fp: 22730.0000 - val_tn: 41270.0000 - val_fn: 22730.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-21760000-22016000
[INFO] processing batch 22016000-22272000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123690.0000 - fp: 68310.0000 - tn: 123690.0000 - fn: 68310.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6443 - val_loss: 0.6521 - val_tp: 41104.0000 - val_fp: 22896.0000 - val_tn: 41104.0000 - val_fn: 22896.0000 - val_accuracy: 0.6423 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-22016000-22272000
[INFO] processing batch 22272000-22528000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6510 - tp: 123672.0000 - fp: 68328.0000 - tn: 123672.0000 - fn: 68328.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6441 - val_loss: 0.6508 - val_tp: 41243.0000 - val_fp: 22757.0000 - val_tn: 41243.0000 - val_fn: 22757.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-22272000-22528000
[INFO] processing batch 22528000-22784000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123623.0000 - fp: 68377.0000 - tn: 123623.0000 - fn: 68377.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6437 - val_loss: 0.6504 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 41292.0000 - val_fn: 22708.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-22528000-22784000
[INFO] processing batch 22784000-23040000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6507 - tp: 123759.0000 - fp: 68241.0000 - tn: 123759.0000 - fn: 68241.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6447 - val_loss: 0.6514 - val_tp: 41180.0000 - val_fp: 22820.0000 - val_tn: 41180.0000 - val_fn: 22820.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-22784000-23040000
[INFO] processing batch 23040000-23296000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6515 - tp: 123507.0000 - fp: 68493.0000 - tn: 123507.0000 - fn: 68493.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6431 - val_loss: 0.6507 - val_tp: 41255.0000 - val_fp: 22745.0000 - val_tn: 41255.0000 - val_fn: 22745.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-23040000-23296000
[INFO] processing batch 23296000-23552000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6512 - tp: 123601.0000 - fp: 68399.0000 - tn: 123601.0000 - fn: 68399.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6441 - val_loss: 0.6511 - val_tp: 41213.0000 - val_fp: 22787.0000 - val_tn: 41213.0000 - val_fn: 22787.0000 - val_accuracy: 0.6440 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.6440
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-23296000-23552000
[INFO] processing batch 23552000-23808000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6508 - tp: 123749.0000 - fp: 68251.0000 - tn: 123749.0000 - fn: 68251.0000 - accuracy: 0.6445 - precision: 0.6445 - recall: 0.6445 - auc: 0.6443 - val_loss: 0.6504 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 41292.0000 - val_fn: 22708.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-23552000-23808000
[INFO] processing batch 23808000-24064000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6512 - tp: 123603.0000 - fp: 68397.0000 - tn: 123603.0000 - fn: 68397.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6436 - val_loss: 0.6516 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 41165.0000 - val_fn: 22835.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-23808000-24064000
[INFO] processing batch 24064000-24320000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6512 - tp: 123599.0000 - fp: 68401.0000 - tn: 123599.0000 - fn: 68401.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6514 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 41184.0000 - val_fn: 22816.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-24064000-24320000
[INFO] processing batch 24320000-24576000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6517 - tp: 123440.0000 - fp: 68560.0000 - tn: 123440.0000 - fn: 68560.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6426 - val_loss: 0.6515 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 41169.0000 - val_fn: 22831.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-007-files-0-50-batch-24320000-24576000
[33m[LOSS] 0.6515171966552734[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6515171966552734  <  0.001
[33m[INFO] epoch 8/10[0m
[33m[INFO] loading file 1-50/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (24819975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] Shape when encoding dataset: (24819975, 17)
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
missing -1
len(df.columns) 108
numFeatures 107
[INFO] Shape AFTER encoding dataset: (24819975, 108)
[INFO] processing batch 0-256000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.2746 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1963 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-0-256000
[INFO] processing batch 256000-512000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.7750 - tp: 112918.0000 - fp: 79082.0000 - tn: 112918.0000 - fn: 79082.0000 - accuracy: 0.5881 - precision: 0.5881 - recall: 0.5881 - auc: 0.5878 - val_loss: 0.7953 - val_tp: 33927.0000 - val_fp: 30073.0000 - val_tn: 33927.0000 - val_fn: 30073.0000 - val_accuracy: 0.5301 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-256000-512000
[INFO] processing batch 512000-768000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5935 - tp: 138284.0000 - fp: 53716.0000 - tn: 138284.0000 - fn: 53716.0000 - accuracy: 0.7202 - precision: 0.7202 - recall: 0.7202 - auc: 0.7184 - val_loss: 0.3413 - val_tp: 62058.0000 - val_fp: 1942.0000 - val_tn: 62058.0000 - val_fn: 1942.0000 - val_accuracy: 0.9697 - val_precision: 0.9697 - val_recall: 0.9697 - val_auc: 0.9697
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-512000-768000
[INFO] processing batch 768000-1024000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6890 - tp: 117250.0000 - fp: 74750.0000 - tn: 117250.0000 - fn: 74750.0000 - accuracy: 0.6107 - precision: 0.6107 - recall: 0.6107 - auc: 0.6096 - val_loss: 0.4872 - val_tp: 55591.0000 - val_fp: 8409.0000 - val_tn: 55591.0000 - val_fn: 8409.0000 - val_accuracy: 0.8686 - val_precision: 0.8686 - val_recall: 0.8686 - val_auc: 0.8686
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-768000-1024000
[INFO] processing batch 1024000-1280000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.6134 - tp: 133967.0000 - fp: 58033.0000 - tn: 133967.0000 - fn: 58033.0000 - accuracy: 0.6977 - precision: 0.6977 - recall: 0.6977 - auc: 0.6976 - val_loss: 0.3751 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-1024000-1280000
[INFO] processing batch 1280000-1536000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.2796 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2148 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-1280000-1536000
[INFO] processing batch 1536000-1792000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1798 - tp: 191999.0000 - fp: 1.0000 - tn: 191999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1514 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-1536000-1792000
[INFO] processing batch 1792000-2048000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5576 - tp: 148221.0000 - fp: 43779.0000 - tn: 148221.0000 - fn: 43779.0000 - accuracy: 0.7720 - precision: 0.7720 - recall: 0.7720 - auc: 0.7712 - val_loss: 0.3329 - val_tp: 57941.0000 - val_fp: 6059.0000 - val_tn: 57941.0000 - val_fn: 6059.0000 - val_accuracy: 0.9053 - val_precision: 0.9053 - val_recall: 0.9053 - val_auc: 0.9053
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-1792000-2048000
[INFO] processing batch 2048000-2304000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5960 - tp: 141714.0000 - fp: 50286.0000 - tn: 141714.0000 - fn: 50286.0000 - accuracy: 0.7381 - precision: 0.7381 - recall: 0.7381 - auc: 0.7380 - val_loss: 0.2187 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-2048000-2304000
[INFO] processing batch 2304000-2560000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1792 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1467 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-2304000-2560000
[INFO] processing batch 2560000-2816000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1258 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1081 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-2560000-2816000
[INFO] processing batch 2816000-3072000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5806 - tp: 148720.0000 - fp: 43280.0000 - tn: 148720.0000 - fn: 43280.0000 - accuracy: 0.7746 - precision: 0.7746 - recall: 0.7746 - auc: 0.7745 - val_loss: 0.8173 - val_tp: 40961.0000 - val_fp: 23039.0000 - val_tn: 40961.0000 - val_fn: 23039.0000 - val_accuracy: 0.6400 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.6400
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-2816000-3072000
[INFO] processing batch 3072000-3328000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6963 - tp: 131495.0000 - fp: 60505.0000 - tn: 131495.0000 - fn: 60505.0000 - accuracy: 0.6849 - precision: 0.6849 - recall: 0.6849 - auc: 0.6842 - val_loss: 0.2114 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-3072000-3328000
[INFO] processing batch 3328000-3584000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1759 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1454 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-3328000-3584000
[INFO] processing batch 3584000-3840000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1252 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1081 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-3584000-3840000
[INFO] processing batch 3840000-4096000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4912 - tp: 157534.0000 - fp: 34466.0000 - tn: 157534.0000 - fn: 34466.0000 - accuracy: 0.8205 - precision: 0.8205 - recall: 0.8205 - auc: 0.8204 - val_loss: 0.4939 - val_tp: 52219.0000 - val_fp: 11781.0000 - val_tn: 52219.0000 - val_fn: 11781.0000 - val_accuracy: 0.8159 - val_precision: 0.8159 - val_recall: 0.8159 - val_auc: 0.8159
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-3840000-4096000
[INFO] processing batch 4096000-4352000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1326 - tp: 190188.0000 - fp: 1812.0000 - tn: 190188.0000 - fn: 1812.0000 - accuracy: 0.9906 - precision: 0.9906 - recall: 0.9906 - auc: 0.9905 - val_loss: 0.0972 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-4096000-4352000
[INFO] processing batch 4352000-4608000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0849 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0742 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-4352000-4608000
[INFO] processing batch 4608000-4864000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4711 - tp: 161451.0000 - fp: 30549.0000 - tn: 161451.0000 - fn: 30549.0000 - accuracy: 0.8409 - precision: 0.8409 - recall: 0.8409 - auc: 0.8419 - val_loss: 0.0967 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-4608000-4864000
[INFO] processing batch 4864000-5120000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0841 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0724 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-4864000-5120000
[INFO] processing batch 5120000-5376000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.0637 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0561 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-5120000-5376000
[INFO] processing batch 5376000-5632000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0502 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0448 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-5376000-5632000
[INFO] processing batch 5632000-5888000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5880 - tp: 155809.0000 - fp: 36191.0000 - tn: 155809.0000 - fn: 36191.0000 - accuracy: 0.8115 - precision: 0.8115 - recall: 0.8115 - auc: 0.8107 - val_loss: 0.0754 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-5632000-5888000
[INFO] processing batch 5888000-6144000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0676 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0595 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-5888000-6144000
[INFO] processing batch 6144000-6400000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.3169 - tp: 174156.0000 - fp: 17844.0000 - tn: 174156.0000 - fn: 17844.0000 - accuracy: 0.9071 - precision: 0.9071 - recall: 0.9071 - auc: 0.9073 - val_loss: 1.0183 - val_tp: 41108.0000 - val_fp: 22892.0000 - val_tn: 41108.0000 - val_fn: 22892.0000 - val_accuracy: 0.6423 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-6144000-6400000
[INFO] processing batch 6400000-6656000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.7347 - tp: 138766.0000 - fp: 53234.0000 - tn: 138766.0000 - fn: 53234.0000 - accuracy: 0.7227 - precision: 0.7227 - recall: 0.7227 - auc: 0.7224 - val_loss: 0.1268 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-6400000-6656000
[INFO] processing batch 6656000-6912000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1104 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0947 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-6656000-6912000
[INFO] processing batch 6912000-7168000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.0833 - tp: 191998.0000 - fp: 2.0000 - tn: 191998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0732 - val_tp: 63999.0000 - val_fp: 1.0000 - val_tn: 63999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-6912000-7168000
[INFO] processing batch 7168000-7424000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0653 - tp: 191999.0000 - fp: 1.0000 - tn: 191999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9226 - val_tp: 44344.0000 - val_fp: 19656.0000 - val_tn: 44344.0000 - val_fn: 19656.0000 - val_accuracy: 0.6929 - val_precision: 0.6929 - val_recall: 0.6929 - val_auc: 0.6929
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-7168000-7424000
[INFO] processing batch 7424000-7680000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 1.1980 - tp: 102062.0000 - fp: 89938.0000 - tn: 102062.0000 - fn: 89938.0000 - accuracy: 0.5316 - precision: 0.5316 - recall: 0.5316 - auc: 0.5324 - val_loss: 0.5688 - val_tp: 49859.0000 - val_fp: 14141.0000 - val_tn: 49859.0000 - val_fn: 14141.0000 - val_accuracy: 0.7790 - val_precision: 0.7790 - val_recall: 0.7790 - val_auc: 0.7790
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-7424000-7680000
[INFO] processing batch 7680000-7936000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1178 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1072 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-7680000-7936000
[INFO] processing batch 7936000-8192000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.0980 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0894 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-7936000-8192000
[INFO] processing batch 8192000-8448000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4576 - tp: 161781.0000 - fp: 30219.0000 - tn: 161781.0000 - fn: 30219.0000 - accuracy: 0.8426 - precision: 0.8426 - recall: 0.8426 - auc: 0.8426 - val_loss: 0.1249 - val_tp: 63369.0000 - val_fp: 631.0000 - val_tn: 63369.0000 - val_fn: 631.0000 - val_accuracy: 0.9901 - val_precision: 0.9901 - val_recall: 0.9901 - val_auc: 0.9901
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-8192000-8448000
[INFO] processing batch 8448000-8704000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.8325 - tp: 123282.0000 - fp: 68718.0000 - tn: 123282.0000 - fn: 68718.0000 - accuracy: 0.6421 - precision: 0.6421 - recall: 0.6421 - auc: 0.6404 - val_loss: 0.8146 - val_tp: 39692.0000 - val_fp: 24308.0000 - val_tn: 39692.0000 - val_fn: 24308.0000 - val_accuracy: 0.6202 - val_precision: 0.6202 - val_recall: 0.6202 - val_auc: 0.6202
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-8448000-8704000
[INFO] processing batch 8704000-8960000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1878 - tp: 188028.0000 - fp: 3972.0000 - tn: 188028.0000 - fn: 3972.0000 - accuracy: 0.9793 - precision: 0.9793 - recall: 0.9793 - auc: 0.9792 - val_loss: 0.1330 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-8704000-8960000
[INFO] processing batch 8960000-9216000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1173 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1033 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-8960000-9216000
[INFO] processing batch 9216000-9472000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.8606 - tp: 120440.0000 - fp: 71560.0000 - tn: 120440.0000 - fn: 71560.0000 - accuracy: 0.6273 - precision: 0.6273 - recall: 0.6273 - auc: 0.6242 - val_loss: 0.1683 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-9216000-9472000
[INFO] processing batch 9472000-9728000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4373 - tp: 161553.0000 - fp: 30447.0000 - tn: 161553.0000 - fn: 30447.0000 - accuracy: 0.8414 - precision: 0.8414 - recall: 0.8414 - auc: 0.8415 - val_loss: 0.4474 - val_tp: 53468.0000 - val_fp: 10532.0000 - val_tn: 53468.0000 - val_fn: 10532.0000 - val_accuracy: 0.8354 - val_precision: 0.8354 - val_recall: 0.8354 - val_auc: 0.8354
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-9472000-9728000
[INFO] processing batch 9728000-9984000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1469 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1258 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-9728000-9984000
[INFO] processing batch 9984000-10240000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1104 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0969 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-9984000-10240000
[INFO] processing batch 10240000-10496000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1187 - tp: 189510.0000 - fp: 2490.0000 - tn: 189510.0000 - fn: 2490.0000 - accuracy: 0.9870 - precision: 0.9870 - recall: 0.9870 - auc: 0.9871 - val_loss: 1.2495 - val_tp: 33975.0000 - val_fp: 30025.0000 - val_tn: 33975.0000 - val_fn: 30025.0000 - val_accuracy: 0.5309 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.5309
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-10240000-10496000
[INFO] processing batch 10496000-10752000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 1.1051 - tp: 101670.0000 - fp: 90330.0000 - tn: 101670.0000 - fn: 90330.0000 - accuracy: 0.5295 - precision: 0.5295 - recall: 0.5295 - auc: 0.5292 - val_loss: 0.9856 - val_tp: 34015.0000 - val_fp: 29985.0000 - val_tn: 34015.0000 - val_fn: 29985.0000 - val_accuracy: 0.5315 - val_precision: 0.5315 - val_recall: 0.5315 - val_auc: 0.5315
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-10496000-10752000
[INFO] processing batch 10752000-11008000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.9153 - tp: 101693.0000 - fp: 90307.0000 - tn: 101693.0000 - fn: 90307.0000 - accuracy: 0.5297 - precision: 0.5297 - recall: 0.5297 - auc: 0.5299 - val_loss: 0.3828 - val_tp: 56989.0000 - val_fp: 7011.0000 - val_tn: 56989.0000 - val_fn: 7011.0000 - val_accuracy: 0.8905 - val_precision: 0.8905 - val_recall: 0.8905 - val_auc: 0.8905
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-10752000-11008000
[INFO] processing batch 11008000-11264000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.2125 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1856 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-11008000-11264000
[INFO] processing batch 11264000-11520000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1647 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1460 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-11264000-11520000
[INFO] processing batch 11520000-11776000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1309 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1172 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-11520000-11776000
[INFO] processing batch 11776000-12032000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4990 - tp: 156412.0000 - fp: 35588.0000 - tn: 156412.0000 - fn: 35588.0000 - accuracy: 0.8146 - precision: 0.8146 - recall: 0.8146 - auc: 0.8148 - val_loss: 0.8288 - val_tp: 41134.0000 - val_fp: 22866.0000 - val_tn: 41134.0000 - val_fn: 22866.0000 - val_accuracy: 0.6427 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.6427
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-11776000-12032000
[INFO] processing batch 12032000-12288000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.7781 - tp: 123527.0000 - fp: 68473.0000 - tn: 123527.0000 - fn: 68473.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6434 - val_loss: 0.7356 - val_tp: 41219.0000 - val_fp: 22781.0000 - val_tn: 41219.0000 - val_fn: 22781.0000 - val_accuracy: 0.6440 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.6440
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-12032000-12288000
[INFO] processing batch 12288000-12544000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.7097 - tp: 123560.0000 - fp: 68440.0000 - tn: 123560.0000 - fn: 68440.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6431 - val_loss: 0.6867 - val_tp: 41268.0000 - val_fp: 22732.0000 - val_tn: 41268.0000 - val_fn: 22732.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-12288000-12544000
[INFO] processing batch 12544000-12800000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6750 - tp: 123588.0000 - fp: 68412.0000 - tn: 123588.0000 - fn: 68412.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6639 - val_tp: 41269.0000 - val_fp: 22731.0000 - val_tn: 41269.0000 - val_fn: 22731.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-12544000-12800000
[INFO] processing batch 12800000-13056000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6596 - tp: 123531.0000 - fp: 68469.0000 - tn: 123531.0000 - fn: 68469.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6431 - val_loss: 0.6555 - val_tp: 41181.0000 - val_fp: 22819.0000 - val_tn: 41181.0000 - val_fn: 22819.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-12800000-13056000
[INFO] processing batch 13056000-13312000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6534 - tp: 123615.0000 - fp: 68385.0000 - tn: 123615.0000 - fn: 68385.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6435 - val_loss: 0.6523 - val_tp: 41192.0000 - val_fp: 22808.0000 - val_tn: 41192.0000 - val_fn: 22808.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-13056000-13312000
[INFO] processing batch 13312000-13568000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6522 - tp: 123437.0000 - fp: 68563.0000 - tn: 123437.0000 - fn: 68563.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6431 - val_loss: 0.6516 - val_tp: 41179.0000 - val_fp: 22821.0000 - val_tn: 41179.0000 - val_fn: 22821.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-13312000-13568000
[INFO] processing batch 13568000-13824000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.6515 - tp: 123539.0000 - fp: 68461.0000 - tn: 123539.0000 - fn: 68461.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6434 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-13568000-13824000
[INFO] processing batch 13824000-14080000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123556.0000 - fp: 68444.0000 - tn: 123556.0000 - fn: 68444.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6515 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 41173.0000 - val_fn: 22827.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-13824000-14080000
[INFO] processing batch 14080000-14336000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.6510 - tp: 123681.0000 - fp: 68319.0000 - tn: 123681.0000 - fn: 68319.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6510 - val_tp: 41221.0000 - val_fp: 22779.0000 - val_tn: 41221.0000 - val_fn: 22779.0000 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.6441
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-14080000-14336000
[INFO] processing batch 14336000-14592000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123523.0000 - fp: 68477.0000 - tn: 123523.0000 - fn: 68477.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6433 - val_loss: 0.6513 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 41197.0000 - val_fn: 22803.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-14336000-14592000
[INFO] processing batch 14592000-14848000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123652.0000 - fp: 68348.0000 - tn: 123652.0000 - fn: 68348.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6438 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-14592000-14848000
[INFO] processing batch 14848000-15104000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.6513 - tp: 123594.0000 - fp: 68406.0000 - tn: 123594.0000 - fn: 68406.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6436 - val_loss: 0.6512 - val_tp: 41205.0000 - val_fp: 22795.0000 - val_tn: 41205.0000 - val_fn: 22795.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-14848000-15104000
[INFO] processing batch 15104000-15360000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.6511 - tp: 123629.0000 - fp: 68371.0000 - tn: 123629.0000 - fn: 68371.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6438 - val_loss: 0.6509 - val_tp: 41234.0000 - val_fp: 22766.0000 - val_tn: 41234.0000 - val_fn: 22766.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-15104000-15360000
[INFO] processing batch 15360000-15616000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123632.0000 - fp: 68368.0000 - tn: 123632.0000 - fn: 68368.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6506 - val_tp: 41266.0000 - val_fp: 22734.0000 - val_tn: 41266.0000 - val_fn: 22734.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-15360000-15616000
[INFO] processing batch 15616000-15872000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123527.0000 - fp: 68473.0000 - tn: 123527.0000 - fn: 68473.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6429 - val_loss: 0.6513 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 41197.0000 - val_fn: 22803.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-15616000-15872000
[INFO] processing batch 15872000-16128000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123531.0000 - fp: 68469.0000 - tn: 123531.0000 - fn: 68469.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6433 - val_loss: 0.6515 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 41173.0000 - val_fn: 22827.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-15872000-16128000
[INFO] processing batch 16128000-16384000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6507 - tp: 123781.0000 - fp: 68219.0000 - tn: 123781.0000 - fn: 68219.0000 - accuracy: 0.6447 - precision: 0.6447 - recall: 0.6447 - auc: 0.6446 - val_loss: 0.6513 - val_tp: 41195.0000 - val_fp: 22805.0000 - val_tn: 41195.0000 - val_fn: 22805.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-16128000-16384000
[INFO] processing batch 16384000-16640000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 16s - loss: 0.6512 - tp: 123621.0000 - fp: 68379.0000 - tn: 123621.0000 - fn: 68379.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6516 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 41165.0000 - val_fn: 22835.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-16384000-16640000
[INFO] processing batch 16640000-16896000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6518 - tp: 123417.0000 - fp: 68583.0000 - tn: 123417.0000 - fn: 68583.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6426 - val_loss: 0.6510 - val_tp: 41230.0000 - val_fp: 22770.0000 - val_tn: 41230.0000 - val_fn: 22770.0000 - val_accuracy: 0.6442 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.6442
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-16640000-16896000
[INFO] processing batch 16896000-17152000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123600.0000 - fp: 68400.0000 - tn: 123600.0000 - fn: 68400.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6441 - val_loss: 0.6513 - val_tp: 41198.0000 - val_fp: 22802.0000 - val_tn: 41198.0000 - val_fn: 22802.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-16896000-17152000
[INFO] processing batch 17152000-17408000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123711.0000 - fp: 68289.0000 - tn: 123711.0000 - fn: 68289.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6442 - val_loss: 0.6515 - val_tp: 41168.0000 - val_fp: 22832.0000 - val_tn: 41168.0000 - val_fn: 22832.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-17152000-17408000
[INFO] processing batch 17408000-17664000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123701.0000 - fp: 68299.0000 - tn: 123701.0000 - fn: 68299.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6443 - val_loss: 0.6520 - val_tp: 41118.0000 - val_fp: 22882.0000 - val_tn: 41118.0000 - val_fn: 22882.0000 - val_accuracy: 0.6425 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.6425
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-17408000-17664000
[INFO] processing batch 17664000-17920000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123546.0000 - fp: 68454.0000 - tn: 123546.0000 - fn: 68454.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6430 - val_loss: 0.6523 - val_tp: 41089.0000 - val_fp: 22911.0000 - val_tn: 41089.0000 - val_fn: 22911.0000 - val_accuracy: 0.6420 - val_precision: 0.6420 - val_recall: 0.6420 - val_auc: 0.6420
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-17664000-17920000
[INFO] processing batch 17920000-18176000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123681.0000 - fp: 68319.0000 - tn: 123681.0000 - fn: 68319.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6440 - val_loss: 0.6509 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 41233.0000 - val_fn: 22767.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-17920000-18176000
[INFO] processing batch 18176000-18432000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6511 - tp: 123640.0000 - fp: 68360.0000 - tn: 123640.0000 - fn: 68360.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6436 - val_loss: 0.6503 - val_tp: 41298.0000 - val_fp: 22702.0000 - val_tn: 41298.0000 - val_fn: 22702.0000 - val_accuracy: 0.6453 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.6453
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-18176000-18432000
[INFO] processing batch 18432000-18688000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123615.0000 - fp: 68385.0000 - tn: 123615.0000 - fn: 68385.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6438 - val_loss: 0.6509 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 41233.0000 - val_fn: 22767.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-18432000-18688000
[INFO] processing batch 18688000-18944000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123645.0000 - fp: 68355.0000 - tn: 123645.0000 - fn: 68355.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6440 - val_loss: 0.6514 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 41184.0000 - val_fn: 22816.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-18688000-18944000
[INFO] processing batch 18944000-19200000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6503 - tp: 123888.0000 - fp: 68112.0000 - tn: 123888.0000 - fn: 68112.0000 - accuracy: 0.6453 - precision: 0.6453 - recall: 0.6453 - auc: 0.6452 - val_loss: 0.6515 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 41169.0000 - val_fn: 22831.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-18944000-19200000
[INFO] processing batch 19200000-19456000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123500.0000 - fp: 68500.0000 - tn: 123500.0000 - fn: 68500.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6428 - val_loss: 0.6513 - val_tp: 41189.0000 - val_fp: 22811.0000 - val_tn: 41189.0000 - val_fn: 22811.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-19200000-19456000
[INFO] processing batch 19456000-19712000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123689.0000 - fp: 68311.0000 - tn: 123689.0000 - fn: 68311.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6441 - val_loss: 0.6515 - val_tp: 41166.0000 - val_fp: 22834.0000 - val_tn: 41166.0000 - val_fn: 22834.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-19456000-19712000
[INFO] processing batch 19712000-19968000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6518 - tp: 123402.0000 - fp: 68598.0000 - tn: 123402.0000 - fn: 68598.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6425 - val_loss: 0.6508 - val_tp: 41242.0000 - val_fp: 22758.0000 - val_tn: 41242.0000 - val_fn: 22758.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-19712000-19968000
[INFO] processing batch 19968000-20224000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123541.0000 - fp: 68459.0000 - tn: 123541.0000 - fn: 68459.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6432 - val_loss: 0.6509 - val_tp: 41241.0000 - val_fp: 22759.0000 - val_tn: 41241.0000 - val_fn: 22759.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-19968000-20224000
[INFO] processing batch 20224000-20480000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123640.0000 - fp: 68360.0000 - tn: 123640.0000 - fn: 68360.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6436 - val_loss: 0.6511 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 41209.0000 - val_fn: 22791.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-20224000-20480000
[INFO] processing batch 20480000-20736000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123598.0000 - fp: 68402.0000 - tn: 123598.0000 - fn: 68402.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6509 - val_tp: 41235.0000 - val_fp: 22765.0000 - val_tn: 41235.0000 - val_fn: 22765.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-20480000-20736000
[INFO] processing batch 20736000-20992000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6507 - tp: 123769.0000 - fp: 68231.0000 - tn: 123769.0000 - fn: 68231.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6443 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-20736000-20992000
[INFO] processing batch 20992000-21248000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6517 - tp: 123459.0000 - fp: 68541.0000 - tn: 123459.0000 - fn: 68541.0000 - accuracy: 0.6430 - precision: 0.6430 - recall: 0.6430 - auc: 0.6429 - val_loss: 0.6511 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 41209.0000 - val_fn: 22791.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-20992000-21248000
[INFO] processing batch 21248000-21504000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.6510 - tp: 123683.0000 - fp: 68317.0000 - tn: 123683.0000 - fn: 68317.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6439 - val_loss: 0.6514 - val_tp: 41183.0000 - val_fp: 22817.0000 - val_tn: 41183.0000 - val_fn: 22817.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-21248000-21504000
[INFO] processing batch 21504000-21760000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6513 - tp: 123564.0000 - fp: 68436.0000 - tn: 123564.0000 - fn: 68436.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6507 - val_tp: 41254.0000 - val_fp: 22746.0000 - val_tn: 41254.0000 - val_fn: 22746.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-21504000-21760000
[INFO] processing batch 21760000-22016000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123717.0000 - fp: 68283.0000 - tn: 123717.0000 - fn: 68283.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6441 - val_loss: 0.6506 - val_tp: 41270.0000 - val_fp: 22730.0000 - val_tn: 41270.0000 - val_fn: 22730.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-21760000-22016000
[INFO] processing batch 22016000-22272000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.6510 - tp: 123690.0000 - fp: 68310.0000 - tn: 123690.0000 - fn: 68310.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6441 - val_loss: 0.6521 - val_tp: 41104.0000 - val_fp: 22896.0000 - val_tn: 41104.0000 - val_fn: 22896.0000 - val_accuracy: 0.6423 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-22016000-22272000
[INFO] processing batch 22272000-22528000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123672.0000 - fp: 68328.0000 - tn: 123672.0000 - fn: 68328.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6438 - val_loss: 0.6508 - val_tp: 41243.0000 - val_fp: 22757.0000 - val_tn: 41243.0000 - val_fn: 22757.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-22272000-22528000
[INFO] processing batch 22528000-22784000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123623.0000 - fp: 68377.0000 - tn: 123623.0000 - fn: 68377.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6442 - val_loss: 0.6504 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 41292.0000 - val_fn: 22708.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-22528000-22784000
[INFO] processing batch 22784000-23040000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6507 - tp: 123759.0000 - fp: 68241.0000 - tn: 123759.0000 - fn: 68241.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6514 - val_tp: 41180.0000 - val_fp: 22820.0000 - val_tn: 41180.0000 - val_fn: 22820.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-22784000-23040000
[INFO] processing batch 23040000-23296000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123507.0000 - fp: 68493.0000 - tn: 123507.0000 - fn: 68493.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6437 - val_loss: 0.6507 - val_tp: 41255.0000 - val_fp: 22745.0000 - val_tn: 41255.0000 - val_fn: 22745.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-23040000-23296000
[INFO] processing batch 23296000-23552000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123601.0000 - fp: 68399.0000 - tn: 123601.0000 - fn: 68399.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6436 - val_loss: 0.6511 - val_tp: 41213.0000 - val_fp: 22787.0000 - val_tn: 41213.0000 - val_fn: 22787.0000 - val_accuracy: 0.6440 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.6440
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-23296000-23552000
[INFO] processing batch 23552000-23808000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6508 - tp: 123749.0000 - fp: 68251.0000 - tn: 123749.0000 - fn: 68251.0000 - accuracy: 0.6445 - precision: 0.6445 - recall: 0.6445 - auc: 0.6444 - val_loss: 0.6504 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 41292.0000 - val_fn: 22708.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-23552000-23808000
[INFO] processing batch 23808000-24064000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123603.0000 - fp: 68397.0000 - tn: 123603.0000 - fn: 68397.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6436 - val_loss: 0.6516 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 41165.0000 - val_fn: 22835.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-23808000-24064000
[INFO] processing batch 24064000-24320000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123599.0000 - fp: 68401.0000 - tn: 123599.0000 - fn: 68401.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6434 - val_loss: 0.6514 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 41184.0000 - val_fn: 22816.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-24064000-24320000
[INFO] processing batch 24320000-24576000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6517 - tp: 123440.0000 - fp: 68560.0000 - tn: 123440.0000 - fn: 68560.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6426 - val_loss: 0.6515 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 41169.0000 - val_fn: 22831.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-008-files-0-50-batch-24320000-24576000
[33m[LOSS] 0.6515243315696716[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6515243315696716  <  0.001
[33m[INFO] epoch 9/10[0m
[33m[INFO] loading file 1-50/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (24819975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] Shape when encoding dataset: (24819975, 17)
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
missing -1
len(df.columns) 108
numFeatures 107
[INFO] Shape AFTER encoding dataset: (24819975, 108)
[INFO] processing batch 0-256000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.2757 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1971 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-0-256000
[INFO] processing batch 256000-512000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.7743 - tp: 112918.0000 - fp: 79082.0000 - tn: 112918.0000 - fn: 79082.0000 - accuracy: 0.5881 - precision: 0.5881 - recall: 0.5881 - auc: 0.5887 - val_loss: 0.7947 - val_tp: 33927.0000 - val_fp: 30073.0000 - val_tn: 33927.0000 - val_fn: 30073.0000 - val_accuracy: 0.5301 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-256000-512000
[INFO] processing batch 512000-768000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5934 - tp: 138284.0000 - fp: 53716.0000 - tn: 138284.0000 - fn: 53716.0000 - accuracy: 0.7202 - precision: 0.7202 - recall: 0.7202 - auc: 0.7188 - val_loss: 0.3421 - val_tp: 62058.0000 - val_fp: 1942.0000 - val_tn: 62058.0000 - val_fn: 1942.0000 - val_accuracy: 0.9697 - val_precision: 0.9697 - val_recall: 0.9697 - val_auc: 0.9697
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-512000-768000
[INFO] processing batch 768000-1024000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6887 - tp: 117250.0000 - fp: 74750.0000 - tn: 117250.0000 - fn: 74750.0000 - accuracy: 0.6107 - precision: 0.6107 - recall: 0.6107 - auc: 0.6122 - val_loss: 0.4878 - val_tp: 55591.0000 - val_fp: 8409.0000 - val_tn: 55591.0000 - val_fn: 8409.0000 - val_accuracy: 0.8686 - val_precision: 0.8686 - val_recall: 0.8686 - val_auc: 0.8686
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-768000-1024000
[INFO] processing batch 1024000-1280000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6134 - tp: 133967.0000 - fp: 58033.0000 - tn: 133967.0000 - fn: 58033.0000 - accuracy: 0.6977 - precision: 0.6977 - recall: 0.6977 - auc: 0.6978 - val_loss: 0.3759 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-1024000-1280000
[INFO] processing batch 1280000-1536000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.2801 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2152 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-1280000-1536000
[INFO] processing batch 1536000-1792000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1801 - tp: 191999.0000 - fp: 1.0000 - tn: 191999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1517 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-1536000-1792000
[INFO] processing batch 1792000-2048000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5575 - tp: 148221.0000 - fp: 43779.0000 - tn: 148221.0000 - fn: 43779.0000 - accuracy: 0.7720 - precision: 0.7720 - recall: 0.7720 - auc: 0.7675 - val_loss: 0.3329 - val_tp: 57941.0000 - val_fp: 6059.0000 - val_tn: 57941.0000 - val_fn: 6059.0000 - val_accuracy: 0.9053 - val_precision: 0.9053 - val_recall: 0.9053 - val_auc: 0.9053
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-1792000-2048000
[INFO] processing batch 2048000-2304000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.5961 - tp: 141714.0000 - fp: 50286.0000 - tn: 141714.0000 - fn: 50286.0000 - accuracy: 0.7381 - precision: 0.7381 - recall: 0.7381 - auc: 0.7363 - val_loss: 0.2182 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-2048000-2304000
[INFO] processing batch 2304000-2560000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1790 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1465 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-2304000-2560000
[INFO] processing batch 2560000-2816000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.1257 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1081 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-2560000-2816000
[INFO] processing batch 2816000-3072000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5806 - tp: 148720.0000 - fp: 43280.0000 - tn: 148720.0000 - fn: 43280.0000 - accuracy: 0.7746 - precision: 0.7746 - recall: 0.7746 - auc: 0.7753 - val_loss: 0.8173 - val_tp: 40961.0000 - val_fp: 23039.0000 - val_tn: 40961.0000 - val_fn: 23039.0000 - val_accuracy: 0.6400 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.6400
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-2816000-3072000
[INFO] processing batch 3072000-3328000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.6963 - tp: 131495.0000 - fp: 60505.0000 - tn: 131495.0000 - fn: 60505.0000 - accuracy: 0.6849 - precision: 0.6849 - recall: 0.6849 - auc: 0.6836 - val_loss: 0.2112 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-3072000-3328000
[INFO] processing batch 3328000-3584000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.1758 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1453 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-3328000-3584000
[INFO] processing batch 3584000-3840000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1252 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1081 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-3584000-3840000
[INFO] processing batch 3840000-4096000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4912 - tp: 157534.0000 - fp: 34466.0000 - tn: 157534.0000 - fn: 34466.0000 - accuracy: 0.8205 - precision: 0.8205 - recall: 0.8205 - auc: 0.8202 - val_loss: 0.4939 - val_tp: 52219.0000 - val_fp: 11781.0000 - val_tn: 52219.0000 - val_fn: 11781.0000 - val_accuracy: 0.8159 - val_precision: 0.8159 - val_recall: 0.8159 - val_auc: 0.8159
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-3840000-4096000
[INFO] processing batch 4096000-4352000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1326 - tp: 190188.0000 - fp: 1812.0000 - tn: 190188.0000 - fn: 1812.0000 - accuracy: 0.9906 - precision: 0.9906 - recall: 0.9906 - auc: 0.9907 - val_loss: 0.0972 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-4096000-4352000
[INFO] processing batch 4352000-4608000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.0849 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0742 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-4352000-4608000
[INFO] processing batch 4608000-4864000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.4711 - tp: 161451.0000 - fp: 30549.0000 - tn: 161451.0000 - fn: 30549.0000 - accuracy: 0.8409 - precision: 0.8409 - recall: 0.8409 - auc: 0.8406 - val_loss: 0.0966 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-4608000-4864000
[INFO] processing batch 4864000-5120000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0840 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0723 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-4864000-5120000
[INFO] processing batch 5120000-5376000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0637 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0561 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-5120000-5376000
[INFO] processing batch 5376000-5632000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0501 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0447 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-5376000-5632000
[INFO] processing batch 5632000-5888000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.5881 - tp: 155809.0000 - fp: 36191.0000 - tn: 155809.0000 - fn: 36191.0000 - accuracy: 0.8115 - precision: 0.8115 - recall: 0.8115 - auc: 0.8110 - val_loss: 0.0754 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-5632000-5888000
[INFO] processing batch 5888000-6144000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.0675 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0594 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-5888000-6144000
[INFO] processing batch 6144000-6400000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.3169 - tp: 174156.0000 - fp: 17844.0000 - tn: 174156.0000 - fn: 17844.0000 - accuracy: 0.9071 - precision: 0.9071 - recall: 0.9071 - auc: 0.9078 - val_loss: 1.0187 - val_tp: 41108.0000 - val_fp: 22892.0000 - val_tn: 41108.0000 - val_fn: 22892.0000 - val_accuracy: 0.6423 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-6144000-6400000
[INFO] processing batch 6400000-6656000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.7347 - tp: 138766.0000 - fp: 53234.0000 - tn: 138766.0000 - fn: 53234.0000 - accuracy: 0.7227 - precision: 0.7227 - recall: 0.7227 - auc: 0.7224 - val_loss: 0.1267 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-6400000-6656000
[INFO] processing batch 6656000-6912000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 16s - loss: 0.1104 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0947 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-6656000-6912000
[INFO] processing batch 6912000-7168000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.0832 - tp: 191998.0000 - fp: 2.0000 - tn: 191998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0732 - val_tp: 63999.0000 - val_fp: 1.0000 - val_tn: 63999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-6912000-7168000
[INFO] processing batch 7168000-7424000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0653 - tp: 191999.0000 - fp: 1.0000 - tn: 191999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9227 - val_tp: 44344.0000 - val_fp: 19656.0000 - val_tn: 44344.0000 - val_fn: 19656.0000 - val_accuracy: 0.6929 - val_precision: 0.6929 - val_recall: 0.6929 - val_auc: 0.6929
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-7168000-7424000
[INFO] processing batch 7424000-7680000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 1.1985 - tp: 102062.0000 - fp: 89938.0000 - tn: 102062.0000 - fn: 89938.0000 - accuracy: 0.5316 - precision: 0.5316 - recall: 0.5316 - auc: 0.5316 - val_loss: 0.5690 - val_tp: 49859.0000 - val_fp: 14141.0000 - val_tn: 49859.0000 - val_fn: 14141.0000 - val_accuracy: 0.7790 - val_precision: 0.7790 - val_recall: 0.7790 - val_auc: 0.7790
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-7424000-7680000
[INFO] processing batch 7680000-7936000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1176 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1071 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-7680000-7936000
[INFO] processing batch 7936000-8192000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0979 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0893 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-7936000-8192000
[INFO] processing batch 8192000-8448000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4576 - tp: 161781.0000 - fp: 30219.0000 - tn: 161781.0000 - fn: 30219.0000 - accuracy: 0.8426 - precision: 0.8426 - recall: 0.8426 - auc: 0.8422 - val_loss: 0.1248 - val_tp: 63369.0000 - val_fp: 631.0000 - val_tn: 63369.0000 - val_fn: 631.0000 - val_accuracy: 0.9901 - val_precision: 0.9901 - val_recall: 0.9901 - val_auc: 0.9901
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-8192000-8448000
[INFO] processing batch 8448000-8704000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.8325 - tp: 123282.0000 - fp: 68718.0000 - tn: 123282.0000 - fn: 68718.0000 - accuracy: 0.6421 - precision: 0.6421 - recall: 0.6421 - auc: 0.6413 - val_loss: 0.8146 - val_tp: 39692.0000 - val_fp: 24308.0000 - val_tn: 39692.0000 - val_fn: 24308.0000 - val_accuracy: 0.6202 - val_precision: 0.6202 - val_recall: 0.6202 - val_auc: 0.6202
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-8448000-8704000
[INFO] processing batch 8704000-8960000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1878 - tp: 188028.0000 - fp: 3972.0000 - tn: 188028.0000 - fn: 3972.0000 - accuracy: 0.9793 - precision: 0.9793 - recall: 0.9793 - auc: 0.9802 - val_loss: 0.1329 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-8704000-8960000
[INFO] processing batch 8960000-9216000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1172 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1033 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-8960000-9216000
[INFO] processing batch 9216000-9472000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.8606 - tp: 120440.0000 - fp: 71560.0000 - tn: 120440.0000 - fn: 71560.0000 - accuracy: 0.6273 - precision: 0.6273 - recall: 0.6273 - auc: 0.6256 - val_loss: 0.1684 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-9216000-9472000
[INFO] processing batch 9472000-9728000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.4373 - tp: 161553.0000 - fp: 30447.0000 - tn: 161553.0000 - fn: 30447.0000 - accuracy: 0.8414 - precision: 0.8414 - recall: 0.8414 - auc: 0.8415 - val_loss: 0.4474 - val_tp: 53468.0000 - val_fp: 10532.0000 - val_tn: 53468.0000 - val_fn: 10532.0000 - val_accuracy: 0.8354 - val_precision: 0.8354 - val_recall: 0.8354 - val_auc: 0.8354
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-9472000-9728000
[INFO] processing batch 9728000-9984000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1470 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1259 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-9728000-9984000
[INFO] processing batch 9984000-10240000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1105 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0970 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-9984000-10240000
[INFO] processing batch 10240000-10496000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1188 - tp: 189510.0000 - fp: 2490.0000 - tn: 189510.0000 - fn: 2490.0000 - accuracy: 0.9870 - precision: 0.9870 - recall: 0.9870 - auc: 0.9877 - val_loss: 1.2491 - val_tp: 33975.0000 - val_fp: 30025.0000 - val_tn: 33975.0000 - val_fn: 30025.0000 - val_accuracy: 0.5309 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.5309
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-10240000-10496000
[INFO] processing batch 10496000-10752000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 1.1048 - tp: 101670.0000 - fp: 90330.0000 - tn: 101670.0000 - fn: 90330.0000 - accuracy: 0.5295 - precision: 0.5295 - recall: 0.5295 - auc: 0.5297 - val_loss: 0.9853 - val_tp: 34015.0000 - val_fp: 29985.0000 - val_tn: 34015.0000 - val_fn: 29985.0000 - val_accuracy: 0.5315 - val_precision: 0.5315 - val_recall: 0.5315 - val_auc: 0.5315
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-10496000-10752000
[INFO] processing batch 10752000-11008000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.9151 - tp: 101693.0000 - fp: 90307.0000 - tn: 101693.0000 - fn: 90307.0000 - accuracy: 0.5297 - precision: 0.5297 - recall: 0.5297 - auc: 0.5298 - val_loss: 0.3829 - val_tp: 56989.0000 - val_fp: 7011.0000 - val_tn: 56989.0000 - val_fn: 7011.0000 - val_accuracy: 0.8905 - val_precision: 0.8905 - val_recall: 0.8905 - val_auc: 0.8905
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-10752000-11008000
[INFO] processing batch 11008000-11264000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.2126 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1856 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-11008000-11264000
[INFO] processing batch 11264000-11520000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1648 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1460 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-11264000-11520000
[INFO] processing batch 11520000-11776000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1310 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1172 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-11520000-11776000
[INFO] processing batch 11776000-12032000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.4990 - tp: 156412.0000 - fp: 35588.0000 - tn: 156412.0000 - fn: 35588.0000 - accuracy: 0.8146 - precision: 0.8146 - recall: 0.8146 - auc: 0.8141 - val_loss: 0.8284 - val_tp: 41134.0000 - val_fp: 22866.0000 - val_tn: 41134.0000 - val_fn: 22866.0000 - val_accuracy: 0.6427 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.6427
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-11776000-12032000
[INFO] processing batch 12032000-12288000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.7781 - tp: 123527.0000 - fp: 68473.0000 - tn: 123527.0000 - fn: 68473.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6435 - val_loss: 0.7356 - val_tp: 41219.0000 - val_fp: 22781.0000 - val_tn: 41219.0000 - val_fn: 22781.0000 - val_accuracy: 0.6440 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.6440
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-12032000-12288000
[INFO] processing batch 12288000-12544000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.7097 - tp: 123560.0000 - fp: 68440.0000 - tn: 123560.0000 - fn: 68440.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6867 - val_tp: 41268.0000 - val_fp: 22732.0000 - val_tn: 41268.0000 - val_fn: 22732.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-12288000-12544000
[INFO] processing batch 12544000-12800000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6750 - tp: 123588.0000 - fp: 68412.0000 - tn: 123588.0000 - fn: 68412.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6441 - val_loss: 0.6638 - val_tp: 41269.0000 - val_fp: 22731.0000 - val_tn: 41269.0000 - val_fn: 22731.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-12544000-12800000
[INFO] processing batch 12800000-13056000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6596 - tp: 123531.0000 - fp: 68469.0000 - tn: 123531.0000 - fn: 68469.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6432 - val_loss: 0.6555 - val_tp: 41181.0000 - val_fp: 22819.0000 - val_tn: 41181.0000 - val_fn: 22819.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-12800000-13056000
[INFO] processing batch 13056000-13312000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6534 - tp: 123615.0000 - fp: 68385.0000 - tn: 123615.0000 - fn: 68385.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6441 - val_loss: 0.6523 - val_tp: 41192.0000 - val_fp: 22808.0000 - val_tn: 41192.0000 - val_fn: 22808.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-13056000-13312000
[INFO] processing batch 13312000-13568000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6522 - tp: 123437.0000 - fp: 68563.0000 - tn: 123437.0000 - fn: 68563.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6423 - val_loss: 0.6516 - val_tp: 41179.0000 - val_fp: 22821.0000 - val_tn: 41179.0000 - val_fn: 22821.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-13312000-13568000
[INFO] processing batch 13568000-13824000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6515 - tp: 123539.0000 - fp: 68461.0000 - tn: 123539.0000 - fn: 68461.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6438 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-13568000-13824000
[INFO] processing batch 13824000-14080000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123556.0000 - fp: 68444.0000 - tn: 123556.0000 - fn: 68444.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6515 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 41173.0000 - val_fn: 22827.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-13824000-14080000
[INFO] processing batch 14080000-14336000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123681.0000 - fp: 68319.0000 - tn: 123681.0000 - fn: 68319.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6510 - val_tp: 41221.0000 - val_fp: 22779.0000 - val_tn: 41221.0000 - val_fn: 22779.0000 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.6441
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-14080000-14336000
[INFO] processing batch 14336000-14592000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6515 - tp: 123523.0000 - fp: 68477.0000 - tn: 123523.0000 - fn: 68477.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6432 - val_loss: 0.6513 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 41197.0000 - val_fn: 22803.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-14336000-14592000
[INFO] processing batch 14592000-14848000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123652.0000 - fp: 68348.0000 - tn: 123652.0000 - fn: 68348.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6440 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-14592000-14848000
[INFO] processing batch 14848000-15104000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6513 - tp: 123594.0000 - fp: 68406.0000 - tn: 123594.0000 - fn: 68406.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6512 - val_tp: 41205.0000 - val_fp: 22795.0000 - val_tn: 41205.0000 - val_fn: 22795.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-14848000-15104000
[INFO] processing batch 15104000-15360000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6511 - tp: 123629.0000 - fp: 68371.0000 - tn: 123629.0000 - fn: 68371.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6438 - val_loss: 0.6509 - val_tp: 41234.0000 - val_fp: 22766.0000 - val_tn: 41234.0000 - val_fn: 22766.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-15104000-15360000
[INFO] processing batch 15360000-15616000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123632.0000 - fp: 68368.0000 - tn: 123632.0000 - fn: 68368.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6506 - val_tp: 41266.0000 - val_fp: 22734.0000 - val_tn: 41266.0000 - val_fn: 22734.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-15360000-15616000
[INFO] processing batch 15616000-15872000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6515 - tp: 123527.0000 - fp: 68473.0000 - tn: 123527.0000 - fn: 68473.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6437 - val_loss: 0.6513 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 41197.0000 - val_fn: 22803.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-15616000-15872000
[INFO] processing batch 15872000-16128000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6514 - tp: 123531.0000 - fp: 68469.0000 - tn: 123531.0000 - fn: 68469.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6438 - val_loss: 0.6515 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 41173.0000 - val_fn: 22827.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-15872000-16128000
[INFO] processing batch 16128000-16384000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6507 - tp: 123781.0000 - fp: 68219.0000 - tn: 123781.0000 - fn: 68219.0000 - accuracy: 0.6447 - precision: 0.6447 - recall: 0.6447 - auc: 0.6448 - val_loss: 0.6513 - val_tp: 41195.0000 - val_fp: 22805.0000 - val_tn: 41195.0000 - val_fn: 22805.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-16128000-16384000
[INFO] processing batch 16384000-16640000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123621.0000 - fp: 68379.0000 - tn: 123621.0000 - fn: 68379.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6439 - val_loss: 0.6516 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 41165.0000 - val_fn: 22835.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-16384000-16640000
[INFO] processing batch 16640000-16896000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6518 - tp: 123417.0000 - fp: 68583.0000 - tn: 123417.0000 - fn: 68583.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6427 - val_loss: 0.6510 - val_tp: 41230.0000 - val_fp: 22770.0000 - val_tn: 41230.0000 - val_fn: 22770.0000 - val_accuracy: 0.6442 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.6442
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-16640000-16896000
[INFO] processing batch 16896000-17152000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123600.0000 - fp: 68400.0000 - tn: 123600.0000 - fn: 68400.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6434 - val_loss: 0.6512 - val_tp: 41198.0000 - val_fp: 22802.0000 - val_tn: 41198.0000 - val_fn: 22802.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-16896000-17152000
[INFO] processing batch 17152000-17408000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123711.0000 - fp: 68289.0000 - tn: 123711.0000 - fn: 68289.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6442 - val_loss: 0.6515 - val_tp: 41168.0000 - val_fp: 22832.0000 - val_tn: 41168.0000 - val_fn: 22832.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-17152000-17408000
[INFO] processing batch 17408000-17664000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123701.0000 - fp: 68299.0000 - tn: 123701.0000 - fn: 68299.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6441 - val_loss: 0.6520 - val_tp: 41118.0000 - val_fp: 22882.0000 - val_tn: 41118.0000 - val_fn: 22882.0000 - val_accuracy: 0.6425 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.6425
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-17408000-17664000
[INFO] processing batch 17664000-17920000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123546.0000 - fp: 68454.0000 - tn: 123546.0000 - fn: 68454.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6432 - val_loss: 0.6523 - val_tp: 41089.0000 - val_fp: 22911.0000 - val_tn: 41089.0000 - val_fn: 22911.0000 - val_accuracy: 0.6420 - val_precision: 0.6420 - val_recall: 0.6420 - val_auc: 0.6420
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-17664000-17920000
[INFO] processing batch 17920000-18176000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123681.0000 - fp: 68319.0000 - tn: 123681.0000 - fn: 68319.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6441 - val_loss: 0.6509 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 41233.0000 - val_fn: 22767.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-17920000-18176000
[INFO] processing batch 18176000-18432000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123640.0000 - fp: 68360.0000 - tn: 123640.0000 - fn: 68360.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6436 - val_loss: 0.6503 - val_tp: 41298.0000 - val_fp: 22702.0000 - val_tn: 41298.0000 - val_fn: 22702.0000 - val_accuracy: 0.6453 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.6453
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-18176000-18432000
[INFO] processing batch 18432000-18688000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123615.0000 - fp: 68385.0000 - tn: 123615.0000 - fn: 68385.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6440 - val_loss: 0.6509 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 41233.0000 - val_fn: 22767.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-18432000-18688000
[INFO] processing batch 18688000-18944000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123645.0000 - fp: 68355.0000 - tn: 123645.0000 - fn: 68355.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6441 - val_loss: 0.6514 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 41184.0000 - val_fn: 22816.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-18688000-18944000
[INFO] processing batch 18944000-19200000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6503 - tp: 123888.0000 - fp: 68112.0000 - tn: 123888.0000 - fn: 68112.0000 - accuracy: 0.6453 - precision: 0.6453 - recall: 0.6453 - auc: 0.6452 - val_loss: 0.6515 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 41169.0000 - val_fn: 22831.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-18944000-19200000
[INFO] processing batch 19200000-19456000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123500.0000 - fp: 68500.0000 - tn: 123500.0000 - fn: 68500.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6430 - val_loss: 0.6513 - val_tp: 41189.0000 - val_fp: 22811.0000 - val_tn: 41189.0000 - val_fn: 22811.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-19200000-19456000
[INFO] processing batch 19456000-19712000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6510 - tp: 123689.0000 - fp: 68311.0000 - tn: 123689.0000 - fn: 68311.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6515 - val_tp: 41166.0000 - val_fp: 22834.0000 - val_tn: 41166.0000 - val_fn: 22834.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-19456000-19712000
[INFO] processing batch 19712000-19968000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6518 - tp: 123402.0000 - fp: 68598.0000 - tn: 123402.0000 - fn: 68598.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6426 - val_loss: 0.6508 - val_tp: 41242.0000 - val_fp: 22758.0000 - val_tn: 41242.0000 - val_fn: 22758.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-19712000-19968000
[INFO] processing batch 19968000-20224000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123541.0000 - fp: 68459.0000 - tn: 123541.0000 - fn: 68459.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6436 - val_loss: 0.6509 - val_tp: 41241.0000 - val_fp: 22759.0000 - val_tn: 41241.0000 - val_fn: 22759.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-19968000-20224000
[INFO] processing batch 20224000-20480000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123640.0000 - fp: 68360.0000 - tn: 123640.0000 - fn: 68360.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6437 - val_loss: 0.6511 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 41209.0000 - val_fn: 22791.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-20224000-20480000
[INFO] processing batch 20480000-20736000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6512 - tp: 123598.0000 - fp: 68402.0000 - tn: 123598.0000 - fn: 68402.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6431 - val_loss: 0.6509 - val_tp: 41235.0000 - val_fp: 22765.0000 - val_tn: 41235.0000 - val_fn: 22765.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-20480000-20736000
[INFO] processing batch 20736000-20992000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6507 - tp: 123769.0000 - fp: 68231.0000 - tn: 123769.0000 - fn: 68231.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6449 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-20736000-20992000
[INFO] processing batch 20992000-21248000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6517 - tp: 123459.0000 - fp: 68541.0000 - tn: 123459.0000 - fn: 68541.0000 - accuracy: 0.6430 - precision: 0.6430 - recall: 0.6430 - auc: 0.6430 - val_loss: 0.6512 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 41209.0000 - val_fn: 22791.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-20992000-21248000
[INFO] processing batch 21248000-21504000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123683.0000 - fp: 68317.0000 - tn: 123683.0000 - fn: 68317.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6443 - val_loss: 0.6514 - val_tp: 41183.0000 - val_fp: 22817.0000 - val_tn: 41183.0000 - val_fn: 22817.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-21248000-21504000
[INFO] processing batch 21504000-21760000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.6513 - tp: 123564.0000 - fp: 68436.0000 - tn: 123564.0000 - fn: 68436.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6438 - val_loss: 0.6507 - val_tp: 41254.0000 - val_fp: 22746.0000 - val_tn: 41254.0000 - val_fn: 22746.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-21504000-21760000
[INFO] processing batch 21760000-22016000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123717.0000 - fp: 68283.0000 - tn: 123717.0000 - fn: 68283.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6441 - val_loss: 0.6506 - val_tp: 41270.0000 - val_fp: 22730.0000 - val_tn: 41270.0000 - val_fn: 22730.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-21760000-22016000
[INFO] processing batch 22016000-22272000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123690.0000 - fp: 68310.0000 - tn: 123690.0000 - fn: 68310.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6444 - val_loss: 0.6521 - val_tp: 41104.0000 - val_fp: 22896.0000 - val_tn: 41104.0000 - val_fn: 22896.0000 - val_accuracy: 0.6423 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-22016000-22272000
[INFO] processing batch 22272000-22528000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.6510 - tp: 123672.0000 - fp: 68328.0000 - tn: 123672.0000 - fn: 68328.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6442 - val_loss: 0.6508 - val_tp: 41243.0000 - val_fp: 22757.0000 - val_tn: 41243.0000 - val_fn: 22757.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-22272000-22528000
[INFO] processing batch 22528000-22784000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123623.0000 - fp: 68377.0000 - tn: 123623.0000 - fn: 68377.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6437 - val_loss: 0.6504 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 41292.0000 - val_fn: 22708.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-22528000-22784000
[INFO] processing batch 22784000-23040000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6507 - tp: 123759.0000 - fp: 68241.0000 - tn: 123759.0000 - fn: 68241.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6514 - val_tp: 41180.0000 - val_fp: 22820.0000 - val_tn: 41180.0000 - val_fn: 22820.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-22784000-23040000
[INFO] processing batch 23040000-23296000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123507.0000 - fp: 68493.0000 - tn: 123507.0000 - fn: 68493.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6431 - val_loss: 0.6507 - val_tp: 41255.0000 - val_fp: 22745.0000 - val_tn: 41255.0000 - val_fn: 22745.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-23040000-23296000
[INFO] processing batch 23296000-23552000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123601.0000 - fp: 68399.0000 - tn: 123601.0000 - fn: 68399.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6436 - val_loss: 0.6511 - val_tp: 41213.0000 - val_fp: 22787.0000 - val_tn: 41213.0000 - val_fn: 22787.0000 - val_accuracy: 0.6440 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.6440
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-23296000-23552000
[INFO] processing batch 23552000-23808000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6508 - tp: 123749.0000 - fp: 68251.0000 - tn: 123749.0000 - fn: 68251.0000 - accuracy: 0.6445 - precision: 0.6445 - recall: 0.6445 - auc: 0.6444 - val_loss: 0.6504 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 41292.0000 - val_fn: 22708.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-23552000-23808000
[INFO] processing batch 23808000-24064000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123603.0000 - fp: 68397.0000 - tn: 123603.0000 - fn: 68397.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6436 - val_loss: 0.6516 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 41165.0000 - val_fn: 22835.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-23808000-24064000
[INFO] processing batch 24064000-24320000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123599.0000 - fp: 68401.0000 - tn: 123599.0000 - fn: 68401.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6436 - val_loss: 0.6514 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 41184.0000 - val_fn: 22816.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-24064000-24320000
[INFO] processing batch 24320000-24576000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6517 - tp: 123440.0000 - fp: 68560.0000 - tn: 123440.0000 - fn: 68560.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6428 - val_loss: 0.6515 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 41169.0000 - val_fn: 22831.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-009-files-0-50-batch-24320000-24576000
[33m[LOSS] 0.6515205264091491[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6515205264091491  <  0.001
[33m[INFO] epoch 10/10[0m
[33m[INFO] loading file 1-50/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (24819975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] Shape when encoding dataset: (24819975, 17)
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
missing -1
len(df.columns) 108
numFeatures 107
[INFO] Shape AFTER encoding dataset: (24819975, 108)
[INFO] processing batch 0-256000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.2753 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1968 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-0-256000
[INFO] processing batch 256000-512000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.7747 - tp: 112918.0000 - fp: 79082.0000 - tn: 112918.0000 - fn: 79082.0000 - accuracy: 0.5881 - precision: 0.5881 - recall: 0.5881 - auc: 0.5879 - val_loss: 0.7951 - val_tp: 33927.0000 - val_fp: 30073.0000 - val_tn: 33927.0000 - val_fn: 30073.0000 - val_accuracy: 0.5301 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.5301
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-256000-512000
[INFO] processing batch 512000-768000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5934 - tp: 138284.0000 - fp: 53716.0000 - tn: 138284.0000 - fn: 53716.0000 - accuracy: 0.7202 - precision: 0.7202 - recall: 0.7202 - auc: 0.7190 - val_loss: 0.3420 - val_tp: 62058.0000 - val_fp: 1942.0000 - val_tn: 62058.0000 - val_fn: 1942.0000 - val_accuracy: 0.9697 - val_precision: 0.9697 - val_recall: 0.9697 - val_auc: 0.9697
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-512000-768000
[INFO] processing batch 768000-1024000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6888 - tp: 117250.0000 - fp: 74750.0000 - tn: 117250.0000 - fn: 74750.0000 - accuracy: 0.6107 - precision: 0.6107 - recall: 0.6107 - auc: 0.6097 - val_loss: 0.4877 - val_tp: 55591.0000 - val_fp: 8409.0000 - val_tn: 55591.0000 - val_fn: 8409.0000 - val_accuracy: 0.8686 - val_precision: 0.8686 - val_recall: 0.8686 - val_auc: 0.8686
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-768000-1024000
[INFO] processing batch 1024000-1280000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6134 - tp: 133967.0000 - fp: 58033.0000 - tn: 133967.0000 - fn: 58033.0000 - accuracy: 0.6977 - precision: 0.6977 - recall: 0.6977 - auc: 0.6969 - val_loss: 0.3757 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-1024000-1280000
[INFO] processing batch 1280000-1536000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.2799 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2150 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-1280000-1536000
[INFO] processing batch 1536000-1792000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1799 - tp: 191999.0000 - fp: 1.0000 - tn: 191999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1515 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-1536000-1792000
[INFO] processing batch 1792000-2048000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5575 - tp: 148221.0000 - fp: 43779.0000 - tn: 148221.0000 - fn: 43779.0000 - accuracy: 0.7720 - precision: 0.7720 - recall: 0.7720 - auc: 0.7716 - val_loss: 0.3330 - val_tp: 57941.0000 - val_fp: 6059.0000 - val_tn: 57941.0000 - val_fn: 6059.0000 - val_accuracy: 0.9053 - val_precision: 0.9053 - val_recall: 0.9053 - val_auc: 0.9053
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-1792000-2048000
[INFO] processing batch 2048000-2304000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5960 - tp: 141714.0000 - fp: 50286.0000 - tn: 141714.0000 - fn: 50286.0000 - accuracy: 0.7381 - precision: 0.7381 - recall: 0.7381 - auc: 0.7376 - val_loss: 0.2185 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-2048000-2304000
[INFO] processing batch 2304000-2560000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1792 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1467 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-2304000-2560000
[INFO] processing batch 2560000-2816000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1258 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1082 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-2560000-2816000
[INFO] processing batch 2816000-3072000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.5806 - tp: 148720.0000 - fp: 43280.0000 - tn: 148720.0000 - fn: 43280.0000 - accuracy: 0.7746 - precision: 0.7746 - recall: 0.7746 - auc: 0.7747 - val_loss: 0.8171 - val_tp: 40961.0000 - val_fp: 23039.0000 - val_tn: 40961.0000 - val_fn: 23039.0000 - val_accuracy: 0.6400 - val_precision: 0.6400 - val_recall: 0.6400 - val_auc: 0.6400
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-2816000-3072000
[INFO] processing batch 3072000-3328000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6963 - tp: 131495.0000 - fp: 60505.0000 - tn: 131495.0000 - fn: 60505.0000 - accuracy: 0.6849 - precision: 0.6849 - recall: 0.6849 - auc: 0.6844 - val_loss: 0.2114 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-3072000-3328000
[INFO] processing batch 3328000-3584000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1759 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1454 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-3328000-3584000
[INFO] processing batch 3584000-3840000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1253 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1081 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-3584000-3840000
[INFO] processing batch 3840000-4096000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4912 - tp: 157534.0000 - fp: 34466.0000 - tn: 157534.0000 - fn: 34466.0000 - accuracy: 0.8205 - precision: 0.8205 - recall: 0.8205 - auc: 0.8206 - val_loss: 0.4939 - val_tp: 52219.0000 - val_fp: 11781.0000 - val_tn: 52219.0000 - val_fn: 11781.0000 - val_accuracy: 0.8159 - val_precision: 0.8159 - val_recall: 0.8159 - val_auc: 0.8159
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-3840000-4096000
[INFO] processing batch 4096000-4352000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1327 - tp: 190188.0000 - fp: 1812.0000 - tn: 190188.0000 - fn: 1812.0000 - accuracy: 0.9906 - precision: 0.9906 - recall: 0.9906 - auc: 0.9906 - val_loss: 0.0972 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-4096000-4352000
[INFO] processing batch 4352000-4608000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0849 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0742 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-4352000-4608000
[INFO] processing batch 4608000-4864000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.4711 - tp: 161451.0000 - fp: 30549.0000 - tn: 161451.0000 - fn: 30549.0000 - accuracy: 0.8409 - precision: 0.8409 - recall: 0.8409 - auc: 0.8410 - val_loss: 0.0967 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-4608000-4864000
[INFO] processing batch 4864000-5120000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.0840 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0723 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-4864000-5120000
[INFO] processing batch 5120000-5376000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0637 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0561 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-5120000-5376000
[INFO] processing batch 5376000-5632000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0501 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0447 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-5376000-5632000
[INFO] processing batch 5632000-5888000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.5881 - tp: 155809.0000 - fp: 36191.0000 - tn: 155809.0000 - fn: 36191.0000 - accuracy: 0.8115 - precision: 0.8115 - recall: 0.8115 - auc: 0.8110 - val_loss: 0.0755 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-5632000-5888000
[INFO] processing batch 5888000-6144000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0675 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0595 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-5888000-6144000
[INFO] processing batch 6144000-6400000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.3169 - tp: 174156.0000 - fp: 17844.0000 - tn: 174156.0000 - fn: 17844.0000 - accuracy: 0.9071 - precision: 0.9071 - recall: 0.9071 - auc: 0.9056 - val_loss: 1.0182 - val_tp: 41108.0000 - val_fp: 22892.0000 - val_tn: 41108.0000 - val_fn: 22892.0000 - val_accuracy: 0.6423 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-6144000-6400000
[INFO] processing batch 6400000-6656000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.7348 - tp: 138766.0000 - fp: 53234.0000 - tn: 138766.0000 - fn: 53234.0000 - accuracy: 0.7227 - precision: 0.7227 - recall: 0.7227 - auc: 0.7235 - val_loss: 0.1267 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-6400000-6656000
[INFO] processing batch 6656000-6912000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1104 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0947 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-6656000-6912000
[INFO] processing batch 6912000-7168000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0833 - tp: 191998.0000 - fp: 2.0000 - tn: 191998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0732 - val_tp: 63999.0000 - val_fp: 1.0000 - val_tn: 63999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-6912000-7168000
[INFO] processing batch 7168000-7424000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.0653 - tp: 191999.0000 - fp: 1.0000 - tn: 191999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9225 - val_tp: 44344.0000 - val_fp: 19656.0000 - val_tn: 44344.0000 - val_fn: 19656.0000 - val_accuracy: 0.6929 - val_precision: 0.6929 - val_recall: 0.6929 - val_auc: 0.6929
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-7168000-7424000
[INFO] processing batch 7424000-7680000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 1.1983 - tp: 102062.0000 - fp: 89938.0000 - tn: 102062.0000 - fn: 89938.0000 - accuracy: 0.5316 - precision: 0.5316 - recall: 0.5316 - auc: 0.5318 - val_loss: 0.5689 - val_tp: 49859.0000 - val_fp: 14141.0000 - val_tn: 49859.0000 - val_fn: 14141.0000 - val_accuracy: 0.7790 - val_precision: 0.7790 - val_recall: 0.7790 - val_auc: 0.7790
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-7424000-7680000
[INFO] processing batch 7680000-7936000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1177 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1071 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-7680000-7936000
[INFO] processing batch 7936000-8192000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.0980 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0894 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-7936000-8192000
[INFO] processing batch 8192000-8448000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4576 - tp: 161781.0000 - fp: 30219.0000 - tn: 161781.0000 - fn: 30219.0000 - accuracy: 0.8426 - precision: 0.8426 - recall: 0.8426 - auc: 0.8417 - val_loss: 0.1248 - val_tp: 63369.0000 - val_fp: 631.0000 - val_tn: 63369.0000 - val_fn: 631.0000 - val_accuracy: 0.9901 - val_precision: 0.9901 - val_recall: 0.9901 - val_auc: 0.9901
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-8192000-8448000
[INFO] processing batch 8448000-8704000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.8325 - tp: 123282.0000 - fp: 68718.0000 - tn: 123282.0000 - fn: 68718.0000 - accuracy: 0.6421 - precision: 0.6421 - recall: 0.6421 - auc: 0.6420 - val_loss: 0.8146 - val_tp: 39692.0000 - val_fp: 24308.0000 - val_tn: 39692.0000 - val_fn: 24308.0000 - val_accuracy: 0.6202 - val_precision: 0.6202 - val_recall: 0.6202 - val_auc: 0.6202
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-8448000-8704000
[INFO] processing batch 8704000-8960000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1879 - tp: 188028.0000 - fp: 3972.0000 - tn: 188028.0000 - fn: 3972.0000 - accuracy: 0.9793 - precision: 0.9793 - recall: 0.9793 - auc: 0.9787 - val_loss: 0.1330 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-8704000-8960000
[INFO] processing batch 8960000-9216000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1173 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1034 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-8960000-9216000
[INFO] processing batch 9216000-9472000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.8603 - tp: 120440.0000 - fp: 71560.0000 - tn: 120440.0000 - fn: 71560.0000 - accuracy: 0.6273 - precision: 0.6273 - recall: 0.6273 - auc: 0.6247 - val_loss: 0.1684 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-9216000-9472000
[INFO] processing batch 9472000-9728000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.4373 - tp: 161553.0000 - fp: 30447.0000 - tn: 161553.0000 - fn: 30447.0000 - accuracy: 0.8414 - precision: 0.8414 - recall: 0.8414 - auc: 0.8414 - val_loss: 0.4474 - val_tp: 53468.0000 - val_fp: 10532.0000 - val_tn: 53468.0000 - val_fn: 10532.0000 - val_accuracy: 0.8354 - val_precision: 0.8354 - val_recall: 0.8354 - val_auc: 0.8354
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-9472000-9728000
[INFO] processing batch 9728000-9984000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1470 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1259 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-9728000-9984000
[INFO] processing batch 9984000-10240000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1105 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0970 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-9984000-10240000
[INFO] processing batch 10240000-10496000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.1188 - tp: 189510.0000 - fp: 2490.0000 - tn: 189510.0000 - fn: 2490.0000 - accuracy: 0.9870 - precision: 0.9870 - recall: 0.9870 - auc: 0.9868 - val_loss: 1.2492 - val_tp: 33975.0000 - val_fp: 30025.0000 - val_tn: 33975.0000 - val_fn: 30025.0000 - val_accuracy: 0.5309 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.5309
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-10240000-10496000
[INFO] processing batch 10496000-10752000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 1.1048 - tp: 101670.0000 - fp: 90330.0000 - tn: 101670.0000 - fn: 90330.0000 - accuracy: 0.5295 - precision: 0.5295 - recall: 0.5295 - auc: 0.5292 - val_loss: 0.9854 - val_tp: 34015.0000 - val_fp: 29985.0000 - val_tn: 34015.0000 - val_fn: 29985.0000 - val_accuracy: 0.5315 - val_precision: 0.5315 - val_recall: 0.5315 - val_auc: 0.5315
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-10496000-10752000
[INFO] processing batch 10752000-11008000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.9152 - tp: 101693.0000 - fp: 90307.0000 - tn: 101693.0000 - fn: 90307.0000 - accuracy: 0.5297 - precision: 0.5297 - recall: 0.5297 - auc: 0.5295 - val_loss: 0.3829 - val_tp: 56989.0000 - val_fp: 7011.0000 - val_tn: 56989.0000 - val_fn: 7011.0000 - val_accuracy: 0.8905 - val_precision: 0.8905 - val_recall: 0.8905 - val_auc: 0.8905
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-10752000-11008000
[INFO] processing batch 11008000-11264000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.2126 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1856 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-11008000-11264000
[INFO] processing batch 11264000-11520000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1647 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1460 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-11264000-11520000
[INFO] processing batch 11520000-11776000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.1309 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1172 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-11520000-11776000
[INFO] processing batch 11776000-12032000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.4990 - tp: 156412.0000 - fp: 35588.0000 - tn: 156412.0000 - fn: 35588.0000 - accuracy: 0.8146 - precision: 0.8146 - recall: 0.8146 - auc: 0.8136 - val_loss: 0.8288 - val_tp: 41134.0000 - val_fp: 22866.0000 - val_tn: 41134.0000 - val_fn: 22866.0000 - val_accuracy: 0.6427 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.6427
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-11776000-12032000
[INFO] processing batch 12032000-12288000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.7782 - tp: 123527.0000 - fp: 68473.0000 - tn: 123527.0000 - fn: 68473.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6432 - val_loss: 0.7357 - val_tp: 41219.0000 - val_fp: 22781.0000 - val_tn: 41219.0000 - val_fn: 22781.0000 - val_accuracy: 0.6440 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.6440
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-12032000-12288000
[INFO] processing batch 12288000-12544000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.7097 - tp: 123560.0000 - fp: 68440.0000 - tn: 123560.0000 - fn: 68440.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6436 - val_loss: 0.6868 - val_tp: 41268.0000 - val_fp: 22732.0000 - val_tn: 41268.0000 - val_fn: 22732.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-12288000-12544000
[INFO] processing batch 12544000-12800000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6750 - tp: 123588.0000 - fp: 68412.0000 - tn: 123588.0000 - fn: 68412.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6435 - val_loss: 0.6639 - val_tp: 41269.0000 - val_fp: 22731.0000 - val_tn: 41269.0000 - val_fn: 22731.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-12544000-12800000
[INFO] processing batch 12800000-13056000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6596 - tp: 123531.0000 - fp: 68469.0000 - tn: 123531.0000 - fn: 68469.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6438 - val_loss: 0.6555 - val_tp: 41181.0000 - val_fp: 22819.0000 - val_tn: 41181.0000 - val_fn: 22819.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-12800000-13056000
[INFO] processing batch 13056000-13312000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6534 - tp: 123615.0000 - fp: 68385.0000 - tn: 123615.0000 - fn: 68385.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6433 - val_loss: 0.6523 - val_tp: 41192.0000 - val_fp: 22808.0000 - val_tn: 41192.0000 - val_fn: 22808.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-13056000-13312000
[INFO] processing batch 13312000-13568000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6522 - tp: 123437.0000 - fp: 68563.0000 - tn: 123437.0000 - fn: 68563.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6426 - val_loss: 0.6516 - val_tp: 41179.0000 - val_fp: 22821.0000 - val_tn: 41179.0000 - val_fn: 22821.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-13312000-13568000
[INFO] processing batch 13568000-13824000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6515 - tp: 123539.0000 - fp: 68461.0000 - tn: 123539.0000 - fn: 68461.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6435 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-13568000-13824000
[INFO] processing batch 13824000-14080000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123556.0000 - fp: 68444.0000 - tn: 123556.0000 - fn: 68444.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6515 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 41173.0000 - val_fn: 22827.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-13824000-14080000
[INFO] processing batch 14080000-14336000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6510 - tp: 123681.0000 - fp: 68319.0000 - tn: 123681.0000 - fn: 68319.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6510 - val_tp: 41221.0000 - val_fp: 22779.0000 - val_tn: 41221.0000 - val_fn: 22779.0000 - val_accuracy: 0.6441 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.6441
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-14080000-14336000
[INFO] processing batch 14336000-14592000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123523.0000 - fp: 68477.0000 - tn: 123523.0000 - fn: 68477.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6430 - val_loss: 0.6513 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 41197.0000 - val_fn: 22803.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-14336000-14592000
[INFO] processing batch 14592000-14848000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123652.0000 - fp: 68348.0000 - tn: 123652.0000 - fn: 68348.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6439 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-14592000-14848000
[INFO] processing batch 14848000-15104000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6512 - tp: 123594.0000 - fp: 68406.0000 - tn: 123594.0000 - fn: 68406.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6437 - val_loss: 0.6512 - val_tp: 41205.0000 - val_fp: 22795.0000 - val_tn: 41205.0000 - val_fn: 22795.0000 - val_accuracy: 0.6438 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.6438
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-14848000-15104000
[INFO] processing batch 15104000-15360000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.6511 - tp: 123629.0000 - fp: 68371.0000 - tn: 123629.0000 - fn: 68371.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6435 - val_loss: 0.6509 - val_tp: 41234.0000 - val_fp: 22766.0000 - val_tn: 41234.0000 - val_fn: 22766.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-15104000-15360000
[INFO] processing batch 15360000-15616000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123632.0000 - fp: 68368.0000 - tn: 123632.0000 - fn: 68368.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6436 - val_loss: 0.6506 - val_tp: 41266.0000 - val_fp: 22734.0000 - val_tn: 41266.0000 - val_fn: 22734.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-15360000-15616000
[INFO] processing batch 15616000-15872000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6515 - tp: 123527.0000 - fp: 68473.0000 - tn: 123527.0000 - fn: 68473.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6429 - val_loss: 0.6513 - val_tp: 41197.0000 - val_fp: 22803.0000 - val_tn: 41197.0000 - val_fn: 22803.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-15616000-15872000
[INFO] processing batch 15872000-16128000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123531.0000 - fp: 68469.0000 - tn: 123531.0000 - fn: 68469.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6430 - val_loss: 0.6515 - val_tp: 41173.0000 - val_fp: 22827.0000 - val_tn: 41173.0000 - val_fn: 22827.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-15872000-16128000
[INFO] processing batch 16128000-16384000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6507 - tp: 123781.0000 - fp: 68219.0000 - tn: 123781.0000 - fn: 68219.0000 - accuracy: 0.6447 - precision: 0.6447 - recall: 0.6447 - auc: 0.6446 - val_loss: 0.6513 - val_tp: 41195.0000 - val_fp: 22805.0000 - val_tn: 41195.0000 - val_fn: 22805.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-16128000-16384000
[INFO] processing batch 16384000-16640000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123621.0000 - fp: 68379.0000 - tn: 123621.0000 - fn: 68379.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6442 - val_loss: 0.6516 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 41165.0000 - val_fn: 22835.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-16384000-16640000
[INFO] processing batch 16640000-16896000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6518 - tp: 123417.0000 - fp: 68583.0000 - tn: 123417.0000 - fn: 68583.0000 - accuracy: 0.6428 - precision: 0.6428 - recall: 0.6428 - auc: 0.6426 - val_loss: 0.6510 - val_tp: 41230.0000 - val_fp: 22770.0000 - val_tn: 41230.0000 - val_fn: 22770.0000 - val_accuracy: 0.6442 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.6442
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-16640000-16896000
[INFO] processing batch 16896000-17152000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6512 - tp: 123600.0000 - fp: 68400.0000 - tn: 123600.0000 - fn: 68400.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6437 - val_loss: 0.6512 - val_tp: 41198.0000 - val_fp: 22802.0000 - val_tn: 41198.0000 - val_fn: 22802.0000 - val_accuracy: 0.6437 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.6437
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-16896000-17152000
[INFO] processing batch 17152000-17408000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123711.0000 - fp: 68289.0000 - tn: 123711.0000 - fn: 68289.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6443 - val_loss: 0.6515 - val_tp: 41168.0000 - val_fp: 22832.0000 - val_tn: 41168.0000 - val_fn: 22832.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-17152000-17408000
[INFO] processing batch 17408000-17664000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123701.0000 - fp: 68299.0000 - tn: 123701.0000 - fn: 68299.0000 - accuracy: 0.6443 - precision: 0.6443 - recall: 0.6443 - auc: 0.6443 - val_loss: 0.6520 - val_tp: 41118.0000 - val_fp: 22882.0000 - val_tn: 41118.0000 - val_fn: 22882.0000 - val_accuracy: 0.6425 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.6425
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-17408000-17664000
[INFO] processing batch 17664000-17920000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123546.0000 - fp: 68454.0000 - tn: 123546.0000 - fn: 68454.0000 - accuracy: 0.6435 - precision: 0.6435 - recall: 0.6435 - auc: 0.6435 - val_loss: 0.6523 - val_tp: 41089.0000 - val_fp: 22911.0000 - val_tn: 41089.0000 - val_fn: 22911.0000 - val_accuracy: 0.6420 - val_precision: 0.6420 - val_recall: 0.6420 - val_auc: 0.6420
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-17664000-17920000
[INFO] processing batch 17920000-18176000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6510 - tp: 123681.0000 - fp: 68319.0000 - tn: 123681.0000 - fn: 68319.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6441 - val_loss: 0.6509 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 41233.0000 - val_fn: 22767.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-17920000-18176000
[INFO] processing batch 18176000-18432000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123640.0000 - fp: 68360.0000 - tn: 123640.0000 - fn: 68360.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6436 - val_loss: 0.6503 - val_tp: 41298.0000 - val_fp: 22702.0000 - val_tn: 41298.0000 - val_fn: 22702.0000 - val_accuracy: 0.6453 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.6453
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-18176000-18432000
[INFO] processing batch 18432000-18688000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.6512 - tp: 123615.0000 - fp: 68385.0000 - tn: 123615.0000 - fn: 68385.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6439 - val_loss: 0.6509 - val_tp: 41233.0000 - val_fp: 22767.0000 - val_tn: 41233.0000 - val_fn: 22767.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-18432000-18688000
[INFO] processing batch 18688000-18944000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123645.0000 - fp: 68355.0000 - tn: 123645.0000 - fn: 68355.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6439 - val_loss: 0.6514 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 41184.0000 - val_fn: 22816.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-18688000-18944000
[INFO] processing batch 18944000-19200000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6503 - tp: 123888.0000 - fp: 68112.0000 - tn: 123888.0000 - fn: 68112.0000 - accuracy: 0.6453 - precision: 0.6453 - recall: 0.6453 - auc: 0.6453 - val_loss: 0.6515 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 41169.0000 - val_fn: 22831.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-18944000-19200000
[INFO] processing batch 19200000-19456000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123500.0000 - fp: 68500.0000 - tn: 123500.0000 - fn: 68500.0000 - accuracy: 0.6432 - precision: 0.6432 - recall: 0.6432 - auc: 0.6430 - val_loss: 0.6513 - val_tp: 41189.0000 - val_fp: 22811.0000 - val_tn: 41189.0000 - val_fn: 22811.0000 - val_accuracy: 0.6436 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.6436
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-19200000-19456000
[INFO] processing batch 19456000-19712000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6510 - tp: 123689.0000 - fp: 68311.0000 - tn: 123689.0000 - fn: 68311.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6441 - val_loss: 0.6515 - val_tp: 41166.0000 - val_fp: 22834.0000 - val_tn: 41166.0000 - val_fn: 22834.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-19456000-19712000
[INFO] processing batch 19712000-19968000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6518 - tp: 123402.0000 - fp: 68598.0000 - tn: 123402.0000 - fn: 68598.0000 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - auc: 0.6428 - val_loss: 0.6508 - val_tp: 41242.0000 - val_fp: 22758.0000 - val_tn: 41242.0000 - val_fn: 22758.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-19712000-19968000
[INFO] processing batch 19968000-20224000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6514 - tp: 123541.0000 - fp: 68459.0000 - tn: 123541.0000 - fn: 68459.0000 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - auc: 0.6434 - val_loss: 0.6509 - val_tp: 41241.0000 - val_fp: 22759.0000 - val_tn: 41241.0000 - val_fn: 22759.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-19968000-20224000
[INFO] processing batch 20224000-20480000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6511 - tp: 123640.0000 - fp: 68360.0000 - tn: 123640.0000 - fn: 68360.0000 - accuracy: 0.6440 - precision: 0.6440 - recall: 0.6440 - auc: 0.6435 - val_loss: 0.6511 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 41209.0000 - val_fn: 22791.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-20224000-20480000
[INFO] processing batch 20480000-20736000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6512 - tp: 123598.0000 - fp: 68402.0000 - tn: 123598.0000 - fn: 68402.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6439 - val_loss: 0.6509 - val_tp: 41235.0000 - val_fp: 22765.0000 - val_tn: 41235.0000 - val_fn: 22765.0000 - val_accuracy: 0.6443 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.6443
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-20480000-20736000
[INFO] processing batch 20736000-20992000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 15s - loss: 0.6507 - tp: 123769.0000 - fp: 68231.0000 - tn: 123769.0000 - fn: 68231.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6446 - val_loss: 0.6511 - val_tp: 41212.0000 - val_fp: 22788.0000 - val_tn: 41212.0000 - val_fn: 22788.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-20736000-20992000
[INFO] processing batch 20992000-21248000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6517 - tp: 123459.0000 - fp: 68541.0000 - tn: 123459.0000 - fn: 68541.0000 - accuracy: 0.6430 - precision: 0.6430 - recall: 0.6430 - auc: 0.6433 - val_loss: 0.6512 - val_tp: 41209.0000 - val_fp: 22791.0000 - val_tn: 41209.0000 - val_fn: 22791.0000 - val_accuracy: 0.6439 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.6439
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-20992000-21248000
[INFO] processing batch 21248000-21504000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123683.0000 - fp: 68317.0000 - tn: 123683.0000 - fn: 68317.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6442 - val_loss: 0.6514 - val_tp: 41183.0000 - val_fp: 22817.0000 - val_tn: 41183.0000 - val_fn: 22817.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-21248000-21504000
[INFO] processing batch 21504000-21760000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6513 - tp: 123564.0000 - fp: 68436.0000 - tn: 123564.0000 - fn: 68436.0000 - accuracy: 0.6436 - precision: 0.6436 - recall: 0.6436 - auc: 0.6436 - val_loss: 0.6507 - val_tp: 41254.0000 - val_fp: 22746.0000 - val_tn: 41254.0000 - val_fn: 22746.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-21504000-21760000
[INFO] processing batch 21760000-22016000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6509 - tp: 123717.0000 - fp: 68283.0000 - tn: 123717.0000 - fn: 68283.0000 - accuracy: 0.6444 - precision: 0.6444 - recall: 0.6444 - auc: 0.6442 - val_loss: 0.6506 - val_tp: 41270.0000 - val_fp: 22730.0000 - val_tn: 41270.0000 - val_fn: 22730.0000 - val_accuracy: 0.6448 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.6448
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-21760000-22016000
[INFO] processing batch 22016000-22272000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6510 - tp: 123690.0000 - fp: 68310.0000 - tn: 123690.0000 - fn: 68310.0000 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - auc: 0.6439 - val_loss: 0.6521 - val_tp: 41104.0000 - val_fp: 22896.0000 - val_tn: 41104.0000 - val_fn: 22896.0000 - val_accuracy: 0.6423 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.6423
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-22016000-22272000
[INFO] processing batch 22272000-22528000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6510 - tp: 123672.0000 - fp: 68328.0000 - tn: 123672.0000 - fn: 68328.0000 - accuracy: 0.6441 - precision: 0.6441 - recall: 0.6441 - auc: 0.6440 - val_loss: 0.6508 - val_tp: 41243.0000 - val_fp: 22757.0000 - val_tn: 41243.0000 - val_fn: 22757.0000 - val_accuracy: 0.6444 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.6444
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-22272000-22528000
[INFO] processing batch 22528000-22784000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123623.0000 - fp: 68377.0000 - tn: 123623.0000 - fn: 68377.0000 - accuracy: 0.6439 - precision: 0.6439 - recall: 0.6439 - auc: 0.6440 - val_loss: 0.6504 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 41292.0000 - val_fn: 22708.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-22528000-22784000
[INFO] processing batch 22784000-23040000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6507 - tp: 123759.0000 - fp: 68241.0000 - tn: 123759.0000 - fn: 68241.0000 - accuracy: 0.6446 - precision: 0.6446 - recall: 0.6446 - auc: 0.6447 - val_loss: 0.6514 - val_tp: 41180.0000 - val_fp: 22820.0000 - val_tn: 41180.0000 - val_fn: 22820.0000 - val_accuracy: 0.6434 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.6434
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-22784000-23040000
[INFO] processing batch 23040000-23296000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6515 - tp: 123507.0000 - fp: 68493.0000 - tn: 123507.0000 - fn: 68493.0000 - accuracy: 0.6433 - precision: 0.6433 - recall: 0.6433 - auc: 0.6436 - val_loss: 0.6507 - val_tp: 41255.0000 - val_fp: 22745.0000 - val_tn: 41255.0000 - val_fn: 22745.0000 - val_accuracy: 0.6446 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.6446
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-23040000-23296000
[INFO] processing batch 23296000-23552000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123601.0000 - fp: 68399.0000 - tn: 123601.0000 - fn: 68399.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6437 - val_loss: 0.6511 - val_tp: 41213.0000 - val_fp: 22787.0000 - val_tn: 41213.0000 - val_fn: 22787.0000 - val_accuracy: 0.6440 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.6440
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-23296000-23552000
[INFO] processing batch 23552000-23808000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6508 - tp: 123749.0000 - fp: 68251.0000 - tn: 123749.0000 - fn: 68251.0000 - accuracy: 0.6445 - precision: 0.6445 - recall: 0.6445 - auc: 0.6444 - val_loss: 0.6504 - val_tp: 41292.0000 - val_fp: 22708.0000 - val_tn: 41292.0000 - val_fn: 22708.0000 - val_accuracy: 0.6452 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.6452
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-23552000-23808000
[INFO] processing batch 23808000-24064000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 13s - loss: 0.6512 - tp: 123603.0000 - fp: 68397.0000 - tn: 123603.0000 - fn: 68397.0000 - accuracy: 0.6438 - precision: 0.6438 - recall: 0.6438 - auc: 0.6432 - val_loss: 0.6516 - val_tp: 41165.0000 - val_fp: 22835.0000 - val_tn: 41165.0000 - val_fn: 22835.0000 - val_accuracy: 0.6432 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.6432
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-23808000-24064000
[INFO] processing batch 24064000-24320000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6512 - tp: 123599.0000 - fp: 68401.0000 - tn: 123599.0000 - fn: 68401.0000 - accuracy: 0.6437 - precision: 0.6437 - recall: 0.6437 - auc: 0.6435 - val_loss: 0.6514 - val_tp: 41184.0000 - val_fp: 22816.0000 - val_tn: 41184.0000 - val_fn: 22816.0000 - val_accuracy: 0.6435 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.6435
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-24064000-24320000
[INFO] processing batch 24320000-24576000/24819975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 14s - loss: 0.6517 - tp: 123440.0000 - fp: 68560.0000 - tn: 123440.0000 - fn: 68560.0000 - accuracy: 0.6429 - precision: 0.6429 - recall: 0.6429 - auc: 0.6431 - val_loss: 0.6515 - val_tp: 41169.0000 - val_fp: 22831.0000 - val_tn: 41169.0000 - val_fn: 22831.0000 - val_accuracy: 0.6433 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.6433
[INFO] saving weights to checkpoints/lstm-epoch-010-files-0-50-batch-24320000-24576000
[33m[LOSS] 0.6515171737670898[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6515171737670898  <  0.001
--- 16552.635906219482 seconds ---
2020-02-09 19:43:15.468373: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-02-09 19:43:15.468537: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-02-09 19:43:15.468552: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-02-09 19:43:16.823450: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-02-09 19:43:16.823479: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-02-09 19:43:16.823509: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (bastia): /proc/driver/nvidia/version does not exist
2020-02-09 19:43:16.823697: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-09 19:43:16.843989: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2112050000 Hz
2020-02-09 19:43:16.845495: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x513feb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-09 19:43:16.845531: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow backend.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
2020-02-09 19:45:03.416455: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-09 19:45:03.422225: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 19:45:03.424994: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 19:45:03.444546: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-09 19:45:03.445874: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-09 19:45:03.447739: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 19:45:03.449583: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 19:45:03.454342: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
=================================================
        SCORING v0.4.5 (binary)
=================================================
Date: 2020-02-09 19:43:16.813309
------------DNN info-------------
dnnBatchSize 16
wrapLayerSize 8
coreLayerSize 32
numCoreLayers 3
outputLayerActivation sigmoid
output_dim 2
loss binary_crossentropy
optimizer adam
------------DNN info-------------
[INFO] input_shape (16, 107)
[INFO] LSTM first and last layer neurons: 8
[INFO] adding core layer 0
[INFO] adding core layer 1
[INFO] adding core layer 2
[INFO] created DNN
loading weights: checkpoints/*
loading file checkpoints/lstm-epoch-010-files-0-50-batch-9984000-10240000
[33m[INFO] model summary:[0m
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 16, 8)             3712      
_________________________________________________________________
dropout_1 (Dropout)          (None, 16, 8)             0         
_________________________________________________________________
lstm_2 (LSTM)                (None, 16, 32)            5248      
_________________________________________________________________
dropout_2 (Dropout)          (None, 16, 32)            0         
_________________________________________________________________
lstm_3 (LSTM)                (None, 16, 32)            8320      
_________________________________________________________________
dropout_3 (Dropout)          (None, 16, 32)            0         
_________________________________________________________________
lstm_4 (LSTM)                (None, 16, 32)            8320      
_________________________________________________________________
dropout_4 (Dropout)          (None, 16, 32)            0         
_________________________________________________________________
lstm_5 (LSTM)                (None, 16, 8)             1312      
_________________________________________________________________
dropout_5 (Dropout)          (None, 16, 8)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 16, 1)             9         
_________________________________________________________________
dropout_6 (Dropout)          (None, 16, 1)             0         
_________________________________________________________________
dense_2 (Dense)              (None, 16, 2)             4         
=================================================================
Total params: 26,925
Trainable params: 26,925
Non-trainable params: 0
_________________________________________________________________
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2015-12-31_130240_112.log.part10_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2015-12-31_181648_113.log.part08_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2015-12-31_181648_113.log.part09_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2015-12-31_233049_114.log.part11_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-01_151435_117.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-01_151435_117.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-01_151435_117.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-01_203011_118.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-01_203011_118.log.part07_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-02_014558_119.log.part06_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-02_121729_121.log.part12_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-02_121729_121.log.part13_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-02_121729_121.log.part14_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-02_172943_122.log.part03_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-02_172943_122.log.part04_sorted-labeled.csv
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/eval/2016-01-02_172943_122.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (7939824, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] Shape when encoding dataset: (7939824, 17)
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
missing 15
adding missing-0
adding missing-1
adding missing-2
adding missing-3
adding missing-4
adding missing-5
adding missing-6
adding missing-7
adding missing-8
adding missing-9
adding missing-10
adding missing-11
adding missing-12
adding missing-13
adding missing-14
adding missing-15
len(df.columns) 108
numFeatures 107
[INFO] Shape AFTER encoding dataset: (7939824, 108)
[INFO] processing batch 0-256000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 1 1 ... 0 1 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.9134154074192047
tp :  164503.0
fp :  91497.0
tn :  164503.0
fn :  91497.0
accuracy :  0.6425898671150208
precision :  0.6425898671150208
recall :  0.6425898671150208
auc :  0.642589807510376

y_eval {0: 164503, 1: 91497}
pred {0: 256000}
[INFO] confusion matrix for file 
[[164503      0]
 [ 91497      0]]
[INFO] confusion matrix after adding it to total:
[[164503      0]
 [ 91497      0]]
[INFO] processing batch 256000-512000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [1 0 1 ... 1 1 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.24606400501728057
tp :  239293.0
fp :  16707.0
tn :  239293.0
fn :  16707.0
accuracy :  0.934738278388977
precision :  0.934738278388977
recall :  0.934738278388977
auc :  0.934738278388977

y_eval {0: 239293, 1: 16707}
pred {0: 256000}
[INFO] confusion matrix for file 
[[239293      0]
 [ 16707      0]]
[INFO] confusion matrix after adding it to total:
[[403796      0]
 [108204      0]]
[INFO] processing batch 512000-768000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 1 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.2750013089329004
tp :  236050.0
fp :  19950.0
tn :  236050.0
fn :  19950.0
accuracy :  0.922070324420929
precision :  0.922070324420929
recall :  0.922070324420929
auc :  0.9220702648162842

y_eval {0: 236050, 1: 19950}
pred {0: 256000}
[INFO] confusion matrix for file 
[[236050      0]
 [ 19950      0]]
[INFO] confusion matrix after adding it to total:
[[639846      0]
 [128154      0]]
[INFO] processing batch 768000-1024000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 1 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.8428968722820283
tp :  172406.0
fp :  83594.0
tn :  172406.0
fn :  83594.0
accuracy :  0.6734609603881836
precision :  0.6734609603881836
recall :  0.6734609603881836
auc :  0.6734609603881836

y_eval {0: 172406, 1: 83594}
pred {0: 256000}
[INFO] confusion matrix for file 
[[172406      0]
 [ 83594      0]]
[INFO] confusion matrix after adding it to total:
[[812252      0]
 [211748      0]]
[INFO] processing batch 1024000-1280000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [1 0 1 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1606806913018226
tp :  136792.0
fp :  119208.0
tn :  136792.0
fn :  119208.0
accuracy :  0.5343437790870667
precision :  0.5343437790870667
recall :  0.5343437790870667
auc :  0.5343437194824219

y_eval {0: 136792, 1: 119208}
pred {0: 256000}
[INFO] confusion matrix for file 
[[136792      0]
 [119208      0]]
[INFO] confusion matrix after adding it to total:
[[949044      0]
 [330956      0]]
[INFO] processing batch 1280000-1536000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09698738902807236
tp :  256000.0
fp :  0.0
tn :  256000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 256000}
pred {0: 256000}
[INFO] confusion matrix for file 
[[256000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[1205044       0]
 [ 330956       0]]
[INFO] processing batch 1536000-1792000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 1 1 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.14990970027446746
tp :  250069.0
fp :  5931.0
tn :  250069.0
fn :  5931.0
accuracy :  0.9768320322036743
precision :  0.9768320322036743
recall :  0.9768320322036743
auc :  0.9768320322036743

y_eval {0: 250069, 1: 5931}
pred {0: 256000}
[INFO] confusion matrix for file 
[[250069      0]
 [  5931      0]]
[INFO] confusion matrix after adding it to total:
[[1455113       0]
 [ 336887       0]]
[INFO] processing batch 1792000-2048000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 1] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.3585830102562904
tp :  226683.0
fp :  29317.0
tn :  226683.0
fn :  29317.0
accuracy :  0.8854804635047913
precision :  0.8854804635047913
recall :  0.8854804635047913
auc :  0.8854804039001465

y_eval {0: 226683, 1: 29317}
pred {0: 256000}
[INFO] confusion matrix for file 
[[226683      0]
 [ 29317      0]]
[INFO] confusion matrix after adding it to total:
[[1681796       0]
 [ 366204       0]]
[INFO] processing batch 2048000-2304000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [1 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.7060983508378267
tp :  187737.0
fp :  68263.0
tn :  187737.0
fn :  68263.0
accuracy :  0.7333476543426514
precision :  0.7333476543426514
recall :  0.7333476543426514
auc :  0.7333476543426514

y_eval {0: 187737, 1: 68263}
pred {0: 256000}
[INFO] confusion matrix for file 
[[187737      0]
 [ 68263      0]]
[INFO] confusion matrix after adding it to total:
[[1869533       0]
 [ 434467       0]]
[INFO] processing batch 2304000-2560000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09698738902807236
tp :  256000.0
fp :  0.0
tn :  256000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 256000}
pred {0: 256000}
[INFO] confusion matrix for file 
[[256000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[2125533       0]
 [ 434467       0]]
[INFO] processing batch 2560000-2816000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09698738902807236
tp :  256000.0
fp :  0.0
tn :  256000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 256000}
pred {0: 256000}
[INFO] confusion matrix for file 
[[256000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[2381533       0]
 [ 434467       0]]
[INFO] processing batch 2816000-3072000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 1 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.5249702926278115
tp :  208036.0
fp :  47964.0
tn :  208036.0
fn :  47964.0
accuracy :  0.8126406073570251
precision :  0.8126406073570251
recall :  0.8126406073570251
auc :  0.8126406669616699

y_eval {0: 208036, 1: 47964}
pred {0: 256000}
[INFO] confusion matrix for file 
[[208036      0]
 [ 47964      0]]
[INFO] confusion matrix after adding it to total:
[[2589569       0]
 [ 482431       0]]
[INFO] processing batch 3072000-3328000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.3511234264224768
tp :  227519.0
fp :  28481.0
tn :  227519.0
fn :  28481.0
accuracy :  0.8887460827827454
precision :  0.8887460827827454
recall :  0.8887460827827454
auc :  0.8887460231781006

y_eval {0: 227519, 1: 28481}
pred {0: 256000}
[INFO] confusion matrix for file 
[[227519      0]
 [ 28481      0]]
[INFO] confusion matrix after adding it to total:
[[2817088       0]
 [ 510912       0]]
[INFO] processing batch 3328000-3584000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09698738902807236
tp :  256000.0
fp :  0.0
tn :  256000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 256000}
pred {0: 256000}
[INFO] confusion matrix for file 
[[256000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[3073088       0]
 [ 510912       0]]
[INFO] processing batch 3584000-3840000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.251881791844964
tp :  238641.0
fp :  17359.0
tn :  238641.0
fn :  17359.0
accuracy :  0.9321914315223694
precision :  0.9321914315223694
recall :  0.9321914315223694
auc :  0.9321914315223694

y_eval {0: 238641, 1: 17359}
pred {0: 256000}
[INFO] confusion matrix for file 
[[238641      0]
 [ 17359      0]]
[INFO] confusion matrix after adding it to total:
[[3311729       0]
 [ 528271       0]]
[INFO] processing batch 3840000-4096000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 1 1 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.7553265259712935
tp :  182220.0
fp :  73780.0
tn :  182220.0
fn :  73780.0
accuracy :  0.7117968797683716
precision :  0.7117968797683716
recall :  0.7117968797683716
auc :  0.7117968797683716

y_eval {0: 182220, 1: 73780}
pred {0: 256000}
[INFO] confusion matrix for file 
[[182220      0]
 [ 73780      0]]
[INFO] confusion matrix after adding it to total:
[[3493949       0]
 [ 602051       0]]
[INFO] processing batch 4096000-4352000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 1 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.1760719630420208
tp :  247137.0
fp :  8863.0
tn :  247137.0
fn :  8863.0
accuracy :  0.9653788805007935
precision :  0.9653788805007935
recall :  0.9653788805007935
auc :  0.9653788805007935

y_eval {0: 247137, 1: 8863}
pred {0: 256000}
[INFO] confusion matrix for file 
[[247137      0]
 [  8863      0]]
[INFO] confusion matrix after adding it to total:
[[3741086       0]
 [ 610914       0]]
[INFO] processing batch 4352000-4608000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 1 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.4213831507563591
tp :  219645.0
fp :  36355.0
tn :  219645.0
fn :  36355.0
accuracy :  0.8579882979393005
precision :  0.8579882979393005
recall :  0.8579882979393005
auc :  0.8579883575439453

y_eval {0: 219645, 1: 36355}
pred {0: 256000}
[INFO] confusion matrix for file 
[[219645      0]
 [ 36355      0]]
[INFO] confusion matrix after adding it to total:
[[3960731       0]
 [ 647269       0]]
[INFO] processing batch 4608000-4864000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 1 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.6019847277402878
tp :  199405.0
fp :  56595.0
tn :  199405.0
fn :  56595.0
accuracy :  0.7789257764816284
precision :  0.7789257764816284
recall :  0.7789257764816284
auc :  0.7789257764816284

y_eval {0: 199405, 1: 56595}
pred {0: 256000}
[INFO] confusion matrix for file 
[[199405      0]
 [ 56595      0]]
[INFO] confusion matrix after adding it to total:
[[4160136       0]
 [ 703864       0]]
[INFO] processing batch 4864000-5120000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09698738902807236
tp :  256000.0
fp :  0.0
tn :  256000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 256000}
pred {0: 256000}
[INFO] confusion matrix for file 
[[256000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[4416136       0]
 [ 703864       0]]
[INFO] processing batch 5120000-5376000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09698738902807236
tp :  256000.0
fp :  0.0
tn :  256000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 256000}
pred {0: 256000}
[INFO] confusion matrix for file 
[[256000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[4672136       0]
 [ 703864       0]]
[INFO] processing batch 5376000-5632000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.0970052350461483
tp :  255998.0
fp :  2.0
tn :  255998.0
fn :  2.0
accuracy :  0.9999921917915344
precision :  0.9999921917915344
recall :  0.9999921917915344
auc :  0.9999921917915344

y_eval {0: 255998, 1: 2}
pred {0: 256000}
[INFO] confusion matrix for file 
[[255998      0]
 [     2      0]]
[INFO] confusion matrix after adding it to total:
[[4928134       0]
 [ 703866       0]]
[INFO] processing batch 5632000-5888000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.2650163980424404
tp :  237169.0
fp :  18831.0
tn :  237169.0
fn :  18831.0
accuracy :  0.9264414310455322
precision :  0.9264414310455322
recall :  0.9264414310455322
auc :  0.926441490650177

y_eval {0: 237169, 1: 18831}
pred {0: 256000}
[INFO] confusion matrix for file 
[[237169      0]
 [ 18831      0]]
[INFO] confusion matrix after adding it to total:
[[5165303       0]
 [ 722697       0]]
[INFO] processing batch 5888000-6144000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.43772997872531416
tp :  217813.0
fp :  38187.0
tn :  217813.0
fn :  38187.0
accuracy :  0.8508320450782776
precision :  0.8508320450782776
recall :  0.8508320450782776
auc :  0.8508320450782776

y_eval {0: 217813, 1: 38187}
pred {0: 256000}
[INFO] confusion matrix for file 
[[217813      0]
 [ 38187      0]]
[INFO] confusion matrix after adding it to total:
[[5383116       0]
 [ 760884       0]]
[INFO] processing batch 6144000-6400000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [1 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.16907630561292172
tp :  247921.0
fp :  8079.0
tn :  247921.0
fn :  8079.0
accuracy :  0.9684414267539978
precision :  0.9684414267539978
recall :  0.9684414267539978
auc :  0.9684414863586426

y_eval {0: 247921, 1: 8079}
pred {0: 256000}
[INFO] confusion matrix for file 
[[247921      0]
 [  8079      0]]
[INFO] confusion matrix after adding it to total:
[[5631037       0]
 [ 768963       0]]
[INFO] processing batch 6400000-6656000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09698738902807236
tp :  256000.0
fp :  0.0
tn :  256000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 256000}
pred {0: 256000}
[INFO] confusion matrix for file 
[[256000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[5887037       0]
 [ 768963       0]]
[INFO] processing batch 6656000-6912000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 1 0 1] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.235695471316576
tp :  240455.0
fp :  15545.0
tn :  240455.0
fn :  15545.0
accuracy :  0.9392773509025574
precision :  0.9392773509025574
recall :  0.9392773509025574
auc :  0.9392774105072021

y_eval {0: 240455, 1: 15545}
pred {0: 256000}
[INFO] confusion matrix for file 
[[240455      0]
 [ 15545      0]]
[INFO] confusion matrix after adding it to total:
[[6127492       0]
 [ 784508       0]]
[INFO] processing batch 6912000-7168000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 1] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.9073120757341385
tp :  165187.0
fp :  90813.0
tn :  165187.0
fn :  90813.0
accuracy :  0.6452617049217224
precision :  0.6452617049217224
recall :  0.6452617049217224
auc :  0.6452617049217224

y_eval {0: 165187, 1: 90813}
pred {0: 256000}
[INFO] confusion matrix for file 
[[165187      0]
 [ 90813      0]]
[INFO] confusion matrix after adding it to total:
[[6292679       0]
 [ 875321       0]]
[INFO] processing batch 7168000-7424000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 1 ... 0 1 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.9139775527715683
tp :  164440.0
fp :  91560.0
tn :  164440.0
fn :  91560.0
accuracy :  0.6423437595367432
precision :  0.6423437595367432
recall :  0.6423437595367432
auc :  0.6423437595367432

y_eval {0: 164440, 1: 91560}
pred {0: 256000}
[INFO] confusion matrix for file 
[[164440      0]
 [ 91560      0]]
[INFO] confusion matrix after adding it to total:
[[6457119       0]
 [ 966881       0]]
[INFO] processing batch 7424000-7680000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [1 0 1 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.28063171698153017
tp :  235419.0
fp :  20581.0
tn :  235419.0
fn :  20581.0
accuracy :  0.9196054935455322
precision :  0.9196054935455322
recall :  0.9196054935455322
auc :  0.9196054935455322

y_eval {0: 235419, 1: 20581}
pred {0: 256000}
[INFO] confusion matrix for file 
[[235419      0]
 [ 20581      0]]
[INFO] confusion matrix after adding it to total:
[[6692538       0]
 [ 987462       0]]
[INFO] processing batch 7680000-7936000/7939824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [0 0 0 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.09698738902807236
tp :  256000.0
fp :  0.0
tn :  256000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 256000}
pred {0: 256000}
[INFO] confusion matrix for file 
[[256000      0]
 [     0      0]]
[INFO] confusion matrix after adding it to total:
[[6948538       0]
 [ 987462       0]]
--- 407.399596452713 seconds ---
