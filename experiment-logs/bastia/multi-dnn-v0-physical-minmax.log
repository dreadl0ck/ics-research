Using TensorFlow backend.
set classes to: ['Normal', 'Attack']
=================================================
        TRAINING v0.4.1 (binaryClasses)
=================================================
Date: 2020-02-06 22:17:14.174835
[33m[INFO] using Sequential Dense layers[0m
2020-02-06 22:17:14.178505: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-06 22:17:14.192964: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa2e0cdb4f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-06 22:17:14.192996: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
[INFO] adding core layer 0
[INFO] created DNN
[33m[INFO] epoch 1/3[0m
[33m[INFO] loading file 1-1/1 on epoch 1/3[0m
[INFO] reading file data/SWaT_Dataset_Attack_v0-fixed-zscore-train-test.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (337500, 46)
[INFO] sampling 1.0
dropping all time related columns...
[INFO] columns: Index([' Timestamp', 'FIT101', 'LIT101', ' MV101', 'P101', 'P102', ' AIT201',
       'AIT202', 'AIT203', 'FIT201', ' MV201', ' P201', 'P203', ' P204',
       'P205', 'P206', 'DPIT301', 'FIT301', 'LIT301', 'MV301', 'MV302',
       ' MV303', 'MV304', 'P302', 'AIT401', 'AIT402', 'FIT401', 'LIT401',
       'P402', 'P403', 'UV401', 'AIT501', 'AIT502', 'AIT503', 'AIT504',
       'FIT501', 'FIT502', 'FIT503', 'FIT504', 'P501', 'PIT501', 'PIT502',
       'PIT503', 'FIT601', 'P602', 'Normal/Attack'],
      dtype='object')
[INFO] processing batch 0-500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6735 - tp: 375.0000 - fp: 5.0000 - tn: 395.0000 - fn: 25.0000 - accuracy: 0.9625 - precision: 0.9868 - recall: 0.9375 - auc: 0.9520 - val_loss: 0.6463 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 500-1000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6243 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5903 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 1000-1500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5493 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5117 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 1500-2000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7131 - tp: 254.0000 - fp: 146.0000 - tn: 254.0000 - fn: 146.0000 - accuracy: 0.6350 - precision: 0.6350 - recall: 0.6350 - auc: 0.6079 - val_loss: 0.9392 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 2000-2500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8981 - tp: 0.0000e+00 - fp: 400.0000 - tn: 0.0000e+00 - fn: 400.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 0.8280 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 2500-3000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7034 - tp: 206.0000 - fp: 194.0000 - tn: 206.0000 - fn: 194.0000 - accuracy: 0.5150 - precision: 0.5150 - recall: 0.5150 - auc: 0.4861 - val_loss: 0.6165 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 3000-3500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7761 - tp: 68.0000 - fp: 332.0000 - tn: 68.0000 - fn: 332.0000 - accuracy: 0.1700 - precision: 0.1700 - recall: 0.1700 - auc: 0.1572 - val_loss: 0.7506 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 3500-4000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6446 - tp: 389.0000 - fp: 11.0000 - tn: 389.0000 - fn: 11.0000 - accuracy: 0.9725 - precision: 0.9725 - recall: 0.9725 - auc: 0.9778 - val_loss: 0.6344 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 4000-4500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6211 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5999 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 4500-5000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5758 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8069 - val_tp: 20.0000 - val_fp: 80.0000 - val_tn: 20.0000 - val_fn: 80.0000 - val_accuracy: 0.2000 - val_precision: 0.2000 - val_recall: 0.2000 - val_auc: 0.1740
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 5000-5500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8186 - tp: 97.0000 - fp: 303.0000 - tn: 97.0000 - fn: 303.0000 - accuracy: 0.2425 - precision: 0.2425 - recall: 0.2425 - auc: 0.2367 - val_loss: 0.5663 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 5500-6000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5732 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5656 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 6000-6500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5530 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6771 - val_tp: 59.0000 - val_fp: 41.0000 - val_tn: 59.0000 - val_fn: 41.0000 - val_accuracy: 0.5900 - val_precision: 0.5900 - val_recall: 0.5900 - val_auc: 0.5900
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 6500-7000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8537 - tp: 51.0000 - fp: 349.0000 - tn: 51.0000 - fn: 349.0000 - accuracy: 0.1275 - precision: 0.1275 - recall: 0.1275 - auc: 0.1387 - val_loss: 0.5373 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 7000-7500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6852 - tp: 255.0000 - fp: 145.0000 - tn: 255.0000 - fn: 145.0000 - accuracy: 0.6375 - precision: 0.6375 - recall: 0.6375 - auc: 0.6094 - val_loss: 0.7126 - val_tp: 49.0000 - val_fp: 51.0000 - val_tn: 49.0000 - val_fn: 51.0000 - val_accuracy: 0.4900 - val_precision: 0.4900 - val_recall: 0.4900 - val_auc: 0.3503
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 7500-8000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7145 - tp: 205.0000 - fp: 195.0000 - tn: 205.0000 - fn: 195.0000 - accuracy: 0.5125 - precision: 0.5125 - recall: 0.5125 - auc: 0.4965 - val_loss: 0.8384 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 8000-8500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6593 - tp: 266.0000 - fp: 134.0000 - tn: 266.0000 - fn: 134.0000 - accuracy: 0.6650 - precision: 0.6650 - recall: 0.6650 - auc: 0.6723 - val_loss: 0.5747 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 8500-9000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5705 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5563 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 9000-9500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5541 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5288 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 9500-10000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5288 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5007 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 10000-10500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4947 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4577 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 10500-11000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4499 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4082 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 11000-11500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4015 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0884 - val_tp: 10.0000 - val_fp: 90.0000 - val_tn: 10.0000 - val_fn: 90.0000 - val_accuracy: 0.1000 - val_precision: 0.1000 - val_recall: 0.1000 - val_auc: 0.0996
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 11500-12000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.1591 - tp: 0.0000e+00 - fp: 400.0000 - tn: 0.0000e+00 - fn: 400.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 1.0045 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 12000-12500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9300 - tp: 26.0000 - fp: 374.0000 - tn: 26.0000 - fn: 374.0000 - accuracy: 0.0650 - precision: 0.0650 - recall: 0.0650 - auc: 0.0729 - val_loss: 0.5124 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 12500-13000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4756 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4529 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 13000-13500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4601 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4545 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 13500-14000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4285 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3727 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 14000-14500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4350 - tp: 394.0000 - fp: 6.0000 - tn: 394.0000 - fn: 6.0000 - accuracy: 0.9850 - precision: 0.9850 - recall: 0.9850 - auc: 0.9887 - val_loss: 0.2957 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 14500-15000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3587 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2165 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 15000-15500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4133 - tp: 380.0000 - fp: 20.0000 - tn: 380.0000 - fn: 20.0000 - accuracy: 0.9500 - precision: 0.9500 - recall: 0.9500 - auc: 0.9486 - val_loss: 1.6989 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 15500-16000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9871 - tp: 37.0000 - fp: 363.0000 - tn: 37.0000 - fn: 363.0000 - accuracy: 0.0925 - precision: 0.0925 - recall: 0.0925 - auc: 0.0784 - val_loss: 0.6746 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 16000-16500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4881 - tp: 328.0000 - fp: 72.0000 - tn: 328.0000 - fn: 72.0000 - accuracy: 0.8200 - precision: 0.8200 - recall: 0.8200 - auc: 0.8741 - val_loss: 0.2424 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 16500-17000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3330 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0795 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 17000-17500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2981 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1208 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 17500-18000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3111 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2267 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 18000-18500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3099 - tp: 398.0000 - fp: 2.0000 - tn: 398.0000 - fn: 2.0000 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - auc: 0.9974 - val_loss: 0.0834 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 18500-19000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3013 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0695 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 19000-19500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2945 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0584 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 19500-20000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2921 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0839 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 20000-20500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2676 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0084 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 20500-21000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2769 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0038 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 21000-21500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2496 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0132 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 21500-22000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2473 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0121 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 22000-22500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2663 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0123 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 22500-23000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2412 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0123 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 23000-23500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2227 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0116 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 23500-24000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2487 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0276 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 24000-24500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2309 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0033 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 24500-25000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2281 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.4141e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 25000-25500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2333 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 25500-26000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2094 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.7175e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 26000-26500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2116 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4665e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 26500-27000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2239 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0024 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 27000-27500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2258 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 27500-28000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2228 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0031 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 28000-28500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2177 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0033 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 28500-29000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1855 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 29000-29500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1957 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0027 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 29500-30000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2033 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.6730e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 30000-30500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2045 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4070e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 30500-31000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1929 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0014 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 31000-31500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1956 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.8452e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 31500-32000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1956 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.4358e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 32000-32500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1791 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.4264e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 32500-33000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1793 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 33000-33500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2017 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0012 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 33500-34000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1878 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 34000-34500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1866 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0045 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 34500-35000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1750 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9537e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 35000-35500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1919 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.7882e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 35500-36000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1813 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0023 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 36000-36500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1818 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3248e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 36500-37000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1700 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.2247e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 37000-37500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1614 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.2815e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 37500-38000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1866 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 38000-38500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1638 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0011 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 38500-39000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1625 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0013 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 39000-39500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1596 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0020 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 39500-40000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1521 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0014 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 40000-40500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1534 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.4297e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 40500-41000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1643 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.0747e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 41000-41500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1638 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.1067e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 41500-42000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1507 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.5917e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 42000-42500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1514 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4755e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 42500-43000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1429 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.0694e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 43000-43500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1527 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.9649e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 43500-44000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1581 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.1437e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 44000-44500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1402 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.7967e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 44500-45000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1384 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0014 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 45000-45500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1388 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 45500-46000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1327 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.2579e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 46000-46500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1399 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.9765e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 46500-47000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1188 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.8246e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 47000-47500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1299 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.7501e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 47500-48000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1304 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.0615e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 48000-48500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1364 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.0567e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 48500-49000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1308 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.1458e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 49000-49500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1267 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0011 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 49500-50000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1331 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.6546e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 50000-50500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1330 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3971e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 50500-51000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1260 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.0444e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 51000-51500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1250 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.2256e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 51500-52000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1261 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.2760e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 52000-52500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1105 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.7280e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 52500-53000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1151 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.8249e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 53000-53500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1138 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.8496e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 53500-54000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1121 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.9893e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 54000-54500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1186 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.4363e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 54500-55000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1164 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.8705e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 55000-55500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1078 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.5655e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 55500-56000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1081 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.4739e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 56000-56500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1120 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.9626e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 56500-57000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1152 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.6657e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 57000-57500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1054 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.5001e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 57500-58000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1038 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6072e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 58000-58500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1122 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.0016e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 58500-59000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1095 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.4276e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 59000-59500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1001 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.2430e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 59500-60000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1001 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.5136e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 60000-60500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1023 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0720e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 60500-61000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0888 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.4015e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 61000-61500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0982 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6461e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 61500-62000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1014 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.0006e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 62000-62500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0959 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.6469e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 62500-63000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0904 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.7088e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 63000-63500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0903 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.2319e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 63500-64000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1015 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.0924e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 64000-64500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1050 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.0795e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 64500-65000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0975 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.3387e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 65000-65500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0860 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0672e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 65500-66000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0904 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2893e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 66000-66500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0956 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.5111e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 66500-67000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0899 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.1162e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 67000-67500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0815 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3347e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 67500-68000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0801 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.1243e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 68000-68500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0823 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.1521e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 68500-69000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0845 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.6668e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 69000-69500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0827 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.7718e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 69500-70000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0846 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.5418e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 70000-70500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0777 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3715e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 70500-71000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0838 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3256e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 71000-71500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0878 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7572e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 71500-72000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0734 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.4180e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 72000-72500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0749 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.0921e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 72500-73000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0732 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.7830e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 73000-73500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0797 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.0560e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 73500-74000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.7265 - tp: 300.0000 - fp: 100.0000 - tn: 300.0000 - fn: 100.0000 - accuracy: 0.7500 - precision: 0.7500 - recall: 0.7500 - auc: 0.7394 - val_loss: 2.8777 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 74000-74500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.1037 - tp: 20.0000 - fp: 380.0000 - tn: 20.0000 - fn: 380.0000 - accuracy: 0.0500 - precision: 0.0500 - recall: 0.0500 - auc: 0.0177 - val_loss: 1.1385 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 74500-75000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6435 - tp: 318.0000 - fp: 82.0000 - tn: 318.0000 - fn: 82.0000 - accuracy: 0.7950 - precision: 0.7950 - recall: 0.7950 - auc: 0.8039 - val_loss: 0.2262 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 75000-75500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1972 - tp: 397.0000 - fp: 3.0000 - tn: 397.0000 - fn: 3.0000 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925 - auc: 0.9991 - val_loss: 0.1011 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 75500-76000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1205 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0807 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 76000-76500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1135 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0944 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 76500-77000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1235 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1146 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 77000-77500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1360 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1370 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 77500-78000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1256 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1262 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 78000-78500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1272 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1209 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 78500-79000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1212 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1085 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 79000-79500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1069 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0937 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 79500-80000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0877 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0604 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 80000-80500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0922 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0468 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 80500-81000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0907 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0655 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 81000-81500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0883 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0802 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 81500-82000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0913 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0713 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 82000-82500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0868 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0659 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 82500-83000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0831 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0576 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 83000-83500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0789 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0489 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 83500-84000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0795 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0373 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 84000-84500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0737 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0263 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 84500-85000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0706 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0348 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 85000-85500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0707 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0376 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 85500-86000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0721 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0411 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 86000-86500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0714 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0346 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 86500-87000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0727 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0326 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 87000-87500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0697 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0282 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 87500-88000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0679 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0238 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 88000-88500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0683 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0191 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 88500-89000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0761 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0156 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 89000-89500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0660 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0239 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 89500-90000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0642 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0253 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 90000-90500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0645 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0227 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 90500-91000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.9271 - tp: 185.0000 - fp: 215.0000 - tn: 185.0000 - fn: 215.0000 - accuracy: 0.4625 - precision: 0.4625 - recall: 0.4625 - auc: 0.4654 - val_loss: 0.5558 - val_tp: 82.0000 - val_fp: 18.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.8200 - val_precision: 0.8200 - val_recall: 0.8200 - val_auc: 0.8290
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 91000-91500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0828 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0796 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 91500-92000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0895 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0814 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 92000-92500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.6681 - tp: 140.0000 - fp: 260.0000 - tn: 140.0000 - fn: 260.0000 - accuracy: 0.3500 - precision: 0.3500 - recall: 0.3500 - auc: 0.3396 - val_loss: 2.6322 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 92500-93000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5233 - tp: 329.0000 - fp: 71.0000 - tn: 329.0000 - fn: 71.0000 - accuracy: 0.8225 - precision: 0.8225 - recall: 0.8225 - auc: 0.8195 - val_loss: 0.1283 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 93000-93500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1291 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2068 - val_tp: 45.0000 - val_fp: 55.0000 - val_tn: 45.0000 - val_fn: 55.0000 - val_accuracy: 0.4500 - val_precision: 0.4500 - val_recall: 0.4500 - val_auc: 0.3150
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 93500-94000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.2047 - tp: 179.0000 - fp: 221.0000 - tn: 179.0000 - fn: 221.0000 - accuracy: 0.4475 - precision: 0.4475 - recall: 0.4475 - auc: 0.4849 - val_loss: 0.1409 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 94000-94500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1348 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1356 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 94500-95000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1411 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - val_loss: 0.1376 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 95000-95500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1260 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1203 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 95500-96000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1211 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1146 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 96000-96500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1150 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1270 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 96500-97000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1341 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1366 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 97000-97500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1359 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 0.9999 - val_loss: 0.1212 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 97500-98000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1045 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0968 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 98000-98500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0968 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0937 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 98500-99000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0946 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0908 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 99000-99500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0923 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0889 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 99500-100000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0910 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0865 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 100000-100500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0914 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0843 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 100500-101000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0874 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0718 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 101000-101500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0786 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0611 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 101500-102000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0721 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0534 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 102000-102500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0697 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0618 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 102500-103000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0733 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0693 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 103000-103500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.0553 - tp: 92.0000 - fp: 308.0000 - tn: 92.0000 - fn: 308.0000 - accuracy: 0.2300 - precision: 0.2300 - recall: 0.2300 - auc: 0.2266 - val_loss: 2.5666 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 103500-104000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.9271 - tp: 91.0000 - fp: 309.0000 - tn: 91.0000 - fn: 309.0000 - accuracy: 0.2275 - precision: 0.2275 - recall: 0.2275 - auc: 0.2331 - val_loss: 0.1065 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 104000-104500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1171 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1231 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 104500-105000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1197 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1178 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 105000-105500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1132 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1105 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 105500-106000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1108 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1076 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 106000-106500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1080 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1047 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 106500-107000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1038 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1019 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 107000-107500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1031 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0992 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 107500-108000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1002 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0970 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 108000-108500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0972 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0926 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 108500-109000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0944 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0910 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 109000-109500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0964 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0880 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 109500-110000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0874 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0832 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 110000-110500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0841 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0777 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 110500-111000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0849 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0840 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 111000-111500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0855 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0823 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 111500-112000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0846 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0810 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 112000-112500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0838 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0793 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 112500-113000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0795 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0776 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 113000-113500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0790 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0720 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 113500-114000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0686 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0620 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 114000-114500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0656 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0491 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 114500-115000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0682 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0572 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 115000-115500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0709 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0685 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 115500-116000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4739 - tp: 343.0000 - fp: 57.0000 - tn: 343.0000 - fn: 57.0000 - accuracy: 0.8575 - precision: 0.8575 - recall: 0.8575 - auc: 0.8326 - val_loss: 2.8329 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 116000-116500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.3491 - tp: 41.0000 - fp: 359.0000 - tn: 41.0000 - fn: 359.0000 - accuracy: 0.1025 - precision: 0.1025 - recall: 0.1025 - auc: 0.1067 - val_loss: 2.2268 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 116500-117000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3065 - tp: 362.0000 - fp: 38.0000 - tn: 362.0000 - fn: 38.0000 - accuracy: 0.9050 - precision: 0.9050 - recall: 0.9050 - auc: 0.9088 - val_loss: 0.1023 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 117000-117500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.2828 - tp: 0.0000e+00 - fp: 400.0000 - tn: 0.0000e+00 - fn: 400.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 2.1014 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 117500-118000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.1656 - tp: 181.0000 - fp: 219.0000 - tn: 181.0000 - fn: 219.0000 - accuracy: 0.4525 - precision: 0.4525 - recall: 0.4525 - auc: 0.5186 - val_loss: 0.0990 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 118000-118500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1085 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0755 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 118500-119000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0995 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0769 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 119000-119500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1014 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0885 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 119500-120000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0906 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0597 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 120000-120500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0919 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1170 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 120500-121000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2073 - tp: 384.0000 - fp: 16.0000 - tn: 384.0000 - fn: 16.0000 - accuracy: 0.9600 - precision: 0.9600 - recall: 0.9600 - auc: 0.9881 - val_loss: 0.1420 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 121000-121500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1224 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1277 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 121500-122000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1191 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1232 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 122000-122500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1179 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1194 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 122500-123000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1099 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1163 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 123000-123500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0830 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0467 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 123500-124000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0695 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0244 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 124000-124500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0685 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0444 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 124500-125000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0795 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0884 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 125000-125500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0968 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0925 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 125500-126000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0919 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0980 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 126000-126500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0980 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1059 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 126500-127000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1008 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1076 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 127000-127500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1063 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0742 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 127500-128000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0705 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0407 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 128000-128500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0621 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0192 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 128500-129000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0617 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0357 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 129000-129500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0658 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0573 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 129500-130000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0644 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0385 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 130000-130500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0734 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0549 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 130500-131000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0675 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0568 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 131000-131500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0676 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0591 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 131500-132000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0648 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0281 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 132000-132500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0535 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0135 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 132500-133000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0554 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6646 - val_tp: 18.0000 - val_fp: 82.0000 - val_tn: 18.0000 - val_fn: 82.0000 - val_accuracy: 0.1800 - val_precision: 0.1800 - val_recall: 0.1800 - val_auc: 0.2781
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 133000-133500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.8693 - tp: 77.0000 - fp: 323.0000 - tn: 77.0000 - fn: 323.0000 - accuracy: 0.1925 - precision: 0.1925 - recall: 0.1925 - auc: 0.1758 - val_loss: 0.0303 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 133500-134000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0695 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0511 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 134000-134500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0701 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0458 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 134500-135000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0674 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0293 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 135000-135500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0646 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0313 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 135500-136000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0555 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0040 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 136000-136500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0580 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0020 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 136500-137000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0547 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0053 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 137000-137500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0577 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0222 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 137500-138000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0596 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0268 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 138000-138500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0608 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0232 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 138500-139000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0563 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0287 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 139000-139500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0567 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0342 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 139500-140000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0615 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0083 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 140000-140500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0509 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0058 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 140500-141000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0528 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0022 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 141000-141500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0480 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0063 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 141500-142000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0500 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0128 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 142000-142500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0507 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0144 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 142500-143000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0482 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.5173 - val_tp: 54.0000 - val_fp: 46.0000 - val_tn: 54.0000 - val_fn: 46.0000 - val_accuracy: 0.5400 - val_precision: 0.5400 - val_recall: 0.5400 - val_auc: 0.7110
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 143000-143500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.7355 - tp: 9.0000 - fp: 391.0000 - tn: 9.0000 - fn: 391.0000 - accuracy: 0.0225 - precision: 0.0225 - recall: 0.0225 - auc: 0.0060 - val_loss: 1.4332 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 143500-144000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7674 - tp: 281.0000 - fp: 119.0000 - tn: 281.0000 - fn: 119.0000 - accuracy: 0.7025 - precision: 0.7025 - recall: 0.7025 - auc: 0.7846 - val_loss: 0.0255 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 144000-144500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0673 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0147 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 144500-145000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0669 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0819 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 145000-145500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0952 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0625 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 145500-146000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0870 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1034 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 146000-146500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0933 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0869 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 146500-147000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0901 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0797 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 147000-147500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0872 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0788 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 147500-148000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1505 - tp: 390.0000 - fp: 10.0000 - tn: 390.0000 - fn: 10.0000 - accuracy: 0.9750 - precision: 0.9750 - recall: 0.9750 - auc: 0.9873 - val_loss: 0.0431 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 148000-148500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0561 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 148500-149000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0565 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0336 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 149000-149500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0618 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0218 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 149500-150000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0637 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0487 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 150000-150500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0620 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0593 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 150500-151000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0649 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0549 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 151000-151500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1835 - tp: 386.0000 - fp: 14.0000 - tn: 386.0000 - fn: 14.0000 - accuracy: 0.9650 - precision: 0.9650 - recall: 0.9650 - auc: 0.9862 - val_loss: 0.1047 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 151500-152000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0625 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - val_loss: 0.0180 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 152000-152500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0508 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0128 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 152500-153000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0483 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0273 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 153000-153500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0575 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0148 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 153500-154000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0518 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0336 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 154000-154500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0585 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0386 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 154500-155000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0565 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0433 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 155000-155500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0568 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0398 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 155500-156000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0559 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0232 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 156000-156500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0507 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0083 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 156500-157000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0479 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0084 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 157000-157500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0429 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0182 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 157500-158000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0457 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0202 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 158000-158500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0486 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0197 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 158500-159000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0465 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0223 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 159000-159500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0480 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0245 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 159500-160000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0475 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0214 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 160000-160500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0457 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0059 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 160500-161000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0424 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 161000-161500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0414 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0159 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 161500-162000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0446 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0142 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 162000-162500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0466 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0204 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 162500-163000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0443 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0154 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 163000-163500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0427 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0173 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 163500-164000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0451 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0129 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 164000-164500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0435 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0048 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 164500-165000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0421 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0020 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 165000-165500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0420 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 165500-166000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0432 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0104 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 166000-166500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0405 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0078 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 166500-167000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0394 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0098 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 167000-167500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0415 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0110 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 167500-168000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0434 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0126 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 168000-168500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0412 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0132 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 168500-169000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0383 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0039 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 169000-169500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0395 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0014 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 169500-170000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0374 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0045 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 170000-170500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0402 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 170500-171000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0381 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0038 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 171000-171500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0386 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0037 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 171500-172000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0386 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0061 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 172000-172500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.0832 - tp: 290.0000 - fp: 110.0000 - tn: 290.0000 - fn: 110.0000 - accuracy: 0.7250 - precision: 0.7250 - recall: 0.7250 - auc: 0.7620 - val_loss: 3.9432 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 172500-173000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8017 - tp: 311.0000 - fp: 89.0000 - tn: 311.0000 - fn: 89.0000 - accuracy: 0.7775 - precision: 0.7775 - recall: 0.7775 - auc: 0.7806 - val_loss: 3.0539 - val_tp: 10.0000 - val_fp: 90.0000 - val_tn: 10.0000 - val_fn: 90.0000 - val_accuracy: 0.1000 - val_precision: 0.1000 - val_recall: 0.1000 - val_auc: 0.0290
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 173000-173500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 3.0243 - tp: 0.0000e+00 - fp: 400.0000 - tn: 0.0000e+00 - fn: 400.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 2.6457 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 173500-174000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2194 - tp: 378.0000 - fp: 22.0000 - tn: 378.0000 - fn: 22.0000 - accuracy: 0.9450 - precision: 0.9450 - recall: 0.9450 - auc: 0.9437 - val_loss: 0.0921 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 174000-174500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1049 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0972 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 174500-175000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0924 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0877 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 175000-175500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0852 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0851 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 175500-176000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0806 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0796 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 176000-176500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0782 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0756 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 176500-177000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0755 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0732 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 177000-177500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0755 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0763 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 177500-178000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0723 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0607 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 178000-178500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0659 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0576 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 178500-179000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0629 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0558 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 179000-179500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0622 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0587 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 179500-180000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0613 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0575 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 180000-180500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0610 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0569 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 180500-181000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0607 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0565 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 181000-181500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0749 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0785 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 181500-182000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0673 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0553 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 182000-182500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0542 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0403 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 182500-183000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0499 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0442 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 183000-183500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0510 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0425 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 183500-184000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0498 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0455 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 184000-184500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0508 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0451 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 184500-185000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0503 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0453 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 185000-185500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0537 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0522 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 185500-186000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0535 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0394 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 186000-186500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0471 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0398 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 186500-187000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0535 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0456 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 187000-187500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0472 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0296 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 187500-188000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0441 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0282 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 188000-188500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0450 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0307 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 188500-189000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0451 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0314 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 189000-189500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0418 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0324 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 189500-190000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0455 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0335 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 190000-190500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0445 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0346 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 190500-191000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0469 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0387 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 191000-191500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0410 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0177 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 191500-192000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0440 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0498 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 192000-192500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0478 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0385 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 192500-193000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0380 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0148 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 193000-193500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0358 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0202 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 193500-194000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0382 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0210 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 194000-194500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0378 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0221 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 194500-195000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0379 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0237 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 195000-195500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0376 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0255 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 195500-196000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0381 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0356 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 196000-196500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0394 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0223 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 196500-197000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0349 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0153 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 197000-197500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0413 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0463 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 197500-198000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0397 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0193 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 198000-198500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.0458 - tp: 296.0000 - fp: 104.0000 - tn: 296.0000 - fn: 104.0000 - accuracy: 0.7400 - precision: 0.7400 - recall: 0.7400 - auc: 0.7594 - val_loss: 3.5552 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 198500-199000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 3.1367 - tp: 0.0000e+00 - fp: 400.0000 - tn: 0.0000e+00 - fn: 400.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 2.7015 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 199000-199500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.5295 - tp: 11.0000 - fp: 389.0000 - tn: 11.0000 - fn: 389.0000 - accuracy: 0.0275 - precision: 0.0275 - recall: 0.0275 - auc: 0.0119 - val_loss: 1.9080 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 199500-200000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.1952 - tp: 210.0000 - fp: 190.0000 - tn: 210.0000 - fn: 190.0000 - accuracy: 0.5250 - precision: 0.5250 - recall: 0.5250 - auc: 0.5770 - val_loss: 0.0711 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 200000-200500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1105 - tp: 393.0000 - fp: 7.0000 - tn: 393.0000 - fn: 7.0000 - accuracy: 0.9825 - precision: 0.9825 - recall: 0.9825 - auc: 0.9908 - val_loss: 0.0628 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 200500-201000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0819 - tp: 398.0000 - fp: 2.0000 - tn: 398.0000 - fn: 2.0000 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - auc: 0.9998 - val_loss: 0.0616 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 201000-201500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1018 - tp: 395.0000 - fp: 5.0000 - tn: 395.0000 - fn: 5.0000 - accuracy: 0.9875 - precision: 0.9875 - recall: 0.9875 - auc: 0.9903 - val_loss: 0.0609 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 201500-202000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0676 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0584 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 202000-202500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0681 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0718 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 202500-203000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0698 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0573 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 203000-203500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0600 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0419 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 203500-204000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0623 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0446 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 204000-204500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0528 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0368 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 204500-205000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0635 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - val_loss: 0.0509 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 205000-205500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0581 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0478 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 205500-206000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0554 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0474 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 206000-206500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0549 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0485 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 206500-207000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0570 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0427 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 207000-207500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0513 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0278 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 207500-208000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0498 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0585 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 208000-208500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0585 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0448 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 208500-209000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0462 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0234 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 209000-209500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0454 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0314 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 209500-210000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0476 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0317 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 210000-210500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0472 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0336 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 210500-211000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0476 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0386 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 211000-211500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0477 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0417 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 211500-212000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0522 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0374 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 212000-212500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0463 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0286 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 212500-213000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0457 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0208 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 213000-213500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0580 - tp: 398.0000 - fp: 2.0000 - tn: 398.0000 - fn: 2.0000 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - val_loss: 0.0446 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 213500-214000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0466 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0234 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 214000-214500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0441 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0237 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 214500-215000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0416 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0253 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 215000-215500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0381 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0166 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 215500-216000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0416 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0273 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 216000-216500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0413 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0271 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 216500-217000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0420 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0273 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 217000-217500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0424 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0286 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 217500-218000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0408 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0233 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 218000-218500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0366 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0156 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 218500-219000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0366 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0118 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 219000-219500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0359 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0205 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 219500-220000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0380 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0211 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 220000-220500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0392 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0207 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 220500-221000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0394 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0223 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 221000-221500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0380 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0240 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 221500-222000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0396 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0253 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 222000-222500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0372 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0184 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 222500-223000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0360 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0083 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 223000-223500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0342 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0111 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 223500-224000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0332 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0132 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 224000-224500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0355 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0130 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 224500-225000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0360 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0140 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 225000-225500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0352 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0155 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 225500-226000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0356 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0178 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 226000-226500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0342 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0183 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 226500-227000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0346 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0104 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 227000-227500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0320 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0057 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 227500-228000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7885 - tp: 328.0000 - fp: 72.0000 - tn: 328.0000 - fn: 72.0000 - accuracy: 0.8200 - precision: 0.8200 - recall: 0.8200 - auc: 0.8216 - val_loss: 3.6995 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 228000-228500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 3.1782 - tp: 2.0000 - fp: 398.0000 - tn: 2.0000 - fn: 398.0000 - accuracy: 0.0050 - precision: 0.0050 - recall: 0.0050 - auc: 2.8750e-04 - val_loss: 2.6194 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 228500-229000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.1502 - tp: 53.0000 - fp: 347.0000 - tn: 53.0000 - fn: 347.0000 - accuracy: 0.1325 - precision: 0.1325 - recall: 0.1325 - auc: 0.1117 - val_loss: 0.8232 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 229000-229500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.5472 - tp: 153.0000 - fp: 247.0000 - tn: 153.0000 - fn: 247.0000 - accuracy: 0.3825 - precision: 0.3825 - recall: 0.3825 - auc: 0.5352 - val_loss: 0.0490 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 229500-230000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.3024 - tp: 76.0000 - fp: 324.0000 - tn: 76.0000 - fn: 324.0000 - accuracy: 0.1900 - precision: 0.1900 - recall: 0.1900 - auc: 0.2311 - val_loss: 2.3739 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 230000-230500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.3177 - tp: 33.0000 - fp: 367.0000 - tn: 33.0000 - fn: 367.0000 - accuracy: 0.0825 - precision: 0.0825 - recall: 0.0825 - auc: 0.0765 - val_loss: 2.2216 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 230500-231000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.5609 - tp: 120.0000 - fp: 280.0000 - tn: 120.0000 - fn: 280.0000 - accuracy: 0.3000 - precision: 0.3000 - recall: 0.3000 - auc: 0.3620 - val_loss: 0.0567 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 231000-231500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.2522 - tp: 185.0000 - fp: 215.0000 - tn: 185.0000 - fn: 215.0000 - accuracy: 0.4625 - precision: 0.4625 - recall: 0.4625 - auc: 0.6485 - val_loss: 5.5338e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 231500-232000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.8084 - tp: 157.0000 - fp: 243.0000 - tn: 157.0000 - fn: 243.0000 - accuracy: 0.3925 - precision: 0.3925 - recall: 0.3925 - auc: 0.5476 - val_loss: 0.1614 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 232000-232500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.2789 - tp: 184.0000 - fp: 216.0000 - tn: 184.0000 - fn: 216.0000 - accuracy: 0.4600 - precision: 0.4600 - recall: 0.4600 - auc: 0.6230 - val_loss: 0.0126 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 232500-233000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.1610 - tp: 192.0000 - fp: 208.0000 - tn: 192.0000 - fn: 208.0000 - accuracy: 0.4800 - precision: 0.4800 - recall: 0.4800 - auc: 0.6540 - val_loss: 4.4730e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 233000-233500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.1063 - tp: 197.0000 - fp: 203.0000 - tn: 197.0000 - fn: 203.0000 - accuracy: 0.4925 - precision: 0.4925 - recall: 0.4925 - auc: 0.6941 - val_loss: 2.9914e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 233500-234000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.0599 - tp: 200.0000 - fp: 200.0000 - tn: 200.0000 - fn: 200.0000 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.5000 - auc: 0.7123 - val_loss: 1.6411e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 234000-234500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.1141 - tp: 189.0000 - fp: 211.0000 - tn: 189.0000 - fn: 211.0000 - accuracy: 0.4725 - precision: 0.4725 - recall: 0.4725 - auc: 0.6760 - val_loss: 1.1555e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 234500-235000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9643 - tp: 215.0000 - fp: 185.0000 - tn: 215.0000 - fn: 185.0000 - accuracy: 0.5375 - precision: 0.5375 - recall: 0.5375 - auc: 0.7388 - val_loss: 6.3717e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 235000-235500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9794 - tp: 209.0000 - fp: 191.0000 - tn: 209.0000 - fn: 191.0000 - accuracy: 0.5225 - precision: 0.5225 - recall: 0.5225 - auc: 0.7484 - val_loss: 3.9208e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 235500-236000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9742 - tp: 206.0000 - fp: 194.0000 - tn: 206.0000 - fn: 194.0000 - accuracy: 0.5150 - precision: 0.5150 - recall: 0.5150 - auc: 0.7409 - val_loss: 2.4068e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 236000-236500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.0163 - tp: 195.0000 - fp: 205.0000 - tn: 195.0000 - fn: 205.0000 - accuracy: 0.4875 - precision: 0.4875 - recall: 0.4875 - auc: 0.7170 - val_loss: 1.6785e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 236500-237000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.0028 - tp: 194.0000 - fp: 206.0000 - tn: 194.0000 - fn: 206.0000 - accuracy: 0.4850 - precision: 0.4850 - recall: 0.4850 - auc: 0.7207 - val_loss: 1.2279e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 237000-237500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9846 - tp: 196.0000 - fp: 204.0000 - tn: 196.0000 - fn: 204.0000 - accuracy: 0.4900 - precision: 0.4900 - recall: 0.4900 - auc: 0.7182 - val_loss: 7.6413e-07 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 237500-238000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9214 - tp: 205.0000 - fp: 195.0000 - tn: 205.0000 - fn: 195.0000 - accuracy: 0.5125 - precision: 0.5125 - recall: 0.5125 - auc: 0.7369 - val_loss: 4.9114e-07 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 238000-238500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9451 - tp: 196.0000 - fp: 204.0000 - tn: 196.0000 - fn: 204.0000 - accuracy: 0.4900 - precision: 0.4900 - recall: 0.4900 - auc: 0.7323 - val_loss: 3.5763e-07 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 238500-239000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9544 - tp: 190.0000 - fp: 210.0000 - tn: 190.0000 - fn: 210.0000 - accuracy: 0.4750 - precision: 0.4750 - recall: 0.4750 - auc: 0.7165 - val_loss: 2.3842e-07 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 239000-239500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9389 - tp: 190.0000 - fp: 210.0000 - tn: 190.0000 - fn: 210.0000 - accuracy: 0.4750 - precision: 0.4750 - recall: 0.4750 - auc: 0.7114 - val_loss: 6.9260e-07 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 239500-240000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9487 - tp: 184.0000 - fp: 216.0000 - tn: 184.0000 - fn: 216.0000 - accuracy: 0.4600 - precision: 0.4600 - recall: 0.4600 - auc: 0.7003 - val_loss: 1.1921e-07 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 240000-240500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8786 - tp: 197.0000 - fp: 203.0000 - tn: 197.0000 - fn: 203.0000 - accuracy: 0.4925 - precision: 0.4925 - recall: 0.4925 - auc: 0.7298 - val_loss: 1.1921e-07 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 240500-241000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8832 - tp: 192.0000 - fp: 208.0000 - tn: 192.0000 - fn: 208.0000 - accuracy: 0.4800 - precision: 0.4800 - recall: 0.4800 - auc: 0.7244 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 241000-241500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8118 - tp: 206.0000 - fp: 194.0000 - tn: 206.0000 - fn: 194.0000 - accuracy: 0.5150 - precision: 0.5150 - recall: 0.5150 - auc: 0.7575 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 241500-242000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8172 - tp: 201.0000 - fp: 199.0000 - tn: 201.0000 - fn: 199.0000 - accuracy: 0.5025 - precision: 0.5025 - recall: 0.5025 - auc: 0.7525 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 242000-242500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8095 - tp: 200.0000 - fp: 200.0000 - tn: 200.0000 - fn: 200.0000 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.5000 - auc: 0.7425 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 242500-243000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7632 - tp: 208.0000 - fp: 192.0000 - tn: 208.0000 - fn: 192.0000 - accuracy: 0.5200 - precision: 0.5200 - recall: 0.5200 - auc: 0.7624 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 243000-243500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8477 - tp: 183.0000 - fp: 217.0000 - tn: 183.0000 - fn: 217.0000 - accuracy: 0.4575 - precision: 0.4575 - recall: 0.4575 - auc: 0.7030 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 243500-244000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7366 - tp: 208.0000 - fp: 192.0000 - tn: 208.0000 - fn: 192.0000 - accuracy: 0.5200 - precision: 0.5200 - recall: 0.5200 - auc: 0.7696 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 244000-244500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7881 - tp: 191.0000 - fp: 209.0000 - tn: 191.0000 - fn: 209.0000 - accuracy: 0.4775 - precision: 0.4775 - recall: 0.4775 - auc: 0.7270 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 244500-245000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6992 - tp: 212.0000 - fp: 188.0000 - tn: 212.0000 - fn: 188.0000 - accuracy: 0.5300 - precision: 0.5300 - recall: 0.5300 - auc: 0.7767 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 245000-245500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6918 - tp: 211.0000 - fp: 189.0000 - tn: 211.0000 - fn: 189.0000 - accuracy: 0.5275 - precision: 0.5275 - recall: 0.5275 - auc: 0.7720 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 245500-246000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6315 - tp: 225.0000 - fp: 175.0000 - tn: 225.0000 - fn: 175.0000 - accuracy: 0.5625 - precision: 0.5625 - recall: 0.5625 - auc: 0.8042 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 246000-246500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7374 - tp: 192.0000 - fp: 208.0000 - tn: 192.0000 - fn: 208.0000 - accuracy: 0.4800 - precision: 0.4800 - recall: 0.4800 - auc: 0.7270 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 246500-247000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6857 - tp: 204.0000 - fp: 196.0000 - tn: 204.0000 - fn: 196.0000 - accuracy: 0.5100 - precision: 0.5100 - recall: 0.5100 - auc: 0.7501 - val_loss: 8.3446e-09 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 247000-247500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6533 - tp: 209.0000 - fp: 191.0000 - tn: 209.0000 - fn: 191.0000 - accuracy: 0.5225 - precision: 0.5225 - recall: 0.5225 - auc: 0.7697 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 247500-248000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6888 - tp: 196.0000 - fp: 204.0000 - tn: 196.0000 - fn: 204.0000 - accuracy: 0.4900 - precision: 0.4900 - recall: 0.4900 - auc: 0.7348 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 248000-248500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6621 - tp: 201.0000 - fp: 199.0000 - tn: 201.0000 - fn: 199.0000 - accuracy: 0.5025 - precision: 0.5025 - recall: 0.5025 - auc: 0.7500 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 248500-249000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6771 - tp: 193.0000 - fp: 207.0000 - tn: 193.0000 - fn: 207.0000 - accuracy: 0.4825 - precision: 0.4825 - recall: 0.4825 - auc: 0.7296 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 249000-249500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6419 - tp: 200.0000 - fp: 200.0000 - tn: 200.0000 - fn: 200.0000 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.5000 - auc: 0.7500 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 249500-250000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6228 - tp: 203.0000 - fp: 197.0000 - tn: 203.0000 - fn: 197.0000 - accuracy: 0.5075 - precision: 0.5075 - recall: 0.5075 - auc: 0.7550 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 250000-250500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6350 - tp: 197.0000 - fp: 203.0000 - tn: 197.0000 - fn: 203.0000 - accuracy: 0.4925 - precision: 0.4925 - recall: 0.4925 - auc: 0.7348 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 250500-251000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6604 - tp: 184.0000 - fp: 216.0000 - tn: 184.0000 - fn: 216.0000 - accuracy: 0.4600 - precision: 0.4600 - recall: 0.4600 - auc: 0.7084 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 251000-251500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5947 - tp: 203.0000 - fp: 197.0000 - tn: 203.0000 - fn: 197.0000 - accuracy: 0.5075 - precision: 0.5075 - recall: 0.5075 - auc: 0.7556 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 251500-252000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5446 - tp: 216.0000 - fp: 184.0000 - tn: 216.0000 - fn: 184.0000 - accuracy: 0.5400 - precision: 0.5400 - recall: 0.5400 - auc: 0.7884 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 252000-252500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5448 - tp: 213.0000 - fp: 187.0000 - tn: 213.0000 - fn: 187.0000 - accuracy: 0.5325 - precision: 0.5325 - recall: 0.5325 - auc: 0.7814 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 252500-253000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6051 - tp: 189.0000 - fp: 211.0000 - tn: 189.0000 - fn: 211.0000 - accuracy: 0.4725 - precision: 0.4725 - recall: 0.4725 - auc: 0.7217 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 253000-253500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5839 - tp: 193.0000 - fp: 207.0000 - tn: 193.0000 - fn: 207.0000 - accuracy: 0.4825 - precision: 0.4825 - recall: 0.4825 - auc: 0.7322 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 253500-254000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5930 - tp: 187.0000 - fp: 213.0000 - tn: 187.0000 - fn: 213.0000 - accuracy: 0.4675 - precision: 0.4675 - recall: 0.4675 - auc: 0.7154 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 254000-254500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5803 - tp: 188.0000 - fp: 212.0000 - tn: 188.0000 - fn: 212.0000 - accuracy: 0.4700 - precision: 0.4700 - recall: 0.4700 - auc: 0.7165 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 254500-255000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5671 - tp: 189.0000 - fp: 211.0000 - tn: 189.0000 - fn: 211.0000 - accuracy: 0.4725 - precision: 0.4725 - recall: 0.4725 - auc: 0.7217 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 255000-255500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5121 - tp: 206.0000 - fp: 194.0000 - tn: 206.0000 - fn: 194.0000 - accuracy: 0.5150 - precision: 0.5150 - recall: 0.5150 - auc: 0.7648 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 255500-256000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5727 - tp: 180.0000 - fp: 220.0000 - tn: 180.0000 - fn: 220.0000 - accuracy: 0.4500 - precision: 0.4500 - recall: 0.4500 - auc: 0.6948 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 256000-256500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4900 - tp: 208.0000 - fp: 192.0000 - tn: 208.0000 - fn: 192.0000 - accuracy: 0.5200 - precision: 0.5200 - recall: 0.5200 - auc: 0.7696 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 256500-257000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4735 - tp: 212.0000 - fp: 188.0000 - tn: 212.0000 - fn: 188.0000 - accuracy: 0.5300 - precision: 0.5300 - recall: 0.5300 - auc: 0.7791 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 257000-257500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4784 - tp: 207.0000 - fp: 193.0000 - tn: 207.0000 - fn: 193.0000 - accuracy: 0.5175 - precision: 0.5175 - recall: 0.5175 - auc: 0.7672 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 257500-258000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4956 - tp: 197.0000 - fp: 203.0000 - tn: 197.0000 - fn: 203.0000 - accuracy: 0.4925 - precision: 0.4925 - recall: 0.4925 - auc: 0.7424 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 258000-258500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5098 - tp: 188.0000 - fp: 212.0000 - tn: 188.0000 - fn: 212.0000 - accuracy: 0.4700 - precision: 0.4700 - recall: 0.4700 - auc: 0.7191 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 258500-259000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4708 - tp: 201.0000 - fp: 199.0000 - tn: 201.0000 - fn: 199.0000 - accuracy: 0.5025 - precision: 0.5025 - recall: 0.5025 - auc: 0.7525 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 259000-259500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4846 - tp: 192.0000 - fp: 208.0000 - tn: 192.0000 - fn: 208.0000 - accuracy: 0.4800 - precision: 0.4800 - recall: 0.4800 - auc: 0.7296 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 259500-260000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4489 - tp: 204.0000 - fp: 196.0000 - tn: 204.0000 - fn: 196.0000 - accuracy: 0.5100 - precision: 0.5100 - recall: 0.5100 - auc: 0.7599 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 260000-260500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4813 - tp: 187.0000 - fp: 213.0000 - tn: 187.0000 - fn: 213.0000 - accuracy: 0.4675 - precision: 0.4675 - recall: 0.4675 - auc: 0.7164 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 260500-261000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4356 - tp: 204.0000 - fp: 196.0000 - tn: 204.0000 - fn: 196.0000 - accuracy: 0.5100 - precision: 0.5100 - recall: 0.5100 - auc: 0.7599 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 261000-261500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3974 - tp: 219.0000 - fp: 181.0000 - tn: 219.0000 - fn: 181.0000 - accuracy: 0.5475 - precision: 0.5475 - recall: 0.5475 - auc: 0.7930 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 261500-262000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4371 - tp: 197.0000 - fp: 203.0000 - tn: 197.0000 - fn: 203.0000 - accuracy: 0.4925 - precision: 0.4925 - recall: 0.4925 - auc: 0.7424 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 262000-262500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4412 - tp: 193.0000 - fp: 207.0000 - tn: 193.0000 - fn: 207.0000 - accuracy: 0.4825 - precision: 0.4825 - recall: 0.4825 - auc: 0.7322 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 262500-263000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4103 - tp: 204.0000 - fp: 196.0000 - tn: 204.0000 - fn: 196.0000 - accuracy: 0.5100 - precision: 0.5100 - recall: 0.5100 - auc: 0.7599 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 263000-263500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4247 - tp: 194.0000 - fp: 206.0000 - tn: 194.0000 - fn: 206.0000 - accuracy: 0.4850 - precision: 0.4850 - recall: 0.4850 - auc: 0.7348 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 263500-264000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 4.6230 - tp: 210.0000 - fp: 190.0000 - tn: 210.0000 - fn: 190.0000 - accuracy: 0.5250 - precision: 0.5250 - recall: 0.5250 - auc: 0.5979 - val_loss: 4.4140 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 264000-264500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.0168 - tp: 224.0000 - fp: 176.0000 - tn: 224.0000 - fn: 176.0000 - accuracy: 0.5600 - precision: 0.5600 - recall: 0.5600 - auc: 0.3375 - val_loss: 0.5726 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 264500-265000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6706 - tp: 294.0000 - fp: 106.0000 - tn: 294.0000 - fn: 106.0000 - accuracy: 0.7350 - precision: 0.7350 - recall: 0.7350 - auc: 0.6917 - val_loss: 0.9455 - val_tp: 50.0000 - val_fp: 50.0000 - val_tn: 50.0000 - val_fn: 50.0000 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_auc: 0.2500
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 265000-265500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.3556 - tp: 243.0000 - fp: 157.0000 - tn: 243.0000 - fn: 157.0000 - accuracy: 0.6075 - precision: 0.6075 - recall: 0.6075 - auc: 0.4311 - val_loss: 0.7083 - val_tp: 21.0000 - val_fp: 79.0000 - val_tn: 21.0000 - val_fn: 79.0000 - val_accuracy: 0.2100 - val_precision: 0.2100 - val_recall: 0.2100 - val_auc: 0.0828
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 265500-266000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8287 - tp: 276.0000 - fp: 124.0000 - tn: 276.0000 - fn: 124.0000 - accuracy: 0.6900 - precision: 0.6900 - recall: 0.6900 - auc: 0.5962 - val_loss: 0.5353 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 266000-266500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4833 - tp: 382.0000 - fp: 18.0000 - tn: 382.0000 - fn: 18.0000 - accuracy: 0.9550 - precision: 0.9550 - recall: 0.9550 - auc: 0.9791 - val_loss: 0.3387 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 266500-267000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3648 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1879 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 267000-267500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3628 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1542 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 267500-268000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3075 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2652 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 268000-268500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3658 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 0.9999 - val_loss: 0.2380 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 268500-269000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2750 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0600 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 269000-269500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2666 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0626 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 269500-270000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2437 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0123 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 270000-270500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2528 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0064 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 270500-271000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2374 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0039 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 271000-271500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2660 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0084 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 271500-272000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2358 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0988 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 272000-272500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2822 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0953 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 272500-273000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2404 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0096 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 273000-273500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2324 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0040 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 273500-274000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2147 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0027 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 274000-274500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2148 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 274500-275000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2063 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0074 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 275000-275500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2091 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0094 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 275500-276000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2122 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0652 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 276000-276500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2136 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0047 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 276500-277000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1972 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0119 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 277000-277500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2040 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0018 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 277500-278000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1921 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0011 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 278000-278500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1938 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0064 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 278500-279000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1793 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0017 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 279000-279500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.8893 - tp: 279.0000 - fp: 121.0000 - tn: 279.0000 - fn: 121.0000 - accuracy: 0.6975 - precision: 0.6975 - recall: 0.6975 - auc: 0.6796 - val_loss: 0.0952 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 279500-280000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2763 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1225 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 280000-280500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.4313 - tp: 89.0000 - fp: 311.0000 - tn: 89.0000 - fn: 311.0000 - accuracy: 0.2225 - precision: 0.2225 - recall: 0.2225 - auc: 0.2194 - val_loss: 0.9570 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 280500-281000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9870 - tp: 96.0000 - fp: 304.0000 - tn: 96.0000 - fn: 304.0000 - accuracy: 0.2400 - precision: 0.2400 - recall: 0.2400 - auc: 0.2744 - val_loss: 0.6696 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 281000-281500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6857 - tp: 223.0000 - fp: 177.0000 - tn: 223.0000 - fn: 177.0000 - accuracy: 0.5575 - precision: 0.5575 - recall: 0.5575 - auc: 0.5895 - val_loss: 0.4400 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 281500-282000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5801 - tp: 310.0000 - fp: 90.0000 - tn: 310.0000 - fn: 90.0000 - accuracy: 0.7750 - precision: 0.7750 - recall: 0.7750 - auc: 0.8145 - val_loss: 0.5366 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 282000-282500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5351 - tp: 324.0000 - fp: 76.0000 - tn: 324.0000 - fn: 76.0000 - accuracy: 0.8100 - precision: 0.8100 - recall: 0.8100 - auc: 0.8834 - val_loss: 0.4541 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 282500-283000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4235 - tp: 389.0000 - fp: 11.0000 - tn: 389.0000 - fn: 11.0000 - accuracy: 0.9725 - precision: 0.9725 - recall: 0.9725 - auc: 0.9918 - val_loss: 0.3894 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 283000-283500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3533 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3100 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 283500-284000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3258 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3181 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 284000-284500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3142 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3162 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 284500-285000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2764 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2292 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 285000-285500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2197 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1103 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 285500-286000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2102 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1232 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 286000-286500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2254 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2087 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 286500-287000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2141 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1937 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 287000-287500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2040 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1674 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 287500-288000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1902 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1425 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 288000-288500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1814 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1243 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 288500-289000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1810 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1230 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 289000-289500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1629 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0982 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 289500-290000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1633 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0978 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 290000-290500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1677 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0888 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 290500-291000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1701 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0934 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 291000-291500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1708 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0986 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 291500-292000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1660 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0958 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 292000-292500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1554 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0761 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 292500-293000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1512 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0789 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 293000-293500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1576 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0738 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 293500-294000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1409 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0616 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 294000-294500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1495 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0614 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 294500-295000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1578 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0614 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 295000-295500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1513 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0753 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 295500-296000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1424 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0650 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 296000-296500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1456 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0526 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 296500-297000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1283 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0457 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 297000-297500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1370 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0468 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 297500-298000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1393 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0479 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 298000-298500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1312 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0362 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 298500-299000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1293 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0419 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 299000-299500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1335 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0376 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 299500-300000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1340 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0441 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 300000-300500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1363 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0369 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 300500-301000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1340 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0333 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 301000-301500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1318 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0313 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 301500-302000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1133 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0381 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 302000-302500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1170 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0286 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 302500-303000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.0066 - tp: 153.0000 - fp: 247.0000 - tn: 153.0000 - fn: 247.0000 - accuracy: 0.3825 - precision: 0.3825 - recall: 0.3825 - auc: 0.3896 - val_loss: 2.5986 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 303000-303500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2659 - tp: 380.0000 - fp: 20.0000 - tn: 380.0000 - fn: 20.0000 - accuracy: 0.9500 - precision: 0.9500 - recall: 0.9500 - auc: 0.9496 - val_loss: 0.0988 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 303500-304000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1618 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1281 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 304000-304500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1534 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1227 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 304500-305000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1528 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1259 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 305000-305500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1266 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0900 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 305500-306000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1399 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0955 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 306000-306500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1321 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0998 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 306500-307000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1361 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0926 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 307000-307500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1306 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0845 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 307500-308000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1216 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0782 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 308000-308500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1172 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0839 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 308500-309000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1248 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0818 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 309000-309500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1181 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0650 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 309500-310000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1150 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0483 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 310000-310500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1095 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0725 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 310500-311000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1098 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0639 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 311000-311500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1110 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0577 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 311500-312000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1107 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0522 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 312000-312500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1101 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0475 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 312500-313000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1099 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0569 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 313000-313500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1109 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0603 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 313500-314000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1009 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0342 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 314000-314500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1037 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0388 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 314500-315000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0998 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0439 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 315000-315500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1018 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0407 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 315500-316000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1022 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0377 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 316000-316500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1021 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0345 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 316500-317000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1041 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0318 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 317000-317500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0978 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0416 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 317500-318000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0960 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0443 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 318000-318500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0935 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0291 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 318500-319000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0964 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0428 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 319000-319500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0901 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0310 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 319500-320000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0935 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0278 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 320000-320500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0931 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0253 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 320500-321000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0934 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0233 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 321000-321500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0942 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0310 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 321500-322000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0915 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0386 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 322000-322500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0884 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0319 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 322500-323000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0902 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0242 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 323000-323500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0889 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0345 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 323500-324000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0897 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0256 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 324000-324500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0847 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0200 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 324500-325000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0870 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0186 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 325000-325500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0883 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0173 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 325500-326000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0823 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0246 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 326000-326500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0855 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0325 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 326500-327000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0833 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0184 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 327000-327500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0793 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0226 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 327500-328000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0799 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0197 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 328000-328500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0763 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0164 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 328500-329000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0793 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0147 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 329000-329500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0763 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0135 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 329500-330000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0786 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0130 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 330000-330500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0742 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0195 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 330500-331000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0784 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0253 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 331000-331500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0756 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0166 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 331500-332000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0720 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0229 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 332000-332500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0761 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0145 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 332500-333000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0650 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0120 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 333000-333500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0729 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0110 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 333500-334000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0685 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 334000-334500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0687 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0203 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 334500-335000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0701 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0228 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 335000-335500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0740 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0217 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 335500-336000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0662 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0232 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 336000-336500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0676 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0123 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 336500-337000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0635 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0201 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 337000-337500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0737 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0116 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[33m[LOSS] 0.011599398776888847[0m
[33m[INFO] epoch 2/3[0m
[33m[INFO] loading file 1-1/1 on epoch 2/3[0m
[INFO] reading file data/SWaT_Dataset_Attack_v0-fixed-zscore-train-test.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (337500, 46)
[INFO] sampling 1.0
dropping all time related columns...
[INFO] columns: Index([' Timestamp', 'FIT101', 'LIT101', ' MV101', 'P101', 'P102', ' AIT201',
       'AIT202', 'AIT203', 'FIT201', ' MV201', ' P201', 'P203', ' P204',
       'P205', 'P206', 'DPIT301', 'FIT301', 'LIT301', 'MV301', 'MV302',
       ' MV303', 'MV304', 'P302', 'AIT401', 'AIT402', 'FIT401', 'LIT401',
       'P402', 'P403', 'UV401', 'AIT501', 'AIT502', 'AIT503', 'AIT504',
       'FIT501', 'FIT502', 'FIT503', 'FIT504', 'P501', 'PIT501', 'PIT502',
       'PIT503', 'FIT601', 'P602', 'Normal/Attack'],
      dtype='object')
[INFO] processing batch 0-500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0686 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0181 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 500-1000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0654 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0207 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 1000-1500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0700 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0138 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 1500-2000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.4180 - tp: 254.0000 - fp: 146.0000 - tn: 254.0000 - fn: 146.0000 - accuracy: 0.6350 - precision: 0.6350 - recall: 0.6350 - auc: 0.6515 - val_loss: 3.3742 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 2000-2500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.9912 - tp: 0.0000e+00 - fp: 400.0000 - tn: 0.0000e+00 - fn: 400.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 2.5138 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 2500-3000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.1765 - tp: 206.0000 - fp: 194.0000 - tn: 206.0000 - fn: 194.0000 - accuracy: 0.5150 - precision: 0.5150 - recall: 0.5150 - auc: 0.5140 - val_loss: 0.1454 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 3000-3500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.6122 - tp: 90.0000 - fp: 310.0000 - tn: 90.0000 - fn: 310.0000 - accuracy: 0.2250 - precision: 0.2250 - recall: 0.2250 - auc: 0.2227 - val_loss: 1.1610 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 3500-4000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2189 - tp: 389.0000 - fp: 11.0000 - tn: 389.0000 - fn: 11.0000 - accuracy: 0.9725 - precision: 0.9725 - recall: 0.9725 - auc: 0.9719 - val_loss: 0.1726 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 4000-4500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1739 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1644 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 4500-5000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1615 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6090 - val_tp: 20.0000 - val_fp: 80.0000 - val_tn: 20.0000 - val_fn: 80.0000 - val_accuracy: 0.2000 - val_precision: 0.2000 - val_recall: 0.2000 - val_auc: 0.2260
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 5000-5500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.4703 - tp: 97.0000 - fp: 303.0000 - tn: 97.0000 - fn: 303.0000 - accuracy: 0.2425 - precision: 0.2425 - recall: 0.2425 - auc: 0.2720 - val_loss: 0.1651 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 5500-6000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1729 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1578 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 6000-6500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1583 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8953 - val_tp: 59.0000 - val_fp: 41.0000 - val_tn: 59.0000 - val_fn: 41.0000 - val_accuracy: 0.5900 - val_precision: 0.5900 - val_recall: 0.5900 - val_auc: 0.5262
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 6500-7000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.6864 - tp: 51.0000 - fp: 349.0000 - tn: 51.0000 - fn: 349.0000 - accuracy: 0.1275 - precision: 0.1275 - recall: 0.1275 - auc: 0.1229 - val_loss: 0.1716 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 7000-7500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7481 - tp: 257.0000 - fp: 143.0000 - tn: 257.0000 - fn: 143.0000 - accuracy: 0.6425 - precision: 0.6425 - recall: 0.6425 - auc: 0.6731 - val_loss: 0.9516 - val_tp: 49.0000 - val_fp: 51.0000 - val_tn: 49.0000 - val_fn: 51.0000 - val_accuracy: 0.4900 - val_precision: 0.4900 - val_recall: 0.4900 - val_auc: 0.4609
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 7500-8000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8965 - tp: 208.0000 - fp: 192.0000 - tn: 208.0000 - fn: 192.0000 - accuracy: 0.5200 - precision: 0.5200 - recall: 0.5200 - auc: 0.5289 - val_loss: 1.5899 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 8000-8500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6757 - tp: 269.0000 - fp: 131.0000 - tn: 269.0000 - fn: 131.0000 - accuracy: 0.6725 - precision: 0.6725 - recall: 0.6725 - auc: 0.6827 - val_loss: 0.2116 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 8500-9000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2219 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - val_loss: 0.2039 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 9000-9500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2241 - tp: 397.0000 - fp: 3.0000 - tn: 397.0000 - fn: 3.0000 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925 - auc: 0.9985 - val_loss: 0.2361 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 9500-10000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2773 - tp: 384.0000 - fp: 16.0000 - tn: 384.0000 - fn: 16.0000 - accuracy: 0.9600 - precision: 0.9600 - recall: 0.9600 - auc: 0.9857 - val_loss: 0.2006 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 10000-10500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2095 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - val_loss: 0.1824 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 10500-11000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1814 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1706 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 11000-11500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1741 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.5750 - val_tp: 10.0000 - val_fp: 90.0000 - val_tn: 10.0000 - val_fn: 90.0000 - val_accuracy: 0.1000 - val_precision: 0.1000 - val_recall: 0.1000 - val_auc: 0.0630
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 11500-12000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.5422 - tp: 38.0000 - fp: 362.0000 - tn: 38.0000 - fn: 362.0000 - accuracy: 0.0950 - precision: 0.0950 - recall: 0.0950 - auc: 0.0743 - val_loss: 1.4233 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 12000-12500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.3541 - tp: 82.0000 - fp: 318.0000 - tn: 82.0000 - fn: 318.0000 - accuracy: 0.2050 - precision: 0.2050 - recall: 0.2050 - auc: 0.2056 - val_loss: 0.2078 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 12500-13000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2018 - tp: 398.0000 - fp: 2.0000 - tn: 398.0000 - fn: 2.0000 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - auc: 0.9999 - val_loss: 0.1753 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 13000-13500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2078 - tp: 395.0000 - fp: 5.0000 - tn: 395.0000 - fn: 5.0000 - accuracy: 0.9875 - precision: 0.9875 - recall: 0.9875 - auc: 0.9997 - val_loss: 0.2197 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 13500-14000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2209 - tp: 398.0000 - fp: 2.0000 - tn: 398.0000 - fn: 2.0000 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - auc: 0.9998 - val_loss: 0.1921 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 14000-14500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2888 - tp: 375.0000 - fp: 25.0000 - tn: 375.0000 - fn: 25.0000 - accuracy: 0.9375 - precision: 0.9375 - recall: 0.9375 - auc: 0.9487 - val_loss: 0.1818 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 14500-15000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1751 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1631 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 15000-15500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2506 - tp: 380.0000 - fp: 20.0000 - tn: 380.0000 - fn: 20.0000 - accuracy: 0.9500 - precision: 0.9500 - recall: 0.9500 - auc: 0.9551 - val_loss: 1.9215 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 15500-16000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.4723 - tp: 71.0000 - fp: 329.0000 - tn: 71.0000 - fn: 329.0000 - accuracy: 0.1775 - precision: 0.1775 - recall: 0.1775 - auc: 0.1929 - val_loss: 1.3049 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 16000-16500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4963 - tp: 316.0000 - fp: 84.0000 - tn: 316.0000 - fn: 84.0000 - accuracy: 0.7900 - precision: 0.7900 - recall: 0.7900 - auc: 0.8173 - val_loss: 0.1756 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 16500-17000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1579 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1054 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 17000-17500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1485 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1321 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 17500-18000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1562 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1633 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 18000-18500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1624 - tp: 398.0000 - fp: 2.0000 - tn: 398.0000 - fn: 2.0000 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - val_loss: 0.1291 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 18500-19000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1512 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1239 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 19000-19500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1471 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1203 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 19500-20000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1963 - tp: 390.0000 - fp: 10.0000 - tn: 390.0000 - fn: 10.0000 - accuracy: 0.9750 - precision: 0.9750 - recall: 0.9750 - auc: 0.9900 - val_loss: 0.1667 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 20000-20500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1510 - tp: 394.0000 - fp: 6.0000 - tn: 394.0000 - fn: 6.0000 - accuracy: 0.9850 - precision: 0.9850 - recall: 0.9850 - auc: 0.9996 - val_loss: 0.0835 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 20500-21000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1062 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0621 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 21000-21500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1054 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0786 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 21500-22000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1118 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0772 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 22000-22500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1174 - tp: 397.0000 - fp: 3.0000 - tn: 397.0000 - fn: 3.0000 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925 - auc: 0.9999 - val_loss: 0.0784 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 22500-23000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1055 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0782 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 23000-23500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1034 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0772 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 23500-24000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1000 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0747 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 24000-24500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0977 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0588 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 24500-25000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0912 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0494 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 25000-25500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0949 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0749 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 25500-26000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0944 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0397 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 26000-26500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0813 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0348 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 26500-27000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0863 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0463 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 27000-27500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0911 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - val_loss: 0.0443 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 27500-28000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0826 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0501 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 28000-28500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0867 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0512 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 28500-29000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0819 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0526 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 29000-29500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0898 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - val_loss: 0.0540 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 29500-30000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0854 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0223 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 30000-30500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0832 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0402 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 30500-31000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0812 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0430 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 31000-31500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0758 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0215 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 31500-32000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0723 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0308 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 32000-32500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0724 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0318 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 32500-33000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0748 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0339 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 33000-33500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0734 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0358 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 33500-34000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0728 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0391 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 34000-34500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0697 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0386 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 34500-35000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0654 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0287 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 35000-35500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0677 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0237 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 35500-36000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0775 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0442 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 36000-36500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0696 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0211 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 36500-37000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0682 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0183 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 37000-37500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0652 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0276 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 37500-38000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0685 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0265 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 38000-38500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0711 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0331 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 38500-39000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0712 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0360 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 39000-39500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0697 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0414 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 39500-40000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0676 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0397 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 40000-40500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0616 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0139 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 40500-41000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0576 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0314 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 41000-41500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0659 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0324 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 41500-42000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0597 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0149 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 42000-42500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0620 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0233 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 42500-43000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0617 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0241 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 43000-43500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0629 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0288 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 43500-44000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0618 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0290 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 44000-44500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0606 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0309 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 44500-45000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0640 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0371 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 45000-45500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0654 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0319 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 45500-46000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0551 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0135 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 46000-46500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0603 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0125 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 46500-47000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0539 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0182 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 47000-47500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0612 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0145 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 47500-48000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0531 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0230 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 48000-48500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0569 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0246 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 48500-49000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0600 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0266 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 49000-49500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0520 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0278 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 49500-50000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0604 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0179 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 50000-50500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0554 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0091 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 50500-51000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0541 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 51000-51500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0505 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0158 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 51500-52000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0518 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0198 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 52000-52500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0510 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0191 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 52500-53000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0509 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0188 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 53000-53500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0562 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0214 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 53500-54000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0547 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0219 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 54000-54500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0517 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0123 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 54500-55000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0464 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0071 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 55000-55500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0506 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0100 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 55500-56000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0482 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0127 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 56000-56500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0516 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0139 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 56500-57000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0492 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0158 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 57000-57500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0508 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0170 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 57500-58000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0511 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0180 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 58000-58500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0477 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0204 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 58500-59000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0477 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0077 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 59000-59500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0475 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0057 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 59500-60000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0455 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0095 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 60000-60500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0481 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0104 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 60500-61000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0439 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0116 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 61000-61500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0428 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0124 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 61500-62000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0448 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0137 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 62000-62500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0451 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0148 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 62500-63000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0421 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0143 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 63000-63500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0454 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0049 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 63500-64000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0455 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0046 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 64000-64500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0457 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0079 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 64500-65000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0449 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0063 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 65000-65500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0435 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0099 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 65500-66000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0464 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0109 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 66000-66500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0410 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0118 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 66500-67000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0450 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0127 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 67000-67500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0398 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0073 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 67500-68000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0395 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0033 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 68000-68500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0413 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 68500-69000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0397 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0076 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 69000-69500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0367 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0081 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 69500-70000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0409 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0091 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 70000-70500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0373 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0106 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 70500-71000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0372 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0109 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 71000-71500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0385 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0110 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 71500-72000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0386 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0049 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 72000-72500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0407 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0031 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 72500-73000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0402 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0059 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 73000-73500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0373 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0060 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 73500-74000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.1270 - tp: 300.0000 - fp: 100.0000 - tn: 300.0000 - fn: 100.0000 - accuracy: 0.7500 - precision: 0.7500 - recall: 0.7500 - auc: 0.7559 - val_loss: 4.0214 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 74000-74500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 3.2659 - tp: 1.0000 - fp: 399.0000 - tn: 1.0000 - fn: 399.0000 - accuracy: 0.0025 - precision: 0.0025 - recall: 0.0025 - auc: 6.2500e-06 - val_loss: 2.1671 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 74500-75000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3548 - tp: 345.0000 - fp: 55.0000 - tn: 345.0000 - fn: 55.0000 - accuracy: 0.8625 - precision: 0.8625 - recall: 0.8625 - auc: 0.9131 - val_loss: 0.1379 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 75000-75500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1328 - tp: 393.0000 - fp: 7.0000 - tn: 393.0000 - fn: 7.0000 - accuracy: 0.9825 - precision: 0.9825 - recall: 0.9825 - auc: 0.9988 - val_loss: 0.0552 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 75500-76000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0615 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0504 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 76000-76500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0562 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0510 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 76500-77000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0598 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0537 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 77000-77500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0671 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0654 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 77500-78000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0632 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0588 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 78000-78500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0657 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0593 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 78500-79000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0612 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0563 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 79000-79500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0598 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0542 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 79500-80000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0535 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0443 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 80000-80500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0511 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0401 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 80500-81000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0494 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0420 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 81000-81500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0510 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0460 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 81500-82000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0535 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0449 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 82000-82500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0490 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0455 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 82500-83000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0527 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0449 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 83000-83500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0518 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0443 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 83500-84000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0480 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0370 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 84000-84500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0455 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0315 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 84500-85000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0433 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0331 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 85000-85500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0459 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0347 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 85500-86000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0449 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0389 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 86000-86500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0459 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0397 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 86500-87000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0481 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0386 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 87000-87500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0453 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0386 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 87500-88000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0475 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0381 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 88000-88500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0441 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0295 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 88500-89000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0421 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0258 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 89000-89500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0392 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0287 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 89500-90000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0404 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0341 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 90000-90500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0404 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0341 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 90500-91000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.8188 - tp: 185.0000 - fp: 215.0000 - tn: 185.0000 - fn: 215.0000 - accuracy: 0.4625 - precision: 0.4625 - recall: 0.4625 - auc: 0.4867 - val_loss: 0.6111 - val_tp: 82.0000 - val_fp: 18.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.8200 - val_precision: 0.8200 - val_recall: 0.8200 - val_auc: 0.8344
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 91000-91500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0495 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0462 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 91500-92000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0516 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0471 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 92000-92500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.9736 - tp: 140.0000 - fp: 260.0000 - tn: 140.0000 - fn: 260.0000 - accuracy: 0.3500 - precision: 0.3500 - recall: 0.3500 - auc: 0.3408 - val_loss: 3.1542 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 92500-93000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5850 - tp: 329.0000 - fp: 71.0000 - tn: 329.0000 - fn: 71.0000 - accuracy: 0.8225 - precision: 0.8225 - recall: 0.8225 - auc: 0.8253 - val_loss: 0.0508 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 93000-93500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0579 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6628 - val_tp: 45.0000 - val_fp: 55.0000 - val_tn: 45.0000 - val_fn: 55.0000 - val_accuracy: 0.4500 - val_precision: 0.4500 - val_recall: 0.4500 - val_auc: 0.5850
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 93500-94000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.6099 - tp: 179.0000 - fp: 221.0000 - tn: 179.0000 - fn: 221.0000 - accuracy: 0.4475 - precision: 0.4475 - recall: 0.4475 - auc: 0.4510 - val_loss: 0.0720 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 94000-94500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0769 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0785 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 94500-95000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0843 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - val_loss: 0.0825 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 95000-95500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0771 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0753 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 95500-96000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0743 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0712 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 96000-96500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0712 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0778 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 96500-97000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0825 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0852 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 97000-97500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0853 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0827 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 97500-98000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0732 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0704 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 98000-98500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0651 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0602 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 98500-99000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0612 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0580 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 99000-99500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0629 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0558 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 99500-100000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0563 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0532 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 100000-100500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0559 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0506 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 100500-101000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0545 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0624 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 101000-101500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0630 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0660 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 101500-102000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0637 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0653 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 102000-102500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0597 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0553 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 102500-103000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0560 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0479 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 103000-103500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.3143 - tp: 92.0000 - fp: 308.0000 - tn: 92.0000 - fn: 308.0000 - accuracy: 0.2300 - precision: 0.2300 - recall: 0.2300 - auc: 0.2337 - val_loss: 2.8659 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 103500-104000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.1156 - tp: 91.0000 - fp: 309.0000 - tn: 91.0000 - fn: 309.0000 - accuracy: 0.2275 - precision: 0.2275 - recall: 0.2275 - auc: 0.1881 - val_loss: 0.0802 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 104000-104500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0866 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0877 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 104500-105000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0873 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0859 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 105000-105500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0827 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0820 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 105500-106000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0842 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0823 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 106000-106500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0806 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0800 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 106500-107000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0790 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0769 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 107000-107500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0772 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0749 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 107500-108000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0869 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 0.9998 - val_loss: 0.0766 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 108000-108500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0759 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0745 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 108500-109000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0732 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0672 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 109000-109500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0694 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0684 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 109500-110000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0699 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0657 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 110000-110500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0674 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0634 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 110500-111000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0636 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0602 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 111000-111500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0626 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0593 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 111500-112000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0622 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0593 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 112000-112500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0612 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0584 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 112500-113000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0596 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0574 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 113000-113500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0590 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0562 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 113500-114000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0590 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0550 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 114000-114500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0565 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0532 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 114500-115000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0539 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0515 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 115000-115500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0538 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0512 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 115500-116000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4699 - tp: 343.0000 - fp: 57.0000 - tn: 343.0000 - fn: 57.0000 - accuracy: 0.8575 - precision: 0.8575 - recall: 0.8575 - auc: 0.8640 - val_loss: 3.0077 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 116000-116500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.1797 - tp: 73.0000 - fp: 327.0000 - tn: 73.0000 - fn: 327.0000 - accuracy: 0.1825 - precision: 0.1825 - recall: 0.1825 - auc: 0.1865 - val_loss: 1.0763 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 116500-117000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3084 - tp: 364.0000 - fp: 36.0000 - tn: 364.0000 - fn: 36.0000 - accuracy: 0.9100 - precision: 0.9100 - recall: 0.9100 - auc: 0.9002 - val_loss: 0.0827 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 117000-117500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.4921 - tp: 0.0000e+00 - fp: 400.0000 - tn: 0.0000e+00 - fn: 400.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 2.1829 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 117500-118000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.2114 - tp: 180.0000 - fp: 220.0000 - tn: 180.0000 - fn: 220.0000 - accuracy: 0.4500 - precision: 0.4500 - recall: 0.4500 - auc: 0.5021 - val_loss: 0.0759 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 118000-118500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0885 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0704 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 118500-119000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0814 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0644 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 119000-119500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0802 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0775 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 119500-120000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0749 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0522 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 120000-120500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0729 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1216 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 120500-121000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2469 - tp: 371.0000 - fp: 29.0000 - tn: 371.0000 - fn: 29.0000 - accuracy: 0.9275 - precision: 0.9275 - recall: 0.9275 - auc: 0.9605 - val_loss: 0.0979 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 121000-121500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0898 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - val_loss: 0.0797 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 121500-122000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0833 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0798 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 122000-122500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0829 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0840 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 122500-123000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0850 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0867 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 123000-123500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0663 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0501 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 123500-124000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0587 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0454 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 124000-124500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0589 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0511 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 124500-125000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0629 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0623 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 125000-125500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0705 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0705 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 125500-126000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0725 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0789 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 126000-126500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0833 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0822 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 126500-127000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0871 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0835 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 127000-127500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0864 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - val_loss: 0.0552 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 127500-128000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0566 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0508 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 128000-128500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0543 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0446 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 128500-129000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0529 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0475 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 129000-129500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0533 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0499 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 129500-130000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0535 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0408 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 130000-130500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0549 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0492 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 130500-131000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0533 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0506 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 131000-131500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0569 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0547 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 131500-132000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0550 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0419 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 132000-132500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0486 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0386 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 132500-133000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0478 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8689 - val_tp: 18.0000 - val_fp: 82.0000 - val_tn: 18.0000 - val_fn: 82.0000 - val_accuracy: 0.1800 - val_precision: 0.1800 - val_recall: 0.1800 - val_auc: 0.3174
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 133000-133500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.1314 - tp: 75.0000 - fp: 325.0000 - tn: 75.0000 - fn: 325.0000 - accuracy: 0.1875 - precision: 0.1875 - recall: 0.1875 - auc: 0.1870 - val_loss: 0.0440 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 133500-134000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0526 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0439 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 134000-134500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0538 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0525 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 134500-135000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0586 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0408 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 135000-135500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0557 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0415 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 135500-136000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0431 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0238 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 136000-136500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0456 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0251 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 136500-137000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0479 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0265 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 137000-137500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0448 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0332 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 137500-138000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0488 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0373 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 138000-138500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0610 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 0.9956 - val_loss: 0.0348 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 138500-139000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0473 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0392 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 139000-139500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0554 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0453 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 139500-140000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0562 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0306 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 140000-140500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0508 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0303 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 140500-141000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0432 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0241 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 141000-141500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0430 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0264 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 141500-142000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0423 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0263 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 142000-142500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0400 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0257 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 142500-143000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0416 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9442 - val_tp: 54.0000 - val_fp: 46.0000 - val_tn: 54.0000 - val_fn: 46.0000 - val_accuracy: 0.5400 - val_precision: 0.5400 - val_recall: 0.5400 - val_auc: 0.7758
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 143000-143500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.0212 - tp: 108.0000 - fp: 292.0000 - tn: 108.0000 - fn: 292.0000 - accuracy: 0.2700 - precision: 0.2700 - recall: 0.2700 - auc: 0.3070 - val_loss: 0.3439 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 143500-144000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7096 - tp: 310.0000 - fp: 90.0000 - tn: 310.0000 - fn: 90.0000 - accuracy: 0.7750 - precision: 0.7750 - recall: 0.7750 - auc: 0.8402 - val_loss: 0.0235 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 144000-144500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0471 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0181 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 144500-145000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0483 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0382 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 145000-145500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0733 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0262 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 145500-146000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0666 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 0.9957 - val_loss: 0.0420 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 146000-146500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0592 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0406 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 146500-147000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0582 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0413 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 147000-147500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0574 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0427 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 147500-148000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0749 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 0.9953 - val_loss: 0.0298 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 148000-148500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0420 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0147 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 148500-149000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0440 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0236 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 149000-149500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0426 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0168 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 149500-150000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0451 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0347 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 150000-150500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0486 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0440 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 150500-151000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0455 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0322 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 151000-151500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0964 - tp: 392.0000 - fp: 8.0000 - tn: 392.0000 - fn: 8.0000 - accuracy: 0.9800 - precision: 0.9800 - recall: 0.9800 - auc: 0.9990 - val_loss: 0.0464 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 151500-152000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0469 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0247 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 152000-152500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0392 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0169 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 152500-153000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0403 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0206 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 153000-153500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0390 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0109 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 153500-154000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0399 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0258 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 154000-154500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0412 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0310 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 154500-155000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0424 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0366 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 155000-155500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0452 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0300 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 155500-156000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0433 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0320 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 156000-156500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0408 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0142 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 156500-157000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0371 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0124 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 157000-157500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0363 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0169 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 157500-158000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0378 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0178 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 158000-158500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0352 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0176 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 158500-159000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0333 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0204 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 159000-159500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0405 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0232 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 159500-160000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0344 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0206 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 160000-160500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0380 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0151 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 160500-161000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0366 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0128 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 161000-161500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0364 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0170 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 161500-162000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0366 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0119 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 162000-162500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0346 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0206 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 162500-163000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0364 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0168 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 163000-163500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0341 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0191 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 163500-164000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0338 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0143 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 164000-164500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0347 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0119 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 164500-165000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0327 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0089 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 165000-165500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0326 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0097 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 165500-166000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0333 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0129 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 166000-166500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0320 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0077 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 166500-167000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0313 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0121 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 167000-167500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0333 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0133 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 167500-168000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0332 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0155 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 168000-168500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0314 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0143 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 168500-169000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0328 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0129 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 169000-169500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0301 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0054 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 169500-170000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0304 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0074 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 170000-170500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0287 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0060 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 170500-171000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0305 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0062 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 171000-171500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0309 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0063 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 171500-172000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0304 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0088 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 172000-172500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.1583 - tp: 291.0000 - fp: 109.0000 - tn: 291.0000 - fn: 109.0000 - accuracy: 0.7275 - precision: 0.7275 - recall: 0.7275 - auc: 0.7642 - val_loss: 4.1247 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 172500-173000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8886 - tp: 311.0000 - fp: 89.0000 - tn: 311.0000 - fn: 89.0000 - accuracy: 0.7775 - precision: 0.7775 - recall: 0.7775 - auc: 0.7623 - val_loss: 3.2132 - val_tp: 10.0000 - val_fp: 90.0000 - val_tn: 10.0000 - val_fn: 90.0000 - val_accuracy: 0.1000 - val_precision: 0.1000 - val_recall: 0.1000 - val_auc: 0.0700
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 173000-173500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 3.2756 - tp: 0.0000e+00 - fp: 400.0000 - tn: 0.0000e+00 - fn: 400.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 2.9809 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 173500-174000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2141 - tp: 378.0000 - fp: 22.0000 - tn: 378.0000 - fn: 22.0000 - accuracy: 0.9450 - precision: 0.9450 - recall: 0.9450 - auc: 0.9471 - val_loss: 0.0597 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 174000-174500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0579 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0535 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 174500-175000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0578 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0492 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 175000-175500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0544 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0452 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 175500-176000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0532 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0450 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 176000-176500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0503 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0442 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 176500-177000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0519 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0456 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 177000-177500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0589 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0616 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 177500-178000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0562 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0383 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 178000-178500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0468 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0366 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 178500-179000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0436 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0329 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 179000-179500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0457 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0374 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 179500-180000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0459 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0367 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 180000-180500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0429 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0371 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 180500-181000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0423 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0380 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 181000-181500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0848 - tp: 397.0000 - fp: 3.0000 - tn: 397.0000 - fn: 3.0000 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925 - auc: 0.9961 - val_loss: 0.0638 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 181500-182000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0579 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0454 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 182000-182500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0442 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0344 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 182500-183000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0420 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0336 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 183000-183500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0412 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0307 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 183500-184000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0396 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0342 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 184000-184500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0403 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0337 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 184500-185000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0406 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0342 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 185000-185500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0383 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0372 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 185500-186000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0431 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0343 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 186000-186500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0383 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0340 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 186500-187000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0456 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0382 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 187000-187500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0393 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0259 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 187500-188000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0351 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0246 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 188000-188500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0351 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0269 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 188500-189000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0343 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0262 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 189000-189500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0351 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0268 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 189500-190000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0341 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0275 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 190000-190500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0361 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0286 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 190500-191000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0368 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0320 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 191000-191500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0346 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0222 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 191500-192000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0364 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0351 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 192000-192500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0422 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0324 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 192500-193000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0326 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0193 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 193000-193500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0328 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0203 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 193500-194000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0320 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0190 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 194000-194500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0320 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0208 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 194500-195000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0321 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0219 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 195000-195500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0328 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0232 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 195500-196000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0333 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0272 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 196000-196500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0341 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0247 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 196500-197000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0315 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0184 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 197000-197500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0342 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0321 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 197500-198000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0335 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0238 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 198000-198500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7204 - tp: 313.0000 - fp: 87.0000 - tn: 313.0000 - fn: 87.0000 - accuracy: 0.7825 - precision: 0.7825 - recall: 0.7825 - auc: 0.8419 - val_loss: 1.5352 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 198500-199000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.0668 - tp: 123.0000 - fp: 277.0000 - tn: 123.0000 - fn: 277.0000 - accuracy: 0.3075 - precision: 0.3075 - recall: 0.3075 - auc: 0.3949 - val_loss: 0.0434 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 199000-199500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.7651 - tp: 157.0000 - fp: 243.0000 - tn: 157.0000 - fn: 243.0000 - accuracy: 0.3925 - precision: 0.3925 - recall: 0.3925 - auc: 0.5547 - val_loss: 6.6956e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 199500-200000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.2331 - tp: 233.0000 - fp: 167.0000 - tn: 233.0000 - fn: 167.0000 - accuracy: 0.5825 - precision: 0.5825 - recall: 0.5825 - auc: 0.6815 - val_loss: 0.0357 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 200000-200500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0448 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0113 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 200500-201000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0456 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0221 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 201000-201500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0525 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - val_loss: 0.0256 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 201500-202000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0472 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0247 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 202000-202500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0572 - tp: 398.0000 - fp: 2.0000 - tn: 398.0000 - fn: 2.0000 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - auc: 0.9999 - val_loss: 0.0443 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 202500-203000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0499 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0319 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 203000-203500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0381 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0145 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 203500-204000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0381 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0167 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 204000-204500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0415 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0130 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 204500-205000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0507 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 0.9998 - val_loss: 0.0240 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 205000-205500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0415 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0212 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 205500-206000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0393 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0221 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 206000-206500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0393 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0252 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 206500-207000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0377 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0228 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 207000-207500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0356 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0127 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 207500-208000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0348 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0356 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 208000-208500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0438 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0298 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 208500-209000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0340 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0111 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 209000-209500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0336 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0177 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 209500-210000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0385 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0161 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 210000-210500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0351 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0190 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 210500-211000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0376 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0232 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 211000-211500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0381 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0286 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 211500-212000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0411 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0245 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 212000-212500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0350 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0196 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 212500-213000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0325 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0112 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 213000-213500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0536 - tp: 397.0000 - fp: 3.0000 - tn: 397.0000 - fn: 3.0000 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925 - auc: 0.9999 - val_loss: 0.0294 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 213500-214000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0364 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0179 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 214000-214500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0331 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0167 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 214500-215000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0312 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0169 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 215000-215500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0312 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0107 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 215500-216000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0318 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0194 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 216000-216500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0341 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0203 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 216500-217000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0329 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0218 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 217000-217500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0324 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0208 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 217500-218000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0321 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0224 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 218000-218500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0297 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0151 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 218500-219000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0286 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0103 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 219000-219500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0303 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0177 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 219500-220000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0309 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0182 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 220000-220500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0299 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0181 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 220500-221000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0284 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0209 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 221000-221500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0334 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - val_loss: 0.0247 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 221500-222000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0336 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0229 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 222000-222500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0357 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0211 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 222500-223000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0266 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0099 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 223000-223500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0254 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0098 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 223500-224000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0280 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0121 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 224000-224500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0288 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0115 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 224500-225000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0263 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0127 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 225000-225500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0292 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0150 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 225500-226000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0289 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0188 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 226000-226500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0256 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0159 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 226500-227000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0298 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0129 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 227000-227500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0271 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0077 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 227500-228000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6985 - tp: 328.0000 - fp: 72.0000 - tn: 328.0000 - fn: 72.0000 - accuracy: 0.8200 - precision: 0.8200 - recall: 0.8200 - auc: 0.8460 - val_loss: 3.5761 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 228000-228500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.4913 - tp: 82.0000 - fp: 318.0000 - tn: 82.0000 - fn: 318.0000 - accuracy: 0.2050 - precision: 0.2050 - recall: 0.2050 - auc: 0.1972 - val_loss: 0.9862 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 228500-229000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.8838 - tp: 145.0000 - fp: 255.0000 - tn: 145.0000 - fn: 255.0000 - accuracy: 0.3625 - precision: 0.3625 - recall: 0.3625 - auc: 0.4911 - val_loss: 0.0135 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 229000-229500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.6256 - tp: 167.0000 - fp: 233.0000 - tn: 167.0000 - fn: 233.0000 - accuracy: 0.4175 - precision: 0.4175 - recall: 0.4175 - auc: 0.6268 - val_loss: 5.7633e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 229500-230000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.5569 - tp: 92.0000 - fp: 308.0000 - tn: 92.0000 - fn: 308.0000 - accuracy: 0.2300 - precision: 0.2300 - recall: 0.2300 - auc: 0.3121 - val_loss: 2.6518 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 230000-230500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.1896 - tp: 64.0000 - fp: 336.0000 - tn: 64.0000 - fn: 336.0000 - accuracy: 0.1600 - precision: 0.1600 - recall: 0.1600 - auc: 0.2033 - val_loss: 0.7102 - val_tp: 63.0000 - val_fp: 37.0000 - val_tn: 63.0000 - val_fn: 37.0000 - val_accuracy: 0.6300 - val_precision: 0.6300 - val_recall: 0.6300 - val_auc: 0.4460
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 230500-231000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.4123 - tp: 174.0000 - fp: 226.0000 - tn: 174.0000 - fn: 226.0000 - accuracy: 0.4350 - precision: 0.4350 - recall: 0.4350 - auc: 0.6078 - val_loss: 7.2516e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 231000-231500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.2547 - tp: 199.0000 - fp: 201.0000 - tn: 199.0000 - fn: 201.0000 - accuracy: 0.4975 - precision: 0.4975 - recall: 0.4975 - auc: 0.6850 - val_loss: 5.1319e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 231500-232000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.4413 - tp: 168.0000 - fp: 232.0000 - tn: 168.0000 - fn: 232.0000 - accuracy: 0.4200 - precision: 0.4200 - recall: 0.4200 - auc: 0.6242 - val_loss: 4.6796e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 232000-232500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.2846 - tp: 182.0000 - fp: 218.0000 - tn: 182.0000 - fn: 218.0000 - accuracy: 0.4550 - precision: 0.4550 - recall: 0.4550 - auc: 0.6332 - val_loss: 0.0123 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 232500-233000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.1818 - tp: 202.0000 - fp: 198.0000 - tn: 202.0000 - fn: 198.0000 - accuracy: 0.5050 - precision: 0.5050 - recall: 0.5050 - auc: 0.7107 - val_loss: 8.6458e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 233000-233500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.1960 - tp: 193.0000 - fp: 207.0000 - tn: 193.0000 - fn: 207.0000 - accuracy: 0.4825 - precision: 0.4825 - recall: 0.4825 - auc: 0.7030 - val_loss: 3.5885e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 233500-234000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.1436 - tp: 203.0000 - fp: 197.0000 - tn: 203.0000 - fn: 197.0000 - accuracy: 0.5075 - precision: 0.5075 - recall: 0.5075 - auc: 0.7108 - val_loss: 6.0622e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 234000-234500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.0388 - tp: 217.0000 - fp: 183.0000 - tn: 217.0000 - fn: 183.0000 - accuracy: 0.5425 - precision: 0.5425 - recall: 0.5425 - auc: 0.7633 - val_loss: 9.6713e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 234500-235000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.0705 - tp: 207.0000 - fp: 193.0000 - tn: 207.0000 - fn: 193.0000 - accuracy: 0.5175 - precision: 0.5175 - recall: 0.5175 - auc: 0.7480 - val_loss: 5.0245e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 235000-235500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.1349 - tp: 191.0000 - fp: 209.0000 - tn: 191.0000 - fn: 209.0000 - accuracy: 0.4775 - precision: 0.4775 - recall: 0.4775 - auc: 0.7168 - val_loss: 1.9026e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 235500-236000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.0586 - tp: 201.0000 - fp: 199.0000 - tn: 201.0000 - fn: 199.0000 - accuracy: 0.5025 - precision: 0.5025 - recall: 0.5025 - auc: 0.7402 - val_loss: 1.2993e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 236000-236500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.0658 - tp: 197.0000 - fp: 203.0000 - tn: 197.0000 - fn: 203.0000 - accuracy: 0.4925 - precision: 0.4925 - recall: 0.4925 - auc: 0.7272 - val_loss: 9.6929e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 236500-237000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.1036 - tp: 186.0000 - fp: 214.0000 - tn: 186.0000 - fn: 214.0000 - accuracy: 0.4650 - precision: 0.4650 - recall: 0.4650 - auc: 0.7005 - val_loss: 9.3030e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 237000-237500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.0239 - tp: 197.0000 - fp: 203.0000 - tn: 197.0000 - fn: 203.0000 - accuracy: 0.4925 - precision: 0.4925 - recall: 0.4925 - auc: 0.7399 - val_loss: 8.6999e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 237500-238000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9262 - tp: 213.0000 - fp: 187.0000 - tn: 213.0000 - fn: 187.0000 - accuracy: 0.5325 - precision: 0.5325 - recall: 0.5325 - auc: 0.7698 - val_loss: 8.5449e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 238000-238500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9831 - tp: 199.0000 - fp: 201.0000 - tn: 199.0000 - fn: 201.0000 - accuracy: 0.4975 - precision: 0.4975 - recall: 0.4975 - auc: 0.7299 - val_loss: 8.2111e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 238500-239000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9290 - tp: 206.0000 - fp: 194.0000 - tn: 206.0000 - fn: 194.0000 - accuracy: 0.5150 - precision: 0.5150 - recall: 0.5150 - auc: 0.7551 - val_loss: 5.9867e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 239000-239500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9960 - tp: 188.0000 - fp: 212.0000 - tn: 188.0000 - fn: 212.0000 - accuracy: 0.4700 - precision: 0.4700 - recall: 0.4700 - auc: 0.7164 - val_loss: 5.0874e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 239500-240000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9193 - tp: 200.0000 - fp: 200.0000 - tn: 200.0000 - fn: 200.0000 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.5000 - auc: 0.7475 - val_loss: 4.5228e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 240000-240500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8791 - tp: 206.0000 - fp: 194.0000 - tn: 206.0000 - fn: 194.0000 - accuracy: 0.5150 - precision: 0.5150 - recall: 0.5150 - auc: 0.7551 - val_loss: 3.1209e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 240500-241000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8632 - tp: 206.0000 - fp: 194.0000 - tn: 206.0000 - fn: 194.0000 - accuracy: 0.5150 - precision: 0.5150 - recall: 0.5150 - auc: 0.7602 - val_loss: 3.8981e-07 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 241000-241500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8751 - tp: 200.0000 - fp: 200.0000 - tn: 200.0000 - fn: 200.0000 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.5000 - auc: 0.7475 - val_loss: 2.8133e-07 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 241500-242000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8411 - tp: 204.0000 - fp: 196.0000 - tn: 204.0000 - fn: 196.0000 - accuracy: 0.5100 - precision: 0.5100 - recall: 0.5100 - auc: 0.7599 - val_loss: 2.4557e-07 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 242000-242500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7604 - tp: 221.0000 - fp: 179.0000 - tn: 221.0000 - fn: 179.0000 - accuracy: 0.5525 - precision: 0.5525 - recall: 0.5525 - auc: 0.7930 - val_loss: 2.2411e-07 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 242500-243000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8107 - tp: 205.0000 - fp: 195.0000 - tn: 205.0000 - fn: 195.0000 - accuracy: 0.5125 - precision: 0.5125 - recall: 0.5125 - auc: 0.7623 - val_loss: 1.5497e-07 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 243000-243500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7998 - tp: 205.0000 - fp: 195.0000 - tn: 205.0000 - fn: 195.0000 - accuracy: 0.5125 - precision: 0.5125 - recall: 0.5125 - auc: 0.7575 - val_loss: 7.3075e-07 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 243500-244000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8005 - tp: 201.0000 - fp: 199.0000 - tn: 201.0000 - fn: 199.0000 - accuracy: 0.5025 - precision: 0.5025 - recall: 0.5025 - auc: 0.7475 - val_loss: 1.0252e-07 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 244000-244500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8169 - tp: 193.0000 - fp: 207.0000 - tn: 193.0000 - fn: 207.0000 - accuracy: 0.4825 - precision: 0.4825 - recall: 0.4825 - auc: 0.7322 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 244500-245000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7579 - tp: 205.0000 - fp: 195.0000 - tn: 205.0000 - fn: 195.0000 - accuracy: 0.5125 - precision: 0.5125 - recall: 0.5125 - auc: 0.7608 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 245000-245500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7624 - tp: 200.0000 - fp: 200.0000 - tn: 200.0000 - fn: 200.0000 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.5000 - auc: 0.7500 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 245500-246000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7177 - tp: 209.0000 - fp: 191.0000 - tn: 209.0000 - fn: 191.0000 - accuracy: 0.5225 - precision: 0.5225 - recall: 0.5225 - auc: 0.7696 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 246000-246500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7813 - tp: 188.0000 - fp: 212.0000 - tn: 188.0000 - fn: 212.0000 - accuracy: 0.4700 - precision: 0.4700 - recall: 0.4700 - auc: 0.7191 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 246500-247000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7242 - tp: 200.0000 - fp: 200.0000 - tn: 200.0000 - fn: 200.0000 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.5000 - auc: 0.7500 - val_loss: 2.7882e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 247000-247500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7931 - tp: 177.0000 - fp: 223.0000 - tn: 177.0000 - fn: 223.0000 - accuracy: 0.4425 - precision: 0.4425 - recall: 0.4425 - auc: 0.6892 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 247500-248000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6775 - tp: 206.0000 - fp: 194.0000 - tn: 206.0000 - fn: 194.0000 - accuracy: 0.5150 - precision: 0.5150 - recall: 0.5150 - auc: 0.7648 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 248000-248500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6668 - tp: 206.0000 - fp: 194.0000 - tn: 206.0000 - fn: 194.0000 - accuracy: 0.5150 - precision: 0.5150 - recall: 0.5150 - auc: 0.7648 - val_loss: 5.7697e-07 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 248500-249000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6356 - tp: 212.0000 - fp: 188.0000 - tn: 212.0000 - fn: 188.0000 - accuracy: 0.5300 - precision: 0.5300 - recall: 0.5300 - auc: 0.7791 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 249000-249500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6647 - tp: 200.0000 - fp: 200.0000 - tn: 200.0000 - fn: 200.0000 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.5000 - auc: 0.7500 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 249500-250000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6423 - tp: 204.0000 - fp: 196.0000 - tn: 204.0000 - fn: 196.0000 - accuracy: 0.5100 - precision: 0.5100 - recall: 0.5100 - auc: 0.7574 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 250000-250500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6073 - tp: 211.0000 - fp: 189.0000 - tn: 211.0000 - fn: 189.0000 - accuracy: 0.5275 - precision: 0.5275 - recall: 0.5275 - auc: 0.7767 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 250500-251000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5569 - tp: 224.0000 - fp: 176.0000 - tn: 224.0000 - fn: 176.0000 - accuracy: 0.5600 - precision: 0.5600 - recall: 0.5600 - auc: 0.8064 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 251000-251500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6311 - tp: 198.0000 - fp: 202.0000 - tn: 198.0000 - fn: 202.0000 - accuracy: 0.4950 - precision: 0.4950 - recall: 0.4950 - auc: 0.7424 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 251500-252000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5971 - tp: 205.0000 - fp: 195.0000 - tn: 205.0000 - fn: 195.0000 - accuracy: 0.5125 - precision: 0.5125 - recall: 0.5125 - auc: 0.7623 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 252000-252500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5729 - tp: 210.0000 - fp: 190.0000 - tn: 210.0000 - fn: 190.0000 - accuracy: 0.5250 - precision: 0.5250 - recall: 0.5250 - auc: 0.7744 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 252500-253000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5734 - tp: 207.0000 - fp: 193.0000 - tn: 207.0000 - fn: 193.0000 - accuracy: 0.5175 - precision: 0.5175 - recall: 0.5175 - auc: 0.7648 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 253000-253500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6410 - tp: 180.0000 - fp: 220.0000 - tn: 180.0000 - fn: 220.0000 - accuracy: 0.4500 - precision: 0.4500 - recall: 0.4500 - auc: 0.6975 - val_loss: 3.9339e-08 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 253500-254000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5885 - tp: 195.0000 - fp: 205.0000 - tn: 195.0000 - fn: 205.0000 - accuracy: 0.4875 - precision: 0.4875 - recall: 0.4875 - auc: 0.7348 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 254000-254500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6075 - tp: 184.0000 - fp: 216.0000 - tn: 184.0000 - fn: 216.0000 - accuracy: 0.4600 - precision: 0.4600 - recall: 0.4600 - auc: 0.7084 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 254500-255000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5683 - tp: 195.0000 - fp: 205.0000 - tn: 195.0000 - fn: 205.0000 - accuracy: 0.4875 - precision: 0.4875 - recall: 0.4875 - auc: 0.7373 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 255000-255500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5578 - tp: 195.0000 - fp: 205.0000 - tn: 195.0000 - fn: 205.0000 - accuracy: 0.4875 - precision: 0.4875 - recall: 0.4875 - auc: 0.7373 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 255500-256000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5478 - tp: 195.0000 - fp: 205.0000 - tn: 195.0000 - fn: 205.0000 - accuracy: 0.4875 - precision: 0.4875 - recall: 0.4875 - auc: 0.7373 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 256000-256500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4884 - tp: 214.0000 - fp: 186.0000 - tn: 214.0000 - fn: 186.0000 - accuracy: 0.5350 - precision: 0.5350 - recall: 0.5350 - auc: 0.7838 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 256500-257000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4995 - tp: 207.0000 - fp: 193.0000 - tn: 207.0000 - fn: 193.0000 - accuracy: 0.5175 - precision: 0.5175 - recall: 0.5175 - auc: 0.7672 - val_loss: 9.5367e-09 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 257000-257500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5090 - tp: 200.0000 - fp: 200.0000 - tn: 200.0000 - fn: 200.0000 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.5000 - auc: 0.7500 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 257500-258000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5230 - tp: 191.0000 - fp: 209.0000 - tn: 191.0000 - fn: 209.0000 - accuracy: 0.4775 - precision: 0.4775 - recall: 0.4775 - auc: 0.7270 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 258000-258500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4944 - tp: 199.0000 - fp: 201.0000 - tn: 199.0000 - fn: 201.0000 - accuracy: 0.4975 - precision: 0.4975 - recall: 0.4975 - auc: 0.7475 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 258500-259000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4554 - tp: 212.0000 - fp: 188.0000 - tn: 212.0000 - fn: 188.0000 - accuracy: 0.5300 - precision: 0.5300 - recall: 0.5300 - auc: 0.7791 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 259000-259500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5035 - tp: 189.0000 - fp: 211.0000 - tn: 189.0000 - fn: 211.0000 - accuracy: 0.4725 - precision: 0.4725 - recall: 0.4725 - auc: 0.7217 - val_loss: 6.9141e-08 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 259500-260000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4731 - tp: 198.0000 - fp: 202.0000 - tn: 198.0000 - fn: 202.0000 - accuracy: 0.4950 - precision: 0.4950 - recall: 0.4950 - auc: 0.7450 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 260000-260500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4682 - tp: 197.0000 - fp: 203.0000 - tn: 197.0000 - fn: 203.0000 - accuracy: 0.4925 - precision: 0.4925 - recall: 0.4925 - auc: 0.7424 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 260500-261000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4311 - tp: 210.0000 - fp: 190.0000 - tn: 210.0000 - fn: 190.0000 - accuracy: 0.5250 - precision: 0.5250 - recall: 0.5250 - auc: 0.7744 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 261000-261500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5084 - tp: 173.0000 - fp: 227.0000 - tn: 173.0000 - fn: 227.0000 - accuracy: 0.4325 - precision: 0.4325 - recall: 0.4325 - auc: 0.6779 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 261500-262000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4654 - tp: 188.0000 - fp: 212.0000 - tn: 188.0000 - fn: 212.0000 - accuracy: 0.4700 - precision: 0.4700 - recall: 0.4700 - auc: 0.7191 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 262000-262500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4490 - tp: 192.0000 - fp: 208.0000 - tn: 192.0000 - fn: 208.0000 - accuracy: 0.4800 - precision: 0.4800 - recall: 0.4800 - auc: 0.7296 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 262500-263000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3977 - tp: 213.0000 - fp: 187.0000 - tn: 213.0000 - fn: 187.0000 - accuracy: 0.5325 - precision: 0.5325 - recall: 0.5325 - auc: 0.7814 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 263000-263500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4224 - tp: 198.0000 - fp: 202.0000 - tn: 198.0000 - fn: 202.0000 - accuracy: 0.4950 - precision: 0.4950 - recall: 0.4950 - auc: 0.7450 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 263500-264000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.8651 - tp: 205.0000 - fp: 195.0000 - tn: 205.0000 - fn: 195.0000 - accuracy: 0.5125 - precision: 0.5125 - recall: 0.5125 - auc: 0.5817 - val_loss: 1.3305 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 264000-264500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.2661 - tp: 289.0000 - fp: 111.0000 - tn: 289.0000 - fn: 111.0000 - accuracy: 0.7225 - precision: 0.7225 - recall: 0.7225 - auc: 0.6195 - val_loss: 0.2716 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 264500-265000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5678 - tp: 344.0000 - fp: 56.0000 - tn: 344.0000 - fn: 56.0000 - accuracy: 0.8600 - precision: 0.8600 - recall: 0.8600 - auc: 0.8418 - val_loss: 0.7420 - val_tp: 50.0000 - val_fp: 50.0000 - val_tn: 50.0000 - val_fn: 50.0000 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_auc: 0.7235
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 265000-265500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.5078 - tp: 272.0000 - fp: 128.0000 - tn: 272.0000 - fn: 128.0000 - accuracy: 0.6800 - precision: 0.6800 - recall: 0.6800 - auc: 0.5368 - val_loss: 0.2523 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 265500-266000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6074 - tp: 336.0000 - fp: 64.0000 - tn: 336.0000 - fn: 64.0000 - accuracy: 0.8400 - precision: 0.8400 - recall: 0.8400 - auc: 0.8348 - val_loss: 0.2417 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 266000-266500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4077 - tp: 381.0000 - fp: 19.0000 - tn: 381.0000 - fn: 19.0000 - accuracy: 0.9525 - precision: 0.9525 - recall: 0.9525 - auc: 0.9895 - val_loss: 0.2580 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 266500-267000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4073 - tp: 381.0000 - fp: 19.0000 - tn: 381.0000 - fn: 19.0000 - accuracy: 0.9525 - precision: 0.9525 - recall: 0.9525 - auc: 0.9788 - val_loss: 0.2693 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 267000-267500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4063 - tp: 396.0000 - fp: 4.0000 - tn: 396.0000 - fn: 4.0000 - accuracy: 0.9900 - precision: 0.9900 - recall: 0.9900 - auc: 0.9998 - val_loss: 0.3449 - val_tp: 99.0000 - val_fp: 1.0000 - val_tn: 99.0000 - val_fn: 1.0000 - val_accuracy: 0.9900 - val_precision: 0.9900 - val_recall: 0.9900 - val_auc: 0.9999
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 267500-268000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4319 - tp: 383.0000 - fp: 17.0000 - tn: 383.0000 - fn: 17.0000 - accuracy: 0.9575 - precision: 0.9575 - recall: 0.9575 - auc: 0.9592 - val_loss: 0.2533 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 268000-268500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3480 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - val_loss: 0.2464 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 268500-269000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3408 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2091 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 269000-269500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3414 - tp: 395.0000 - fp: 5.0000 - tn: 395.0000 - fn: 5.0000 - accuracy: 0.9875 - precision: 0.9875 - recall: 0.9875 - auc: 0.9930 - val_loss: 0.2246 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 269500-270000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3360 - tp: 393.0000 - fp: 7.0000 - tn: 393.0000 - fn: 7.0000 - accuracy: 0.9825 - precision: 0.9825 - recall: 0.9825 - auc: 0.9936 - val_loss: 0.1969 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 270000-270500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3388 - tp: 386.0000 - fp: 14.0000 - tn: 386.0000 - fn: 14.0000 - accuracy: 0.9650 - precision: 0.9650 - recall: 0.9650 - auc: 0.9858 - val_loss: 0.1924 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 270500-271000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3201 - tp: 394.0000 - fp: 6.0000 - tn: 394.0000 - fn: 6.0000 - accuracy: 0.9850 - precision: 0.9850 - recall: 0.9850 - auc: 0.9967 - val_loss: 0.1895 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 271000-271500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2712 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 0.9975 - val_loss: 0.1924 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 271500-272000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2731 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2299 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 272000-272500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2686 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2288 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 272500-273000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2366 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1611 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 273000-273500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2217 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1449 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 273500-274000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2260 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1267 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 274000-274500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2269 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1044 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 274500-275000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2345 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1111 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 275000-275500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2278 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1127 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 275500-276000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2246 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1768 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 276000-276500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2194 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0955 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 276500-277000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1918 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0972 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 277000-277500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2170 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0654 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 277500-278000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1897 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0523 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 278000-278500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1818 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0715 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 278500-279000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1883 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0310 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 279000-279500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.1299 - tp: 279.0000 - fp: 121.0000 - tn: 279.0000 - fn: 121.0000 - accuracy: 0.6975 - precision: 0.6975 - recall: 0.6975 - auc: 0.7126 - val_loss: 0.1372 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 279500-280000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2461 - tp: 395.0000 - fp: 5.0000 - tn: 395.0000 - fn: 5.0000 - accuracy: 0.9875 - precision: 0.9875 - recall: 0.9875 - auc: 0.9994 - val_loss: 0.1571 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 280000-280500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.4243 - tp: 119.0000 - fp: 281.0000 - tn: 119.0000 - fn: 281.0000 - accuracy: 0.2975 - precision: 0.2975 - recall: 0.2975 - auc: 0.3288 - val_loss: 0.4479 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 280500-281000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9221 - tp: 148.0000 - fp: 252.0000 - tn: 148.0000 - fn: 252.0000 - accuracy: 0.3700 - precision: 0.3700 - recall: 0.3700 - auc: 0.5443 - val_loss: 0.0899 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 281000-281500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7346 - tp: 217.0000 - fp: 183.0000 - tn: 217.0000 - fn: 183.0000 - accuracy: 0.5425 - precision: 0.5425 - recall: 0.5425 - auc: 0.6205 - val_loss: 0.3890 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 281500-282000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4650 - tp: 356.0000 - fp: 44.0000 - tn: 356.0000 - fn: 44.0000 - accuracy: 0.8900 - precision: 0.8900 - recall: 0.8900 - auc: 0.9085 - val_loss: 0.3906 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 282000-282500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3447 - tp: 389.0000 - fp: 11.0000 - tn: 389.0000 - fn: 11.0000 - accuracy: 0.9725 - precision: 0.9725 - recall: 0.9725 - auc: 0.9918 - val_loss: 0.2761 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 282500-283000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2469 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2092 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 283000-283500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2357 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1773 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 283500-284000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2162 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1708 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 284000-284500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1926 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0526 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 284500-285000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1858 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1068 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 285000-285500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1993 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1843 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 285500-286000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2074 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1744 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 286000-286500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1887 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1280 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 286500-287000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1863 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1352 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 287000-287500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1886 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1023 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 287500-288000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1817 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0790 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 288000-288500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1802 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0670 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 288500-289000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1682 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0826 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 289000-289500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1717 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0705 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 289500-290000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1536 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0147 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 290000-290500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1490 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1031 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 290500-291000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1706 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1348 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 291000-291500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1582 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0764 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 291500-292000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1646 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0543 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 292000-292500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1464 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0452 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 292500-293000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1486 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0584 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 293000-293500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1468 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0528 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 293500-294000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1346 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0098 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 294000-294500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1321 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0844 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 294500-295000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1641 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1196 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 295000-295500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1539 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1178 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 295500-296000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1519 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0697 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 296000-296500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1412 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0479 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 296500-297000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1536 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0228 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 297000-297500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1349 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0260 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 297500-298000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1390 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0229 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 298000-298500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1295 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0026 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 298500-299000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1232 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0471 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 299000-299500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1415 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0876 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 299500-300000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1303 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0290 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 300000-300500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1225 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0159 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 300500-301000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1149 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0198 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 301000-301500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1196 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0121 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 301500-302000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1213 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0188 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 302000-302500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1184 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0028 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 302500-303000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.3675 - tp: 152.0000 - fp: 248.0000 - tn: 152.0000 - fn: 248.0000 - accuracy: 0.3800 - precision: 0.3800 - recall: 0.3800 - auc: 0.3536 - val_loss: 2.2294 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 303000-303500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2700 - tp: 380.0000 - fp: 20.0000 - tn: 380.0000 - fn: 20.0000 - accuracy: 0.9500 - precision: 0.9500 - recall: 0.9500 - auc: 0.9431 - val_loss: 0.1309 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 303500-304000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1713 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1778 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 304000-304500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3809 - tp: 360.0000 - fp: 40.0000 - tn: 360.0000 - fn: 40.0000 - accuracy: 0.9000 - precision: 0.9000 - recall: 0.9000 - auc: 0.9248 - val_loss: 0.2053 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 304500-305000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1938 - tp: 390.0000 - fp: 10.0000 - tn: 390.0000 - fn: 10.0000 - accuracy: 0.9750 - precision: 0.9750 - recall: 0.9750 - auc: 0.9984 - val_loss: 0.0892 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 305000-305500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1331 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0996 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 305500-306000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1324 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0923 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 306000-306500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1350 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0853 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 306500-307000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1438 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - val_loss: 0.0808 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 307000-307500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1300 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0797 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 307500-308000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1217 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0799 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 308000-308500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1276 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0810 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 308500-309000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1324 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0752 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 309000-309500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1283 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0801 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 309500-310000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1146 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0796 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 310000-310500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1170 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0729 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 310500-311000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1137 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0636 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 311000-311500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1142 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0636 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 311500-312000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1063 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0628 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 312000-312500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0992 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0626 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 312500-313000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1072 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0619 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 313000-313500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1143 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0672 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 313500-314000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1102 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0681 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 314000-314500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1067 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0663 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 314500-315000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1049 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0573 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 315000-315500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0959 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0539 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 315500-316000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0940 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0532 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 316000-316500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1008 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0527 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 316500-317000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0946 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0521 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 317000-317500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0971 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0502 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 317500-318000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0984 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0576 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 318000-318500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1040 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0582 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 318500-319000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0930 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0527 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 319000-319500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0956 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0463 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 319500-320000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0961 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0455 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 320000-320500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0867 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0449 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 320500-321000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0900 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0444 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 321000-321500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0878 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0427 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 321500-322000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0912 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0460 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 322000-322500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0891 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0501 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 322500-323000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0898 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0504 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 323000-323500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0816 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0438 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 323500-324000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0817 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0388 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 324000-324500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0884 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0389 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 324500-325000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0867 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0386 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 325000-325500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0829 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0382 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 325500-326000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0810 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0367 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 326000-326500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0778 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0441 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 326500-327000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0789 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0453 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 327000-327500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0767 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0428 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 327500-328000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0783 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0348 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 328000-328500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0765 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0340 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 328500-329000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0729 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0333 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 329000-329500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0754 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0327 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 329500-330000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0713 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0324 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 330000-330500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0787 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0315 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 330500-331000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0692 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0388 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 331000-331500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0692 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0393 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 331500-332000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0733 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0327 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 332000-332500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0736 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0298 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 332500-333000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0667 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0292 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 333000-333500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0665 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0289 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 333500-334000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0661 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0285 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 334000-334500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0647 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0278 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 334500-335000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0665 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0336 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 335000-335500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0675 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0336 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 335500-336000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0656 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0267 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 336000-336500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0679 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0355 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 336500-337000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0669 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0322 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 337000-337500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0624 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0255 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[33m[LOSS] 0.025459723174571992[0m
[33m[INFO] epoch 3/3[0m
[33m[INFO] loading file 1-1/1 on epoch 3/3[0m
[INFO] reading file data/SWaT_Dataset_Attack_v0-fixed-zscore-train-test.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (337500, 46)
[INFO] sampling 1.0
dropping all time related columns...
[INFO] columns: Index([' Timestamp', 'FIT101', 'LIT101', ' MV101', 'P101', 'P102', ' AIT201',
       'AIT202', 'AIT203', 'FIT201', ' MV201', ' P201', 'P203', ' P204',
       'P205', 'P206', 'DPIT301', 'FIT301', 'LIT301', 'MV301', 'MV302',
       ' MV303', 'MV304', 'P302', 'AIT401', 'AIT402', 'FIT401', 'LIT401',
       'P402', 'P403', 'UV401', 'AIT501', 'AIT502', 'AIT503', 'AIT504',
       'FIT501', 'FIT502', 'FIT503', 'FIT504', 'P501', 'PIT501', 'PIT502',
       'PIT503', 'FIT601', 'P602', 'Normal/Attack'],
      dtype='object')
[INFO] processing batch 0-500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0678 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0390 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 500-1000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0648 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0372 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 1000-1500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0633 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0400 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 1500-2000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.2411 - tp: 254.0000 - fp: 146.0000 - tn: 254.0000 - fn: 146.0000 - accuracy: 0.6350 - precision: 0.6350 - recall: 0.6350 - auc: 0.6271 - val_loss: 3.1940 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 2000-2500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.9993 - tp: 0.0000e+00 - fp: 400.0000 - tn: 0.0000e+00 - fn: 400.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 2.4729 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 2500-3000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.2313 - tp: 203.0000 - fp: 197.0000 - tn: 203.0000 - fn: 197.0000 - accuracy: 0.5075 - precision: 0.5075 - recall: 0.5075 - auc: 0.4748 - val_loss: 0.1769 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 3000-3500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.9930 - tp: 111.0000 - fp: 289.0000 - tn: 111.0000 - fn: 289.0000 - accuracy: 0.2775 - precision: 0.2775 - recall: 0.2775 - auc: 0.2683 - val_loss: 0.7354 - val_tp: 91.0000 - val_fp: 9.0000 - val_tn: 91.0000 - val_fn: 9.0000 - val_accuracy: 0.9100 - val_precision: 0.9100 - val_recall: 0.9100 - val_auc: 0.8281
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 3500-4000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2413 - tp: 380.0000 - fp: 20.0000 - tn: 380.0000 - fn: 20.0000 - accuracy: 0.9500 - precision: 0.9500 - recall: 0.9500 - auc: 0.9655 - val_loss: 0.1687 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 4000-4500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1751 - tp: 390.0000 - fp: 10.0000 - tn: 390.0000 - fn: 10.0000 - accuracy: 0.9750 - precision: 0.9750 - recall: 0.9750 - auc: 0.9976 - val_loss: 0.1496 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 4500-5000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1287 - tp: 398.0000 - fp: 2.0000 - tn: 398.0000 - fn: 2.0000 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - auc: 0.9999 - val_loss: 2.0813 - val_tp: 20.0000 - val_fp: 80.0000 - val_tn: 20.0000 - val_fn: 80.0000 - val_accuracy: 0.2000 - val_precision: 0.2000 - val_recall: 0.2000 - val_auc: 0.2260
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 5000-5500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.7622 - tp: 97.0000 - fp: 303.0000 - tn: 97.0000 - fn: 303.0000 - accuracy: 0.2425 - precision: 0.2425 - recall: 0.2425 - auc: 0.2238 - val_loss: 0.1600 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 5500-6000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1913 - tp: 386.0000 - fp: 14.0000 - tn: 386.0000 - fn: 14.0000 - accuracy: 0.9650 - precision: 0.9650 - recall: 0.9650 - auc: 0.9891 - val_loss: 0.1341 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 6000-6500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1685 - tp: 393.0000 - fp: 7.0000 - tn: 393.0000 - fn: 7.0000 - accuracy: 0.9825 - precision: 0.9825 - recall: 0.9825 - auc: 0.9938 - val_loss: 1.0405 - val_tp: 59.0000 - val_fp: 41.0000 - val_tn: 59.0000 - val_fn: 41.0000 - val_accuracy: 0.5900 - val_precision: 0.5900 - val_recall: 0.5900 - val_auc: 0.5207
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 6500-7000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.9204 - tp: 51.0000 - fp: 349.0000 - tn: 51.0000 - fn: 349.0000 - accuracy: 0.1275 - precision: 0.1275 - recall: 0.1275 - auc: 0.1099 - val_loss: 0.1626 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 7000-7500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8290 - tp: 261.0000 - fp: 139.0000 - tn: 261.0000 - fn: 139.0000 - accuracy: 0.6525 - precision: 0.6525 - recall: 0.6525 - auc: 0.6515 - val_loss: 0.9147 - val_tp: 49.0000 - val_fp: 51.0000 - val_tn: 49.0000 - val_fn: 51.0000 - val_accuracy: 0.4900 - val_precision: 0.4900 - val_recall: 0.4900 - val_auc: 0.3649
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 7500-8000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.0108 - tp: 198.0000 - fp: 202.0000 - tn: 198.0000 - fn: 202.0000 - accuracy: 0.4950 - precision: 0.4950 - recall: 0.4950 - auc: 0.4897 - val_loss: 1.6675 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 8000-8500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7431 - tp: 250.0000 - fp: 150.0000 - tn: 250.0000 - fn: 150.0000 - accuracy: 0.6250 - precision: 0.6250 - recall: 0.6250 - auc: 0.6447 - val_loss: 0.2351 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 8500-9000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2727 - tp: 378.0000 - fp: 22.0000 - tn: 378.0000 - fn: 22.0000 - accuracy: 0.9450 - precision: 0.9450 - recall: 0.9450 - auc: 0.9794 - val_loss: 0.2097 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 9000-9500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2221 - tp: 388.0000 - fp: 12.0000 - tn: 388.0000 - fn: 12.0000 - accuracy: 0.9700 - precision: 0.9700 - recall: 0.9700 - auc: 0.9934 - val_loss: 0.1996 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 9500-10000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2006 - tp: 393.0000 - fp: 7.0000 - tn: 393.0000 - fn: 7.0000 - accuracy: 0.9825 - precision: 0.9825 - recall: 0.9825 - auc: 0.9994 - val_loss: 0.1566 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 10000-10500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1502 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1185 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 10500-11000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1236 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1024 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 11000-11500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1195 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6928 - val_tp: 10.0000 - val_fp: 90.0000 - val_tn: 10.0000 - val_fn: 90.0000 - val_accuracy: 0.1000 - val_precision: 0.1000 - val_recall: 0.1000 - val_auc: 0.0648
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 11500-12000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.8911 - tp: 16.0000 - fp: 384.0000 - tn: 16.0000 - fn: 384.0000 - accuracy: 0.0400 - precision: 0.0400 - recall: 0.0400 - auc: 0.0081 - val_loss: 1.4957 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 12000-12500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.5052 - tp: 73.0000 - fp: 327.0000 - tn: 73.0000 - fn: 327.0000 - accuracy: 0.1825 - precision: 0.1825 - recall: 0.1825 - auc: 0.1860 - val_loss: 0.1728 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 12500-13000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1744 - tp: 398.0000 - fp: 2.0000 - tn: 398.0000 - fn: 2.0000 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - val_loss: 0.1306 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 13000-13500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1734 - tp: 398.0000 - fp: 2.0000 - tn: 398.0000 - fn: 2.0000 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - auc: 0.9999 - val_loss: 0.1592 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 13500-14000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1781 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1507 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 14000-14500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2743 - tp: 384.0000 - fp: 16.0000 - tn: 384.0000 - fn: 16.0000 - accuracy: 0.9600 - precision: 0.9600 - recall: 0.9600 - auc: 0.9598 - val_loss: 0.1068 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 14500-15000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1385 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1101 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 15000-15500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2367 - tp: 380.0000 - fp: 20.0000 - tn: 380.0000 - fn: 20.0000 - accuracy: 0.9500 - precision: 0.9500 - recall: 0.9500 - auc: 0.9558 - val_loss: 2.1162 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 15500-16000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.4386 - tp: 88.0000 - fp: 312.0000 - tn: 88.0000 - fn: 312.0000 - accuracy: 0.2200 - precision: 0.2200 - recall: 0.2200 - auc: 0.2052 - val_loss: 1.1811 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 16000-16500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4937 - tp: 323.0000 - fp: 77.0000 - tn: 323.0000 - fn: 77.0000 - accuracy: 0.8075 - precision: 0.8075 - recall: 0.8075 - auc: 0.8260 - val_loss: 0.1353 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 16500-17000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1555 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0871 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 17000-17500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1472 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - val_loss: 0.0976 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 17500-18000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1429 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1436 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 18000-18500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1388 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0948 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 18500-19000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1220 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0992 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 19000-19500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1245 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1008 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 19500-20000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1833 - tp: 390.0000 - fp: 10.0000 - tn: 390.0000 - fn: 10.0000 - accuracy: 0.9750 - precision: 0.9750 - recall: 0.9750 - auc: 0.9935 - val_loss: 0.1677 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 20000-20500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1468 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - val_loss: 0.0781 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 20500-21000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1120 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0663 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 21000-21500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1078 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0719 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 21500-22000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1027 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0723 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 22000-22500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1083 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - val_loss: 0.0692 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 22500-23000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0969 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0709 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 23000-23500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1046 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0718 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 23500-24000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0976 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0802 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 24000-24500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0986 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0613 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 24500-25000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0926 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0620 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 25000-25500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0982 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0706 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 25500-26000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0952 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0541 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 26000-26500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0935 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0527 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 26500-27000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0897 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0569 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 27000-27500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0915 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - val_loss: 0.0556 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 27500-28000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0847 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0563 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 28000-28500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0853 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0576 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 28500-29000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0871 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0590 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 29000-29500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0867 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0588 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 29500-30000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0832 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0436 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 30000-30500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0764 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0541 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 30500-31000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0858 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0520 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 31000-31500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0824 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0434 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 31500-32000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0787 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0470 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 32000-32500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0722 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0478 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 32500-33000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0744 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0463 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 33000-33500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0753 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0480 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 33500-34000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0781 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0503 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 34000-34500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0776 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0553 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 34500-35000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0756 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0440 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 35000-35500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0715 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0451 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 35500-36000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0773 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0518 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 36000-36500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0722 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0410 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 36500-37000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0710 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0409 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 37000-37500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0748 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0447 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 37500-38000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0740 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0439 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 38000-38500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0709 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0451 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 38500-39000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0658 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0470 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 39000-39500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0710 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0499 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 39500-40000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0782 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0483 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 40000-40500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0646 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0367 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 40500-41000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0674 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0454 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 41000-41500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0717 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0446 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 41500-42000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0598 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0374 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 42000-42500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0642 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0404 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 42500-43000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0585 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0408 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 43000-43500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0677 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0410 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 43500-44000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0631 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0411 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 44000-44500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0637 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0424 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 44500-45000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0638 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0474 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 45000-45500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0734 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0445 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 45500-46000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0636 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0336 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 46000-46500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0586 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0339 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 46500-47000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0565 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0359 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 47000-47500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0583 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0374 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 47500-48000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0599 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0361 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 48000-48500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0622 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0370 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 48500-49000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0584 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0379 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 49000-49500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0603 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0383 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 49500-50000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0607 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0330 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 50000-50500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0561 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0293 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 50500-51000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0520 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0304 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 51000-51500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0560 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0327 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 51500-52000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0555 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0341 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 52000-52500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0504 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0323 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 52500-53000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0544 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0322 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 53000-53500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0558 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0336 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 53500-54000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0535 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0333 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 54000-54500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0575 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0284 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 54500-55000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0570 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0267 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 55000-55500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0505 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0278 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 55500-56000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0487 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0291 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 56000-56500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0464 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0275 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 56500-57000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0519 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0290 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 57000-57500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0495 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0295 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 57500-58000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0495 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0300 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 58000-58500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0469 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0294 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 58500-59000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0464 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0237 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 59000-59500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0449 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0235 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 59500-60000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0457 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0254 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 60000-60500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0480 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0259 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 60500-61000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0466 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0248 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 61000-61500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0492 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0254 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 61500-62000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0455 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0262 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 62000-62500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0473 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0253 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 62500-63000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0464 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0258 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 63000-63500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0444 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0200 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 63500-64000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0439 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0207 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 64000-64500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0435 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0226 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 64500-65000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0449 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0208 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 65000-65500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0438 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0224 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 65500-66000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0480 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0230 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 66000-66500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0408 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0235 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 66500-67000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0430 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0230 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 67000-67500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0395 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0200 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 67500-68000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0419 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0185 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 68000-68500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0441 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0187 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 68500-69000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0381 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0209 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 69000-69500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0466 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0203 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 69500-70000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0394 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0204 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 70000-70500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0400 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0211 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 70500-71000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0402 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0215 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 71000-71500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0401 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0206 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 71500-72000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0374 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0174 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 72000-72500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0417 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0168 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 72500-73000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0382 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0182 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 73000-73500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0365 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0184 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 73500-74000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.0313 - tp: 300.0000 - fp: 100.0000 - tn: 300.0000 - fn: 100.0000 - accuracy: 0.7500 - precision: 0.7500 - recall: 0.7500 - auc: 0.7523 - val_loss: 3.8496 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 74000-74500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 3.6705 - tp: 0.0000e+00 - fp: 400.0000 - tn: 0.0000e+00 - fn: 400.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 3.4262 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 74500-75000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2111 - tp: 379.0000 - fp: 21.0000 - tn: 379.0000 - fn: 21.0000 - accuracy: 0.9475 - precision: 0.9475 - recall: 0.9475 - auc: 0.9510 - val_loss: 0.0473 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 75000-75500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0597 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0390 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 75500-76000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0531 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0356 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 76000-76500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0505 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0364 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 76500-77000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0508 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0377 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 77000-77500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0514 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0396 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 77500-78000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0521 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0379 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 78000-78500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0498 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0378 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 78500-79000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0479 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0371 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 79000-79500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0512 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0366 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 79500-80000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0469 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0332 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 80000-80500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0446 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0300 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 80500-81000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0462 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0311 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 81000-81500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0466 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0340 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 81500-82000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0459 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0336 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 82000-82500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0431 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0332 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 82500-83000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0447 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0331 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 83000-83500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0478 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0329 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 83500-84000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0451 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0295 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 84000-84500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0440 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0260 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 84500-85000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0416 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0271 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 85000-85500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0414 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0277 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 85500-86000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0431 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0302 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 86000-86500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0417 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0307 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 86500-87000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0415 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0302 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 87000-87500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0386 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0302 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 87500-88000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0432 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0299 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 88000-88500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0425 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0265 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 88500-89000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0391 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0237 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 89000-89500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0410 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0249 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 89500-90000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0369 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0276 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 90000-90500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0397 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0276 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 90500-91000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.9179 - tp: 185.0000 - fp: 215.0000 - tn: 185.0000 - fn: 215.0000 - accuracy: 0.4625 - precision: 0.4625 - recall: 0.4625 - auc: 0.4595 - val_loss: 0.6527 - val_tp: 82.0000 - val_fp: 18.0000 - val_tn: 82.0000 - val_fn: 18.0000 - val_accuracy: 0.8200 - val_precision: 0.8200 - val_recall: 0.8200 - val_auc: 0.8200
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 91000-91500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0449 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0346 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 91500-92000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0441 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0353 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 92000-92500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.1186 - tp: 140.0000 - fp: 260.0000 - tn: 140.0000 - fn: 260.0000 - accuracy: 0.3500 - precision: 0.3500 - recall: 0.3500 - auc: 0.3461 - val_loss: 3.3462 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 92500-93000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6139 - tp: 329.0000 - fp: 71.0000 - tn: 329.0000 - fn: 71.0000 - accuracy: 0.8225 - precision: 0.8225 - recall: 0.8225 - auc: 0.8291 - val_loss: 0.0396 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 93000-93500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0509 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8026 - val_tp: 45.0000 - val_fp: 55.0000 - val_tn: 45.0000 - val_fn: 55.0000 - val_accuracy: 0.4500 - val_precision: 0.4500 - val_recall: 0.4500 - val_auc: 0.5085
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 93500-94000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.8315 - tp: 179.0000 - fp: 221.0000 - tn: 179.0000 - fn: 221.0000 - accuracy: 0.4475 - precision: 0.4475 - recall: 0.4475 - auc: 0.4189 - val_loss: 0.0482 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 94000-94500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0599 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0556 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 94500-95000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0636 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0542 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 95000-95500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0619 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0557 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 95500-96000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0612 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0551 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 96000-96500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0610 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0514 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 96500-97000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0568 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0500 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 97000-97500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0584 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0487 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 97500-98000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0542 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0492 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 98000-98500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0588 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0503 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 98500-99000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0570 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0499 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 99000-99500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0586 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0492 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 99500-100000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0573 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0486 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 100000-100500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0563 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0479 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 100500-101000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0550 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0460 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 101000-101500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0541 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0451 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 101500-102000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0522 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0441 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 102000-102500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0516 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0440 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 102500-103000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0501 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0443 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 103000-103500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.3897 - tp: 92.0000 - fp: 308.0000 - tn: 92.0000 - fn: 308.0000 - accuracy: 0.2300 - precision: 0.2300 - recall: 0.2300 - auc: 0.2253 - val_loss: 3.0276 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 103500-104000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.2753 - tp: 91.0000 - fp: 309.0000 - tn: 91.0000 - fn: 309.0000 - accuracy: 0.2275 - precision: 0.2275 - recall: 0.2275 - auc: 0.2351 - val_loss: 0.0564 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 104000-104500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0678 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0580 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 104500-105000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0666 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0602 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 105000-105500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0811 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0765 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 105500-106000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0828 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0767 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 106000-106500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0758 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0685 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 106500-107000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0743 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0656 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 107000-107500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0721 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0651 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 107500-108000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0676 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0544 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 108000-108500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0595 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0527 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 108500-109000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0597 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0547 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 109000-109500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0678 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0599 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 109500-110000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0608 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0517 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 110000-110500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0567 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0506 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 110500-111000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0581 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0529 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 111000-111500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0603 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0522 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 111500-112000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0587 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0513 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 112000-112500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0571 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0511 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 112500-113000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0575 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0508 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 113000-113500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0574 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0506 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 113500-114000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0559 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0480 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 114000-114500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0519 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0436 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 114500-115000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0531 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0452 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 115000-115500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0547 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0469 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 115500-116000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4800 - tp: 343.0000 - fp: 57.0000 - tn: 343.0000 - fn: 57.0000 - accuracy: 0.8575 - precision: 0.8575 - recall: 0.8575 - auc: 0.8578 - val_loss: 3.0758 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 116000-116500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.0454 - tp: 105.0000 - fp: 295.0000 - tn: 105.0000 - fn: 295.0000 - accuracy: 0.2625 - precision: 0.2625 - recall: 0.2625 - auc: 0.2944 - val_loss: 0.5042 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 116500-117000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2917 - tp: 367.0000 - fp: 33.0000 - tn: 367.0000 - fn: 33.0000 - accuracy: 0.9175 - precision: 0.9175 - recall: 0.9175 - auc: 0.9166 - val_loss: 0.0671 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 117000-117500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.6019 - tp: 0.0000e+00 - fp: 400.0000 - tn: 0.0000e+00 - fn: 400.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 2.2311 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 117500-118000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.2053 - tp: 187.0000 - fp: 213.0000 - tn: 187.0000 - fn: 213.0000 - accuracy: 0.4675 - precision: 0.4675 - recall: 0.4675 - auc: 0.4876 - val_loss: 0.0787 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 118000-118500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0944 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0961 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 118500-119000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1064 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0970 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 119000-119500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1130 - tp: 396.0000 - fp: 4.0000 - tn: 396.0000 - fn: 4.0000 - accuracy: 0.9900 - precision: 0.9900 - recall: 0.9900 - auc: 0.9957 - val_loss: 0.0784 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 119500-120000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0904 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0571 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 120000-120500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0825 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0985 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 120500-121000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1397 - tp: 397.0000 - fp: 3.0000 - tn: 397.0000 - fn: 3.0000 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925 - auc: 0.9995 - val_loss: 0.0829 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 121000-121500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0872 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0569 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 121500-122000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0780 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0589 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 122000-122500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0777 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0620 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 122500-123000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0822 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0699 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 123000-123500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0653 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0414 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 123500-124000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0635 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0365 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 124000-124500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0651 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0477 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 124500-125000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0706 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0604 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 125000-125500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0790 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0730 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 125500-126000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0855 - tp: 398.0000 - fp: 2.0000 - tn: 398.0000 - fn: 2.0000 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - val_loss: 0.0658 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 126000-126500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0826 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0841 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 126500-127000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0932 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0906 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 127000-127500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0900 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0546 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 127500-128000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0622 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0521 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 128000-128500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0574 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0454 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 128500-129000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0581 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0482 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 129000-129500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0564 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0460 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 129500-130000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0568 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0401 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 130000-130500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0547 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0431 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 130500-131000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0534 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0449 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 131000-131500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0572 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0474 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 131500-132000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0561 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0403 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 132000-132500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0499 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0382 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 132500-133000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0528 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.4363 - val_tp: 18.0000 - val_fp: 82.0000 - val_tn: 18.0000 - val_fn: 82.0000 - val_accuracy: 0.1800 - val_precision: 0.1800 - val_recall: 0.1800 - val_auc: 0.3089
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 133000-133500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.7606 - tp: 116.0000 - fp: 284.0000 - tn: 116.0000 - fn: 284.0000 - accuracy: 0.2900 - precision: 0.2900 - recall: 0.2900 - auc: 0.3193 - val_loss: 0.0396 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 133500-134000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0544 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0394 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 134000-134500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0600 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0507 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 134500-135000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0568 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0310 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 135000-135500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0531 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0317 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 135500-136000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0476 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0176 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 136000-136500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0517 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0202 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 136500-137000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0507 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0245 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 137000-137500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0498 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0262 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 137500-138000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0517 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0308 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 138000-138500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0737 - tp: 397.0000 - fp: 3.0000 - tn: 397.0000 - fn: 3.0000 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925 - auc: 0.9956 - val_loss: 0.0279 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 138500-139000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0519 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0336 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 139000-139500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0586 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0384 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 139500-140000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0548 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0264 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 140000-140500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0473 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0309 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 140500-141000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0510 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0271 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 141000-141500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0462 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0252 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 141500-142000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0468 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0201 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 142000-142500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0469 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0189 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 142500-143000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0430 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4363 - val_tp: 80.0000 - val_fp: 20.0000 - val_tn: 80.0000 - val_fn: 20.0000 - val_accuracy: 0.8000 - val_precision: 0.8000 - val_recall: 0.8000 - val_auc: 0.9226
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 143000-143500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.6885 - tp: 156.0000 - fp: 244.0000 - tn: 156.0000 - fn: 244.0000 - accuracy: 0.3900 - precision: 0.3900 - recall: 0.3900 - auc: 0.4846 - val_loss: 0.0805 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 143500-144000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8618 - tp: 289.0000 - fp: 111.0000 - tn: 289.0000 - fn: 111.0000 - accuracy: 0.7225 - precision: 0.7225 - recall: 0.7225 - auc: 0.7883 - val_loss: 0.0164 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 144000-144500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0520 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0192 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 144500-145000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0515 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0261 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 145000-145500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0594 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0237 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 145500-146000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0541 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0258 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 146000-146500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0540 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0237 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 146500-147000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0508 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0248 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 147000-147500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0505 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0434 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 147500-148000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0499 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0219 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 148000-148500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0473 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0156 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 148500-149000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0438 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0194 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 149000-149500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0429 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0249 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 149500-150000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0469 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0256 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 150000-150500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0453 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0338 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 150500-151000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0423 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0312 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 151000-151500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1041 - tp: 393.0000 - fp: 7.0000 - tn: 393.0000 - fn: 7.0000 - accuracy: 0.9825 - precision: 0.9825 - recall: 0.9825 - auc: 0.9922 - val_loss: 0.0377 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 151500-152000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0482 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0264 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 152000-152500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0424 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0193 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 152500-153000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0420 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0170 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 153000-153500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0405 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0186 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 153500-154000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0413 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0187 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 154000-154500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0401 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0230 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 154500-155000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0396 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0281 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 155000-155500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0432 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0238 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 155500-156000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0410 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0310 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 156000-156500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0411 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0234 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 156500-157000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0409 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0172 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 157000-157500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0365 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0143 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 157500-158000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0376 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0130 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 158000-158500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0379 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0122 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 158500-159000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0374 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0141 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 159000-159500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0376 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0166 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 159500-160000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0378 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0147 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 160000-160500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0355 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0152 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 160500-161000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0356 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0159 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 161000-161500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0374 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0155 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 161500-162000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0352 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0166 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 162000-162500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0384 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0155 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 162500-163000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0359 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0127 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 163000-163500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0340 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0139 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 163500-164000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0346 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 164000-164500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0333 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0113 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 164500-165000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0368 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0116 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 165000-165500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0335 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0120 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 165500-166000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0359 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0128 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 166000-166500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0326 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0096 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 166500-167000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0351 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0118 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 167000-167500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0320 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0132 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 167500-168000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0319 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0157 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 168000-168500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0339 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0139 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 168500-169000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0331 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0154 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 169000-169500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0322 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0111 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 169500-170000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0322 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0084 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 170000-170500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0318 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0062 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 170500-171000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0314 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0053 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 171000-171500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0301 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0057 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 171500-172000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0310 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0077 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 172000-172500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.1747 - tp: 293.0000 - fp: 107.0000 - tn: 293.0000 - fn: 107.0000 - accuracy: 0.7325 - precision: 0.7325 - recall: 0.7325 - auc: 0.7545 - val_loss: 4.3137 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 172500-173000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9036 - tp: 311.0000 - fp: 89.0000 - tn: 311.0000 - fn: 89.0000 - accuracy: 0.7775 - precision: 0.7775 - recall: 0.7775 - auc: 0.7743 - val_loss: 3.2782 - val_tp: 10.0000 - val_fp: 90.0000 - val_tn: 10.0000 - val_fn: 90.0000 - val_accuracy: 0.1000 - val_precision: 0.1000 - val_recall: 0.1000 - val_auc: 0.1000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 173000-173500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 3.3945 - tp: 0.0000e+00 - fp: 400.0000 - tn: 0.0000e+00 - fn: 400.0000 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 3.1167 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 173500-174000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2116 - tp: 378.0000 - fp: 22.0000 - tn: 378.0000 - fn: 22.0000 - accuracy: 0.9450 - precision: 0.9450 - recall: 0.9450 - auc: 0.9565 - val_loss: 0.0496 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 174000-174500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0520 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0448 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 174500-175000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0518 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0440 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 175000-175500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0507 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0431 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 175500-176000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0479 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0425 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 176000-176500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0501 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0425 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 176500-177000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0487 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0434 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 177000-177500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0530 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0502 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 177500-178000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0515 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0423 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 178000-178500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0483 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0405 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 178500-179000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0446 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0381 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 179000-179500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0473 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0394 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 179500-180000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0449 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0384 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 180000-180500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0452 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0384 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 180500-181000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0434 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0389 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 181000-181500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0570 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0584 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 181500-182000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0569 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0443 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 182000-182500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0462 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0371 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 182500-183000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0433 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0350 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 183000-183500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0412 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0367 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 183500-184000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0402 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0348 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 184000-184500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0425 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0341 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 184500-185000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0398 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0343 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 185000-185500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0404 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0416 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 185500-186000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0432 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0367 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 186000-186500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0412 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0363 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 186500-187000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0463 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0370 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 187000-187500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0396 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0286 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 187500-188000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0385 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0282 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 188000-188500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0381 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0293 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 188500-189000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0384 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0280 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 189000-189500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0374 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0282 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 189500-190000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0359 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0286 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 190000-190500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0363 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0294 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 190500-191000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0400 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0333 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 191000-191500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0373 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0274 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 191500-192000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0357 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0346 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 192000-192500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0411 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0336 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 192500-193000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0354 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0250 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 193000-193500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0354 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0231 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 193500-194000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0331 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0257 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 194000-194500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0335 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0225 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 194500-195000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0316 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0233 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 195000-195500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0323 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0244 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 195500-196000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0340 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0330 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 196000-196500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0368 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0286 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 196500-197000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0325 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0245 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 197000-197500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0358 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0326 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 197500-198000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0351 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0278 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 198000-198500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6290 - tp: 323.0000 - fp: 77.0000 - tn: 323.0000 - fn: 77.0000 - accuracy: 0.8075 - precision: 0.8075 - recall: 0.8075 - auc: 0.8648 - val_loss: 0.9289 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 198500-199000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.0436 - tp: 122.0000 - fp: 278.0000 - tn: 122.0000 - fn: 278.0000 - accuracy: 0.3050 - precision: 0.3050 - recall: 0.3050 - auc: 0.3795 - val_loss: 0.1082 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 199000-199500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.7490 - tp: 156.0000 - fp: 244.0000 - tn: 156.0000 - fn: 244.0000 - accuracy: 0.3900 - precision: 0.3900 - recall: 0.3900 - auc: 0.5750 - val_loss: 0.0022 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 199500-200000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.2284 - tp: 233.0000 - fp: 167.0000 - tn: 233.0000 - fn: 167.0000 - accuracy: 0.5825 - precision: 0.5825 - recall: 0.5825 - auc: 0.6994 - val_loss: 0.0300 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 200000-200500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0461 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0152 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 200500-201000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0425 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0244 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 201000-201500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0469 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0254 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 201500-202000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0442 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0242 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 202000-202500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0487 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0570 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 202500-203000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0769 - tp: 398.0000 - fp: 2.0000 - tn: 398.0000 - fn: 2.0000 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - auc: 0.9999 - val_loss: 0.0352 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 203000-203500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0453 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0188 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 203500-204000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0408 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0183 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 204000-204500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0370 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0151 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 204500-205000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0403 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0211 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 205000-205500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0418 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0184 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 205500-206000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0448 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0196 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 206000-206500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0401 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0228 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 206500-207000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0411 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0236 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 207000-207500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0398 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0172 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 207500-208000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0392 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0303 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 208000-208500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0475 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0311 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 208500-209000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0374 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0163 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 209000-209500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0371 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0163 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 209500-210000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0387 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0160 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 210000-210500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0351 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0147 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 210500-211000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0374 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0184 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 211000-211500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0346 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0226 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 211500-212000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0427 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - val_loss: 0.0306 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 212000-212500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0367 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0252 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 212500-213000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0359 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0173 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 213000-213500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0403 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0332 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 213500-214000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0410 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0225 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 214000-214500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0341 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0159 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 214500-215000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0329 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0143 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 215000-215500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0322 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0107 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 215500-216000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0332 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0147 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 216000-216500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0327 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0152 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 216500-217000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0303 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0169 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 217000-217500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0333 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0239 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 217500-218000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0366 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0244 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 218000-218500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0331 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0159 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 218500-219000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0299 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0106 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 219000-219500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0276 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0135 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 219500-220000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0305 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0126 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 220000-220500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0276 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0126 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 220500-221000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0304 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0150 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 221000-221500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0316 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0186 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 221500-222000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0519 - tp: 398.0000 - fp: 2.0000 - tn: 398.0000 - fn: 2.0000 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - auc: 0.9953 - val_loss: 0.0229 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 222000-222500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0367 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0241 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 222500-223000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0330 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0136 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 223000-223500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0293 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0108 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 223500-224000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0297 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0097 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 224000-224500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0319 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - val_loss: 0.0087 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 224500-225000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0280 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0098 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 225000-225500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0274 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0115 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 225500-226000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0282 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0146 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 226000-226500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0277 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0170 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 226500-227000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0278 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0161 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 227000-227500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0270 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0098 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 227500-228000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8251 - tp: 331.0000 - fp: 69.0000 - tn: 331.0000 - fn: 69.0000 - accuracy: 0.8275 - precision: 0.8275 - recall: 0.8275 - auc: 0.8314 - val_loss: 3.8628 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 228000-228500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.9393 - tp: 36.0000 - fp: 364.0000 - tn: 36.0000 - fn: 364.0000 - accuracy: 0.0900 - precision: 0.0900 - recall: 0.0900 - auc: 0.0575 - val_loss: 2.0040 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 228500-229000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.9524 - tp: 116.0000 - fp: 284.0000 - tn: 116.0000 - fn: 284.0000 - accuracy: 0.2900 - precision: 0.2900 - recall: 0.2900 - auc: 0.3753 - val_loss: 0.0660 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 229000-229500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.6624 - tp: 157.0000 - fp: 243.0000 - tn: 157.0000 - fn: 243.0000 - accuracy: 0.3925 - precision: 0.3925 - recall: 0.3925 - auc: 0.5668 - val_loss: 0.0014 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 229500-230000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 2.1038 - tp: 110.0000 - fp: 290.0000 - tn: 110.0000 - fn: 290.0000 - accuracy: 0.2750 - precision: 0.2750 - recall: 0.2750 - auc: 0.3810 - val_loss: 1.4797 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 230000-230500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.9374 - tp: 104.0000 - fp: 296.0000 - tn: 104.0000 - fn: 296.0000 - accuracy: 0.2600 - precision: 0.2600 - recall: 0.2600 - auc: 0.3707 - val_loss: 0.2738 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 230500-231000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.3967 - tp: 174.0000 - fp: 226.0000 - tn: 174.0000 - fn: 226.0000 - accuracy: 0.4350 - precision: 0.4350 - recall: 0.4350 - auc: 0.6106 - val_loss: 1.3568e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 231000-231500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.4008 - tp: 176.0000 - fp: 224.0000 - tn: 176.0000 - fn: 224.0000 - accuracy: 0.4400 - precision: 0.4400 - recall: 0.4400 - auc: 0.6268 - val_loss: 4.2081e-07 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 231500-232000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.4471 - tp: 170.0000 - fp: 230.0000 - tn: 170.0000 - fn: 230.0000 - accuracy: 0.4250 - precision: 0.4250 - recall: 0.4250 - auc: 0.6217 - val_loss: 0.0119 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 232000-232500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.2693 - tp: 193.0000 - fp: 207.0000 - tn: 193.0000 - fn: 207.0000 - accuracy: 0.4825 - precision: 0.4825 - recall: 0.4825 - auc: 0.6470 - val_loss: 0.0948 - val_tp: 97.0000 - val_fp: 3.0000 - val_tn: 97.0000 - val_fn: 3.0000 - val_accuracy: 0.9700 - val_precision: 0.9700 - val_recall: 0.9700 - val_auc: 0.9991
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 232500-233000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.1876 - tp: 202.0000 - fp: 198.0000 - tn: 202.0000 - fn: 198.0000 - accuracy: 0.5050 - precision: 0.5050 - recall: 0.5050 - auc: 0.6949 - val_loss: 1.9966e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 233000-233500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.0971 - tp: 211.0000 - fp: 189.0000 - tn: 211.0000 - fn: 189.0000 - accuracy: 0.5275 - precision: 0.5275 - recall: 0.5275 - auc: 0.7466 - val_loss: 3.3259e-07 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 233500-234000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.0982 - tp: 208.0000 - fp: 192.0000 - tn: 208.0000 - fn: 192.0000 - accuracy: 0.5200 - precision: 0.5200 - recall: 0.5200 - auc: 0.7378 - val_loss: 3.7193e-07 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 234000-234500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.1441 - tp: 196.0000 - fp: 204.0000 - tn: 196.0000 - fn: 204.0000 - accuracy: 0.4900 - precision: 0.4900 - recall: 0.4900 - auc: 0.7222 - val_loss: 8.3208e-07 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 234500-235000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.1459 - tp: 193.0000 - fp: 207.0000 - tn: 193.0000 - fn: 207.0000 - accuracy: 0.4825 - precision: 0.4825 - recall: 0.4825 - auc: 0.7039 - val_loss: 9.5129e-07 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 235000-235500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.1710 - tp: 183.0000 - fp: 217.0000 - tn: 183.0000 - fn: 217.0000 - accuracy: 0.4575 - precision: 0.4575 - recall: 0.4575 - auc: 0.6968 - val_loss: 1.4710e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 235500-236000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.0085 - tp: 211.0000 - fp: 189.0000 - tn: 211.0000 - fn: 189.0000 - accuracy: 0.5275 - precision: 0.5275 - recall: 0.5275 - auc: 0.7626 - val_loss: 2.1291e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 236000-236500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9907 - tp: 211.0000 - fp: 189.0000 - tn: 211.0000 - fn: 189.0000 - accuracy: 0.5275 - precision: 0.5275 - recall: 0.5275 - auc: 0.7606 - val_loss: 2.7835e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 236500-237000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9789 - tp: 210.0000 - fp: 190.0000 - tn: 210.0000 - fn: 190.0000 - accuracy: 0.5250 - precision: 0.5250 - recall: 0.5250 - auc: 0.7624 - val_loss: 3.8087e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 237000-237500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9900 - tp: 205.0000 - fp: 195.0000 - tn: 205.0000 - fn: 195.0000 - accuracy: 0.5125 - precision: 0.5125 - recall: 0.5125 - auc: 0.7404 - val_loss: 3.4440e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 237500-238000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8872 - tp: 221.0000 - fp: 179.0000 - tn: 221.0000 - fn: 179.0000 - accuracy: 0.5525 - precision: 0.5525 - recall: 0.5525 - auc: 0.7930 - val_loss: 1.9932e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 238000-238500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.0424 - tp: 186.0000 - fp: 214.0000 - tn: 186.0000 - fn: 214.0000 - accuracy: 0.4650 - precision: 0.4650 - recall: 0.4650 - auc: 0.7058 - val_loss: 2.5499e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 238500-239000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9499 - tp: 202.0000 - fp: 198.0000 - tn: 202.0000 - fn: 198.0000 - accuracy: 0.5050 - precision: 0.5050 - recall: 0.5050 - auc: 0.7475 - val_loss: 1.8442e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 239000-239500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9452 - tp: 199.0000 - fp: 201.0000 - tn: 199.0000 - fn: 201.0000 - accuracy: 0.4975 - precision: 0.4975 - recall: 0.4975 - auc: 0.7424 - val_loss: 1.3285e-04 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 239500-240000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8972 - tp: 206.0000 - fp: 194.0000 - tn: 206.0000 - fn: 194.0000 - accuracy: 0.5150 - precision: 0.5150 - recall: 0.5150 - auc: 0.7575 - val_loss: 5.5790e-07 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 240000-240500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9014 - tp: 201.0000 - fp: 199.0000 - tn: 201.0000 - fn: 199.0000 - accuracy: 0.5025 - precision: 0.5025 - recall: 0.5025 - auc: 0.7500 - val_loss: 3.5524e-07 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 240500-241000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9226 - tp: 192.0000 - fp: 208.0000 - tn: 192.0000 - fn: 208.0000 - accuracy: 0.4800 - precision: 0.4800 - recall: 0.4800 - auc: 0.7296 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 241000-241500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7783 - tp: 222.0000 - fp: 178.0000 - tn: 222.0000 - fn: 178.0000 - accuracy: 0.5550 - precision: 0.5550 - recall: 0.5550 - auc: 0.8020 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 241500-242000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8068 - tp: 213.0000 - fp: 187.0000 - tn: 213.0000 - fn: 187.0000 - accuracy: 0.5325 - precision: 0.5325 - recall: 0.5325 - auc: 0.7791 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 242000-242500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9171 - tp: 183.0000 - fp: 217.0000 - tn: 183.0000 - fn: 217.0000 - accuracy: 0.4575 - precision: 0.4575 - recall: 0.4575 - auc: 0.7057 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 242500-243000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8180 - tp: 203.0000 - fp: 197.0000 - tn: 203.0000 - fn: 197.0000 - accuracy: 0.5075 - precision: 0.5075 - recall: 0.5075 - auc: 0.7574 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 243000-243500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8252 - tp: 198.0000 - fp: 202.0000 - tn: 198.0000 - fn: 202.0000 - accuracy: 0.4950 - precision: 0.4950 - recall: 0.4950 - auc: 0.7450 - val_loss: 1.1921e-07 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 243500-244000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8381 - tp: 191.0000 - fp: 209.0000 - tn: 191.0000 - fn: 209.0000 - accuracy: 0.4775 - precision: 0.4775 - recall: 0.4775 - auc: 0.7244 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 244000-244500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.8085 - tp: 195.0000 - fp: 205.0000 - tn: 195.0000 - fn: 205.0000 - accuracy: 0.4875 - precision: 0.4875 - recall: 0.4875 - auc: 0.7348 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 244500-245000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7592 - tp: 204.0000 - fp: 196.0000 - tn: 204.0000 - fn: 196.0000 - accuracy: 0.5100 - precision: 0.5100 - recall: 0.5100 - auc: 0.7575 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 245000-245500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7571 - tp: 201.0000 - fp: 199.0000 - tn: 201.0000 - fn: 199.0000 - accuracy: 0.5025 - precision: 0.5025 - recall: 0.5025 - auc: 0.7500 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 245500-246000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7249 - tp: 206.0000 - fp: 194.0000 - tn: 206.0000 - fn: 194.0000 - accuracy: 0.5150 - precision: 0.5150 - recall: 0.5150 - auc: 0.7648 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 246000-246500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7890 - tp: 185.0000 - fp: 215.0000 - tn: 185.0000 - fn: 215.0000 - accuracy: 0.4625 - precision: 0.4625 - recall: 0.4625 - auc: 0.7111 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 246500-247000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7506 - tp: 192.0000 - fp: 208.0000 - tn: 192.0000 - fn: 208.0000 - accuracy: 0.4800 - precision: 0.4800 - recall: 0.4800 - auc: 0.7296 - val_loss: 2.0903e-05 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 247000-247500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6874 - tp: 206.0000 - fp: 194.0000 - tn: 206.0000 - fn: 194.0000 - accuracy: 0.5150 - precision: 0.5150 - recall: 0.5150 - auc: 0.7648 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 247500-248000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6850 - tp: 204.0000 - fp: 196.0000 - tn: 204.0000 - fn: 196.0000 - accuracy: 0.5100 - precision: 0.5100 - recall: 0.5100 - auc: 0.7574 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 248000-248500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6371 - tp: 214.0000 - fp: 186.0000 - tn: 214.0000 - fn: 186.0000 - accuracy: 0.5350 - precision: 0.5350 - recall: 0.5350 - auc: 0.7838 - val_loss: 1.2064e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 248500-249000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6817 - tp: 198.0000 - fp: 202.0000 - tn: 198.0000 - fn: 202.0000 - accuracy: 0.4950 - precision: 0.4950 - recall: 0.4950 - auc: 0.7450 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 249000-249500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6439 - tp: 206.0000 - fp: 194.0000 - tn: 206.0000 - fn: 194.0000 - accuracy: 0.5150 - precision: 0.5150 - recall: 0.5150 - auc: 0.7648 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 249500-250000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6199 - tp: 210.0000 - fp: 190.0000 - tn: 210.0000 - fn: 190.0000 - accuracy: 0.5250 - precision: 0.5250 - recall: 0.5250 - auc: 0.7744 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 250000-250500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6383 - tp: 201.0000 - fp: 199.0000 - tn: 201.0000 - fn: 199.0000 - accuracy: 0.5025 - precision: 0.5025 - recall: 0.5025 - auc: 0.7525 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 250500-251000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6560 - tp: 192.0000 - fp: 208.0000 - tn: 192.0000 - fn: 208.0000 - accuracy: 0.4800 - precision: 0.4800 - recall: 0.4800 - auc: 0.7296 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 251000-251500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6421 - tp: 193.0000 - fp: 207.0000 - tn: 193.0000 - fn: 207.0000 - accuracy: 0.4825 - precision: 0.4825 - recall: 0.4825 - auc: 0.7322 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 251500-252000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6541 - tp: 185.0000 - fp: 215.0000 - tn: 185.0000 - fn: 215.0000 - accuracy: 0.4625 - precision: 0.4625 - recall: 0.4625 - auc: 0.7111 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 252000-252500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6131 - tp: 195.0000 - fp: 205.0000 - tn: 195.0000 - fn: 205.0000 - accuracy: 0.4875 - precision: 0.4875 - recall: 0.4875 - auc: 0.7373 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 252500-253000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.6196 - tp: 189.0000 - fp: 211.0000 - tn: 189.0000 - fn: 211.0000 - accuracy: 0.4725 - precision: 0.4725 - recall: 0.4725 - auc: 0.7217 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 253000-253500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5953 - tp: 194.0000 - fp: 206.0000 - tn: 194.0000 - fn: 206.0000 - accuracy: 0.4850 - precision: 0.4850 - recall: 0.4850 - auc: 0.7348 - val_loss: 6.6757e-08 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 253500-254000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5833 - tp: 195.0000 - fp: 205.0000 - tn: 195.0000 - fn: 205.0000 - accuracy: 0.4875 - precision: 0.4875 - recall: 0.4875 - auc: 0.7348 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 254000-254500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5392 - tp: 207.0000 - fp: 193.0000 - tn: 207.0000 - fn: 193.0000 - accuracy: 0.5175 - precision: 0.5175 - recall: 0.5175 - auc: 0.7672 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 254500-255000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5799 - tp: 189.0000 - fp: 211.0000 - tn: 189.0000 - fn: 211.0000 - accuracy: 0.4725 - precision: 0.4725 - recall: 0.4725 - auc: 0.7217 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 255000-255500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5207 - tp: 207.0000 - fp: 193.0000 - tn: 207.0000 - fn: 193.0000 - accuracy: 0.5175 - precision: 0.5175 - recall: 0.5175 - auc: 0.7672 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 255500-256000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5095 - tp: 208.0000 - fp: 192.0000 - tn: 208.0000 - fn: 192.0000 - accuracy: 0.5200 - precision: 0.5200 - recall: 0.5200 - auc: 0.7696 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 256000-256500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4870 - tp: 214.0000 - fp: 186.0000 - tn: 214.0000 - fn: 186.0000 - accuracy: 0.5350 - precision: 0.5350 - recall: 0.5350 - auc: 0.7838 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 256500-257000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5399 - tp: 190.0000 - fp: 210.0000 - tn: 190.0000 - fn: 210.0000 - accuracy: 0.4750 - precision: 0.4750 - recall: 0.4750 - auc: 0.7244 - val_loss: 1.9073e-08 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 257000-257500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5055 - tp: 200.0000 - fp: 200.0000 - tn: 200.0000 - fn: 200.0000 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.5000 - auc: 0.7500 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 257500-258000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4903 - tp: 203.0000 - fp: 197.0000 - tn: 203.0000 - fn: 197.0000 - accuracy: 0.5075 - precision: 0.5075 - recall: 0.5075 - auc: 0.7574 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 258000-258500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4864 - tp: 201.0000 - fp: 199.0000 - tn: 201.0000 - fn: 199.0000 - accuracy: 0.5025 - precision: 0.5025 - recall: 0.5025 - auc: 0.7525 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 258500-259000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4550 - tp: 211.0000 - fp: 189.0000 - tn: 211.0000 - fn: 189.0000 - accuracy: 0.5275 - precision: 0.5275 - recall: 0.5275 - auc: 0.7767 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 259000-259500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4641 - tp: 204.0000 - fp: 196.0000 - tn: 204.0000 - fn: 196.0000 - accuracy: 0.5100 - precision: 0.5100 - recall: 0.5100 - auc: 0.7599 - val_loss: 1.0895e-06 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 259500-260000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4596 - tp: 203.0000 - fp: 197.0000 - tn: 203.0000 - fn: 197.0000 - accuracy: 0.5075 - precision: 0.5075 - recall: 0.5075 - auc: 0.7574 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 260000-260500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4655 - tp: 197.0000 - fp: 203.0000 - tn: 197.0000 - fn: 203.0000 - accuracy: 0.4925 - precision: 0.4925 - recall: 0.4925 - auc: 0.7424 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 260500-261000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4655 - tp: 194.0000 - fp: 206.0000 - tn: 194.0000 - fn: 206.0000 - accuracy: 0.4850 - precision: 0.4850 - recall: 0.4850 - auc: 0.7348 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 261000-261500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4816 - tp: 183.0000 - fp: 217.0000 - tn: 183.0000 - fn: 217.0000 - accuracy: 0.4575 - precision: 0.4575 - recall: 0.4575 - auc: 0.7057 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 261500-262000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4512 - tp: 194.0000 - fp: 206.0000 - tn: 194.0000 - fn: 206.0000 - accuracy: 0.4850 - precision: 0.4850 - recall: 0.4850 - auc: 0.7348 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 262000-262500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4048 - tp: 212.0000 - fp: 188.0000 - tn: 212.0000 - fn: 188.0000 - accuracy: 0.5300 - precision: 0.5300 - recall: 0.5300 - auc: 0.7791 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 262500-263000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4231 - tp: 200.0000 - fp: 200.0000 - tn: 200.0000 - fn: 200.0000 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.5000 - auc: 0.7500 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 263000-263500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4415 - tp: 188.0000 - fp: 212.0000 - tn: 188.0000 - fn: 212.0000 - accuracy: 0.4700 - precision: 0.4700 - recall: 0.4700 - auc: 0.7191 - val_loss: 0.0000e+00 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 263500-264000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 3.9160 - tp: 221.0000 - fp: 179.0000 - tn: 221.0000 - fn: 179.0000 - accuracy: 0.5525 - precision: 0.5525 - recall: 0.5525 - auc: 0.6198 - val_loss: 1.7035 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 264000-264500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.5652 - tp: 292.0000 - fp: 108.0000 - tn: 292.0000 - fn: 108.0000 - accuracy: 0.7300 - precision: 0.7300 - recall: 0.7300 - auc: 0.6102 - val_loss: 0.1526 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 264500-265000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5857 - tp: 354.0000 - fp: 46.0000 - tn: 354.0000 - fn: 46.0000 - accuracy: 0.8850 - precision: 0.8850 - recall: 0.8850 - auc: 0.8503 - val_loss: 0.7708 - val_tp: 50.0000 - val_fp: 50.0000 - val_tn: 50.0000 - val_fn: 50.0000 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_auc: 0.7049
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 265000-265500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.1573 - tp: 287.0000 - fp: 113.0000 - tn: 287.0000 - fn: 113.0000 - accuracy: 0.7175 - precision: 0.7175 - recall: 0.7175 - auc: 0.6155 - val_loss: 0.2671 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 265500-266000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7556 - tp: 335.0000 - fp: 65.0000 - tn: 335.0000 - fn: 65.0000 - accuracy: 0.8375 - precision: 0.8375 - recall: 0.8375 - auc: 0.7964 - val_loss: 0.2109 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 266000-266500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3970 - tp: 374.0000 - fp: 26.0000 - tn: 374.0000 - fn: 26.0000 - accuracy: 0.9350 - precision: 0.9350 - recall: 0.9350 - auc: 0.9594 - val_loss: 0.2457 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 266500-267000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4176 - tp: 378.0000 - fp: 22.0000 - tn: 378.0000 - fn: 22.0000 - accuracy: 0.9450 - precision: 0.9450 - recall: 0.9450 - auc: 0.9735 - val_loss: 0.2937 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 267000-267500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3469 - tp: 391.0000 - fp: 9.0000 - tn: 391.0000 - fn: 9.0000 - accuracy: 0.9775 - precision: 0.9775 - recall: 0.9775 - auc: 0.9962 - val_loss: 0.3911 - val_tp: 88.0000 - val_fp: 12.0000 - val_tn: 88.0000 - val_fn: 12.0000 - val_accuracy: 0.8800 - val_precision: 0.8800 - val_recall: 0.8800 - val_auc: 0.9469
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 267500-268000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4081 - tp: 379.0000 - fp: 21.0000 - tn: 379.0000 - fn: 21.0000 - accuracy: 0.9475 - precision: 0.9475 - recall: 0.9475 - auc: 0.9596 - val_loss: 0.2067 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 268000-268500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3229 - tp: 397.0000 - fp: 3.0000 - tn: 397.0000 - fn: 3.0000 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925 - auc: 0.9999 - val_loss: 0.1643 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 268500-269000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3214 - tp: 398.0000 - fp: 2.0000 - tn: 398.0000 - fn: 2.0000 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - val_loss: 0.2340 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 269000-269500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3710 - tp: 387.0000 - fp: 13.0000 - tn: 387.0000 - fn: 13.0000 - accuracy: 0.9675 - precision: 0.9675 - recall: 0.9675 - auc: 0.9711 - val_loss: 0.1815 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 269500-270000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.5243 - tp: 366.0000 - fp: 34.0000 - tn: 366.0000 - fn: 34.0000 - accuracy: 0.9150 - precision: 0.9150 - recall: 0.9150 - auc: 0.9039 - val_loss: 0.2437 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 270000-270500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4214 - tp: 369.0000 - fp: 31.0000 - tn: 369.0000 - fn: 31.0000 - accuracy: 0.9225 - precision: 0.9225 - recall: 0.9225 - auc: 0.9327 - val_loss: 0.2390 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 270500-271000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3797 - tp: 381.0000 - fp: 19.0000 - tn: 381.0000 - fn: 19.0000 - accuracy: 0.9525 - precision: 0.9525 - recall: 0.9525 - auc: 0.9772 - val_loss: 0.2542 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 271000-271500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.4445 - tp: 381.0000 - fp: 19.0000 - tn: 381.0000 - fn: 19.0000 - accuracy: 0.9525 - precision: 0.9525 - recall: 0.9525 - auc: 0.9331 - val_loss: 0.2195 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 271500-272000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2759 - tp: 397.0000 - fp: 3.0000 - tn: 397.0000 - fn: 3.0000 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925 - auc: 0.9973 - val_loss: 0.2309 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 272000-272500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2886 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2307 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 272500-273000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2487 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2031 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 273000-273500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2484 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - val_loss: 0.1832 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 273500-274000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2272 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1599 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 274000-274500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2284 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1102 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 274500-275000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2267 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1616 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 275000-275500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2247 - tp: 397.0000 - fp: 3.0000 - tn: 397.0000 - fn: 3.0000 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925 - auc: 0.9975 - val_loss: 0.0805 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 275500-276000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2252 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1855 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 276000-276500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2323 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1236 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 276500-277000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2102 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1096 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 277000-277500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2006 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0746 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 277500-278000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1953 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0477 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 278000-278500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1803 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1163 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 278500-279000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1905 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0357 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 279000-279500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.4916 - tp: 273.0000 - fp: 127.0000 - tn: 273.0000 - fn: 127.0000 - accuracy: 0.6825 - precision: 0.6825 - recall: 0.6825 - auc: 0.7033 - val_loss: 0.5046 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 279500-280000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3593 - tp: 372.0000 - fp: 28.0000 - tn: 372.0000 - fn: 28.0000 - accuracy: 0.9300 - precision: 0.9300 - recall: 0.9300 - auc: 0.9475 - val_loss: 0.1578 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 280000-280500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.9820 - tp: 191.0000 - fp: 209.0000 - tn: 191.0000 - fn: 209.0000 - accuracy: 0.4775 - precision: 0.4775 - recall: 0.4775 - auc: 0.6477 - val_loss: 0.0118 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 280500-281000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7831 - tp: 180.0000 - fp: 220.0000 - tn: 180.0000 - fn: 220.0000 - accuracy: 0.4500 - precision: 0.4500 - recall: 0.4500 - auc: 0.6554 - val_loss: 0.0138 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 281000-281500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.7042 - tp: 241.0000 - fp: 159.0000 - tn: 241.0000 - fn: 159.0000 - accuracy: 0.6025 - precision: 0.6025 - recall: 0.6025 - auc: 0.6991 - val_loss: 0.1321 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 281500-282000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2504 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 0.9972 - val_loss: 0.1716 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 282000-282500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2490 - tp: 398.0000 - fp: 2.0000 - tn: 398.0000 - fn: 2.0000 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - val_loss: 0.1699 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 282500-283000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2297 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 1.0000 - val_loss: 0.1478 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 283000-283500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2270 - tp: 399.0000 - fp: 1.0000 - tn: 399.0000 - fn: 1.0000 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - auc: 0.9973 - val_loss: 0.1403 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 283500-284000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2090 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1539 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 284000-284500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.3209 - tp: 379.0000 - fp: 21.0000 - tn: 379.0000 - fn: 21.0000 - accuracy: 0.9475 - precision: 0.9475 - recall: 0.9475 - auc: 0.9593 - val_loss: 0.2392 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 284500-285000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2784 - tp: 390.0000 - fp: 10.0000 - tn: 390.0000 - fn: 10.0000 - accuracy: 0.9750 - precision: 0.9750 - recall: 0.9750 - auc: 0.9825 - val_loss: 0.1496 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 285000-285500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1799 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1435 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 285500-286000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2006 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1378 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 286000-286500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1936 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1314 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 286500-287000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1945 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1261 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 287000-287500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1817 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1239 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 287500-288000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1898 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1221 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 288000-288500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1884 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1212 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 288500-289000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1802 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1186 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 289000-289500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1701 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1121 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 289500-290000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1734 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0981 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 290000-290500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1648 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1125 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 290500-291000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1689 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1102 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 291000-291500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1665 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1038 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 291500-292000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1608 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0949 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 292000-292500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1590 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0990 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 292500-293000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1692 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0995 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 293000-293500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1595 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0973 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 293500-294000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1503 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0803 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 294000-294500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1536 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0951 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 294500-295000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1380 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0934 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 295000-295500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1505 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0890 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 295500-296000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1421 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0844 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 296000-296500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1369 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0818 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 296500-297000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1350 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0811 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 297000-297500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1311 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0806 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 297500-298000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1224 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0807 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 298000-298500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1409 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0639 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 298500-299000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1194 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0803 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 299000-299500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1399 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0788 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 299500-300000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1281 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0720 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 300000-300500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1281 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0661 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 300500-301000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1207 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0682 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 301000-301500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1283 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0664 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 301500-302000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1253 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0689 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 302000-302500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1215 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0535 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 302500-303000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 1.7777 - tp: 153.0000 - fp: 247.0000 - tn: 153.0000 - fn: 247.0000 - accuracy: 0.3825 - precision: 0.3825 - recall: 0.3825 - auc: 0.3752 - val_loss: 2.6109 - val_tp: 0.0000e+00 - val_fp: 100.0000 - val_tn: 0.0000e+00 - val_fn: 100.0000 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 303000-303500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.2476 - tp: 380.0000 - fp: 20.0000 - tn: 380.0000 - fn: 20.0000 - accuracy: 0.9500 - precision: 0.9500 - recall: 0.9500 - auc: 0.9533 - val_loss: 0.0829 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 303500-304000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1270 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0806 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 304000-304500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1464 - tp: 398.0000 - fp: 2.0000 - tn: 398.0000 - fn: 2.0000 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - auc: 1.0000 - val_loss: 0.0789 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 304500-305000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1403 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0815 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 305000-305500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1301 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0819 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 305500-306000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1245 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0781 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 306000-306500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1187 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0767 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 306500-307000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1288 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0742 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 307000-307500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1210 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0736 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 307500-308000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1237 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0736 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 308000-308500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1213 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0699 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 308500-309000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1227 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0695 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 309000-309500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1226 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0722 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 309500-310000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1122 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0702 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 310000-310500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1121 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0679 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 310500-311000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1102 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0627 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 311000-311500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1025 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0646 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 311500-312000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1088 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0635 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 312000-312500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1121 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0627 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 312500-313000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1003 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0587 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 313000-313500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1036 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0624 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 313500-314000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0966 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0621 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 314000-314500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0971 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0608 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 314500-315000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1013 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0581 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 315000-315500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0915 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0570 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 315500-316000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1036 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0562 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 316000-316500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.1022 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0551 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 316500-317000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0970 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0539 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 317000-317500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0893 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0500 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 317500-318000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0902 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0546 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 318000-318500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0868 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0540 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 318500-319000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0889 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0523 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 319000-319500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0879 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0496 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 319500-320000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0803 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0493 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 320000-320500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0879 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0484 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 320500-321000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0835 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0473 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 321000-321500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0845 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0438 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 321500-322000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0874 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0436 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 322000-322500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0923 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0480 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 322500-323000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0889 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0475 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 323000-323500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0861 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0459 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 323500-324000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0837 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0432 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 324000-324500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0765 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0433 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 324500-325000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0830 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0425 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 325000-325500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0860 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0414 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 325500-326000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0826 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0377 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 326000-326500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0820 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0425 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 326500-327000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0790 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0426 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 327000-327500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0826 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0416 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 327500-328000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0751 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0390 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 328000-328500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0786 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0385 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 328500-329000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0777 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0376 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 329000-329500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0770 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0361 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 329500-330000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0783 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0335 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 330000-330500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0752 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0310 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 330500-331000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0801 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0367 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 331000-331500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0709 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0376 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 331500-332000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0694 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0358 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 332000-332500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0725 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0339 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 332500-333000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0679 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0339 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 333000-333500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0705 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0332 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 333500-334000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0747 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0319 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 334000-334500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0722 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0317 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 334500-335000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0706 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0330 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 335000-335500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0734 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0315 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 335500-336000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0715 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0299 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 336000-336500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0673 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0334 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 336500-337000/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0678 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0322 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 337000-337500/337500
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 400 samples, validate on 100 samples
Epoch 1/1
 - 0s - loss: 0.0610 - tp: 400.0000 - fp: 0.0000e+00 - tn: 400.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0296 - val_tp: 100.0000 - val_fp: 0.0000e+00 - val_tn: 100.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[33m[LOSS] 0.029609356224536896[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.029609356224536896  <  0.001
--- 86.52630710601807 seconds ---
Using TensorFlow backend.
set classes to: ['Normal', 'Attack']
=================================================
        SCORING v0.4.1 (binaryClasses)
=================================================
Date: 2020-02-06 22:18:43.180285
[33m[INFO] using Sequential Dense layers[0m
2020-02-06 22:18:43.182892: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-06 22:18:43.192512: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb062514a50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-06 22:18:43.192552: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
[INFO] adding core layer 0
[INFO] created DNN
loading weights: checkpoints/*
loading file checkpoints/dnn-epoch-003-files-0-1
[33m[INFO] model summary:[0m
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 10)                460       
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 10)                0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 10)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 50)                550       
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 50)                0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 10)                510       
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU)    (None, 10)                0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 10)                0         
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 11        
_________________________________________________________________
leaky_re_lu_4 (LeakyReLU)    (None, 1)                 0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 1)                 0         
_________________________________________________________________
dense_5 (Dense)              (None, 2)                 4         
=================================================================
Total params: 1,535
Trainable params: 1,535
Non-trainable params: 0
_________________________________________________________________
[INFO] reading file data/SWaT_Dataset_Attack_v0-fixed-zscore-eval.csv
[INFO] process dataset, shape: (112419, 46)
dropping all time related columns...
[INFO] columns: Index([' Timestamp', 'FIT101', 'LIT101', ' MV101', 'P101', 'P102', ' AIT201',
       'AIT202', 'AIT203', 'FIT201', ' MV201', ' P201', 'P203', ' P204',
       'P205', 'P206', 'DPIT301', 'FIT301', 'LIT301', 'MV301', 'MV302',
       ' MV303', 'MV304', 'P302', 'AIT401', 'AIT402', 'FIT401', 'LIT401',
       'P402', 'P403', 'UV401', 'AIT501', 'AIT502', 'AIT503', 'AIT504',
       'FIT501', 'FIT502', 'FIT503', 'FIT504', 'P501', 'PIT501', 'PIT502',
       'PIT503', 'FIT601', 'P602', 'Normal/Attack'],
      dtype='object')
[INFO] analyze dataset: (112419, 46)

[INFO] analyzing data
[INFO] 112419 rows
[INFO] **  Timestamp:112419 (100.0%)
[INFO] ** FIT101:1567 (1.39389%)
[INFO] ** LIT101:7613 (6.77199%)
[INFO] **  MV101:[0.6938601612308597:72.68522%,-1.37943945543643:26.76327%,-3.45273907210372:0.55151%]
[INFO] ** P101:[0.6651894939633108:74.93395%,-1.5033276779817293:25.06605%]
[INFO] ** P102:[-0.08363168789888377:99.91194%,11.957163636189915:0.08806%]
[INFO] **  AIT201:551 (0.49013%)
[INFO] ** AIT202:409 (0.36382%)
[INFO] ** AIT203:828 (0.73653%)
[INFO] ** FIT201:1182 (1.05142%)
[INFO] **  MV201:[0.6553506537900002:75.6349%,-1.4695445682631785:23.85451%,-3.594439790316357:0.51059%]
[INFO] **  P201:[-0.3711397747256085:77.46644%,2.694396681457884:22.53356%]
[INFO] ** P203:[0.6692003594360194:74.75249%,-1.4943174540738025:25.24751%]
[INFO] **  P204:[-0.011157153119183022:100.0%]
[INFO] ** P205:[0.6685077097855787:74.75249%,-1.4958657360862018:25.24751%]
[INFO] ** P206:[-0.011057074654941896:100.0%]
[INFO] ** DPIT301:2660 (2.36615%)
[INFO] ** FIT301:2807 (2.49691%)
[INFO] ** LIT301:6761 (6.01411%)
[INFO] ** MV301:[-0.05968502020378725:98.31167%,8.092538600035379:1.22666%,-8.211908640442951:0.46167%]
[INFO] ** MV302:[0.5583947454367745:81.60186%,-1.6721055916890581:17.64737%,-3.90260592881489:0.75076%]
[INFO] **  MV303:[-0.1286843177487687:96.00068%,5.382740675797965:3.39%,-5.640109311295503:0.60933%]
[INFO] ** MV304:[-0.31215114727669235:95.29172%,2.77348506126076:3.9077%,-3.3977873558141454:0.80058%]
[INFO] ** P302:[0.5419881237902765:83.67625%,-1.8450547779247228:16.32375%]
[INFO] ** AIT401:[-0.6828542003724859:54.02734%,0.5514741309424019:38.80572%,-3.1515108630095705:5.5133%,1.7858024622645985:1.02563%,-4.385839194324459:0.26508%,3.0201307935794866:0.15834%,-5.6201675256466554:0.08095%,5.4887874562165715:0.05515%,-6.8544958569615435:0.03647%,6.7231157875314596:0.01156%,-9.348867693168602:0.00978%,-10.58319602448349:0.00445%,9.191772450168543:0.00267%,7.957444118853655:0.00178%,11.6861442863756:0.00178%]
[INFO] ** AIT402:546 (0.48568%)
[INFO] ** FIT401:325 (0.2891%)
[INFO] ** LIT401:4736 (4.21281%)
[INFO] ** P402:[0.2768891277719205:100.0%]
[INFO] ** P403:[-0.011548802005532082:100.0%]
[INFO] ** UV401:[0.28300123965589524:99.73759%,-3.5335455724279363:0.26241%]
[INFO] ** AIT501:531 (0.47234%)
[INFO] ** AIT502:554 (0.4928%)
[INFO] ** AIT503:898 (0.7988%)
[INFO] ** AIT504:187 (0.16634%)
[INFO] ** FIT501:375 (0.33357%)
[INFO] ** FIT502:845 (0.75165%)
[INFO] ** FIT503:192 (0.17079%)
[INFO] ** FIT504:150 (0.13343%)
[INFO] ** P501:[0.28297375234544503:99.73759%,-3.5338888115564147:0.26241%]
[INFO] ** PIT501:496 (0.44121%)
[INFO] ** PIT502:[-0.08783394075907375:11.23209%,-0.5147752535721024:10.99369%,-0.4759625611392665:9.31159%,-0.12664663319190989:8.68625%,-0.0102078290140447:7.59391%,0.028605105711909738:7.5521%,-0.3983366916873565:6.36547%,-0.2042725026438196:5.72056%,-0.2818981298026107:5.1904%,-0.16545956791786462:5.15037%,-0.3207110645285654:5.12013%,-0.3595239992545207:4.82303%,-0.5535881882980573:3.66219%,0.06741804043786526:2.54494%,-0.5924008807308935:1.67232%,0.10623097516382024:1.34586%,-2.455417870886828:0.6796%,0.18385684461572965:0.66982%,-0.6700267501828034:0.55596%,0.2226697793416852:0.32379%,-0.7088394426156394:0.23928%,0.2614827140676401:0.16545%,-0.7476523773415943:0.11386%,0.3002956487935945:0.10852%,0.3779190953143152:0.05426%,-0.7864653120675492:0.03736%,-0.8640909392263404:0.03202%,0.4167320300402701:0.01601%,0.4555449647662251:0.0089%,-0.9029038739522952:0.00801%,-0.9417165663851312:0.00623%,0.4943578994921801:0.00623%,0.688422573121955:0.00178%,-1.0581551282698771:0.00178%,-0.9805295011110864:0.00178%,-2.261353609155356:0.00089%,-2.0284765580738:0.00089%,-1.7567864995783529:0.00089%,-1.640347937693607:0.00089%,-1.252219317313414:0.00089%]
[INFO] ** PIT503:483 (0.42964%)
[INFO] ** FIT601:1371 (1.21954%)
[INFO] ** P602:[-0.09582773592458206:98.90588%,10.435368922466347:1.09412%]
[INFO] ** Normal/Attack:[Normal:95.28105%,Attack:4.71895%]
[INFO] columns with count within 2-10 {' MV101': 3, 'P101': 2, 'P102': 2, ' MV201': 3, ' P201': 2, 'P203': 2, 'P205': 2, 'MV301': 3, 'MV302': 3, ' MV303': 3, 'MV304': 3, 'P302': 2, 'UV401': 2, 'P501': 2, 'P602': 2, 'Normal/Attack': 2}
[INFO] processing batch 0-500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.028948795050382614
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[500   0]
 [  0   0]]
[INFO] processing batch 500-1000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02896625053882599
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[1000    0]
 [   0    0]]
[INFO] processing batch 1000-1500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029756001338362693
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[1500    0]
 [   0    0]]
[INFO] processing batch 1500-2000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03036056101322174
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[2000    0]
 [   0    0]]
[INFO] processing batch 2000-2500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.027406691044569016
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[2500    0]
 [   0    0]]
[INFO] processing batch 2500-3000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029254465878009797
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[3000    0]
 [   0    0]]
[INFO] processing batch 3000-3500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.032216297924518585
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[3500    0]
 [   0    0]]
[INFO] processing batch 3500-4000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03193573354184628
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[4000    0]
 [   0    0]]
[INFO] processing batch 4000-4500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03064795371890068
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[4500    0]
 [   0    0]]
[INFO] processing batch 4500-5000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029619813084602355
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[5000    0]
 [   0    0]]
[INFO] processing batch 5000-5500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02933757385611534
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[5500    0]
 [   0    0]]
[INFO] processing batch 5500-6000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0313989055454731
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[6000    0]
 [   0    0]]
[INFO] processing batch 6000-6500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03078987707197666
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[6500    0]
 [   0    0]]
[INFO] processing batch 6500-7000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02690867367386818
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[7000    0]
 [   0    0]]
[INFO] processing batch 7000-7500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03113839653134346
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[7500    0]
 [   0    0]]
[INFO] processing batch 7500-8000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03198998141288757
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[8000    0]
 [   0    0]]
[INFO] processing batch 8000-8500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03039152070879936
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[8500    0]
 [   0    0]]
[INFO] processing batch 8500-9000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029235937744379045
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[9000    0]
 [   0    0]]
[INFO] processing batch 9000-9500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.028981228694319724
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[9500    0]
 [   0    0]]
[INFO] processing batch 9500-10000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.031003810897469522
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[10000     0]
 [    0     0]]
[INFO] processing batch 10000-10500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] (500,)
[INFO] Validation score: [33m0.358[0m
[33m[INFO] metrics:[0m
loss :  2.2950959305763243
tp :  179.0
fp :  321.0
tn :  179.0
fn :  321.0
accuracy :  0.3580000102519989
precision :  0.3580000102519989
recall :  0.3580000102519989
auc :  0.16179199516773224

y_eval {0: 179, 1: 321}
pred {0: 500}
[INFO] confusion matrix for file 
[[179   0]
 [321   0]]
[INFO] confusion matrix after adding it to total:
[[10179     0]
 [  321     0]]
[INFO] processing batch 10500-11000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m0.44[0m
[33m[INFO] metrics:[0m
loss :  2.0188156031668187
tp :  220.0
fp :  280.0
tn :  220.0
fn :  280.0
accuracy :  0.4399999976158142
precision :  0.4399999976158142
recall :  0.4399999976158142
auc :  0.418720006942749

y_eval {0: 220, 1: 280}
pred {0: 500}
[INFO] confusion matrix for file 
[[220   0]
 [280   0]]
[INFO] confusion matrix after adding it to total:
[[10399     0]
 [  601     0]]
[INFO] processing batch 11000-11500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02889220231771469
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[10899     0]
 [  601     0]]
[INFO] processing batch 11500-12000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.031944694399833676
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[11399     0]
 [  601     0]]
[INFO] processing batch 12000-12500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030785052239894868
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[11899     0]
 [  601     0]]
[INFO] processing batch 12500-13000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03157891343533993
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[12399     0]
 [  601     0]]
[INFO] processing batch 13000-13500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029756852775812147
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[12899     0]
 [  601     0]]
[INFO] processing batch 13500-14000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030361509546637536
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[13399     0]
 [  601     0]]
[INFO] processing batch 14000-14500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029834453597664835
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[13899     0]
 [  601     0]]
[INFO] processing batch 14500-15000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029678172558546066
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[14399     0]
 [  601     0]]
[INFO] processing batch 15000-15500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03047093152999878
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[14899     0]
 [  601     0]]
[INFO] processing batch 15500-16000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.032399923086166384
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[15399     0]
 [  601     0]]
[INFO] processing batch 16000-16500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030350711315870284
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[15899     0]
 [  601     0]]
[INFO] processing batch 16500-17000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029278268247842788
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[16399     0]
 [  601     0]]
[INFO] processing batch 17000-17500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03224472099542618
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[16899     0]
 [  601     0]]
[INFO] processing batch 17500-18000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03214525604248047
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[17399     0]
 [  601     0]]
[INFO] processing batch 18000-18500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03105880084633827
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[17899     0]
 [  601     0]]
[INFO] processing batch 18500-19000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03029582741856575
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[18399     0]
 [  601     0]]
[INFO] processing batch 19000-19500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029568595036864282
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[18899     0]
 [  601     0]]
[INFO] processing batch 19500-20000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030525400176644325
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[19399     0]
 [  601     0]]
[INFO] processing batch 20000-20500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03022750309109688
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[19899     0]
 [  601     0]]
[INFO] processing batch 20500-21000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03113236254453659
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[20399     0]
 [  601     0]]
[INFO] processing batch 21000-21500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.031160615772008897
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[20899     0]
 [  601     0]]
[INFO] processing batch 21500-22000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.027065861463546753
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[21399     0]
 [  601     0]]
[INFO] processing batch 22000-22500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03064477887749672
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[21899     0]
 [  601     0]]
[INFO] processing batch 22500-23000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03276706743240356
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[22399     0]
 [  601     0]]
[INFO] processing batch 23000-23500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030711766690015792
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[22899     0]
 [  601     0]]
[INFO] processing batch 23500-24000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] (500,)
[INFO] Validation score: [33m0.382[0m
[33m[INFO] metrics:[0m
loss :  2.1714959901571276
tp :  191.0
fp :  309.0
tn :  191.0
fn :  309.0
accuracy :  0.38199999928474426
precision :  0.38199999928474426
recall :  0.38199999928474426
auc :  0.47115999460220337

y_eval {0: 191, 1: 309}
pred {0: 500}
[INFO] confusion matrix for file 
[[191   0]
 [309   0]]
[INFO] confusion matrix after adding it to total:
[[23090     0]
 [  910     0]]
[INFO] processing batch 24000-24500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m0.73[0m
[33m[INFO] metrics:[0m
loss :  0.9544139727205038
tp :  365.0
fp :  135.0
tn :  365.0
fn :  135.0
accuracy :  0.7300000190734863
precision :  0.7300000190734863
recall :  0.7300000190734863
auc :  0.7537599802017212

y_eval {0: 365, 1: 135}
pred {0: 500}
[INFO] confusion matrix for file 
[[365   0]
 [135   0]]
[INFO] confusion matrix after adding it to total:
[[23455     0]
 [ 1045     0]]
[INFO] processing batch 24500-25000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03061854737997055
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[23955     0]
 [ 1045     0]]
[INFO] processing batch 25000-25500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.031908839106559755
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[24455     0]
 [ 1045     0]]
[INFO] processing batch 25500-26000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030951640129089356
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[24955     0]
 [ 1045     0]]
[INFO] processing batch 26000-26500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03119166697561741
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[25455     0]
 [ 1045     0]]
[INFO] processing batch 26500-27000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02692569373548031
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[25955     0]
 [ 1045     0]]
[INFO] processing batch 27000-27500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02869877392053604
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[26455     0]
 [ 1045     0]]
[INFO] processing batch 27500-28000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03211642178893089
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[26955     0]
 [ 1045     0]]
[INFO] processing batch 28000-28500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03202616359293461
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[27455     0]
 [ 1045     0]]
[INFO] processing batch 28500-29000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029788552731275557
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[27955     0]
 [ 1045     0]]
[INFO] processing batch 29000-29500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02926176856458187
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[28455     0]
 [ 1045     0]]
[INFO] processing batch 29500-30000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029044304341077805
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[28955     0]
 [ 1045     0]]
[INFO] processing batch 30000-30500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.028391632437705993
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[29455     0]
 [ 1045     0]]
[INFO] processing batch 30500-31000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029905846506357192
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[29955     0]
 [ 1045     0]]
[INFO] processing batch 31000-31500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029941902697086333
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[30455     0]
 [ 1045     0]]
[INFO] processing batch 31500-32000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03107705166935921
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[30955     0]
 [ 1045     0]]
[INFO] processing batch 32000-32500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.025901424795389174
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[31455     0]
 [ 1045     0]]
[INFO] processing batch 32500-33000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029195829421281815
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[31955     0]
 [ 1045     0]]
[INFO] processing batch 33000-33500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03256313902139664
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[32455     0]
 [ 1045     0]]
[INFO] processing batch 33500-34000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] (500,)
[INFO] Validation score: [33m0.958[0m
[33m[INFO] metrics:[0m
loss :  0.1775516208410263
tp :  479.0
fp :  21.0
tn :  479.0
fn :  21.0
accuracy :  0.9580000042915344
precision :  0.9580000042915344
recall :  0.9580000042915344
auc :  0.9300280213356018

y_eval {0: 479, 1: 21}
pred {0: 500}
[INFO] confusion matrix for file 
[[479   0]
 [ 21   0]]
[INFO] confusion matrix after adding it to total:
[[32934     0]
 [ 1066     0]]
[INFO] processing batch 34000-34500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] (500,)
[INFO] Validation score: [33m0.55[0m
[33m[INFO] metrics:[0m
loss :  1.8243870698213578
tp :  275.0
fp :  225.0
tn :  275.0
fn :  225.0
accuracy :  0.550000011920929
precision :  0.550000011920929
recall :  0.550000011920929
auc :  0.5609639883041382

y_eval {0: 275, 1: 225}
pred {0: 500}
[INFO] confusion matrix for file 
[[275   0]
 [225   0]]
[INFO] confusion matrix after adding it to total:
[[33209     0]
 [ 1291     0]]
[INFO] processing batch 34500-35000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m0.328[0m
[33m[INFO] metrics:[0m
loss :  2.34631922352314
tp :  164.0
fp :  336.0
tn :  164.0
fn :  336.0
accuracy :  0.328000009059906
precision :  0.328000009059906
recall :  0.328000009059906
auc :  0.33556801080703735

y_eval {0: 164, 1: 336}
pred {0: 500}
[INFO] confusion matrix for file 
[[164   0]
 [336   0]]
[INFO] confusion matrix after adding it to total:
[[33373     0]
 [ 1627     0]]
[INFO] processing batch 35000-35500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.031583271265029904
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[33873     0]
 [ 1627     0]]
[INFO] processing batch 35500-36000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.031000526413321496
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[34373     0]
 [ 1627     0]]
[INFO] processing batch 36000-36500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02863225594162941
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[34873     0]
 [ 1627     0]]
[INFO] processing batch 36500-37000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.028432947292923928
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[35373     0]
 [ 1627     0]]
[INFO] processing batch 37000-37500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.027074649661779405
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[35873     0]
 [ 1627     0]]
[INFO] processing batch 37500-38000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.027880038380622862
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[36373     0]
 [ 1627     0]]
[INFO] processing batch 38000-38500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03171794632077217
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[36873     0]
 [ 1627     0]]
[INFO] processing batch 38500-39000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03196855354309082
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[37373     0]
 [ 1627     0]]
[INFO] processing batch 39000-39500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03011933897435665
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[37873     0]
 [ 1627     0]]
[INFO] processing batch 39500-40000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029390467047691344
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[38373     0]
 [ 1627     0]]
[INFO] processing batch 40000-40500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02950839900970459
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[38873     0]
 [ 1627     0]]
[INFO] processing batch 40500-41000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.028659790724515914
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[39373     0]
 [ 1627     0]]
[INFO] processing batch 41000-41500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03018352638185024
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[39873     0]
 [ 1627     0]]
[INFO] processing batch 41500-42000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03002880170941353
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[40373     0]
 [ 1627     0]]
[INFO] processing batch 42000-42500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03164848068356514
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[40873     0]
 [ 1627     0]]
[INFO] processing batch 42500-43000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02683601275086403
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[41373     0]
 [ 1627     0]]
[INFO] processing batch 43000-43500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.028816860496997835
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[41873     0]
 [ 1627     0]]
[INFO] processing batch 43500-44000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03211370632052422
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[42373     0]
 [ 1627     0]]
[INFO] processing batch 44000-44500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030855314016342162
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[42873     0]
 [ 1627     0]]
[INFO] processing batch 44500-45000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02929657791554928
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[43373     0]
 [ 1627     0]]
[INFO] processing batch 45000-45500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02963103035092354
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[43873     0]
 [ 1627     0]]
[INFO] processing batch 45500-46000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02850903369486332
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[44373     0]
 [ 1627     0]]
[INFO] processing batch 46000-46500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.028984284490346908
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[44873     0]
 [ 1627     0]]
[INFO] processing batch 46500-47000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029435312047600744
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[45373     0]
 [ 1627     0]]
[INFO] processing batch 47000-47500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.031093596160411834
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[45873     0]
 [ 1627     0]]
[INFO] processing batch 47500-48000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029956119418144227
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[46373     0]
 [ 1627     0]]
[INFO] processing batch 48000-48500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0262576931566
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[46873     0]
 [ 1627     0]]
[INFO] processing batch 48500-49000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02983643850684166
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[47373     0]
 [ 1627     0]]
[INFO] processing batch 49000-49500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03258158928155899
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[47873     0]
 [ 1627     0]]
[INFO] processing batch 49500-50000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03006585954129696
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[48373     0]
 [ 1627     0]]
[INFO] processing batch 50000-50500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029481110006570815
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[48873     0]
 [ 1627     0]]
[INFO] processing batch 50500-51000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029592154294252396
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[49373     0]
 [ 1627     0]]
[INFO] processing batch 51000-51500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.028815840154886245
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[49873     0]
 [ 1627     0]]
[INFO] processing batch 51500-52000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02862203051149845
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[50373     0]
 [ 1627     0]]
[INFO] processing batch 52000-52500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] (500,)
[INFO] Validation score: [33m0.36[0m
[33m[INFO] metrics:[0m
loss :  2.2577574753761294
tp :  180.0
fp :  320.0
tn :  180.0
fn :  320.0
accuracy :  0.36000001430511475
precision :  0.36000001430511475
recall :  0.36000001430511475
auc :  0.44488000869750977

y_eval {0: 180, 1: 320}
pred {0: 500}
[INFO] confusion matrix for file 
[[180   0]
 [320   0]]
[INFO] confusion matrix after adding it to total:
[[50553     0]
 [ 1947     0]]
[INFO] processing batch 52500-53000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m0.56[0m
[33m[INFO] metrics:[0m
loss :  1.5556427527666092
tp :  280.0
fp :  220.0
tn :  280.0
fn :  220.0
accuracy :  0.5600000023841858
precision :  0.5600000023841858
recall :  0.5600000023841858
auc :  0.5249600410461426

y_eval {0: 280, 1: 220}
pred {0: 500}
[INFO] confusion matrix for file 
[[280   0]
 [220   0]]
[INFO] confusion matrix after adding it to total:
[[50833     0]
 [ 2167     0]]
[INFO] processing batch 53000-53500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030175925463438034
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[51333     0]
 [ 2167     0]]
[INFO] processing batch 53500-54000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02837159466743469
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[51833     0]
 [ 2167     0]]
[INFO] processing batch 54000-54500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02930547797679901
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[52333     0]
 [ 2167     0]]
[INFO] processing batch 54500-55000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02930289922654629
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[52833     0]
 [ 2167     0]]
[INFO] processing batch 55000-55500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029543545216321944
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[53333     0]
 [ 2167     0]]
[INFO] processing batch 55500-56000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.031138029158115386
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[53833     0]
 [ 2167     0]]
[INFO] processing batch 56000-56500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.028471005111932755
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[54333     0]
 [ 2167     0]]
[INFO] processing batch 56500-57000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02868131625652313
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[54833     0]
 [ 2167     0]]
[INFO] processing batch 57000-57500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029070711597800256
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[55333     0]
 [ 2167     0]]
[INFO] processing batch 57500-58000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029472375422716142
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[55833     0]
 [ 2167     0]]
[INFO] processing batch 58000-58500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03029601062834263
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[56333     0]
 [ 2167     0]]
[INFO] processing batch 58500-59000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02544244696199894
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[56833     0]
 [ 2167     0]]
[INFO] processing batch 59000-59500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029115594774484634
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[57333     0]
 [ 2167     0]]
[INFO] processing batch 59500-60000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.032396091490983964
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[57833     0]
 [ 2167     0]]
[INFO] processing batch 60000-60500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03059421646595001
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[58333     0]
 [ 2167     0]]
[INFO] processing batch 60500-61000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029174344047904015
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[58833     0]
 [ 2167     0]]
[INFO] processing batch 61000-61500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029652678593993186
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[59333     0]
 [ 2167     0]]
[INFO] processing batch 61500-62000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.028995513558387757
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[59833     0]
 [ 2167     0]]
[INFO] processing batch 62000-62500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.027463977485895158
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[60333     0]
 [ 2167     0]]
[INFO] processing batch 62500-63000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029298044323921205
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[60833     0]
 [ 2167     0]]
[INFO] processing batch 63000-63500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.031504889637231824
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[61333     0]
 [ 2167     0]]
[INFO] processing batch 63500-64000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0299669733941555
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[61833     0]
 [ 2167     0]]
[INFO] processing batch 64000-64500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02687885093688965
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[62333     0]
 [ 2167     0]]
[INFO] processing batch 64500-65000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03088665345311165
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[62833     0]
 [ 2167     0]]
[INFO] processing batch 65000-65500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03179982936382294
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[63333     0]
 [ 2167     0]]
[INFO] processing batch 65500-66000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030110516414046287
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[63833     0]
 [ 2167     0]]
[INFO] processing batch 66000-66500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029179361000657083
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[64333     0]
 [ 2167     0]]
[INFO] processing batch 66500-67000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.028713143795728684
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[64833     0]
 [ 2167     0]]
[INFO] processing batch 67000-67500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029492619007825852
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[65333     0]
 [ 2167     0]]
[INFO] processing batch 67500-68000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029932037681341173
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[65833     0]
 [ 2167     0]]
[INFO] processing batch 68000-68500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0295728816986084
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[66333     0]
 [ 2167     0]]
[INFO] processing batch 68500-69000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03130579867959023
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[66833     0]
 [ 2167     0]]
[INFO] processing batch 69000-69500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.027007360070943832
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[67333     0]
 [ 2167     0]]
[INFO] processing batch 69500-70000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02935705202817917
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[67833     0]
 [ 2167     0]]
[INFO] processing batch 70000-70500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.031396892786026004
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[68333     0]
 [ 2167     0]]
[INFO] processing batch 70500-71000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03174943071603775
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[68833     0]
 [ 2167     0]]
[INFO] processing batch 71000-71500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030016203492879867
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[69333     0]
 [ 2167     0]]
[INFO] processing batch 71500-72000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02942527487874031
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[69833     0]
 [ 2167     0]]
[INFO] processing batch 72000-72500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029326964288949965
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[70333     0]
 [ 2167     0]]
[INFO] processing batch 72500-73000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.028784087762236597
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[70833     0]
 [ 2167     0]]
[INFO] processing batch 73000-73500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.028661100879311563
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[71333     0]
 [ 2167     0]]
[INFO] processing batch 73500-74000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03121621686220169
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[71833     0]
 [ 2167     0]]
[INFO] processing batch 74000-74500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03126681795716286
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[72333     0]
 [ 2167     0]]
[INFO] processing batch 74500-75000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.026981438249349593
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[72833     0]
 [ 2167     0]]
[INFO] processing batch 75000-75500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03016325291991234
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[73333     0]
 [ 2167     0]]
[INFO] processing batch 75500-76000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03188687342405319
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[73833     0]
 [ 2167     0]]
[INFO] processing batch 76000-76500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030069760784506797
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[74333     0]
 [ 2167     0]]
[INFO] processing batch 76500-77000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02899074211716652
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[74833     0]
 [ 2167     0]]
[INFO] processing batch 77000-77500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029023974299430846
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[75333     0]
 [ 2167     0]]
[INFO] processing batch 77500-78000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030719788759946822
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[75833     0]
 [ 2167     0]]
[INFO] processing batch 78000-78500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030618104591965675
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[76333     0]
 [ 2167     0]]
[INFO] processing batch 78500-79000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030072918444871904
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[76833     0]
 [ 2167     0]]
[INFO] processing batch 79000-79500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03213673824071884
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[77333     0]
 [ 2167     0]]
[INFO] processing batch 79500-80000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.028989075645804406
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[77833     0]
 [ 2167     0]]
[INFO] processing batch 80000-80500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029516753658652306
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[78333     0]
 [ 2167     0]]
[INFO] processing batch 80500-81000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03199143573641777
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[78833     0]
 [ 2167     0]]
[INFO] processing batch 81000-81500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03134207490086555
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[79333     0]
 [ 2167     0]]
[INFO] processing batch 81500-82000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030717592656612395
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[79833     0]
 [ 2167     0]]
[INFO] processing batch 82000-82500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030072131380438804
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[80333     0]
 [ 2167     0]]
[INFO] processing batch 82500-83000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029110854864120482
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[80833     0]
 [ 2167     0]]
[INFO] processing batch 83000-83500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029280768543481828
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[81333     0]
 [ 2167     0]]
[INFO] processing batch 83500-84000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030496922820806502
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[81833     0]
 [ 2167     0]]
[INFO] processing batch 84000-84500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03073633497953415
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[82333     0]
 [ 2167     0]]
[INFO] processing batch 84500-85000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03146941778063774
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[82833     0]
 [ 2167     0]]
[INFO] processing batch 85000-85500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.027079458087682723
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[83333     0]
 [ 2167     0]]
[INFO] processing batch 85500-86000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030267681151628496
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[83833     0]
 [ 2167     0]]
[INFO] processing batch 86000-86500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03263704442977905
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[84333     0]
 [ 2167     0]]
[INFO] processing batch 86500-87000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030938282743096353
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[84833     0]
 [ 2167     0]]
[INFO] processing batch 87000-87500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02995035281777382
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[85333     0]
 [ 2167     0]]
[INFO] processing batch 87500-88000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030284514099359512
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[85833     0]
 [ 2167     0]]
[INFO] processing batch 88000-88500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.029688968792557717
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[86333     0]
 [ 2167     0]]
[INFO] processing batch 88500-89000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03053496541082859
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[86833     0]
 [ 2167     0]]
[INFO] processing batch 89000-89500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0302121125459671
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[87333     0]
 [ 2167     0]]
[INFO] processing batch 89500-90000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03198991963267327
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[87833     0]
 [ 2167     0]]
[INFO] processing batch 90000-90500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02971437619626522
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[88333     0]
 [ 2167     0]]
[INFO] processing batch 90500-91000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.028680879458785058
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[88833     0]
 [ 2167     0]]
[INFO] processing batch 91000-91500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0319192054271698
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[89333     0]
 [ 2167     0]]
[INFO] processing batch 91500-92000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03276078504323959
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[89833     0]
 [ 2167     0]]
[INFO] processing batch 92000-92500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03174632662534714
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[90333     0]
 [ 2167     0]]
[INFO] processing batch 92500-93000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03132236063480377
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[90833     0]
 [ 2167     0]]
[INFO] processing batch 93000-93500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03149834209680557
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[91333     0]
 [ 2167     0]]
[INFO] processing batch 93500-94000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.031216319903731346
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[91833     0]
 [ 2167     0]]
[INFO] processing batch 94000-94500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03097535455226898
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[92333     0]
 [ 2167     0]]
[INFO] processing batch 94500-95000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02897797083854675
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[92833     0]
 [ 2167     0]]
[INFO] processing batch 95000-95500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03171686205267906
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[93333     0]
 [ 2167     0]]
[INFO] processing batch 95500-96000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03280381092429161
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[93833     0]
 [ 2167     0]]
[INFO] processing batch 96000-96500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03240818053483963
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[94333     0]
 [ 2167     0]]
[INFO] processing batch 96500-97000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.031468578159809114
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[94833     0]
 [ 2167     0]]
[INFO] processing batch 97000-97500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030984373897314073
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[95333     0]
 [ 2167     0]]
[INFO] processing batch 97500-98000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.031351295217871666
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[95833     0]
 [ 2167     0]]
[INFO] processing batch 98000-98500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.031080670475959776
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[96333     0]
 [ 2167     0]]
[INFO] processing batch 98500-99000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030975529193878172
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[96833     0]
 [ 2167     0]]
[INFO] processing batch 99000-99500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] (500,)
[INFO] Validation score: [33m0.082[0m
[33m[INFO] metrics:[0m
loss :  3.6645970532894134
tp :  41.0
fp :  459.0
tn :  41.0
fn :  459.0
accuracy :  0.0820000022649765
precision :  0.0820000022649765
recall :  0.0820000022649765
auc :  0.019516002386808395

y_eval {0: 41, 1: 459}
pred {0: 500}
[INFO] confusion matrix for file 
[[ 41   0]
 [459   0]]
[INFO] confusion matrix after adding it to total:
[[96874     0]
 [ 2626     0]]
[INFO] processing batch 99500-100000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] (500,)
[INFO] Validation score: [33m0.814[0m
[33m[INFO] metrics:[0m
loss :  0.6837479817867279
tp :  407.0
fp :  93.0
tn :  407.0
fn :  93.0
accuracy :  0.8140000104904175
precision :  0.8140000104904175
recall :  0.8140000104904175
auc :  0.8637440204620361

y_eval {0: 407, 1: 93}
pred {0: 500}
[INFO] confusion matrix for file 
[[407   0]
 [ 93   0]]
[INFO] confusion matrix after adding it to total:
[[97281     0]
 [ 2719     0]]
[INFO] processing batch 100000-100500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m0.604[0m
[33m[INFO] metrics:[0m
loss :  1.3776709983348847
tp :  302.0
fp :  198.0
tn :  302.0
fn :  198.0
accuracy :  0.6039999723434448
precision :  0.6039999723434448
recall :  0.6039999723434448
auc :  0.6039999723434448

y_eval {0: 302, 1: 198}
pred {0: 500}
[INFO] confusion matrix for file 
[[302   0]
 [198   0]]
[INFO] confusion matrix after adding it to total:
[[97583     0]
 [ 2917     0]]
[INFO] processing batch 100500-101000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] (500,)
[INFO] Validation score: [33m0.294[0m
[33m[INFO] metrics:[0m
loss :  2.4575951340198516
tp :  147.0
fp :  353.0
tn :  147.0
fn :  353.0
accuracy :  0.2939999997615814
precision :  0.2939999997615814
recall :  0.2939999997615814
auc :  0.2940000295639038

y_eval {0: 147, 1: 353}
pred {0: 500}
[INFO] confusion matrix for file 
[[147   0]
 [353   0]]
[INFO] confusion matrix after adding it to total:
[[97730     0]
 [ 3270     0]]
[INFO] processing batch 101000-101500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m0.31[0m
[33m[INFO] metrics:[0m
loss :  2.8465530249774456
tp :  155.0
fp :  345.0
tn :  155.0
fn :  345.0
accuracy :  0.3100000023841858
precision :  0.3100000023841858
recall :  0.3100000023841858
auc :  0.1662600040435791

y_eval {0: 155, 1: 345}
pred {0: 500}
[INFO] confusion matrix for file 
[[155   0]
 [345   0]]
[INFO] confusion matrix after adding it to total:
[[97885     0]
 [ 3615     0]]
[INFO] processing batch 101500-102000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03171473643183708
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[98385     0]
 [ 3615     0]]
[INFO] processing batch 102000-102500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030945626795291902
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[98885     0]
 [ 3615     0]]
[INFO] processing batch 102500-103000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.031357156455516816
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[99385     0]
 [ 3615     0]]
[INFO] processing batch 103000-103500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.031072555407881737
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[99885     0]
 [ 3615     0]]
[INFO] processing batch 103500-104000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.028645783036947252
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[100385      0]
 [  3615      0]]
[INFO] processing batch 104000-104500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.031614226162433624
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[100885      0]
 [  3615      0]]
[INFO] processing batch 104500-105000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03242527008056641
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[101385      0]
 [  3615      0]]
[INFO] processing batch 105000-105500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03241688552498818
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[101885      0]
 [  3615      0]]
[INFO] processing batch 105500-106000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.031386786818504334
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[102385      0]
 [  3615      0]]
[INFO] processing batch 106000-106500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] (500,)
[INFO] Validation score: [33m0.002[0m
[33m[INFO] metrics:[0m
loss :  3.4752668342590334
tp :  1.0
fp :  499.0
tn :  1.0
fn :  499.0
accuracy :  0.0020000000949949026
precision :  0.0020000000949949026
recall :  0.0020000000949949026
auc :  0.003719976171851158

y_eval {0: 1, 1: 499}
pred {0: 500}
[INFO] confusion matrix for file 
[[  1   0]
 [499   0]]
[INFO] confusion matrix after adding it to total:
[[102386      0]
 [  4114      0]]
[INFO] processing batch 106500-107000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] (500,)
[INFO] Validation score: [33m0.0[0m
[33m[INFO] metrics:[0m
loss :  3.454341138839722
tp :  0.0
fp :  500.0
tn :  0.0
fn :  500.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {1: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[  0   0]
 [500   0]]
[INFO] confusion matrix after adding it to total:
[[102386      0]
 [  4614      0]]
[INFO] processing batch 107000-107500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] (500,)
[INFO] Validation score: [33m0.0[0m
[33m[INFO] metrics:[0m
loss :  3.4482898540496825
tp :  0.0
fp :  500.0
tn :  0.0
fn :  500.0
accuracy :  0.0
precision :  0.0
recall :  0.0
auc :  0.0

y_eval {1: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[  0   0]
 [500   0]]
[INFO] confusion matrix after adding it to total:
[[102386      0]
 [  5114      0]]
[INFO] processing batch 107500-108000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m0.618[0m
[33m[INFO] metrics:[0m
loss :  1.3353977145850657
tp :  309.0
fp :  191.0
tn :  309.0
fn :  191.0
accuracy :  0.6179999709129333
precision :  0.6179999709129333
recall :  0.6179999709129333
auc :  0.7272520065307617

y_eval {0: 309, 1: 191}
pred {0: 500}
[INFO] confusion matrix for file 
[[309   0]
 [191   0]]
[INFO] confusion matrix after adding it to total:
[[102695      0]
 [  5305      0]]
[INFO] processing batch 108000-108500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.031853760302066804
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[103195      0]
 [  5305      0]]
[INFO] processing batch 108500-109000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03154830884933472
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[103695      0]
 [  5305      0]]
[INFO] processing batch 109000-109500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.02924173094332218
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[104195      0]
 [  5305      0]]
[INFO] processing batch 109500-110000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.03180543819069862
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[104695      0]
 [  5305      0]]
[INFO] processing batch 110000-110500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.032272042244672776
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[105195      0]
 [  5305      0]]
[INFO] processing batch 110500-111000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.031143062591552733
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[105695      0]
 [  5305      0]]
[INFO] processing batch 111000-111500/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.031192213654518127
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[106195      0]
 [  5305      0]]
[INFO] processing batch 111500-112000/112419
[33m[INFO] measuring accuracy...[0m
x_test.shape: (500, 45)
y_eval [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] (500,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.030608920902013777
tp :  500.0
fp :  0.0
tn :  500.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 500}
pred {0: 500}
[INFO] confusion matrix for file 
[[500   0]
 [  0   0]]
[INFO] confusion matrix after adding it to total:
[[106695      0]
 [  5305      0]]
[INFO] processing batch 112000-112500/112419
--- 6.984651803970337 seconds ---
