2020-02-03 12:55:46.799391: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-02-03 12:55:46.799441: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-02-03 12:55:46.799448: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-02-03 12:55:47.290574: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-02-03 12:55:47.290593: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-02-03 12:55:47.290608: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (brussels): /proc/driver/nvidia/version does not exist
2020-02-03 12:55:47.290713: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-03 12:55:47.313812: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3312000000 Hz
2020-02-03 12:55:47.313999: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f43c00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-03 12:55:47.314010: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-02-03 12:55:49.467026: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-03 12:55:49.479817: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 12:55:49.485431: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 12:55:49.532366: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-03 12:55:49.535148: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-03 12:55:49.539332: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 12:55:49.543441: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 12:55:49.554276: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-03 12:55:51.841844: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-03 12:55:51.845026: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 12:55:51.846454: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 12:55:51.857743: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-03 12:55:51.858494: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-03 12:55:51.859585: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 12:55:51.860698: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 12:55:51.863962: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
=============================
        TRAINING v0.3
=============================
Date: 2020-02-03 12:55:47.286991
[INFO] input_shape (10, 16)
[INFO] LSTM first and last layer neurons: 15
adding core layer 0
[INFO] created DNN
[33m[INFO] epoch 1/10[0m
[33m[INFO] loading file 1-1/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 3s - loss: 0.7451 - tp: 44762.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 35238.0000 - accuracy: 0.9119 - precision: 1.0000 - recall: 0.5595 - auc: 0.9660 - val_loss: 0.1897 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-1-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0894 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0400 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-1-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0479 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9978 - val_loss: 3.5993 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.6476
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-1-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.5057 - tp: 39810.0000 - fp: 35150.0000 - tn: 284850.0000 - fn: 40190.0000 - accuracy: 0.8117 - precision: 0.5311 - recall: 0.4976 - auc: 0.7829 - val_loss: 1.0236 - val_tp: 9629.0000 - val_fp: 8371.0000 - val_tn: 71629.0000 - val_fn: 10371.0000 - val_accuracy: 0.8126 - val_precision: 0.5349 - val_recall: 0.4814 - val_auc: 0.8938
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-1-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.8872 - tp: 40153.0000 - fp: 23851.0000 - tn: 296149.0000 - fn: 39847.0000 - accuracy: 0.8408 - precision: 0.6274 - recall: 0.5019 - auc: 0.9259 - val_loss: 0.6678 - val_tp: 10602.0000 - val_fp: 14.0000 - val_tn: 79986.0000 - val_fn: 9398.0000 - val_accuracy: 0.9059 - val_precision: 0.9987 - val_recall: 0.5301 - val_auc: 0.9543
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-1-batch-400000-500000
[33m[INFO] loading file 2-2/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.4677 - tp: 45457.0000 - fp: 26.0000 - tn: 319974.0000 - fn: 34543.0000 - accuracy: 0.9136 - precision: 0.9994 - recall: 0.5682 - auc: 0.9987 - val_loss: 0.3549 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-1-2-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.3690 - tp: 67236.0000 - fp: 12433.0000 - tn: 307567.0000 - fn: 12764.0000 - accuracy: 0.9370 - precision: 0.8439 - recall: 0.8404 - auc: 0.9814 - val_loss: 0.2111 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-1-2-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.2693 - tp: 72432.0000 - fp: 7568.0000 - tn: 312432.0000 - fn: 7568.0000 - accuracy: 0.9622 - precision: 0.9054 - recall: 0.9054 - auc: 0.9890 - val_loss: 0.8494 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 70593.0000 - val_fn: 9407.0000 - val_accuracy: 0.8119 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.9447
[INFO] saving weights to checkpoints/lstm-epoch-001-files-1-2-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.2793 - tp: 78546.0000 - fp: 1053.0000 - tn: 318947.0000 - fn: 1454.0000 - accuracy: 0.9937 - precision: 0.9868 - recall: 0.9818 - auc: 0.9982 - val_loss: 0.2208 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-1-2-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.3594 - tp: 66252.0000 - fp: 13453.0000 - tn: 306547.0000 - fn: 13748.0000 - accuracy: 0.9320 - precision: 0.8312 - recall: 0.8281 - auc: 0.9797 - val_loss: 0.1994 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-1-2-batch-400000-500000
[33m[INFO] loading file 3-3/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.2516 - tp: 76155.0000 - fp: 3615.0000 - tn: 316385.0000 - fn: 3845.0000 - accuracy: 0.9813 - precision: 0.9547 - recall: 0.9519 - auc: 0.9956 - val_loss: 0.1678 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-3-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.3603 - tp: 59212.0000 - fp: 12326.0000 - tn: 307674.0000 - fn: 20788.0000 - accuracy: 0.9172 - precision: 0.8277 - recall: 0.7401 - auc: 0.9767 - val_loss: 0.3977 - val_tp: 10692.0000 - val_fp: 7580.0000 - val_tn: 72420.0000 - val_fn: 9308.0000 - val_accuracy: 0.8311 - val_precision: 0.5852 - val_recall: 0.5346 - val_auc: 0.9453
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-3-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0144 - tp: 79572.0000 - fp: 196.0000 - tn: 319804.0000 - fn: 428.0000 - accuracy: 0.9984 - precision: 0.9975 - recall: 0.9947 - auc: 1.0000 - val_loss: 0.0030 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-3-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0024 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-3-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0016 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0014 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-2-3-batch-400000-500000
[33m[INFO] loading file 4-4/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0012 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0011 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-3-4-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0010 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.4229e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-3-4-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.5701e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.7897e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-3-4-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.3965 - tp: 71528.0000 - fp: 8472.0000 - tn: 311528.0000 - fn: 8472.0000 - accuracy: 0.9576 - precision: 0.8941 - recall: 0.8941 - auc: 0.9704 - val_loss: 1.4779 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 67806.0000 - val_fn: 12194.0000 - val_accuracy: 0.7561 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.8682
[INFO] saving weights to checkpoints/lstm-epoch-001-files-3-4-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.5725 - tp: 55916.0000 - fp: 22289.0000 - tn: 297711.0000 - fn: 24084.0000 - accuracy: 0.8841 - precision: 0.7150 - recall: 0.6989 - auc: 0.9467 - val_loss: 0.3580 - val_tp: 19149.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 851.0000 - val_accuracy: 0.9915 - val_precision: 1.0000 - val_recall: 0.9574 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-3-4-batch-400000-500000
[33m[INFO] loading file 5-5/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.3462 - tp: 65390.0000 - fp: 13081.0000 - tn: 306919.0000 - fn: 14610.0000 - accuracy: 0.9308 - precision: 0.8333 - recall: 0.8174 - auc: 0.9820 - val_loss: 0.2090 - val_tp: 19805.0000 - val_fp: 68.0000 - val_tn: 79932.0000 - val_fn: 195.0000 - val_accuracy: 0.9974 - val_precision: 0.9966 - val_recall: 0.9902 - val_auc: 0.9999
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-5-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0903 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5305 - val_tp: 15796.0000 - val_fp: 4204.0000 - val_tn: 75796.0000 - val_fn: 4204.0000 - val_accuracy: 0.9159 - val_precision: 0.7898 - val_recall: 0.7898 - val_auc: 0.9811
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-5-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0296 - tp: 79006.0000 - fp: 984.0000 - tn: 319016.0000 - fn: 994.0000 - accuracy: 0.9951 - precision: 0.9877 - recall: 0.9876 - auc: 0.9999 - val_loss: 0.0019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-5-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0016 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0013 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-5-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.2346e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-4-5-batch-400000-500000
[33m[INFO] loading file 6-6/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.9622e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.9159e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-5-6-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.1112e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.4007e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-5-6-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.8209e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.3003e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-5-6-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.9118e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8448 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 75632.0000 - val_fn: 4368.0000 - val_accuracy: 0.9126 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.8635
[INFO] saving weights to checkpoints/lstm-epoch-001-files-5-6-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.2657 - tp: 77015.0000 - fp: 2960.0000 - tn: 317040.0000 - fn: 2985.0000 - accuracy: 0.9851 - precision: 0.9630 - recall: 0.9627 - auc: 0.9767 - val_loss: 0.0522 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-5-6-batch-400000-500000
[33m[INFO] loading file 7-7/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0445 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0382 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-7-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0334 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0295 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-7-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.2711 - tp: 65557.0000 - fp: 13761.0000 - tn: 306239.0000 - fn: 14443.0000 - accuracy: 0.9295 - precision: 0.8265 - recall: 0.8195 - auc: 0.9843 - val_loss: 0.2205 - val_tp: 19784.0000 - val_fp: 173.0000 - val_tn: 79827.0000 - val_fn: 216.0000 - val_accuracy: 0.9961 - val_precision: 0.9913 - val_recall: 0.9892 - val_auc: 0.9997
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-7-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0077 - tp: 79996.0000 - fp: 3.0000 - tn: 319997.0000 - fn: 4.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9999 - auc: 1.0000 - val_loss: 0.0016 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-7-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0013 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0011 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-6-7-batch-400000-500000
[33m[INFO] loading file 8-8/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 9.0217e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.3541e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-7-8-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.3111e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.3934e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-7-8-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.8850e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.3901e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-7-8-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.2417 - tp: 73102.0000 - fp: 6864.0000 - tn: 313136.0000 - fn: 6898.0000 - accuracy: 0.9656 - precision: 0.9142 - recall: 0.9138 - auc: 0.9879 - val_loss: 0.1464 - val_tp: 17352.0000 - val_fp: 2563.0000 - val_tn: 77437.0000 - val_fn: 2648.0000 - val_accuracy: 0.9479 - val_precision: 0.8713 - val_recall: 0.8676 - val_auc: 0.9931
[INFO] saving weights to checkpoints/lstm-epoch-001-files-7-8-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0220 - tp: 79910.0000 - fp: 86.0000 - tn: 319914.0000 - fn: 90.0000 - accuracy: 0.9996 - precision: 0.9989 - recall: 0.9989 - auc: 1.0000 - val_loss: 0.0147 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-7-8-batch-400000-500000
[33m[INFO] loading file 9-9/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0133 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0119 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-9-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0806 - tp: 78584.0000 - fp: 1416.0000 - tn: 318584.0000 - fn: 1416.0000 - accuracy: 0.9929 - precision: 0.9823 - recall: 0.9823 - auc: 0.9964 - val_loss: 0.0118 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-9-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0030 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0014 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-9-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.9848e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-9-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.4443e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.3358e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-8-9-batch-400000-500000
[33m[INFO] loading file 10-10/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.6409e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9611e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-9-10-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0068 - tp: 79936.0000 - fp: 64.0000 - tn: 319936.0000 - fn: 64.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 0.9995 - val_loss: 2.7417 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.7763
[INFO] saving weights to checkpoints/lstm-epoch-001-files-9-10-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.2690 - tp: 73440.0000 - fp: 6555.0000 - tn: 313445.0000 - fn: 6560.0000 - accuracy: 0.9672 - precision: 0.9181 - recall: 0.9180 - auc: 0.9865 - val_loss: 0.6306 - val_tp: 12813.0000 - val_fp: 7187.0000 - val_tn: 72813.0000 - val_fn: 7187.0000 - val_accuracy: 0.8563 - val_precision: 0.6406 - val_recall: 0.6406 - val_auc: 0.9677
[INFO] saving weights to checkpoints/lstm-epoch-001-files-9-10-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0097 - tp: 79602.0000 - fp: 395.0000 - tn: 319605.0000 - fn: 398.0000 - accuracy: 0.9980 - precision: 0.9951 - recall: 0.9950 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-9-10-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0013 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-9-10-batch-400000-500000
[33m[INFO] loading file 11-11/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 9.2128e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.7815e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-11-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.7057e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.8277e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-11-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.1624e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.5739e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-11-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.1015e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6828e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-11-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.4354e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.0038e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-10-11-batch-400000-500000
[33m[INFO] loading file 12-12/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.8415e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.5667e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-11-12-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.3332e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.4412 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 76689.0000 - val_fn: 3311.0000 - val_accuracy: 0.9338 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8965
[INFO] saving weights to checkpoints/lstm-epoch-001-files-11-12-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.1818 - tp: 77825.0000 - fp: 2172.0000 - tn: 317828.0000 - fn: 2175.0000 - accuracy: 0.9891 - precision: 0.9728 - recall: 0.9728 - auc: 0.9862 - val_loss: 0.4864 - val_tp: 17100.0000 - val_fp: 2900.0000 - val_tn: 77100.0000 - val_fn: 2900.0000 - val_accuracy: 0.9420 - val_precision: 0.8550 - val_recall: 0.8550 - val_auc: 0.9871
[INFO] saving weights to checkpoints/lstm-epoch-001-files-11-12-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0719 - tp: 77967.0000 - fp: 2032.0000 - tn: 317968.0000 - fn: 2033.0000 - accuracy: 0.9898 - precision: 0.9746 - recall: 0.9746 - auc: 0.9998 - val_loss: 9.8174e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-11-12-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 8.8721e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.0288e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-11-12-batch-400000-500000
[33m[INFO] loading file 13-13/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.5602e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.8411e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-13-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.3819e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.6788e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-13-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.1971e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.9617 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 75075.0000 - val_fn: 4925.0000 - val_accuracy: 0.9015 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.8461
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-13-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.2263 - tp: 76932.0000 - fp: 3064.0000 - tn: 316936.0000 - fn: 3068.0000 - accuracy: 0.9847 - precision: 0.9617 - recall: 0.9617 - auc: 0.9826 - val_loss: 0.0227 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-13-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0195 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0172 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-12-13-batch-400000-500000
[33m[INFO] loading file 14-14/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.2597 - tp: 68402.0000 - fp: 11591.0000 - tn: 308409.0000 - fn: 11598.0000 - accuracy: 0.9420 - precision: 0.8551 - recall: 0.8550 - auc: 0.9875 - val_loss: 0.3231 - val_tp: 12897.0000 - val_fp: 7103.0000 - val_tn: 72897.0000 - val_fn: 7103.0000 - val_accuracy: 0.8579 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9677
[INFO] saving weights to checkpoints/lstm-epoch-001-files-13-14-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0085 - tp: 79724.0000 - fp: 276.0000 - tn: 319724.0000 - fn: 276.0000 - accuracy: 0.9986 - precision: 0.9966 - recall: 0.9966 - auc: 1.0000 - val_loss: 0.0016 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-13-14-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0013 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0011 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-13-14-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 9.5820e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.3199e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-13-14-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.3951e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.5644e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-13-14-batch-400000-500000
[33m[INFO] loading file 15-15/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 8.2485e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.5254e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-15-batch-0-100000
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.0453e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4979e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-15-batch-100000-200000
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.0484e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.7841e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-15-batch-200000-300000
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.3513e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.7811 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 71586.0000 - val_fn: 8414.0000 - val_accuracy: 0.8317 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.7371
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-15-batch-300000-400000
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.5432 - tp: 42561.0000 - fp: 37439.0000 - tn: 282561.0000 - fn: 37439.0000 - accuracy: 0.8128 - precision: 0.5320 - recall: 0.5320 - auc: 0.7075 - val_loss: 7.5539 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 70627.0000 - val_fn: 9373.0000 - val_accuracy: 0.8125 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.7071
[INFO] saving weights to checkpoints/lstm-epoch-001-files-14-15-batch-400000-500000
[33m[INFO] loading file 16-16/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.5571 - tp: 42492.0000 - fp: 37508.0000 - tn: 282492.0000 - fn: 37508.0000 - accuracy: 0.8125 - precision: 0.5311 - recall: 0.5311 - auc: 0.7070 - val_loss: 7.5611 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 70618.0000 - val_fn: 9382.0000 - val_accuracy: 0.8124 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.7068
[INFO] saving weights to checkpoints/lstm-epoch-001-files-15-16-batch-0-100000
[INFO] processing batch 100000-200000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.3559 - tp: 58380.0000 - fp: 21620.0000 - tn: 298380.0000 - fn: 21620.0000 - accuracy: 0.8919 - precision: 0.7297 - recall: 0.7297 - auc: 0.8311 - val_loss: 2.1830e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-15-16-batch-100000-200000
[INFO] processing batch 200000-300000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.9942e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8174e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-15-16-batch-200000-300000
[INFO] processing batch 300000-400000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.6677e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6040e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-15-16-batch-300000-400000
[INFO] processing batch 400000-500000/439690
[33m[INFO] loading file 17-17/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0042 - tp: 79850.0000 - fp: 150.0000 - tn: 319850.0000 - fn: 150.0000 - accuracy: 0.9992 - precision: 0.9981 - recall: 0.9981 - auc: 1.0000 - val_loss: 7.7561e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-17-batch-0-100000
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.3944e-04 - tp: 79997.0000 - fp: 3.0000 - tn: 319997.0000 - fn: 3.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.8758e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-17-batch-100000-200000
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.5735e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.2730e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-17-batch-200000-300000
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.2955 - tp: 68607.0000 - fp: 11393.0000 - tn: 308607.0000 - fn: 11393.0000 - accuracy: 0.9430 - precision: 0.8576 - recall: 0.8576 - auc: 0.9110 - val_loss: 2.9263 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 76369.0000 - val_fn: 3631.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.8865
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-17-batch-300000-400000
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.9162 - tp: 65526.0000 - fp: 14474.0000 - tn: 305526.0000 - fn: 14474.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.8869 - val_loss: 1.0896 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 78648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9730 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9577
[INFO] saving weights to checkpoints/lstm-epoch-001-files-16-17-batch-400000-500000
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 18-18/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.5857 - tp: 72130.0000 - fp: 7870.0000 - tn: 312130.0000 - fn: 7870.0000 - accuracy: 0.9606 - precision: 0.9016 - recall: 0.9016 - auc: 0.9385 - val_loss: 6.1499 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 72369.0000 - val_fn: 7631.0000 - val_accuracy: 0.8474 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.7615
[INFO] saving weights to checkpoints/lstm-epoch-001-files-17-18-batch-0-100000
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.1050 - tp: 49698.0000 - fp: 30302.0000 - tn: 289698.0000 - fn: 30302.0000 - accuracy: 0.8485 - precision: 0.6212 - recall: 0.6212 - auc: 0.7633 - val_loss: 6.1597 - val_tp: 12356.0000 - val_fp: 7644.0000 - val_tn: 72356.0000 - val_fn: 7644.0000 - val_accuracy: 0.8471 - val_precision: 0.6178 - val_recall: 0.6178 - val_auc: 0.7612
[INFO] saving weights to checkpoints/lstm-epoch-001-files-17-18-batch-100000-200000
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.1368 - tp: 49541.0000 - fp: 30459.0000 - tn: 289541.0000 - fn: 30459.0000 - accuracy: 0.8477 - precision: 0.6193 - recall: 0.6193 - auc: 0.7620 - val_loss: 6.1273 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 72397.0000 - val_fn: 7603.0000 - val_accuracy: 0.8479 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.7624
[INFO] saving weights to checkpoints/lstm-epoch-001-files-17-18-batch-200000-300000
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1063 - tp: 74509.0000 - fp: 5491.0000 - tn: 314509.0000 - fn: 5491.0000 - accuracy: 0.9725 - precision: 0.9314 - recall: 0.9314 - auc: 0.9571 - val_loss: 3.7310e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-17-18-batch-300000-400000
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.5148e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.3109e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-17-18-batch-400000-500000
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 19-19/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.3950e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.8995e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-19-batch-0-100000
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.7355e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.5724e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-19-batch-100000-200000
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.1824e-05 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.2650e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-19-batch-200000-300000
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.1516 - tp: 69321.0000 - fp: 10679.0000 - tn: 309321.0000 - fn: 10679.0000 - accuracy: 0.9466 - precision: 0.8665 - recall: 0.8665 - auc: 0.9166 - val_loss: 9.7660 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 67882.0000 - val_fn: 12118.0000 - val_accuracy: 0.7576 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.6213
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-19-batch-300000-400000
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 9.8246 - tp: 31237.0000 - fp: 48763.0000 - tn: 271237.0000 - fn: 48763.0000 - accuracy: 0.7562 - precision: 0.3905 - recall: 0.3905 - auc: 0.6190 - val_loss: 1.9418e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-18-19-batch-400000-500000
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 20-20/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.9590e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4102 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 79491.0000 - val_fn: 509.0000 - val_accuracy: 0.9898 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9841
[INFO] saving weights to checkpoints/lstm-epoch-001-files-19-20-batch-0-100000
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.9361 - tp: 65427.0000 - fp: 14573.0000 - tn: 305427.0000 - fn: 14573.0000 - accuracy: 0.9271 - precision: 0.8178 - recall: 0.8178 - auc: 0.8861 - val_loss: 2.9359 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 76357.0000 - val_fn: 3643.0000 - val_accuracy: 0.9271 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.8862
[INFO] saving weights to checkpoints/lstm-epoch-001-files-19-20-batch-100000-200000
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.9516 - tp: 65346.0000 - fp: 14654.0000 - tn: 305346.0000 - fn: 14654.0000 - accuracy: 0.9267 - precision: 0.8168 - recall: 0.8168 - auc: 0.8856 - val_loss: 2.9246 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 76371.0000 - val_fn: 3629.0000 - val_accuracy: 0.9274 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.8866
[INFO] saving weights to checkpoints/lstm-epoch-001-files-19-20-batch-200000-300000
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.8011 - tp: 76023.0000 - fp: 3977.0000 - tn: 316023.0000 - fn: 3977.0000 - accuracy: 0.9801 - precision: 0.9503 - recall: 0.9503 - auc: 0.9689 - val_loss: 1.1033e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-19-20-batch-300000-400000
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.0329e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.6748e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-19-20-batch-400000-500000
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 21-21/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539688, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.9558e-05 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.2735e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-21-batch-0-100000
[INFO] processing batch 100000-200000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.7735e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.2976e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-21-batch-100000-200000
[INFO] processing batch 200000-300000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.8571e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.4301e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-21-batch-200000-300000
[INFO] processing batch 300000-400000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.3556e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.5007e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-21-batch-300000-400000
[INFO] processing batch 400000-500000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.1707e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.8424e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-20-21-batch-400000-500000
[INFO] processing batch 500000-600000/539688
[33m[INFO] loading file 22-22/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (308729, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/308729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.0357 - tp: 55006.0000 - fp: 24994.0000 - tn: 295006.0000 - fn: 24994.0000 - accuracy: 0.8750 - precision: 0.6876 - recall: 0.6876 - auc: 0.8047 - val_loss: 7.5658 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.7066
[INFO] saving weights to checkpoints/lstm-epoch-001-files-21-22-batch-0-100000
[INFO] processing batch 100000-200000/308729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.5759 - tp: 42398.0000 - fp: 37602.0000 - tn: 282398.0000 - fn: 37602.0000 - accuracy: 0.8120 - precision: 0.5300 - recall: 0.5300 - auc: 0.7062 - val_loss: 7.6343 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.7040
[INFO] saving weights to checkpoints/lstm-epoch-001-files-21-22-batch-100000-200000
[INFO] processing batch 200000-300000/308729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.5816 - tp: 42370.0000 - fp: 37630.0000 - tn: 282370.0000 - fn: 37630.0000 - accuracy: 0.8118 - precision: 0.5296 - recall: 0.5296 - auc: 0.7060 - val_loss: 7.5562 - val_tp: 10624.0000 - val_fp: 9376.0000 - val_tn: 70624.0000 - val_fn: 9376.0000 - val_accuracy: 0.8125 - val_precision: 0.5312 - val_recall: 0.5312 - val_auc: 0.7070
[INFO] saving weights to checkpoints/lstm-epoch-001-files-21-22-batch-200000-300000
[INFO] processing batch 300000-400000/308729
[33m[INFO] loading file 23-23/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (508729, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.6442 - tp: 66876.0000 - fp: 13124.0000 - tn: 306876.0000 - fn: 13124.0000 - accuracy: 0.9344 - precision: 0.8360 - recall: 0.8360 - auc: 0.8975 - val_loss: 3.2292e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-23-batch-0-100000
[INFO] processing batch 100000-200000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.0330e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.8227e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-23-batch-100000-200000
[INFO] processing batch 200000-300000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.6410e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4799e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-23-batch-200000-300000
[INFO] processing batch 300000-400000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.2955e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.1394e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-23-batch-300000-400000
[INFO] processing batch 400000-500000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.0103e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8772e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-22-23-batch-400000-500000
[INFO] processing batch 500000-600000/508729
[33m[INFO] loading file 24-24/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (508729, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.8771e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6039e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-23-24-batch-0-100000
[INFO] processing batch 100000-200000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.5107e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.4193e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-23-24-batch-100000-200000
[INFO] processing batch 200000-300000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.5424e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2296e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-23-24-batch-200000-300000
[INFO] processing batch 300000-400000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.2848e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0441e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-23-24-batch-300000-400000
[INFO] processing batch 400000-500000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.0782 - tp: 64722.0000 - fp: 15278.0000 - tn: 304722.0000 - fn: 15278.0000 - accuracy: 0.9236 - precision: 0.8090 - recall: 0.8090 - auc: 0.8806 - val_loss: 5.7227 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 72899.0000 - val_fn: 7101.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.7781
[INFO] saving weights to checkpoints/lstm-epoch-001-files-23-24-batch-400000-500000
[INFO] processing batch 500000-600000/508729
[33m[INFO] loading file 25-25/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (508729, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7568 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.7768 - val_loss: 5.7517 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.7770
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-25-batch-0-100000
[INFO] processing batch 100000-200000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7419 - tp: 51501.0000 - fp: 28499.0000 - tn: 291501.0000 - fn: 28499.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.7774 - val_loss: 5.7525 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.7769
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-25-batch-100000-200000
[INFO] processing batch 200000-300000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7489 - tp: 51466.0000 - fp: 28534.0000 - tn: 291466.0000 - fn: 28534.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.7771 - val_loss: 5.7380 - val_tp: 12880.0000 - val_fp: 7120.0000 - val_tn: 72880.0000 - val_fn: 7120.0000 - val_accuracy: 0.8576 - val_precision: 0.6440 - val_recall: 0.6440 - val_auc: 0.7775
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-25-batch-200000-300000
[INFO] processing batch 300000-400000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7542 - tp: 51440.0000 - fp: 28560.0000 - tn: 291440.0000 - fn: 28560.0000 - accuracy: 0.8572 - precision: 0.6430 - recall: 0.6430 - auc: 0.7769 - val_loss: 5.7445 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.7772
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-25-batch-300000-400000
[INFO] processing batch 400000-500000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7413 - tp: 51504.0000 - fp: 28496.0000 - tn: 291504.0000 - fn: 28496.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.7774 - val_loss: 5.7324 - val_tp: 12887.0000 - val_fp: 7113.0000 - val_tn: 72887.0000 - val_fn: 7113.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.7777
[INFO] saving weights to checkpoints/lstm-epoch-001-files-24-25-batch-400000-500000
[INFO] processing batch 500000-600000/508729
[33m[INFO] loading file 26-26/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (508729, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.9227 - tp: 56593.0000 - fp: 23406.0000 - tn: 296594.0000 - fn: 23407.0000 - accuracy: 0.8830 - precision: 0.7074 - recall: 0.7074 - auc: 0.8434 - val_loss: 0.0275 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-25-26-batch-0-100000
[INFO] processing batch 100000-200000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0229 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0200 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-25-26-batch-100000-200000
[INFO] processing batch 200000-300000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0179 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0161 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-25-26-batch-200000-300000
[INFO] processing batch 300000-400000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0146 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0133 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-25-26-batch-300000-400000
[INFO] processing batch 400000-500000/508729
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0122 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0112 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-25-26-batch-400000-500000
[INFO] processing batch 500000-600000/508729
[33m[INFO] loading file 27-27/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (448859, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/448859
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0105 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0097 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-27-batch-0-100000
[INFO] processing batch 100000-200000/448859
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0092 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0085 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-27-batch-100000-200000
[INFO] processing batch 200000-300000/448859
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0079 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0075 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-27-batch-200000-300000
[INFO] processing batch 300000-400000/448859
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0071 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0066 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-26-27-batch-300000-400000
[INFO] processing batch 400000-500000/448859
[33m[INFO] loading file 28-28/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (382775, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/382775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0064 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0059 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-27-28-batch-0-100000
[INFO] processing batch 100000-200000/382775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0056 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0053 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-27-28-batch-100000-200000
[INFO] processing batch 200000-300000/382775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0051 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0052 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-27-28-batch-200000-300000
[INFO] processing batch 300000-400000/382775
[33m[INFO] loading file 29-29/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582775, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0044 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0042 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-29-batch-0-100000
[INFO] processing batch 100000-200000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0040 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0038 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-29-batch-100000-200000
[INFO] processing batch 200000-300000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0036 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0033 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-29-batch-200000-300000
[INFO] processing batch 300000-400000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0032 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0030 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-29-batch-300000-400000
[INFO] processing batch 400000-500000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0030 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-28-29-batch-400000-500000
[INFO] processing batch 500000-600000/582775
[33m[INFO] loading file 30-30/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582775, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0026 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0024 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-29-30-batch-0-100000
[INFO] processing batch 100000-200000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0024 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0022 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-29-30-batch-100000-200000
[INFO] processing batch 200000-300000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0022 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-29-30-batch-200000-300000
[INFO] processing batch 300000-400000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0019 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0017 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-29-30-batch-300000-400000
[INFO] processing batch 400000-500000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0017 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0021 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-29-30-batch-400000-500000
[INFO] processing batch 500000-600000/582775
[33m[INFO] loading file 31-31/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582775, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0016 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0014 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-31-batch-0-100000
[INFO] processing batch 100000-200000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0013 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0012 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-31-batch-100000-200000
[INFO] processing batch 200000-300000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0011 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-31-batch-200000-300000
[INFO] processing batch 300000-400000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0010 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.4081e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-31-batch-300000-400000
[INFO] processing batch 400000-500000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 8.8488e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.2420e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-30-31-batch-400000-500000
[INFO] processing batch 500000-600000/582775
[33m[INFO] loading file 32-32/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582775, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0012 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.4278e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-31-32-batch-0-100000
[INFO] processing batch 100000-200000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 8.7794e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-31-32-batch-100000-200000
[INFO] processing batch 200000-300000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.0649e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.6707e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-31-32-batch-200000-300000
[INFO] processing batch 300000-400000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.2676e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.2205e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-31-32-batch-300000-400000
[INFO] processing batch 400000-500000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.6632e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.3477e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-31-32-batch-400000-500000
[INFO] processing batch 500000-600000/582775
[33m[INFO] loading file 33-33/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582775, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.0541e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.6382e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-33-batch-0-100000
[INFO] processing batch 100000-200000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.1446e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.3381e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-33-batch-100000-200000
[INFO] processing batch 200000-300000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.1180e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.8895e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-33-batch-200000-300000
[INFO] processing batch 300000-400000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.6845e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4919e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-33-batch-300000-400000
[INFO] processing batch 400000-500000/582775
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.4482e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.1767e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-32-33-batch-400000-500000
[INFO] processing batch 500000-600000/582775
[33m[INFO] loading file 34-34/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (424208, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/424208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.1113e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.9268e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-33-34-batch-0-100000
[INFO] processing batch 100000-200000/424208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.8761e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6775e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-33-34-batch-100000-200000
[INFO] processing batch 200000-300000/424208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.3229e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.3176e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-33-34-batch-200000-300000
[INFO] processing batch 300000-400000/424208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.6013e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3076e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-33-34-batch-300000-400000
[INFO] processing batch 400000-500000/424208
[33m[INFO] loading file 35-35/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524208, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.3284e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1531e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-35-batch-0-100000
[INFO] processing batch 100000-200000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.0795e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.8890e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-35-batch-100000-200000
[INFO] processing batch 200000-300000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.0051e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0938e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-35-batch-200000-300000
[INFO] processing batch 300000-400000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 9.9374e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.0177e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-35-batch-300000-400000
[INFO] processing batch 400000-500000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 8.2795e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.6199e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-34-35-batch-400000-500000
[INFO] processing batch 500000-600000/524208
[33m[INFO] loading file 36-36/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524208, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.8553e-04 - tp: 79996.0000 - fp: 4.0000 - tn: 319996.0000 - fn: 4.0000 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - auc: 1.0000 - val_loss: 7.4520e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-35-36-batch-0-100000
[INFO] processing batch 100000-200000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.9942e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.6683e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-35-36-batch-100000-200000
[INFO] processing batch 200000-300000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.8963e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.0315e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-35-36-batch-200000-300000
[INFO] processing batch 300000-400000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.7068e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.3347e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-35-36-batch-300000-400000
[INFO] processing batch 400000-500000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.0712e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.3842e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-35-36-batch-400000-500000
[INFO] processing batch 500000-600000/524208
[33m[INFO] loading file 37-37/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524208, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.7454e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.8401e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-37-batch-0-100000
[INFO] processing batch 100000-200000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.5600e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.2962e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-37-batch-100000-200000
[INFO] processing batch 200000-300000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.0774e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.8488e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-37-batch-200000-300000
[INFO] processing batch 300000-400000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.4025e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.2745e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-37-batch-300000-400000
[INFO] processing batch 400000-500000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.2952e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.8206e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-36-37-batch-400000-500000
[INFO] processing batch 500000-600000/524208
[33m[INFO] loading file 38-38/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524208, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.0298e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.4152e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-37-38-batch-0-100000
[INFO] processing batch 100000-200000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.1871e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.3633e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-37-38-batch-100000-200000
[INFO] processing batch 200000-300000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.6680e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.7282e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-37-38-batch-200000-300000
[INFO] processing batch 300000-400000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.7652e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.6607e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-37-38-batch-300000-400000
[INFO] processing batch 400000-500000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.5389e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4079e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-37-38-batch-400000-500000
[INFO] processing batch 500000-600000/524208
[33m[INFO] loading file 39-39/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524208, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.5390e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.1853e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-39-batch-0-100000
[INFO] processing batch 100000-200000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.2153e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.0465e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-39-batch-100000-200000
[INFO] processing batch 200000-300000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.9426e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8475e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-39-batch-200000-300000
[INFO] processing batch 300000-400000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.9942e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7060e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-39-batch-300000-400000
[INFO] processing batch 400000-500000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.6040e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.5144e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-38-39-batch-400000-500000
[INFO] processing batch 500000-600000/524208
[33m[INFO] loading file 40-40/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524208, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.4846e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.4454e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-39-40-batch-0-100000
[INFO] processing batch 100000-200000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.1513e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2962e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-39-40-batch-100000-200000
[INFO] processing batch 200000-300000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.9414e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.5103e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-39-40-batch-200000-300000
[INFO] processing batch 300000-400000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.4668e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.4055e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-39-40-batch-300000-400000
[INFO] processing batch 400000-500000/524208
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.5577e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3156e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-39-40-batch-400000-500000
[INFO] processing batch 500000-600000/524208
[33m[INFO] loading file 41-41/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (464366, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/464366
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.4843e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.8915e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-41-batch-0-100000
[INFO] processing batch 100000-200000/464366
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.2053e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.1742e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-41-batch-100000-200000
[INFO] processing batch 200000-300000/464366
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1040e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0529e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-41-batch-200000-300000
[INFO] processing batch 300000-400000/464366
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.5446e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0405e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-40-41-batch-300000-400000
[INFO] processing batch 400000-500000/464366
[33m[INFO] loading file 42-42/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (407880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/407880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.0021e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.7552e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-41-42-batch-0-100000
[INFO] processing batch 100000-200000/407880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 9.2679e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.8433e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-41-42-batch-100000-200000
[INFO] processing batch 200000-300000/407880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 8.5047e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.0923e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-41-42-batch-200000-300000
[INFO] processing batch 300000-400000/407880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.5661e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.4587e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-41-42-batch-300000-400000
[INFO] processing batch 400000-500000/407880
[33m[INFO] loading file 43-43/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (507880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 8.0260e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.6589e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-43-batch-0-100000
[INFO] processing batch 100000-200000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.4537e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.1174e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-43-batch-100000-200000
[INFO] processing batch 200000-300000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.4035e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.2981e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-43-batch-200000-300000
[INFO] processing batch 300000-400000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 8.2707e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.7560e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-43-batch-300000-400000
[INFO] processing batch 400000-500000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.0885e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.0312e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-42-43-batch-400000-500000
[INFO] processing batch 500000-600000/507880
[33m[INFO] loading file 44-44/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (507880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.7652e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.5143e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-43-44-batch-0-100000
[INFO] processing batch 100000-200000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.1859e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.9929e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-43-44-batch-100000-200000
[INFO] processing batch 200000-300000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.9738e-05 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.8064e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-43-44-batch-200000-300000
[INFO] processing batch 300000-400000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.4243e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.0315e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-43-44-batch-300000-400000
[INFO] processing batch 400000-500000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.3720e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.1677e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-43-44-batch-400000-500000
[INFO] processing batch 500000-600000/507880
[33m[INFO] loading file 45-45/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (507880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 8.6360e-05 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.0435e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-45-batch-0-100000
[INFO] processing batch 100000-200000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.0080e-05 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.8547e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-45-batch-100000-200000
[INFO] processing batch 200000-300000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.4571e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.8907e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-45-batch-200000-300000
[INFO] processing batch 300000-400000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.5670e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.2670e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-45-batch-300000-400000
[INFO] processing batch 400000-500000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.9481e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.6468e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-44-45-batch-400000-500000
[INFO] processing batch 500000-600000/507880
[33m[INFO] loading file 46-46/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (507880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.0832e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.1319e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-45-46-batch-0-100000
[INFO] processing batch 100000-200000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.4418e-05 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.5004e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-45-46-batch-100000-200000
[INFO] processing batch 200000-300000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.4122e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.6212e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-45-46-batch-200000-300000
[INFO] processing batch 300000-400000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1375e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.8146e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-45-46-batch-300000-400000
[INFO] processing batch 400000-500000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.6484e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.4863e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-45-46-batch-400000-500000
[INFO] processing batch 500000-600000/507880
[33m[INFO] loading file 47-47/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (507880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.0131e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.0959e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-47-batch-0-100000
[INFO] processing batch 100000-200000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.1380e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.3459e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-47-batch-100000-200000
[INFO] processing batch 200000-300000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.0723e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.1145e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-47-batch-200000-300000
[INFO] processing batch 300000-400000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.0685e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.1759e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-47-batch-300000-400000
[INFO] processing batch 400000-500000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.0088e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.8487e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-46-47-batch-400000-500000
[INFO] processing batch 500000-600000/507880
[33m[INFO] loading file 48-48/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (507880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.6834e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.5481e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-47-48-batch-0-100000
[INFO] processing batch 100000-200000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.3772e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.2380e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-47-48-batch-100000-200000
[INFO] processing batch 200000-300000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.0558e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9660e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-47-48-batch-200000-300000
[INFO] processing batch 300000-400000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.8442e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.7235e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-47-48-batch-300000-400000
[INFO] processing batch 400000-500000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.4492e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.1080e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-47-48-batch-400000-500000
[INFO] processing batch 500000-600000/507880
[33m[INFO] loading file 49-49/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (507880, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1592e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.7818e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-49-batch-0-100000
[INFO] processing batch 100000-200000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.0669e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.7179e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-49-batch-100000-200000
[INFO] processing batch 200000-300000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.0712e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.8242e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-49-batch-200000-300000
[INFO] processing batch 300000-400000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.0620e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.3992e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-49-batch-300000-400000
[INFO] processing batch 400000-500000/507880
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.1401e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.8890e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-48-49-batch-400000-500000
[INFO] processing batch 500000-600000/507880
[33m[INFO] loading file 50-50/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (357862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/357862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.6877e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.5004e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-49-50-batch-0-100000
[INFO] processing batch 100000-200000/357862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.0483e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.0912e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-49-50-batch-100000-200000
[INFO] processing batch 200000-300000/357862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.0609e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.9184e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-49-50-batch-200000-300000
[INFO] processing batch 300000-400000/357862
[33m[LOSS] 2.9183866499806753e-06[0m
[33m[INFO] epoch 2/10[0m
[33m[INFO] loading file 1-1/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0507 - tp: 79544.0000 - fp: 456.0000 - tn: 319544.0000 - fn: 456.0000 - accuracy: 0.9977 - precision: 0.9943 - recall: 0.9943 - auc: 0.9969 - val_loss: 9.6383e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-1-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.8447e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2838e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-1-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.3526e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.4481e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-1-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.0374 - tp: 59961.0000 - fp: 20039.0000 - tn: 299961.0000 - fn: 20039.0000 - accuracy: 0.8998 - precision: 0.7495 - recall: 0.7495 - auc: 0.8434 - val_loss: 7.5586 - val_tp: 10621.0000 - val_fp: 9379.0000 - val_tn: 70621.0000 - val_fn: 9379.0000 - val_accuracy: 0.8124 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.7069
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-1-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.5626 - tp: 42464.0000 - fp: 37536.0000 - tn: 282464.0000 - fn: 37536.0000 - accuracy: 0.8123 - precision: 0.5308 - recall: 0.5308 - auc: 0.7068 - val_loss: 7.5683 - val_tp: 10609.0000 - val_fp: 9391.0000 - val_tn: 70609.0000 - val_fn: 9391.0000 - val_accuracy: 0.8122 - val_precision: 0.5304 - val_recall: 0.5304 - val_auc: 0.7065
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-1-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 2-2/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.5898 - tp: 42230.0000 - fp: 37770.0000 - tn: 282230.0000 - fn: 37770.0000 - accuracy: 0.8112 - precision: 0.5279 - recall: 0.5279 - auc: 0.7050 - val_loss: 7.5683 - val_tp: 10609.0000 - val_fp: 9391.0000 - val_tn: 70609.0000 - val_fn: 9391.0000 - val_accuracy: 0.8122 - val_precision: 0.5304 - val_recall: 0.5304 - val_auc: 0.7065
[INFO] saving weights to checkpoints/lstm-epoch-002-files-1-2-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.5699 - tp: 42428.0000 - fp: 37572.0000 - tn: 282428.0000 - fn: 37572.0000 - accuracy: 0.8121 - precision: 0.5304 - recall: 0.5304 - auc: 0.7065 - val_loss: 1.5917 - val_tp: 18025.0000 - val_fp: 1975.0000 - val_tn: 78025.0000 - val_fn: 1975.0000 - val_accuracy: 0.9605 - val_precision: 0.9013 - val_recall: 0.9013 - val_auc: 0.9383
[INFO] saving weights to checkpoints/lstm-epoch-002-files-1-2-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-1-2-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.5138 - tp: 52633.0000 - fp: 27367.0000 - tn: 292633.0000 - fn: 27367.0000 - accuracy: 0.8632 - precision: 0.6579 - recall: 0.6579 - auc: 0.7862 - val_loss: 7.5731 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.7063
[INFO] saving weights to checkpoints/lstm-epoch-002-files-1-2-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.5969 - tp: 42294.0000 - fp: 37706.0000 - tn: 282294.0000 - fn: 37706.0000 - accuracy: 0.8115 - precision: 0.5287 - recall: 0.5287 - auc: 0.7054 - val_loss: 1.7907 - val_tp: 17778.0000 - val_fp: 2222.0000 - val_tn: 77778.0000 - val_fn: 2222.0000 - val_accuracy: 0.9556 - val_precision: 0.8889 - val_recall: 0.8889 - val_auc: 0.9306
[INFO] saving weights to checkpoints/lstm-epoch-002-files-1-2-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 3-3/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.5165 - tp: 72473.0000 - fp: 7527.0000 - tn: 312473.0000 - fn: 7527.0000 - accuracy: 0.9624 - precision: 0.9059 - recall: 0.9059 - auc: 0.9412 - val_loss: 7.5876 - val_tp: 10585.0000 - val_fp: 9415.0000 - val_tn: 70585.0000 - val_fn: 9415.0000 - val_accuracy: 0.8117 - val_precision: 0.5293 - val_recall: 0.5293 - val_auc: 0.7058
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-3-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.5924 - tp: 42316.0000 - fp: 37684.0000 - tn: 282316.0000 - fn: 37684.0000 - accuracy: 0.8116 - precision: 0.5289 - recall: 0.5289 - auc: 0.7056 - val_loss: 7.5940 - val_tp: 10577.0000 - val_fp: 9423.0000 - val_tn: 70577.0000 - val_fn: 9423.0000 - val_accuracy: 0.8115 - val_precision: 0.5289 - val_recall: 0.5289 - val_auc: 0.7055
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-3-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.4821 - tp: 77607.0000 - fp: 2393.0000 - tn: 317607.0000 - fn: 2393.0000 - accuracy: 0.9880 - precision: 0.9701 - recall: 0.9701 - auc: 0.9813 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-3-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-3-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-2-3-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 4-4/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-3-4-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.0602e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-3-4-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-3-4-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-3-4-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.8766 - tp: 45869.0000 - fp: 34131.0000 - tn: 285869.0000 - fn: 34131.0000 - accuracy: 0.8293 - precision: 0.5734 - recall: 0.5734 - auc: 0.7334 - val_loss: 7.7754 - val_tp: 10352.0000 - val_fp: 9648.0000 - val_tn: 70352.0000 - val_fn: 9648.0000 - val_accuracy: 0.8070 - val_precision: 0.5176 - val_recall: 0.5176 - val_auc: 0.6985
[INFO] saving weights to checkpoints/lstm-epoch-002-files-3-4-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 5-5/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.1672 - val_tp: 16070.0000 - val_fp: 3930.0000 - val_tn: 76070.0000 - val_fn: 3930.0000 - val_accuracy: 0.9214 - val_precision: 0.8035 - val_recall: 0.8035 - val_auc: 0.8772
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-5-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7832 - tp: 51296.0000 - fp: 28704.0000 - tn: 291296.0000 - fn: 28704.0000 - accuracy: 0.8565 - precision: 0.6412 - recall: 0.6412 - auc: 0.7758 - val_loss: 5.7622 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.7766
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-5-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.3366 - tp: 63439.0000 - fp: 16561.0000 - tn: 303439.0000 - fn: 16561.0000 - accuracy: 0.9172 - precision: 0.7930 - recall: 0.7930 - auc: 0.8706 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-5-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-5-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-4-5-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 6-6/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-5-6-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-5-6-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-5-6-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-5-6-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.4913 - tp: 67635.0000 - fp: 12365.0000 - tn: 307635.0000 - fn: 12365.0000 - accuracy: 0.9382 - precision: 0.8454 - recall: 0.8454 - auc: 0.9034 - val_loss: 5.8122 - val_tp: 12788.0000 - val_fp: 7212.0000 - val_tn: 72788.0000 - val_fn: 7212.0000 - val_accuracy: 0.8558 - val_precision: 0.6394 - val_recall: 0.6394 - val_auc: 0.7746
[INFO] saving weights to checkpoints/lstm-epoch-002-files-5-6-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 7-7/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7951 - tp: 51237.0000 - fp: 28763.0000 - tn: 291237.0000 - fn: 28763.0000 - accuracy: 0.8562 - precision: 0.6405 - recall: 0.6405 - auc: 0.7753 - val_loss: 5.8235 - val_tp: 12774.0000 - val_fp: 7226.0000 - val_tn: 72774.0000 - val_fn: 7226.0000 - val_accuracy: 0.8555 - val_precision: 0.6387 - val_recall: 0.6387 - val_auc: 0.7742
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-7-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.8023 - tp: 51201.0000 - fp: 28799.0000 - tn: 291201.0000 - fn: 28799.0000 - accuracy: 0.8560 - precision: 0.6400 - recall: 0.6400 - auc: 0.7750 - val_loss: 5.7654 - val_tp: 12846.0000 - val_fp: 7154.0000 - val_tn: 72846.0000 - val_fn: 7154.0000 - val_accuracy: 0.8569 - val_precision: 0.6423 - val_recall: 0.6423 - val_auc: 0.7764
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-7-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7574 - tp: 51424.0000 - fp: 28576.0000 - tn: 291424.0000 - fn: 28576.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.7767 - val_loss: 5.4229 - val_tp: 13271.0000 - val_fp: 6729.0000 - val_tn: 73271.0000 - val_fn: 6729.0000 - val_accuracy: 0.8654 - val_precision: 0.6636 - val_recall: 0.6636 - val_auc: 0.7897
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-7-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-7-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-6-7-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 8-8/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-7-8-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-7-8-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-7-8-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-7-8-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.9113 - tp: 65550.0000 - fp: 14450.0000 - tn: 305550.0000 - fn: 14450.0000 - accuracy: 0.9277 - precision: 0.8194 - recall: 0.8194 - auc: 0.8871 - val_loss: 2.9351 - val_tp: 16358.0000 - val_fp: 3642.0000 - val_tn: 76358.0000 - val_fn: 3642.0000 - val_accuracy: 0.9272 - val_precision: 0.8179 - val_recall: 0.8179 - val_auc: 0.8862
[INFO] saving weights to checkpoints/lstm-epoch-002-files-7-8-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 9-9/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.9321 - tp: 65447.0000 - fp: 14553.0000 - tn: 305447.0000 - fn: 14553.0000 - accuracy: 0.9272 - precision: 0.8181 - recall: 0.8181 - auc: 0.8863 - val_loss: 2.9432 - val_tp: 16348.0000 - val_fp: 3652.0000 - val_tn: 76348.0000 - val_fn: 3652.0000 - val_accuracy: 0.9270 - val_precision: 0.8174 - val_recall: 0.8174 - val_auc: 0.8859
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-9-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.3698 - tp: 68238.0000 - fp: 11762.0000 - tn: 308238.0000 - fn: 11762.0000 - accuracy: 0.9412 - precision: 0.8530 - recall: 0.8530 - auc: 0.9081 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-9-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-9-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-9-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-8-9-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 10-10/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1948e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-9-10-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-9-10-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.0624 - tp: 64800.0000 - fp: 15200.0000 - tn: 304800.0000 - fn: 15200.0000 - accuracy: 0.9240 - precision: 0.8100 - recall: 0.8100 - auc: 0.8812 - val_loss: 5.7614 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 72851.0000 - val_fn: 7149.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.7766
[INFO] saving weights to checkpoints/lstm-epoch-002-files-9-10-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.6521 - tp: 71800.0000 - fp: 8200.0000 - tn: 311800.0000 - fn: 8200.0000 - accuracy: 0.9590 - precision: 0.8975 - recall: 0.8975 - auc: 0.9359 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-9-10-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-9-10-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 11-11/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-11-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-11-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-11-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-11-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-10-11-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 12-12/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-11-12-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-11-12-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.2640 - tp: 68763.0000 - fp: 11237.0000 - tn: 308763.0000 - fn: 11237.0000 - accuracy: 0.9438 - precision: 0.8595 - recall: 0.8595 - auc: 0.9122 - val_loss: 5.7848 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 72822.0000 - val_fn: 7178.0000 - val_accuracy: 0.8564 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.7757
[INFO] saving weights to checkpoints/lstm-epoch-002-files-11-12-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.5814 - tp: 62224.0000 - fp: 17776.0000 - tn: 302224.0000 - fn: 17776.0000 - accuracy: 0.9111 - precision: 0.7778 - recall: 0.7778 - auc: 0.8611 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-11-12-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-11-12-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 13-13/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-13-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-13-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-13-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.5900 - tp: 67145.0000 - fp: 12855.0000 - tn: 307145.0000 - fn: 12855.0000 - accuracy: 0.9357 - precision: 0.8393 - recall: 0.8393 - auc: 0.8996 - val_loss: 5.7759 - val_tp: 12833.0000 - val_fp: 7167.0000 - val_tn: 72833.0000 - val_fn: 7167.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.7760
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-13-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7739 - tp: 51342.0000 - fp: 28658.0000 - tn: 291342.0000 - fn: 28658.0000 - accuracy: 0.8567 - precision: 0.6418 - recall: 0.6418 - auc: 0.7761 - val_loss: 5.7864 - val_tp: 12820.0000 - val_fp: 7180.0000 - val_tn: 72820.0000 - val_fn: 7180.0000 - val_accuracy: 0.8564 - val_precision: 0.6410 - val_recall: 0.6410 - val_auc: 0.7756
[INFO] saving weights to checkpoints/lstm-epoch-002-files-12-13-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 14-14/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7586 - tp: 51418.0000 - fp: 28582.0000 - tn: 291418.0000 - fn: 28582.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.7767 - val_loss: 5.8082 - val_tp: 12793.0000 - val_fp: 7207.0000 - val_tn: 72793.0000 - val_fn: 7207.0000 - val_accuracy: 0.8559 - val_precision: 0.6396 - val_recall: 0.6396 - val_auc: 0.7748
[INFO] saving weights to checkpoints/lstm-epoch-002-files-13-14-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.4676 - tp: 77679.0000 - fp: 2321.0000 - tn: 317679.0000 - fn: 2321.0000 - accuracy: 0.9884 - precision: 0.9710 - recall: 0.9710 - auc: 0.9819 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-13-14-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-13-14-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-13-14-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-13-14-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 15-15/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (557862, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.0160e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-15-batch-0-100000
[INFO] processing batch 100000-200000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.0160e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-15-batch-100000-200000
[INFO] processing batch 200000-300000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.0307e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-15-batch-200000-300000
[INFO] processing batch 300000-400000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-15-batch-300000-400000
[INFO] processing batch 400000-500000/557862
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.7845 - tp: 61216.0000 - fp: 18784.0000 - tn: 301216.0000 - fn: 18784.0000 - accuracy: 0.9061 - precision: 0.7652 - recall: 0.7652 - auc: 0.8532 - val_loss: 7.5199 - val_tp: 10669.0000 - val_fp: 9331.0000 - val_tn: 70669.0000 - val_fn: 9331.0000 - val_accuracy: 0.8134 - val_precision: 0.5335 - val_recall: 0.5335 - val_auc: 0.7084
[INFO] saving weights to checkpoints/lstm-epoch-002-files-14-15-batch-400000-500000
[INFO] processing batch 500000-600000/557862
[33m[INFO] loading file 16-16/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (497552, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/497552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.5636 - tp: 42459.0000 - fp: 37541.0000 - tn: 282459.0000 - fn: 37541.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5307 - auc: 0.7067 - val_loss: 7.5368 - val_tp: 10648.0000 - val_fp: 9352.0000 - val_tn: 70648.0000 - val_fn: 9352.0000 - val_accuracy: 0.8130 - val_precision: 0.5324 - val_recall: 0.5324 - val_auc: 0.7078
[INFO] saving weights to checkpoints/lstm-epoch-002-files-15-16-batch-0-100000
[INFO] processing batch 100000-200000/497552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.5473 - tp: 42540.0000 - fp: 37460.0000 - tn: 282540.0000 - fn: 37460.0000 - accuracy: 0.8127 - precision: 0.5318 - recall: 0.5318 - auc: 0.7073 - val_loss: 7.5803 - val_tp: 10594.0000 - val_fp: 9406.0000 - val_tn: 70594.0000 - val_fn: 9406.0000 - val_accuracy: 0.8119 - val_precision: 0.5297 - val_recall: 0.5297 - val_auc: 0.7061
[INFO] saving weights to checkpoints/lstm-epoch-002-files-15-16-batch-100000-200000
[INFO] processing batch 200000-300000/497552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.3749 - tp: 78139.0000 - fp: 1861.0000 - tn: 318139.0000 - fn: 1861.0000 - accuracy: 0.9907 - precision: 0.9767 - recall: 0.9767 - auc: 0.9855 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-15-16-batch-200000-300000
[INFO] processing batch 300000-400000/497552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-15-16-batch-300000-400000
[INFO] processing batch 400000-500000/497552
[33m[INFO] loading file 17-17/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (597552, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-17-batch-0-100000
[INFO] processing batch 100000-200000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-17-batch-100000-200000
[INFO] processing batch 200000-300000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-17-batch-200000-300000
[INFO] processing batch 300000-400000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.1640 - tp: 79186.0000 - fp: 814.0000 - tn: 319186.0000 - fn: 814.0000 - accuracy: 0.9959 - precision: 0.9898 - recall: 0.9898 - auc: 0.9936 - val_loss: 2.9778 - val_tp: 16305.0000 - val_fp: 3695.0000 - val_tn: 76305.0000 - val_fn: 3695.0000 - val_accuracy: 0.9261 - val_precision: 0.8152 - val_recall: 0.8152 - val_auc: 0.8845
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-17-batch-300000-400000
[INFO] processing batch 400000-500000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.9236 - tp: 65489.0000 - fp: 14511.0000 - tn: 305489.0000 - fn: 14511.0000 - accuracy: 0.9274 - precision: 0.8186 - recall: 0.8186 - auc: 0.8866 - val_loss: 2.8988 - val_tp: 16403.0000 - val_fp: 3597.0000 - val_tn: 76403.0000 - val_fn: 3597.0000 - val_accuracy: 0.9281 - val_precision: 0.8202 - val_recall: 0.8202 - val_auc: 0.8876
[INFO] saving weights to checkpoints/lstm-epoch-002-files-16-17-batch-400000-500000
[INFO] processing batch 500000-600000/597552
[33m[INFO] loading file 18-18/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (597552, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.6588 - tp: 71767.0000 - fp: 8233.0000 - tn: 311767.0000 - fn: 8233.0000 - accuracy: 0.9588 - precision: 0.8971 - recall: 0.8971 - auc: 0.9357 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-17-18-batch-0-100000
[INFO] processing batch 100000-200000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.8111 - tp: 56121.0000 - fp: 23879.0000 - tn: 296121.0000 - fn: 23879.0000 - accuracy: 0.8806 - precision: 0.7015 - recall: 0.7015 - auc: 0.8134 - val_loss: 6.1080 - val_tp: 12421.0000 - val_fp: 7579.0000 - val_tn: 72421.0000 - val_fn: 7579.0000 - val_accuracy: 0.8484 - val_precision: 0.6211 - val_recall: 0.6211 - val_auc: 0.7632
[INFO] saving weights to checkpoints/lstm-epoch-002-files-17-18-batch-100000-200000
[INFO] processing batch 200000-300000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.1384 - tp: 49533.0000 - fp: 30467.0000 - tn: 289533.0000 - fn: 30467.0000 - accuracy: 0.8477 - precision: 0.6192 - recall: 0.6192 - auc: 0.7620 - val_loss: 6.1329 - val_tp: 12390.0000 - val_fp: 7610.0000 - val_tn: 72390.0000 - val_fn: 7610.0000 - val_accuracy: 0.8478 - val_precision: 0.6195 - val_recall: 0.6195 - val_auc: 0.7622
[INFO] saving weights to checkpoints/lstm-epoch-002-files-17-18-batch-200000-300000
[INFO] processing batch 300000-400000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.5331 - tp: 52537.0000 - fp: 27463.0000 - tn: 292537.0000 - fn: 27463.0000 - accuracy: 0.8627 - precision: 0.6567 - recall: 0.6567 - auc: 0.7854 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-17-18-batch-300000-400000
[INFO] processing batch 400000-500000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-17-18-batch-400000-500000
[INFO] processing batch 500000-600000/597552
[33m[INFO] loading file 19-19/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (597552, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-19-batch-0-100000
[INFO] processing batch 100000-200000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-19-batch-100000-200000
[INFO] processing batch 200000-300000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-19-batch-200000-300000
[INFO] processing batch 300000-400000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-19-batch-300000-400000
[INFO] processing batch 400000-500000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.3220 - tp: 43658.0000 - fp: 36342.0000 - tn: 283658.0000 - fn: 36342.0000 - accuracy: 0.8183 - precision: 0.5457 - recall: 0.5457 - auc: 0.7161 - val_loss: 9.8232 - val_tp: 7811.0000 - val_fp: 12189.0000 - val_tn: 67811.0000 - val_fn: 12189.0000 - val_accuracy: 0.7562 - val_precision: 0.3905 - val_recall: 0.3905 - val_auc: 0.6191
[INFO] saving weights to checkpoints/lstm-epoch-002-files-18-19-batch-400000-500000
[INFO] processing batch 500000-600000/597552
[33m[INFO] loading file 20-20/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (597552, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.6398 - tp: 56971.0000 - fp: 23029.0000 - tn: 296971.0000 - fn: 23029.0000 - accuracy: 0.8849 - precision: 0.7121 - recall: 0.7121 - auc: 0.8201 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-19-20-batch-0-100000
[INFO] processing batch 100000-200000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.9079 - tp: 75494.0000 - fp: 4506.0000 - tn: 315494.0000 - fn: 4506.0000 - accuracy: 0.9775 - precision: 0.9437 - recall: 0.9437 - auc: 0.9648 - val_loss: 2.9681 - val_tp: 16317.0000 - val_fp: 3683.0000 - val_tn: 76317.0000 - val_fn: 3683.0000 - val_accuracy: 0.9263 - val_precision: 0.8159 - val_recall: 0.8159 - val_auc: 0.8849
[INFO] saving weights to checkpoints/lstm-epoch-002-files-19-20-batch-100000-200000
[INFO] processing batch 200000-300000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.9407 - tp: 65404.0000 - fp: 14596.0000 - tn: 305404.0000 - fn: 14596.0000 - accuracy: 0.9270 - precision: 0.8176 - recall: 0.8176 - auc: 0.8860 - val_loss: 2.9690 - val_tp: 16316.0000 - val_fp: 3684.0000 - val_tn: 76316.0000 - val_fn: 3684.0000 - val_accuracy: 0.9263 - val_precision: 0.8158 - val_recall: 0.8158 - val_auc: 0.8849
[INFO] saving weights to checkpoints/lstm-epoch-002-files-19-20-batch-200000-300000
[INFO] processing batch 300000-400000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.9234 - tp: 65490.0000 - fp: 14510.0000 - tn: 305490.0000 - fn: 14510.0000 - accuracy: 0.9275 - precision: 0.8186 - recall: 0.8186 - auc: 0.8866 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-19-20-batch-300000-400000
[INFO] processing batch 400000-500000/597552
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-19-20-batch-400000-500000
[INFO] processing batch 500000-600000/597552
[33m[INFO] loading file 21-21/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (597550, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/597550
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-21-batch-0-100000
[INFO] processing batch 100000-200000/597550
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-21-batch-100000-200000
[INFO] processing batch 200000-300000/597550
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-21-batch-200000-300000
[INFO] processing batch 300000-400000/597550
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-21-batch-300000-400000
[INFO] processing batch 400000-500000/597550
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-20-21-batch-400000-500000
[INFO] processing batch 500000-600000/597550
[33m[INFO] loading file 22-22/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (366591, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/366591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.8380 - val_tp: 12756.0000 - val_fp: 7244.0000 - val_tn: 72756.0000 - val_fn: 7244.0000 - val_accuracy: 0.8551 - val_precision: 0.6378 - val_recall: 0.6378 - val_auc: 0.7736
[INFO] saving weights to checkpoints/lstm-epoch-002-files-21-22-batch-0-100000
[INFO] processing batch 100000-200000/366591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.5674 - tp: 42440.0000 - fp: 37560.0000 - tn: 282440.0000 - fn: 37560.0000 - accuracy: 0.8122 - precision: 0.5305 - recall: 0.5305 - auc: 0.7066 - val_loss: 7.5763 - val_tp: 10599.0000 - val_fp: 9401.0000 - val_tn: 70599.0000 - val_fn: 9401.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.7062
[INFO] saving weights to checkpoints/lstm-epoch-002-files-21-22-batch-100000-200000
[INFO] processing batch 200000-300000/366591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.5916 - tp: 42320.0000 - fp: 37680.0000 - tn: 282320.0000 - fn: 37680.0000 - accuracy: 0.8116 - precision: 0.5290 - recall: 0.5290 - auc: 0.7056 - val_loss: 7.5763 - val_tp: 10599.0000 - val_fp: 9401.0000 - val_tn: 70599.0000 - val_fn: 9401.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.7062
[INFO] saving weights to checkpoints/lstm-epoch-002-files-21-22-batch-200000-300000
[INFO] processing batch 300000-400000/366591
[33m[INFO] loading file 23-23/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (566591, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.5685 - tp: 42435.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37565.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5304 - auc: 0.7065 - val_loss: 2.2050 - val_tp: 17264.0000 - val_fp: 2736.0000 - val_tn: 77264.0000 - val_fn: 2736.0000 - val_accuracy: 0.9453 - val_precision: 0.8632 - val_recall: 0.8632 - val_auc: 0.9145
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-23-batch-0-100000
[INFO] processing batch 100000-200000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-23-batch-100000-200000
[INFO] processing batch 200000-300000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-23-batch-200000-300000
[INFO] processing batch 300000-400000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-23-batch-300000-400000
[INFO] processing batch 400000-500000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1926e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-22-23-batch-400000-500000
[INFO] processing batch 500000-600000/566591
[33m[INFO] loading file 24-24/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (566591, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-23-24-batch-0-100000
[INFO] processing batch 100000-200000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-23-24-batch-100000-200000
[INFO] processing batch 200000-300000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-23-24-batch-200000-300000
[INFO] processing batch 300000-400000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-23-24-batch-300000-400000
[INFO] processing batch 400000-500000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1921e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.4716 - val_tp: 18174.0000 - val_fp: 1826.0000 - val_tn: 78174.0000 - val_fn: 1826.0000 - val_accuracy: 0.9635 - val_precision: 0.9087 - val_recall: 0.9087 - val_auc: 0.9429
[INFO] saving weights to checkpoints/lstm-epoch-002-files-23-24-batch-400000-500000
[INFO] processing batch 500000-600000/566591
[33m[INFO] loading file 25-25/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (566591, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7330 - tp: 51545.0000 - fp: 28455.0000 - tn: 291545.0000 - fn: 28455.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.7777 - val_loss: 5.7429 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.7773
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-25-batch-0-100000
[INFO] processing batch 100000-200000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7552 - tp: 51435.0000 - fp: 28565.0000 - tn: 291435.0000 - fn: 28565.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.7768 - val_loss: 5.7566 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.7768
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-25-batch-100000-200000
[INFO] processing batch 200000-300000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7463 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.7772 - val_loss: 5.7276 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 72893.0000 - val_fn: 7107.0000 - val_accuracy: 0.8579 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.7779
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-25-batch-200000-300000
[INFO] processing batch 300000-400000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7497 - tp: 51462.0000 - fp: 28538.0000 - tn: 291462.0000 - fn: 28538.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.7770 - val_loss: 5.7324 - val_tp: 12887.0000 - val_fp: 7113.0000 - val_tn: 72887.0000 - val_fn: 7113.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.7777
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-25-batch-300000-400000
[INFO] processing batch 400000-500000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7594 - tp: 51414.0000 - fp: 28586.0000 - tn: 291414.0000 - fn: 28586.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.7767 - val_loss: 5.7195 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.7782
[INFO] saving weights to checkpoints/lstm-epoch-002-files-24-25-batch-400000-500000
[INFO] processing batch 500000-600000/566591
[33m[INFO] loading file 26-26/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (566591, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7425 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.7773 - val_loss: 5.7550 - val_tp: 12859.0000 - val_fp: 7141.0000 - val_tn: 72859.0000 - val_fn: 7141.0000 - val_accuracy: 0.8572 - val_precision: 0.6429 - val_recall: 0.6429 - val_auc: 0.7768
[INFO] saving weights to checkpoints/lstm-epoch-002-files-25-26-batch-0-100000
[INFO] processing batch 100000-200000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7193 - tp: 51613.0000 - fp: 28387.0000 - tn: 291613.0000 - fn: 28387.0000 - accuracy: 0.8581 - precision: 0.6452 - recall: 0.6452 - auc: 0.7782 - val_loss: 5.7606 - val_tp: 12852.0000 - val_fp: 7148.0000 - val_tn: 72852.0000 - val_fn: 7148.0000 - val_accuracy: 0.8570 - val_precision: 0.6426 - val_recall: 0.6426 - val_auc: 0.7766
[INFO] saving weights to checkpoints/lstm-epoch-002-files-25-26-batch-100000-200000
[INFO] processing batch 200000-300000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7473 - tp: 51474.0000 - fp: 28526.0000 - tn: 291474.0000 - fn: 28526.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.7771 - val_loss: 5.7517 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.7770
[INFO] saving weights to checkpoints/lstm-epoch-002-files-25-26-batch-200000-300000
[INFO] processing batch 300000-400000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7272 - tp: 51574.0000 - fp: 28426.0000 - tn: 291574.0000 - fn: 28426.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.7779 - val_loss: 5.7735 - val_tp: 12836.0000 - val_fp: 7164.0000 - val_tn: 72836.0000 - val_fn: 7164.0000 - val_accuracy: 0.8567 - val_precision: 0.6418 - val_recall: 0.6418 - val_auc: 0.7761
[INFO] saving weights to checkpoints/lstm-epoch-002-files-25-26-batch-300000-400000
[INFO] processing batch 400000-500000/566591
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7338 - tp: 51541.0000 - fp: 28459.0000 - tn: 291541.0000 - fn: 28459.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.7777 - val_loss: 5.7606 - val_tp: 12852.0000 - val_fp: 7148.0000 - val_tn: 72852.0000 - val_fn: 7148.0000 - val_accuracy: 0.8570 - val_precision: 0.6426 - val_recall: 0.6426 - val_auc: 0.7766
[INFO] saving weights to checkpoints/lstm-epoch-002-files-25-26-batch-400000-500000
[INFO] processing batch 500000-600000/566591
[33m[INFO] loading file 27-27/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (506721, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/506721
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7342 - tp: 51539.0000 - fp: 28461.0000 - tn: 291539.0000 - fn: 28461.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.7776 - val_loss: 5.7671 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.7764
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-27-batch-0-100000
[INFO] processing batch 100000-200000/506721
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7507 - tp: 51457.0000 - fp: 28543.0000 - tn: 291457.0000 - fn: 28543.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.7770 - val_loss: 5.7477 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.7771
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-27-batch-100000-200000
[INFO] processing batch 200000-300000/506721
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7247 - tp: 51586.0000 - fp: 28414.0000 - tn: 291586.0000 - fn: 28414.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.7780 - val_loss: 5.7260 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 72895.0000 - val_fn: 7105.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.7780
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-27-batch-200000-300000
[INFO] processing batch 300000-400000/506721
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7610 - tp: 51406.0000 - fp: 28594.0000 - tn: 291406.0000 - fn: 28594.0000 - accuracy: 0.8570 - precision: 0.6426 - recall: 0.6426 - auc: 0.7766 - val_loss: 5.7477 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.7771
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-27-batch-300000-400000
[INFO] processing batch 400000-500000/506721
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7346 - tp: 51537.0000 - fp: 28463.0000 - tn: 291537.0000 - fn: 28463.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.7776 - val_loss: 5.8033 - val_tp: 12799.0000 - val_fp: 7201.0000 - val_tn: 72799.0000 - val_fn: 7201.0000 - val_accuracy: 0.8560 - val_precision: 0.6399 - val_recall: 0.6399 - val_auc: 0.7750
[INFO] saving weights to checkpoints/lstm-epoch-002-files-26-27-batch-400000-500000
[INFO] processing batch 500000-600000/506721
[33m[INFO] loading file 28-28/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (340637, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/340637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.6329 - tp: 76607.0000 - fp: 3393.0000 - tn: 316607.0000 - fn: 3393.0000 - accuracy: 0.9830 - precision: 0.9576 - recall: 0.9576 - auc: 0.9747 - val_loss: 6.0981e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-27-28-batch-0-100000
[INFO] processing batch 100000-200000/340637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.0816e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.5063e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-27-28-batch-100000-200000
[INFO] processing batch 200000-300000/340637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.6009e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.7647e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-27-28-batch-200000-300000
[INFO] processing batch 300000-400000/340637
[33m[INFO] loading file 29-29/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (540637, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.0958e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.8475e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-29-batch-0-100000
[INFO] processing batch 100000-200000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.8310e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.7814e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-29-batch-100000-200000
[INFO] processing batch 200000-300000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.6937e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.5863e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-29-batch-200000-300000
[INFO] processing batch 300000-400000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.5484e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.2466e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-29-batch-300000-400000
[INFO] processing batch 400000-500000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.5700e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.1076e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-28-29-batch-400000-500000
[INFO] processing batch 500000-600000/540637
[33m[INFO] loading file 30-30/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (540637, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.6391e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.0858e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-29-30-batch-0-100000
[INFO] processing batch 100000-200000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.4974e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.8817e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-29-30-batch-100000-200000
[INFO] processing batch 200000-300000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.5066e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.7769e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-29-30-batch-200000-300000
[INFO] processing batch 300000-400000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.5744e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.8303e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-29-30-batch-300000-400000
[INFO] processing batch 400000-500000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.4778e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.1737e-05 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-29-30-batch-400000-500000
[INFO] processing batch 500000-600000/540637
[33m[INFO] loading file 31-31/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (540637, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.5113e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4523e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-31-batch-0-100000
[INFO] processing batch 100000-200000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.4188e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.3344e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-31-batch-100000-200000
[INFO] processing batch 200000-300000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.2572e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.1627e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-31-batch-200000-300000
[INFO] processing batch 300000-400000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.0985e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9870e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-31-batch-300000-400000
[INFO] processing batch 400000-500000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.8776e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.7693e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-30-31-batch-400000-500000
[INFO] processing batch 500000-600000/540637
[33m[INFO] loading file 32-32/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (540637, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.3236e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.3287e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-31-32-batch-0-100000
[INFO] processing batch 100000-200000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.4384e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.9390e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-31-32-batch-100000-200000
[INFO] processing batch 200000-300000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.3623e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.6626e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-31-32-batch-200000-300000
[INFO] processing batch 300000-400000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.5478e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4197e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-31-32-batch-300000-400000
[INFO] processing batch 400000-500000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.3240e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.2221e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-31-32-batch-400000-500000
[INFO] processing batch 500000-600000/540637
[33m[INFO] loading file 33-33/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (540637, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.2529e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.0841e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-33-batch-0-100000
[INFO] processing batch 100000-200000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.2142e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8724e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-33-batch-100000-200000
[INFO] processing batch 200000-300000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.7664e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6564e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-33-batch-200000-300000
[INFO] processing batch 300000-400000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.5478e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.5777e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-33-batch-300000-400000
[INFO] processing batch 400000-500000/540637
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.2155e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1706e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-32-33-batch-400000-500000
[INFO] processing batch 500000-600000/540637
[33m[INFO] loading file 34-34/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (382070, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/382070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 8.7360e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.9440e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-33-34-batch-0-100000
[INFO] processing batch 100000-200000/382070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1880e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.3625e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-33-34-batch-100000-200000
[INFO] processing batch 200000-300000/382070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.1159e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.4241e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-33-34-batch-200000-300000
[INFO] processing batch 300000-400000/382070
[33m[INFO] loading file 35-35/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582070, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1176e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.1892e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-35-batch-0-100000
[INFO] processing batch 100000-200000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 8.3236e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.4748e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-35-batch-100000-200000
[INFO] processing batch 200000-300000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.0719e-04 - tp: 79997.0000 - fp: 3.0000 - tn: 319997.0000 - fn: 3.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.9668e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-35-batch-200000-300000
[INFO] processing batch 300000-400000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.0924e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.9161e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-35-batch-300000-400000
[INFO] processing batch 400000-500000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.4311e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.0816e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-34-35-batch-400000-500000
[INFO] processing batch 500000-600000/582070
[33m[INFO] loading file 36-36/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582070, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.2384e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.6582e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-35-36-batch-0-100000
[INFO] processing batch 100000-200000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.4608e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.2000e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-35-36-batch-100000-200000
[INFO] processing batch 200000-300000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.8958e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.1393e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-35-36-batch-200000-300000
[INFO] processing batch 300000-400000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.0500e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.0979e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-35-36-batch-300000-400000
[INFO] processing batch 400000-500000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.0756e-04 - tp: 79994.0000 - fp: 6.0000 - tn: 319994.0000 - fn: 6.0000 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - auc: 1.0000 - val_loss: 1.0453e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-35-36-batch-400000-500000
[INFO] processing batch 500000-600000/582070
[33m[INFO] loading file 37-37/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582070, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.4221e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6496e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-37-batch-0-100000
[INFO] processing batch 100000-200000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.2523e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.9668e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-37-batch-100000-200000
[INFO] processing batch 200000-300000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.4493e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1442e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-37-batch-200000-300000
[INFO] processing batch 300000-400000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.6827e-04 - tp: 79997.0000 - fp: 3.0000 - tn: 319997.0000 - fn: 3.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.9793e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-37-batch-300000-400000
[INFO] processing batch 400000-500000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1097e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.1336e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-36-37-batch-400000-500000
[INFO] processing batch 500000-600000/582070
[33m[INFO] loading file 38-38/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582070, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7394e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.7925e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-37-38-batch-0-100000
[INFO] processing batch 100000-200000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.6334e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.4346e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-37-38-batch-100000-200000
[INFO] processing batch 200000-300000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.1820e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.9500e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-37-38-batch-200000-300000
[INFO] processing batch 300000-400000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.2757e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.1177e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-37-38-batch-300000-400000
[INFO] processing batch 400000-500000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.0834e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.6014e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-37-38-batch-400000-500000
[INFO] processing batch 500000-600000/582070
[33m[INFO] loading file 39-39/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582070, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.1923e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.1197e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-39-batch-0-100000
[INFO] processing batch 100000-200000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.1536e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.6282e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-39-batch-100000-200000
[INFO] processing batch 200000-300000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.4154e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.1880e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-39-batch-200000-300000
[INFO] processing batch 300000-400000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.7668e-05 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.0105e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-39-batch-300000-400000
[INFO] processing batch 400000-500000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.3680e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.8173e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-38-39-batch-400000-500000
[INFO] processing batch 500000-600000/582070
[33m[INFO] loading file 40-40/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (582070, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.5420e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.3316e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-39-40-batch-0-100000
[INFO] processing batch 100000-200000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.0653e-04 - tp: 79995.0000 - fp: 5.0000 - tn: 319995.0000 - fn: 5.0000 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - auc: 1.0000 - val_loss: 4.2869e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-39-40-batch-100000-200000
[INFO] processing batch 200000-300000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.2111e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.1348e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-39-40-batch-200000-300000
[INFO] processing batch 300000-400000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.1069e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.0351e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-39-40-batch-300000-400000
[INFO] processing batch 400000-500000/582070
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.9762e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9134e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-39-40-batch-400000-500000
[INFO] processing batch 500000-600000/582070
[33m[INFO] loading file 41-41/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (522228, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/522228
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.5817e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.7886e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-41-batch-0-100000
[INFO] processing batch 100000-200000/522228
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.7528e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.3377e-05 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-41-batch-100000-200000
[INFO] processing batch 200000-300000/522228
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.0511e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.5453e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-41-batch-200000-300000
[INFO] processing batch 300000-400000/522228
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.8298e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.2171e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-41-batch-300000-400000
[INFO] processing batch 400000-500000/522228
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.4077e-05 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.2541e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-40-41-batch-400000-500000
[INFO] processing batch 500000-600000/522228
[33m[INFO] loading file 42-42/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (365742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/365742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.3218e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.3318e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-41-42-batch-0-100000
[INFO] processing batch 100000-200000/365742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.1219e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.8770e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-41-42-batch-100000-200000
[INFO] processing batch 200000-300000/365742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.7341e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.5016e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-41-42-batch-200000-300000
[INFO] processing batch 300000-400000/365742
[33m[INFO] loading file 43-43/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (565742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.8870e-04 - tp: 79996.0000 - fp: 4.0000 - tn: 319996.0000 - fn: 4.0000 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - auc: 1.0000 - val_loss: 3.8397e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-43-batch-0-100000
[INFO] processing batch 100000-200000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.7634e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6859e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-43-batch-100000-200000
[INFO] processing batch 200000-300000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.5610e-04 - tp: 79996.0000 - fp: 4.0000 - tn: 319996.0000 - fn: 4.0000 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - auc: 1.0000 - val_loss: 4.4833e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-43-batch-200000-300000
[INFO] processing batch 300000-400000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.4615e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.3352e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-43-batch-300000-400000
[INFO] processing batch 400000-500000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.0569e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.0883e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-42-43-batch-400000-500000
[INFO] processing batch 500000-600000/565742
[33m[INFO] loading file 44-44/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (565742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.6177e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9525e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-43-44-batch-0-100000
[INFO] processing batch 100000-200000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.8254e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.7080e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-43-44-batch-100000-200000
[INFO] processing batch 200000-300000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.6128e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.5026e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-43-44-batch-200000-300000
[INFO] processing batch 300000-400000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.9251e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.4178e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-43-44-batch-300000-400000
[INFO] processing batch 400000-500000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.3098e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.1997e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-43-44-batch-400000-500000
[INFO] processing batch 500000-600000/565742
[33m[INFO] loading file 45-45/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (565742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.9779e-04 - tp: 79996.0000 - fp: 4.0000 - tn: 319996.0000 - fn: 4.0000 - accuracy: 1.0000 - precision: 0.9999 - recall: 0.9999 - auc: 1.0000 - val_loss: 7.9419e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-45-batch-0-100000
[INFO] processing batch 100000-200000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.4657e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.4532e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-45-batch-100000-200000
[INFO] processing batch 200000-300000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.8629e-05 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.6811e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-45-batch-200000-300000
[INFO] processing batch 300000-400000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.1496e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.7071e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-45-batch-300000-400000
[INFO] processing batch 400000-500000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.4317e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.1635e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-44-45-batch-400000-500000
[INFO] processing batch 500000-600000/565742
[33m[INFO] loading file 46-46/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (565742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.7300e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.7457e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-45-46-batch-0-100000
[INFO] processing batch 100000-200000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.3075e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.1480e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-45-46-batch-100000-200000
[INFO] processing batch 200000-300000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.7475e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.6410e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-45-46-batch-200000-300000
[INFO] processing batch 300000-400000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.2356e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.2226e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-45-46-batch-300000-400000
[INFO] processing batch 400000-500000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1022e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.2464e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-45-46-batch-400000-500000
[INFO] processing batch 500000-600000/565742
[33m[INFO] loading file 47-47/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (565742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.4661e-04 - tp: 79997.0000 - fp: 3.0000 - tn: 319997.0000 - fn: 3.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.3309e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-47-batch-0-100000
[INFO] processing batch 100000-200000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.3015e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.6283e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-47-batch-100000-200000
[INFO] processing batch 200000-300000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.0573e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9691e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-47-batch-200000-300000
[INFO] processing batch 300000-400000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.9577e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.7729e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-47-batch-300000-400000
[INFO] processing batch 400000-500000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.5492e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.3505e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-46-47-batch-400000-500000
[INFO] processing batch 500000-600000/565742
[33m[INFO] loading file 48-48/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (565742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.4637e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.0155e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-47-48-batch-0-100000
[INFO] processing batch 100000-200000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.8983e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.7671e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-47-48-batch-100000-200000
[INFO] processing batch 200000-300000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.6495e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.0846e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-47-48-batch-200000-300000
[INFO] processing batch 300000-400000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.4526e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.3674e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-47-48-batch-300000-400000
[INFO] processing batch 400000-500000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.2763e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.9570e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-47-48-batch-400000-500000
[INFO] processing batch 500000-600000/565742
[33m[INFO] loading file 49-49/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (565742, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.1549e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.0303e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-49-batch-0-100000
[INFO] processing batch 100000-200000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.9602e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2496e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-49-batch-100000-200000
[INFO] processing batch 200000-300000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.5725e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.3031e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-49-batch-200000-300000
[INFO] processing batch 300000-400000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.2149e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.0828e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-49-batch-300000-400000
[INFO] processing batch 400000-500000/565742
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.4749e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.2950e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-48-49-batch-400000-500000
[INFO] processing batch 500000-600000/565742
[33m[INFO] loading file 50-50/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (415724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/415724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.7119e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.5754e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-49-50-batch-0-100000
[INFO] processing batch 100000-200000/415724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.4484e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.3270e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-49-50-batch-100000-200000
[INFO] processing batch 200000-300000/415724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.2473e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.1637e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-49-50-batch-200000-300000
[INFO] processing batch 300000-400000/415724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.0987e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.0403e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-49-50-batch-300000-400000
[INFO] processing batch 400000-500000/415724
[33m[LOSS] 2.0402995505719446e-06[0m
[33m[INFO] epoch 3/10[0m
[33m[INFO] loading file 1-1/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.1105 - tp: 79034.0000 - fp: 966.0000 - tn: 319034.0000 - fn: 966.0000 - accuracy: 0.9952 - precision: 0.9879 - recall: 0.9879 - auc: 0.9937 - val_loss: 4.5508e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-1-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.7630e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.6288e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-1-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.9770e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8076 - val_tp: 17757.0000 - val_fp: 2243.0000 - val_tn: 77757.0000 - val_fn: 2243.0000 - val_accuracy: 0.9551 - val_precision: 0.8878 - val_recall: 0.8878 - val_auc: 0.9299
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-1-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.7174 - tp: 67275.0000 - fp: 12724.0000 - tn: 307276.0000 - fn: 12725.0000 - accuracy: 0.9364 - precision: 0.8409 - recall: 0.8409 - auc: 0.9625 - val_loss: 0.0038 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-1-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0017 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.5747e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-1-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 2-2/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0155 - tp: 79732.0000 - fp: 268.0000 - tn: 319732.0000 - fn: 268.0000 - accuracy: 0.9987 - precision: 0.9966 - recall: 0.9966 - auc: 0.9993 - val_loss: 8.8271e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-1-2-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.3643 - tp: 61725.0000 - fp: 18275.0000 - tn: 301725.0000 - fn: 18275.0000 - accuracy: 0.9086 - precision: 0.7716 - recall: 0.7716 - auc: 0.9716 - val_loss: 0.3846 - val_tp: 11590.0000 - val_fp: 8410.0000 - val_tn: 71590.0000 - val_fn: 8410.0000 - val_accuracy: 0.8318 - val_precision: 0.5795 - val_recall: 0.5795 - val_auc: 0.9465
[INFO] saving weights to checkpoints/lstm-epoch-003-files-1-2-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0221 - tp: 79620.0000 - fp: 380.0000 - tn: 319620.0000 - fn: 380.0000 - accuracy: 0.9981 - precision: 0.9952 - recall: 0.9952 - auc: 0.9986 - val_loss: 2.8863 - val_tp: 10613.0000 - val_fp: 9387.0000 - val_tn: 70613.0000 - val_fn: 9387.0000 - val_accuracy: 0.8123 - val_precision: 0.5307 - val_recall: 0.5307 - val_auc: 0.7457
[INFO] saving weights to checkpoints/lstm-epoch-003-files-1-2-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.1190 - tp: 77819.0000 - fp: 2181.0000 - tn: 317819.0000 - fn: 2181.0000 - accuracy: 0.9891 - precision: 0.9727 - recall: 0.9727 - auc: 0.9936 - val_loss: 0.0039 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-1-2-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.3637 - tp: 61887.0000 - fp: 18113.0000 - tn: 301887.0000 - fn: 18113.0000 - accuracy: 0.9094 - precision: 0.7736 - recall: 0.7736 - auc: 0.9719 - val_loss: 0.4392 - val_tp: 10663.0000 - val_fp: 9337.0000 - val_tn: 70663.0000 - val_fn: 9337.0000 - val_accuracy: 0.8133 - val_precision: 0.5332 - val_recall: 0.5332 - val_auc: 0.9445
[INFO] saving weights to checkpoints/lstm-epoch-003-files-1-2-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 3-3/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.1651 - tp: 75982.0000 - fp: 4018.0000 - tn: 315982.0000 - fn: 4018.0000 - accuracy: 0.9799 - precision: 0.9498 - recall: 0.9498 - auc: 0.9950 - val_loss: 0.0553 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-3-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.2479 - tp: 71963.0000 - fp: 8037.0000 - tn: 311963.0000 - fn: 8037.0000 - accuracy: 0.9598 - precision: 0.8995 - recall: 0.8995 - auc: 0.9881 - val_loss: 0.6710 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.9449
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-3-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0113 - tp: 79395.0000 - fp: 605.0000 - tn: 319395.0000 - fn: 605.0000 - accuracy: 0.9970 - precision: 0.9924 - recall: 0.9924 - auc: 1.0000 - val_loss: 1.5357e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-3-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.4669e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3728e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-3-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.6445e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2565e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-2-3-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 4-4/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1528e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1462e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-3-4-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.7131e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3763e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-3-4-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.3050e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2113e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-3-4-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1611e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.2847 - val_tp: 8906.0000 - val_fp: 11094.0000 - val_tn: 68906.0000 - val_fn: 11094.0000 - val_accuracy: 0.7781 - val_precision: 0.4453 - val_recall: 0.4453 - val_auc: 0.6533
[INFO] saving weights to checkpoints/lstm-epoch-003-files-3-4-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.6434 - tp: 58586.0000 - fp: 21414.0000 - tn: 298586.0000 - fn: 21414.0000 - accuracy: 0.8929 - precision: 0.7323 - recall: 0.7323 - auc: 0.9446 - val_loss: 0.8568 - val_tp: 7802.0000 - val_fp: 12198.0000 - val_tn: 67802.0000 - val_fn: 12198.0000 - val_accuracy: 0.7560 - val_precision: 0.3901 - val_recall: 0.3901 - val_auc: 0.9070
[INFO] saving weights to checkpoints/lstm-epoch-003-files-3-4-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 5-5/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.2702 - tp: 67723.0000 - fp: 12277.0000 - tn: 307723.0000 - fn: 12277.0000 - accuracy: 0.9386 - precision: 0.8465 - recall: 0.8465 - auc: 0.9861 - val_loss: 0.3113 - val_tp: 13594.0000 - val_fp: 6406.0000 - val_tn: 73594.0000 - val_fn: 6406.0000 - val_accuracy: 0.8719 - val_precision: 0.6797 - val_recall: 0.6797 - val_auc: 0.9688
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-5-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0145 - tp: 79781.0000 - fp: 219.0000 - tn: 319781.0000 - fn: 219.0000 - accuracy: 0.9989 - precision: 0.9973 - recall: 0.9973 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-5-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.1569 - tp: 77666.0000 - fp: 2334.0000 - tn: 317666.0000 - fn: 2334.0000 - accuracy: 0.9883 - precision: 0.9708 - recall: 0.9708 - auc: 0.9904 - val_loss: 0.0179 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-5-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0050 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-5-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0014 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-4-5-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 6-6/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 8.5671e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.6566e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-5-6-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.6149e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.7555e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-5-6-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.0832e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.4536e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-5-6-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.0023e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.5737e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-5-6-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.1943 - tp: 76890.0000 - fp: 3110.0000 - tn: 316890.0000 - fn: 3110.0000 - accuracy: 0.9844 - precision: 0.9611 - recall: 0.9611 - auc: 0.9873 - val_loss: 0.0273 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-5-6-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 7-7/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0102 - tp: 79865.0000 - fp: 135.0000 - tn: 319865.0000 - fn: 135.0000 - accuracy: 0.9993 - precision: 0.9983 - recall: 0.9983 - auc: 0.9999 - val_loss: 6.7151e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-7-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.0327e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.8345e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-7-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.2549 - tp: 71450.0000 - fp: 8550.0000 - tn: 311450.0000 - fn: 8550.0000 - accuracy: 0.9572 - precision: 0.8931 - recall: 0.8931 - auc: 0.9879 - val_loss: 0.3663 - val_tp: 12848.0000 - val_fp: 7152.0000 - val_tn: 72848.0000 - val_fn: 7152.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9680
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-7-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0096 - tp: 79551.0000 - fp: 449.0000 - tn: 319551.0000 - fn: 449.0000 - accuracy: 0.9978 - precision: 0.9944 - recall: 0.9944 - auc: 1.0000 - val_loss: 1.7923e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-7-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.4487e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1725e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-6-7-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 8-8/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 9.2363e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.3014e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-7-8-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.2306e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.1849e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-7-8-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.3523e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.7244e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-7-8-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.1305 - tp: 76033.0000 - fp: 3967.0000 - tn: 316033.0000 - fn: 3967.0000 - accuracy: 0.9802 - precision: 0.9504 - recall: 0.9504 - auc: 0.9962 - val_loss: 0.2742 - val_tp: 16360.0000 - val_fp: 3640.0000 - val_tn: 76360.0000 - val_fn: 3640.0000 - val_accuracy: 0.9272 - val_precision: 0.8180 - val_recall: 0.8180 - val_auc: 0.9917
[INFO] saving weights to checkpoints/lstm-epoch-003-files-7-8-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0149 - tp: 79621.0000 - fp: 379.0000 - tn: 319621.0000 - fn: 379.0000 - accuracy: 0.9981 - precision: 0.9953 - recall: 0.9953 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-7-8-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 9-9/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0013 - tp: 79986.0000 - fp: 14.0000 - tn: 319986.0000 - fn: 14.0000 - accuracy: 0.9999 - precision: 0.9998 - recall: 0.9998 - auc: 1.0000 - val_loss: 8.9469e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-9-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.1373 - tp: 75747.0000 - fp: 4253.0000 - tn: 315747.0000 - fn: 4253.0000 - accuracy: 0.9787 - precision: 0.9468 - recall: 0.9468 - auc: 0.9956 - val_loss: 0.0578 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-9-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0034 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.6623e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-9-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.0142e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7481e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-9-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.3768e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1028e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-8-9-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 10-10/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 8.0076e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.1796e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-9-10-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.8785e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8440 - val_tp: 18412.0000 - val_fp: 1588.0000 - val_tn: 78412.0000 - val_fn: 1588.0000 - val_accuracy: 0.9682 - val_precision: 0.9206 - val_recall: 0.9206 - val_auc: 0.9504
[INFO] saving weights to checkpoints/lstm-epoch-003-files-9-10-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.1218 - tp: 78511.0000 - fp: 1489.0000 - tn: 318511.0000 - fn: 1489.0000 - accuracy: 0.9926 - precision: 0.9814 - recall: 0.9814 - auc: 0.9927 - val_loss: 2.8491 - val_tp: 13136.0000 - val_fp: 6864.0000 - val_tn: 73136.0000 - val_fn: 6864.0000 - val_accuracy: 0.8627 - val_precision: 0.6568 - val_recall: 0.6568 - val_auc: 0.7792
[INFO] saving weights to checkpoints/lstm-epoch-003-files-9-10-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.1331 - tp: 78103.0000 - fp: 1897.0000 - tn: 318103.0000 - fn: 1897.0000 - accuracy: 0.9905 - precision: 0.9763 - recall: 0.9763 - auc: 0.9909 - val_loss: 0.0011 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-9-10-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 8.8197e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.7446e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-9-10-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 11-11/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.7593e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.8439e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-11-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.0512e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.3848e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-11-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.9487e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.5369e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-11-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.2105e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8887e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-11-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.6548e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.4390e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-10-11-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 12-12/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.0467e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1471e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-11-12-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 9.9389e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.4865e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-11-12-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.2779 - tp: 75757.0000 - fp: 4243.0000 - tn: 315757.0000 - fn: 4243.0000 - accuracy: 0.9788 - precision: 0.9470 - recall: 0.9470 - auc: 0.9831 - val_loss: 0.0347 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-11-12-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.1333 - tp: 76524.0000 - fp: 3476.0000 - tn: 316524.0000 - fn: 3476.0000 - accuracy: 0.9826 - precision: 0.9566 - recall: 0.9566 - auc: 0.9966 - val_loss: 0.0351 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-11-12-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0046 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0013 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-11-12-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 13-13/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 9.4759e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.0965e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-13-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.3715e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.2636e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-13-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.5520e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.9842e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-13-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.1716 - tp: 77337.0000 - fp: 2663.0000 - tn: 317337.0000 - fn: 2663.0000 - accuracy: 0.9867 - precision: 0.9667 - recall: 0.9667 - auc: 0.9875 - val_loss: 0.0131 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-13-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0036 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.6354e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-12-13-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 14-14/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.1924 - tp: 74270.0000 - fp: 5730.0000 - tn: 314270.0000 - fn: 5730.0000 - accuracy: 0.9713 - precision: 0.9284 - recall: 0.9284 - auc: 0.9922 - val_loss: 0.5234 - val_tp: 12807.0000 - val_fp: 7193.0000 - val_tn: 72807.0000 - val_fn: 7193.0000 - val_accuracy: 0.8561 - val_precision: 0.6403 - val_recall: 0.6403 - val_auc: 0.9677
[INFO] saving weights to checkpoints/lstm-epoch-003-files-13-14-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0119 - tp: 79472.0000 - fp: 528.0000 - tn: 319472.0000 - fn: 528.0000 - accuracy: 0.9974 - precision: 0.9934 - recall: 0.9934 - auc: 1.0000 - val_loss: 7.9135e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-13-14-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.4954e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.1975e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-13-14-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.1630e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4574e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-13-14-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.0182e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7160e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-13-14-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 15-15/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (515724, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.0012 - tp: 79976.0000 - fp: 24.0000 - tn: 319976.0000 - fn: 24.0000 - accuracy: 0.9999 - precision: 0.9997 - recall: 0.9997 - auc: 1.0000 - val_loss: 8.0526e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-15-batch-0-100000
[INFO] processing batch 100000-200000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.3526e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.3225e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-15-batch-100000-200000
[INFO] processing batch 200000-300000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.1880e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.5525e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-15-batch-200000-300000
[INFO] processing batch 300000-400000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.0412e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8930 - val_tp: 18892.0000 - val_fp: 1108.0000 - val_tn: 78892.0000 - val_fn: 1108.0000 - val_accuracy: 0.9778 - val_precision: 0.9446 - val_recall: 0.9446 - val_auc: 0.9654
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-15-batch-300000-400000
[INFO] processing batch 400000-500000/515724
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.5298 - tp: 42627.0000 - fp: 37373.0000 - tn: 282627.0000 - fn: 37373.0000 - accuracy: 0.8131 - precision: 0.5328 - recall: 0.5328 - auc: 0.7080 - val_loss: 7.5473 - val_tp: 10635.0000 - val_fp: 9365.0000 - val_tn: 70635.0000 - val_fn: 9365.0000 - val_accuracy: 0.8127 - val_precision: 0.5318 - val_recall: 0.5318 - val_auc: 0.7073
[INFO] saving weights to checkpoints/lstm-epoch-003-files-14-15-batch-400000-500000
[INFO] processing batch 500000-600000/515724
[33m[INFO] loading file 16-16/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (455414, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/455414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.5566 - tp: 42494.0000 - fp: 37506.0000 - tn: 282494.0000 - fn: 37506.0000 - accuracy: 0.8125 - precision: 0.5312 - recall: 0.5312 - auc: 0.7070 - val_loss: 7.5562 - val_tp: 10624.0000 - val_fp: 9376.0000 - val_tn: 70624.0000 - val_fn: 9376.0000 - val_accuracy: 0.8125 - val_precision: 0.5312 - val_recall: 0.5312 - val_auc: 0.7070
[INFO] saving weights to checkpoints/lstm-epoch-003-files-15-16-batch-0-100000
[INFO] processing batch 100000-200000/455414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.8442 - tp: 50993.0000 - fp: 29007.0000 - tn: 290993.0000 - fn: 29007.0000 - accuracy: 0.8550 - precision: 0.6374 - recall: 0.6374 - auc: 0.7734 - val_loss: 2.5702e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-15-16-batch-100000-200000
[INFO] processing batch 200000-300000/455414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.2621e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8319e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-15-16-batch-200000-300000
[INFO] processing batch 300000-400000/455414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.2196e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.1683e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-15-16-batch-300000-400000
[INFO] processing batch 400000-500000/455414
[33m[INFO] loading file 17-17/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (555414, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.8953e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2791e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-17-batch-0-100000
[INFO] processing batch 100000-200000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1285e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.8998e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-17-batch-100000-200000
[INFO] processing batch 200000-300000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 8.6051e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.7830e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-17-batch-200000-300000
[INFO] processing batch 300000-400000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.7162 - tp: 71482.0000 - fp: 8518.0000 - tn: 311482.0000 - fn: 8518.0000 - accuracy: 0.9574 - precision: 0.8935 - recall: 0.8935 - auc: 0.9335 - val_loss: 2.9456 - val_tp: 16345.0000 - val_fp: 3655.0000 - val_tn: 76345.0000 - val_fn: 3655.0000 - val_accuracy: 0.9269 - val_precision: 0.8173 - val_recall: 0.8173 - val_auc: 0.8858
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-17-batch-300000-400000
[INFO] processing batch 400000-500000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.9154 - tp: 65530.0000 - fp: 14470.0000 - tn: 305530.0000 - fn: 14470.0000 - accuracy: 0.9277 - precision: 0.8191 - recall: 0.8191 - auc: 0.8870 - val_loss: 2.9238 - val_tp: 16372.0000 - val_fp: 3628.0000 - val_tn: 76372.0000 - val_fn: 3628.0000 - val_accuracy: 0.9274 - val_precision: 0.8186 - val_recall: 0.8186 - val_auc: 0.8866
[INFO] saving weights to checkpoints/lstm-epoch-003-files-16-17-batch-400000-500000
[INFO] processing batch 500000-600000/555414
[33m[INFO] loading file 18-18/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (555414, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.4985 - tp: 77526.0000 - fp: 2474.0000 - tn: 317526.0000 - fn: 2474.0000 - accuracy: 0.9876 - precision: 0.9691 - recall: 0.9691 - auc: 0.9807 - val_loss: 6.1305 - val_tp: 12393.0000 - val_fp: 7607.0000 - val_tn: 72393.0000 - val_fn: 7607.0000 - val_accuracy: 0.8479 - val_precision: 0.6197 - val_recall: 0.6197 - val_auc: 0.7623
[INFO] saving weights to checkpoints/lstm-epoch-003-files-17-18-batch-0-100000
[INFO] processing batch 100000-200000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.1305 - tp: 49572.0000 - fp: 30428.0000 - tn: 289572.0000 - fn: 30428.0000 - accuracy: 0.8479 - precision: 0.6197 - recall: 0.6197 - auc: 0.7623 - val_loss: 6.0395 - val_tp: 12506.0000 - val_fp: 7494.0000 - val_tn: 72506.0000 - val_fn: 7494.0000 - val_accuracy: 0.8501 - val_precision: 0.6253 - val_recall: 0.6253 - val_auc: 0.7658
[INFO] saving weights to checkpoints/lstm-epoch-003-files-17-18-batch-100000-200000
[INFO] processing batch 200000-300000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.1444 - tp: 49503.0000 - fp: 30497.0000 - tn: 289503.0000 - fn: 30497.0000 - accuracy: 0.8475 - precision: 0.6188 - recall: 0.6188 - auc: 0.7617 - val_loss: 6.1474 - val_tp: 12372.0000 - val_fp: 7628.0000 - val_tn: 72372.0000 - val_fn: 7628.0000 - val_accuracy: 0.8474 - val_precision: 0.6186 - val_recall: 0.6186 - val_auc: 0.7616
[INFO] saving weights to checkpoints/lstm-epoch-003-files-17-18-batch-200000-300000
[INFO] processing batch 300000-400000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.3067 - tp: 68551.0000 - fp: 11449.0000 - tn: 308551.0000 - fn: 11449.0000 - accuracy: 0.9428 - precision: 0.8569 - recall: 0.8569 - auc: 0.9106 - val_loss: 3.6562e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-17-18-batch-300000-400000
[INFO] processing batch 400000-500000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.5334e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.2967e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-17-18-batch-400000-500000
[INFO] processing batch 500000-600000/555414
[33m[INFO] loading file 19-19/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (555414, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.1697e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.9864e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-19-batch-0-100000
[INFO] processing batch 100000-200000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.8807e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.8155e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-19-batch-100000-200000
[INFO] processing batch 200000-300000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.7282e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.5498e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-19-batch-200000-300000
[INFO] processing batch 300000-400000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 0.2222 - tp: 78897.0000 - fp: 1103.0000 - tn: 318897.0000 - fn: 1103.0000 - accuracy: 0.9945 - precision: 0.9862 - recall: 0.9862 - auc: 0.9914 - val_loss: 9.7974 - val_tp: 7843.0000 - val_fp: 12157.0000 - val_tn: 67843.0000 - val_fn: 12157.0000 - val_accuracy: 0.7569 - val_precision: 0.3922 - val_recall: 0.3922 - val_auc: 0.6201
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-19-batch-300000-400000
[INFO] processing batch 400000-500000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 9.8375 - tp: 31173.0000 - fp: 48827.0000 - tn: 271173.0000 - fn: 48827.0000 - accuracy: 0.7559 - precision: 0.3897 - recall: 0.3897 - auc: 0.6185 - val_loss: 7.6343 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.7040
[INFO] saving weights to checkpoints/lstm-epoch-003-files-18-19-batch-400000-500000
[INFO] processing batch 500000-600000/555414
[33m[INFO] loading file 20-20/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (555414, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.2666e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.2036e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-19-20-batch-0-100000
[INFO] processing batch 100000-200000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.4602 - tp: 67789.0000 - fp: 12211.0000 - tn: 307789.0000 - fn: 12211.0000 - accuracy: 0.9389 - precision: 0.8474 - recall: 0.8474 - auc: 0.9046 - val_loss: 2.9625 - val_tp: 16324.0000 - val_fp: 3676.0000 - val_tn: 76324.0000 - val_fn: 3676.0000 - val_accuracy: 0.9265 - val_precision: 0.8162 - val_recall: 0.8162 - val_auc: 0.8851
[INFO] saving weights to checkpoints/lstm-epoch-003-files-19-20-batch-100000-200000
[INFO] processing batch 200000-300000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.9434 - tp: 65391.0000 - fp: 14609.0000 - tn: 305391.0000 - fn: 14609.0000 - accuracy: 0.9270 - precision: 0.8174 - recall: 0.8174 - auc: 0.8859 - val_loss: 2.9424 - val_tp: 16349.0000 - val_fp: 3651.0000 - val_tn: 76349.0000 - val_fn: 3651.0000 - val_accuracy: 0.9270 - val_precision: 0.8174 - val_recall: 0.8174 - val_auc: 0.8859
[INFO] saving weights to checkpoints/lstm-epoch-003-files-19-20-batch-200000-300000
[INFO] processing batch 300000-400000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.3765 - tp: 73168.0000 - fp: 6832.0000 - tn: 313168.0000 - fn: 6832.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9466 - val_loss: 1.9829e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-19-20-batch-300000-400000
[INFO] processing batch 400000-500000/555414
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.9618e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.9281e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-19-20-batch-400000-500000
[INFO] processing batch 500000-600000/555414
[33m[INFO] loading file 21-21/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (555412, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/555412
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.8798e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8534e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-21-batch-0-100000
[INFO] processing batch 100000-200000/555412
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.8061e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7744e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-21-batch-100000-200000
[INFO] processing batch 200000-300000/555412
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.7226e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6939e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-21-batch-200000-300000
[INFO] processing batch 300000-400000/555412
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.6853e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6471e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-21-batch-300000-400000
[INFO] processing batch 400000-500000/555412
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.6365e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6117e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-20-21-batch-400000-500000
[INFO] processing batch 500000-600000/555412
[33m[INFO] loading file 22-22/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (324453, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/324453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.5530 - tp: 62365.0000 - fp: 17635.0000 - tn: 302365.0000 - fn: 17635.0000 - accuracy: 0.9118 - precision: 0.7796 - recall: 0.7796 - auc: 0.8622 - val_loss: 7.5626 - val_tp: 10616.0000 - val_fp: 9384.0000 - val_tn: 70616.0000 - val_fn: 9384.0000 - val_accuracy: 0.8123 - val_precision: 0.5308 - val_recall: 0.5308 - val_auc: 0.7068
[INFO] saving weights to checkpoints/lstm-epoch-003-files-21-22-batch-0-100000
[INFO] processing batch 100000-200000/324453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.5699 - tp: 42428.0000 - fp: 37572.0000 - tn: 282428.0000 - fn: 37572.0000 - accuracy: 0.8121 - precision: 0.5304 - recall: 0.5304 - auc: 0.7065 - val_loss: 7.5900 - val_tp: 10582.0000 - val_fp: 9418.0000 - val_tn: 70582.0000 - val_fn: 9418.0000 - val_accuracy: 0.8116 - val_precision: 0.5291 - val_recall: 0.5291 - val_auc: 0.7057
[INFO] saving weights to checkpoints/lstm-epoch-003-files-21-22-batch-100000-200000
[INFO] processing batch 200000-300000/324453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.5856 - tp: 42350.0000 - fp: 37650.0000 - tn: 282350.0000 - fn: 37650.0000 - accuracy: 0.8117 - precision: 0.5294 - recall: 0.5294 - auc: 0.7059 - val_loss: 7.6077 - val_tp: 10560.0000 - val_fp: 9440.0000 - val_tn: 70560.0000 - val_fn: 9440.0000 - val_accuracy: 0.8112 - val_precision: 0.5280 - val_recall: 0.5280 - val_auc: 0.7050
[INFO] saving weights to checkpoints/lstm-epoch-003-files-21-22-batch-200000-300000
[INFO] processing batch 300000-400000/324453
[33m[INFO] loading file 23-23/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524453, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.1278 - tp: 59512.0000 - fp: 20488.0000 - tn: 299512.0000 - fn: 20488.0000 - accuracy: 0.8976 - precision: 0.7439 - recall: 0.7439 - auc: 0.8399 - val_loss: 1.4971e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-23-batch-0-100000
[INFO] processing batch 100000-200000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.4667e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.4459e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-23-batch-100000-200000
[INFO] processing batch 200000-300000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.4158e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.4256e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-23-batch-200000-300000
[INFO] processing batch 300000-400000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.4202e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.4116e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-23-batch-300000-400000
[INFO] processing batch 400000-500000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.4050e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3956e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-22-23-batch-400000-500000
[INFO] processing batch 500000-600000/524453
[33m[INFO] loading file 24-24/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524453, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.3838e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3652e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-23-24-batch-0-100000
[INFO] processing batch 100000-200000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.3489e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3473e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-23-24-batch-100000-200000
[INFO] processing batch 200000-300000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.3466e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3398e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-23-24-batch-200000-300000
[INFO] processing batch 300000-400000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.3436e-07 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3192e-07 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-23-24-batch-300000-400000
[INFO] processing batch 400000-500000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.9515 - tp: 70314.0000 - fp: 9686.0000 - tn: 310314.0000 - fn: 9686.0000 - accuracy: 0.9516 - precision: 0.8789 - recall: 0.8789 - auc: 0.9243 - val_loss: 5.7340 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.7777
[INFO] saving weights to checkpoints/lstm-epoch-003-files-23-24-batch-400000-500000
[INFO] processing batch 500000-600000/524453
[33m[INFO] loading file 25-25/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524453, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7499 - tp: 51461.0000 - fp: 28539.0000 - tn: 291461.0000 - fn: 28539.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.7770 - val_loss: 5.7421 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.7773
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-25-batch-0-100000
[INFO] processing batch 100000-200000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7445 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.7772 - val_loss: 5.7453 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.7772
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-25-batch-100000-200000
[INFO] processing batch 200000-300000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7511 - tp: 51455.0000 - fp: 28545.0000 - tn: 291455.0000 - fn: 28545.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.7770 - val_loss: 5.7558 - val_tp: 12858.0000 - val_fp: 7142.0000 - val_tn: 72858.0000 - val_fn: 7142.0000 - val_accuracy: 0.8572 - val_precision: 0.6429 - val_recall: 0.6429 - val_auc: 0.7768
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-25-batch-200000-300000
[INFO] processing batch 300000-400000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7415 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.7774 - val_loss: 5.7759 - val_tp: 12833.0000 - val_fp: 7167.0000 - val_tn: 72833.0000 - val_fn: 7167.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.7760
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-25-batch-300000-400000
[INFO] processing batch 400000-500000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.7405 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.7774 - val_loss: 5.7590 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.7767
[INFO] saving weights to checkpoints/lstm-epoch-003-files-24-25-batch-400000-500000
[INFO] processing batch 500000-600000/524453
[33m[INFO] loading file 26-26/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (524453, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.4550 - tp: 52874.0000 - fp: 27126.0000 - tn: 292874.0000 - fn: 27126.0000 - accuracy: 0.8644 - precision: 0.6609 - recall: 0.6609 - auc: 0.7875 - val_loss: 2.6148e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-25-26-batch-0-100000
[INFO] processing batch 100000-200000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.6751e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2748e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-25-26-batch-100000-200000
[INFO] processing batch 200000-300000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 9.4967e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.2181e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-25-26-batch-200000-300000
[INFO] processing batch 300000-400000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.6302e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.0848e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-25-26-batch-300000-400000
[INFO] processing batch 400000-500000/524453
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.6014e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.1583e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-25-26-batch-400000-500000
[INFO] processing batch 500000-600000/524453
[33m[INFO] loading file 27-27/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (464583, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/464583
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.5467e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.0549e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-27-batch-0-100000
[INFO] processing batch 100000-200000/464583
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.6296e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4058e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-27-batch-100000-200000
[INFO] processing batch 200000-300000/464583
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.0506e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.7218e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-27-batch-200000-300000
[INFO] processing batch 300000-400000/464583
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.3967e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.0090e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-26-27-batch-300000-400000
[INFO] processing batch 400000-500000/464583
[33m[INFO] loading file 28-28/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (398499, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/398499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.4778e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.2341e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-27-28-batch-0-100000
[INFO] processing batch 100000-200000/398499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.7602e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4960e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-27-28-batch-100000-200000
[INFO] processing batch 200000-300000/398499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.4060e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.3128e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-27-28-batch-200000-300000
[INFO] processing batch 300000-400000/398499
[33m[INFO] loading file 29-29/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (598499, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.7567e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.1512e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-29-batch-0-100000
[INFO] processing batch 100000-200000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.9531e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7445e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-29-batch-100000-200000
[INFO] processing batch 200000-300000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.4277e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3942e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-29-batch-200000-300000
[INFO] processing batch 300000-400000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 9.5273e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.4641e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-29-batch-300000-400000
[INFO] processing batch 400000-500000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.9646e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3077e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-28-29-batch-400000-500000
[INFO] processing batch 500000-600000/598499
[33m[INFO] loading file 30-30/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (598499, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.6073e-05 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.4696e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-29-30-batch-0-100000
[INFO] processing batch 100000-200000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.2837e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.0089e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-29-30-batch-100000-200000
[INFO] processing batch 200000-300000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.6816e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.3589e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-29-30-batch-200000-300000
[INFO] processing batch 300000-400000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.5029e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.4353e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-29-30-batch-300000-400000
[INFO] processing batch 400000-500000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 8.5041e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.4545e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-29-30-batch-400000-500000
[INFO] processing batch 500000-600000/598499
[33m[INFO] loading file 31-31/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (598499, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.6676e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4626e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-31-batch-0-100000
[INFO] processing batch 100000-200000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.0041e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.4639e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-31-batch-100000-200000
[INFO] processing batch 200000-300000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.7942e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.2817e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-31-batch-200000-300000
[INFO] processing batch 300000-400000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.9300e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.6240e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-31-batch-300000-400000
[INFO] processing batch 400000-500000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.3291e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.0883e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-30-31-batch-400000-500000
[INFO] processing batch 500000-600000/598499
[33m[INFO] loading file 32-32/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (598499, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.8222e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.7499e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-31-32-batch-0-100000
[INFO] processing batch 100000-200000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.2594e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.6618e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-31-32-batch-100000-200000
[INFO] processing batch 200000-300000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.4275e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.7830e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-31-32-batch-200000-300000
[INFO] processing batch 300000-400000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.2308e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.7907e-04 - val_tp: 19996.0000 - val_fp: 4.0000 - val_tn: 79996.0000 - val_fn: 4.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9998 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-31-32-batch-300000-400000
[INFO] processing batch 400000-500000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.0604e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.7337e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-31-32-batch-400000-500000
[INFO] processing batch 500000-600000/598499
[33m[INFO] loading file 33-33/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (598499, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.5228e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.2895e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-33-batch-0-100000
[INFO] processing batch 100000-200000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.5217e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.8077e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-33-batch-100000-200000
[INFO] processing batch 200000-300000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.3476e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.2346e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-33-batch-200000-300000
[INFO] processing batch 300000-400000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.7428e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.3772e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-33-batch-300000-400000
[INFO] processing batch 400000-500000/598499
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1160e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.6982e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-32-33-batch-400000-500000
[INFO] processing batch 500000-600000/598499
[33m[INFO] loading file 34-34/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439932, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/439932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.8370e-05 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.7009e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-33-34-batch-0-100000
[INFO] processing batch 100000-200000/439932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.8904e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.5308e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-33-34-batch-100000-200000
[INFO] processing batch 200000-300000/439932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.1587e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.3301e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-33-34-batch-200000-300000
[INFO] processing batch 300000-400000/439932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1784e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.2292e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-33-34-batch-300000-400000
[INFO] processing batch 400000-500000/439932
[33m[INFO] loading file 35-35/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539932, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 8.0852e-05 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.7441e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-35-batch-0-100000
[INFO] processing batch 100000-200000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.5081e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8990e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-35-batch-100000-200000
[INFO] processing batch 200000-300000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.9388e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.8019e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-35-batch-200000-300000
[INFO] processing batch 300000-400000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.5742e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.2742e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-35-batch-300000-400000
[INFO] processing batch 400000-500000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.1319e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9123e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-34-35-batch-400000-500000
[INFO] processing batch 500000-600000/539932
[33m[INFO] loading file 36-36/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539932, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.2368e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6840e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-35-36-batch-0-100000
[INFO] processing batch 100000-200000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.9677e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.4968e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-35-36-batch-100000-200000
[INFO] processing batch 200000-300000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.5857e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.1932e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-35-36-batch-200000-300000
[INFO] processing batch 300000-400000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.2555e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.2997e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-35-36-batch-300000-400000
[INFO] processing batch 400000-500000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.1728e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.3271e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-35-36-batch-400000-500000
[INFO] processing batch 500000-600000/539932
[33m[INFO] loading file 37-37/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539932, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.7198e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6100e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-37-batch-0-100000
[INFO] processing batch 100000-200000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.4175e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.2762e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-37-batch-100000-200000
[INFO] processing batch 200000-300000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.1536e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.0030e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-37-batch-200000-300000
[INFO] processing batch 300000-400000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.8945e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.7912e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-37-batch-300000-400000
[INFO] processing batch 400000-500000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.6246e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.7783e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-36-37-batch-400000-500000
[INFO] processing batch 500000-600000/539932
[33m[INFO] loading file 38-38/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539932, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.5394e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.8985e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-37-38-batch-0-100000
[INFO] processing batch 100000-200000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.6536e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.2684e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-37-38-batch-100000-200000
[INFO] processing batch 200000-300000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.4456e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.9861e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-37-38-batch-200000-300000
[INFO] processing batch 300000-400000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.6873e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.5791e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-37-38-batch-300000-400000
[INFO] processing batch 400000-500000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.4977e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4148e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-37-38-batch-400000-500000
[INFO] processing batch 500000-600000/539932
[33m[INFO] loading file 39-39/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539932, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.0440e-04 - tp: 79997.0000 - fp: 3.0000 - tn: 319997.0000 - fn: 3.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.5537e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-39-batch-0-100000
[INFO] processing batch 100000-200000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.2557e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.6747e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-39-batch-100000-200000
[INFO] processing batch 200000-300000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.3707e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.1287e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-39-batch-200000-300000
[INFO] processing batch 300000-400000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.7436e-05 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.2424e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-39-batch-300000-400000
[INFO] processing batch 400000-500000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.8369e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.4968e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-38-39-batch-400000-500000
[INFO] processing batch 500000-600000/539932
[33m[INFO] loading file 40-40/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539932, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.6471e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.8309e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-39-40-batch-0-100000
[INFO] processing batch 100000-200000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.2482e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.8258e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-39-40-batch-100000-200000
[INFO] processing batch 200000-300000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.9131e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.7894e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-39-40-batch-200000-300000
[INFO] processing batch 300000-400000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.3370e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.2053e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-39-40-batch-300000-400000
[INFO] processing batch 400000-500000/539932
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.0048e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.4264e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-39-40-batch-400000-500000
[INFO] processing batch 500000-600000/539932
[33m[INFO] loading file 41-41/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (480090, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/480090
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1378e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.7924e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-41-batch-0-100000
[INFO] processing batch 100000-200000/480090
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.3922e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.3347e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-41-batch-100000-200000
[INFO] processing batch 200000-300000/480090
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.9182e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.6810e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-41-batch-200000-300000
[INFO] processing batch 300000-400000/480090
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.9189e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.1898e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-40-41-batch-300000-400000
[INFO] processing batch 400000-500000/480090
[33m[INFO] loading file 42-42/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (423604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/423604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.1904e-05 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.3058e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-41-42-batch-0-100000
[INFO] processing batch 100000-200000/423604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.3529e-05 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.7103e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-41-42-batch-100000-200000
[INFO] processing batch 200000-300000/423604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.4110e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.1120e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-41-42-batch-200000-300000
[INFO] processing batch 300000-400000/423604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.0219e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.0976e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-41-42-batch-300000-400000
[INFO] processing batch 400000-500000/423604
[33m[INFO] loading file 43-43/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (523604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.1206e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6181e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-43-batch-0-100000
[INFO] processing batch 100000-200000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 8.3487e-05 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9271e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-43-batch-100000-200000
[INFO] processing batch 200000-300000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.6360e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.8942e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-43-batch-200000-300000
[INFO] processing batch 300000-400000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.7333e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6640e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-43-batch-300000-400000
[INFO] processing batch 400000-500000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.3219e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1984e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-42-43-batch-400000-500000
[INFO] processing batch 500000-600000/523604
[33m[INFO] loading file 44-44/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (523604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.5474e-05 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.8715e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-43-44-batch-0-100000
[INFO] processing batch 100000-200000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 6.9069e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.9033e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-43-44-batch-100000-200000
[INFO] processing batch 200000-300000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.2020e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.8611e-05 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-43-44-batch-200000-300000
[INFO] processing batch 300000-400000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.8069e-05 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.9233e-05 - val_tp: 19998.0000 - val_fp: 2.0000 - val_tn: 79998.0000 - val_fn: 2.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-43-44-batch-300000-400000
[INFO] processing batch 400000-500000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.7320e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.4380e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-43-44-batch-400000-500000
[INFO] processing batch 500000-600000/523604
[33m[INFO] loading file 45-45/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (523604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.3454e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.6468e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-45-batch-0-100000
[INFO] processing batch 100000-200000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.8982e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.0140e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-45-batch-100000-200000
[INFO] processing batch 200000-300000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.3869e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.1156e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-45-batch-200000-300000
[INFO] processing batch 300000-400000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.9093e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.7468e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-45-batch-300000-400000
[INFO] processing batch 400000-500000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.5931e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4690e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-44-45-batch-400000-500000
[INFO] processing batch 500000-600000/523604
[33m[INFO] loading file 46-46/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (523604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.4337e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.1203e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-45-46-batch-0-100000
[INFO] processing batch 100000-200000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.4061e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.7805e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-45-46-batch-100000-200000
[INFO] processing batch 200000-300000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.4380e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.1910e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-45-46-batch-200000-300000
[INFO] processing batch 300000-400000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.5638e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.3614e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-45-46-batch-300000-400000
[INFO] processing batch 400000-500000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.6274e-05 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.2853e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-45-46-batch-400000-500000
[INFO] processing batch 500000-600000/523604
[33m[INFO] loading file 47-47/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (523604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.0884e-05 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.0516e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-47-batch-0-100000
[INFO] processing batch 100000-200000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.9499e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.1365e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-47-batch-100000-200000
[INFO] processing batch 200000-300000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 7.6461e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.0077e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-47-batch-200000-300000
[INFO] processing batch 300000-400000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.5494e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.5325e-05 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-47-batch-300000-400000
[INFO] processing batch 400000-500000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.0671e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.8787e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-46-47-batch-400000-500000
[INFO] processing batch 500000-600000/523604
[33m[INFO] loading file 48-48/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (523604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.3736e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.3833e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-47-48-batch-0-100000
[INFO] processing batch 100000-200000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.2788e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.2163e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-47-48-batch-100000-200000
[INFO] processing batch 200000-300000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 1.2898e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.7004e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-47-48-batch-200000-300000
[INFO] processing batch 300000-400000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.9683e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.9234e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-47-48-batch-300000-400000
[INFO] processing batch 400000-500000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 5.2069e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.6997e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-47-48-batch-400000-500000
[INFO] processing batch 500000-600000/523604
[33m[INFO] loading file 49-49/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (523604, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.3349e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.2601e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-49-batch-0-100000
[INFO] processing batch 100000-200000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 9.6415e-05 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.8557e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-49-batch-100000-200000
[INFO] processing batch 200000-300000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.3737e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.3618e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-49-batch-200000-300000
[INFO] processing batch 300000-400000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 9.4099e-05 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.0320e-04 - val_tp: 19999.0000 - val_fp: 1.0000 - val_tn: 79999.0000 - val_fn: 1.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-49-batch-300000-400000
[INFO] processing batch 400000-500000/523604
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 3.4226e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.0400e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-48-49-batch-400000-500000
[INFO] processing batch 500000-600000/523604
[33m[INFO] loading file 50-50/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (373586, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type', 'unixtime'],
      dtype='object')
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/373586
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.6632e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.8529e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-49-50-batch-0-100000
[INFO] processing batch 100000-200000/373586
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 2.7160e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.5964e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-49-50-batch-100000-200000
[INFO] processing batch 200000-300000/373586
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] using LSTM layers
[INFO] fitting model
Train on 8000 samples, validate on 2000 samples
Epoch 1/1
 - 2s - loss: 4.4982e-05 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.8002e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
Using TensorFlow backend.
train.py:185: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version
of pandas will change to not sort by default.

To accept the future behavior, pass 'sort=False'.

To retain the current behavior and silence the warning, pass 'sort=True'.

  df = pd.concat(df_from_each_file, ignore_index=True)
[INFO] saving weights to checkpoints/lstm-epoch-003-files-49-50-batch-200000-300000
[INFO] processing batch 300000-400000/373586
[33m[LOSS] 2.8001944501738763e-06[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 2.8001944501738763e-06  <  0.001
[STOPPING EARLY]: currentLoss < min_delta => 2.8001944501738763e-06  <  0.001
--- 1657.7000324726105 seconds ---
2020-02-03 13:23:25.869867: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-02-03 13:23:25.869915: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-02-03 13:23:25.869921: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-02-03 13:23:26.361016: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-02-03 13:23:26.361041: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-02-03 13:23:26.361055: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (brussels): /proc/driver/nvidia/version does not exist
2020-02-03 13:23:26.361164: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-03 13:23:26.381802: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3312000000 Hz
2020-02-03 13:23:26.381985: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5d14840 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-03 13:23:26.381997: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-02-03 13:23:28.085247: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-03 13:23:28.088160: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 13:23:28.089451: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 13:23:28.099747: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-03 13:23:28.100424: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/categorical_crossentropy/weighted_loss/concat'.
2020-02-03 13:23:28.101419: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 13:23:28.102421: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-03 13:23:28.104845: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
=============================
        SCORING v0.3
=============================
Date: 2020-02-03 13:23:26.357727
[INFO] input_shape (10, 16)
[INFO] LSTM first and last layer neurons: 15
adding core layer 0
[INFO] created DNN
loading weights: checkpoints/*
loading file checkpoints/lstm-epoch-003-files-9-10-batch-400000-500000
[33m[INFO] model summary:[0m
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 10, 15)            1920      
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 10, 15)            0         
_________________________________________________________________
lstm_2 (LSTM)                (None, 10, 30)            5520      
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 10, 30)            0         
_________________________________________________________________
lstm_3 (LSTM)                (None, 10, 15)            2760      
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU)    (None, 10, 15)            0         
_________________________________________________________________
dense_1 (Dense)              (None, 10, 1)             16        
_________________________________________________________________
leaky_re_lu_4 (LeakyReLU)    (None, 10, 1)             0         
_________________________________________________________________
dense_2 (Dense)              (None, 10, 5)             10        
=================================================================
Total params: 10,226
Trainable params: 10,226
Non-trainable params: 0
_________________________________________________________________
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2015-12-31_130240_112.log.part10_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1364 (0.2728%)
[INFO] ** orig:[0:99.9992%,1:0.0008%]
[INFO] ** type:[0:99.9984%,1:0.0014%,2:0.0002%]
[INFO] ** i/f_name:[2:99.9984%,3:0.0016%]
[INFO] ** i/f_dir:[1:99.9986%,0:0.0014%]
[INFO] ** src:[22:38.114%,9:26.0964%,7:18.2424%,1:17.543%,14:0.0016%,11:0.0012%,10:0.001%,15:0.0004%]
[INFO] ** dst:[21:43.3686%,10:20.8412%,8:18.2422%,9:17.5434%,15:0.0016%,22:0.0014%,6:0.0006%,25:0.0004%,24:0.0002%,18:0.0002%,7:0.0002%]
[INFO] ** proto:[0:99.997%,1:0.0016%,2:0.0014%]
[INFO] ** appi_name:[21:99.9962%,30:0.0016%,26:0.0004%,0:0.0004%,31:0.0002%,27:0.0002%,24:0.0002%,22:0.0002%,16:0.0002%,15:0.0002%,5:0.0002%]
[INFO] ** proxy_src_ip:[18:38.114%,20:26.0964%,13:18.2424%,6:17.543%,17:0.0016%,10:0.0012%,11:0.001%,16:0.0004%]
[INFO] ** modbus_function_code:[0.02961:99.9962%,-33.760870000000004:0.0036%,0.9188299999999999:0.0002%]
[INFO] ** modbus_function_description:[7:49.9988%,11:49.9974%,0:0.0036%,15:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.0954%,1:20.841%,5:18.242%,4:17.5424%,2:17.2726%,0:0.0066%]
[INFO] ** service:[0.0048200000000000005:99.997%,-211.73542999999998:0.0016%,-186.44547:0.0004%,-211.08346:0.0004%,-186.43601999999998:0.0002%,-211.08818:0.0002%,-202.75898:0.0002%]
[INFO] ** s_port:[1.45442:26.0956%,-0.32151:20.8412%,-1.27613:18.242%,-0.23351:17.5424%,-0.33484:17.2728%,-71.33197:0.0016%,-9.54647:0.0008%,-0.24151:0.0006%,-64.19493:0.0004%,-1.02014:0.0004%,-71.14798:0.0004%,1.45709:0.0004%,-1.27347:0.0002%,1.46509:0.0002%,-68.79874000000001:0.0002%,-71.14931:0.0002%,-3.22139:0.0002%,-1.2708:0.0002%,1.47576:0.0002%]
[INFO] ** classification:[normal:79.7796%,Single Stage Single Point:20.2204%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 1 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  3.25232003326416
tp :  64261.0
fp :  35739.0
tn :  364261.0
fn :  35739.0
accuracy :  0.8570441603660583
precision :  0.6426100134849548
recall :  0.6426100134849548
auc :  0.7766312956809998

y_eval {0: 64261, 1: 35739}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64261     0     0     0     0]
 [35739     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[64261     0     0     0     0]
 [35739     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 1 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  3.220395012664795
tp :  64231.0
fp :  35769.0
tn :  364231.0
fn :  35769.0
accuracy :  0.8569240570068359
precision :  0.6423100233078003
recall :  0.6423100233078003
auc :  0.7764437198638916

y_eval {0: 64231, 1: 35769}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64231     0     0     0     0]
 [35769     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[128492      0      0      0      0]
 [ 71508      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.6325115677801194
tp :  70406.0
fp :  29594.0
tn :  370406.0
fn :  29594.0
accuracy :  0.8816237449645996
precision :  0.7040600180625916
recall :  0.7040600180625916
auc :  0.8150375485420227

y_eval {0: 70406, 1: 29594}
pred {0: 100000}
[INFO] confusion matrix for file 
[[70406     0     0     0     0]
 [29594     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[198898      0      0      0      0]
 [101102      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00012651462159119547
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[298898      0      0      0      0]
 [101102      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00016386893868912012
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[398898      0      0      0      0]
 [101102      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2015-12-31_181648_113.log.part08_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1370 (0.274%)
[INFO] ** orig:[0:99.9948%,2:0.0052%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.9948%,3:0.0052%]
[INFO] ** i/f_dir:[1:99.9948%,0:0.0052%]
[INFO] ** src:[22:38.4402%,9:25.9738%,7:18.1202%,1:17.4598%,21:0.0052%,2:0.0004%,15:0.0002%,11:0.0002%]
[INFO] ** dst:[21:43.345%,10:21.0682%,8:18.1202%,9:17.4594%,15:0.0052%,22:0.0012%,19:0.0004%,26:0.0002%,24:0.0002%]
[INFO] ** proto:[0:99.9946%,1:0.0052%,2:0.0002%]
[INFO] ** appi_name:[21:99.9942%,30:0.0052%,23:0.0002%,22:0.0002%,18:0.0002%]
[INFO] ** proxy_src_ip:[18:38.4402%,20:25.9738%,13:18.1202%,6:17.4598%,17:0.0052%,14:0.0004%,16:0.0002%,10:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9942%,-33.760870000000004:0.0058%]
[INFO] ** modbus_function_description:[7:49.998%,11:49.9962%,0:0.0058%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:25.9726%,1:21.0682%,5:18.1198%,4:17.459%,2:17.3718%,0:0.0086%]
[INFO] ** service:[0.0048200000000000005:99.9942%,-211.73542999999998:0.0052%,-211.07873999999998:0.0004%,-211.08818:0.0002%]
[INFO] ** s_port:[1.45442:25.973%,-0.32151:21.0682%,-1.27613:18.12%,-0.23351:17.4592%,-0.33484:17.372%,-71.33197:0.0052%,-0.24151:0.0006%,1.45709:0.0004%,8.38348:0.0004%,-1.27347:0.0002%,1.46509:0.0002%,1.47576:0.0002%,-71.14931:0.0002%,-1.02014:0.0002%]
[INFO] ** classification:[normal:80.1196%,Multi Stage Multi Point:14.47%,Single Stage Multi Point:5.4104%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  4.360322913522751
tp :  72948.0
fp :  27052.0
tn :  372948.0
fn :  27052.0
accuracy :  0.8917920589447021
precision :  0.7294800281524658
recall :  0.7294800281524658
auc :  0.8309250473976135

y_eval {0: 72948, 2: 27052}
pred {0: 100000}
[INFO] confusion matrix for file 
[[72948     0     0     0     0]
 [    0     0     0     0     0]
 [27052     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[471846      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  8.743544975295663e-05
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[571846      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00010659775182139129
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[671846      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  4.0667197094534755
tp :  74770.0
fp :  25230.0
tn :  374770.0
fn :  25230.0
accuracy :  0.8990797400474548
precision :  0.7476999759674072
recall :  0.7476999759674072
auc :  0.8421977758407593

y_eval {0: 74770, 4: 25230}
pred {0: 100000}
[INFO] confusion matrix for file 
[[74770     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [25230     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[746616      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [ 25230      0      0      0      0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 4 0 ... 4 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  7.594987942504883
tp :  52880.0
fp :  47120.0
tn :  352880.0
fn :  47120.0
accuracy :  0.8115200996398926
precision :  0.5288000106811523
recall :  0.5288000106811523
auc :  0.7046506404876709

y_eval {0: 52880, 4: 47120}
pred {0: 100000}
[INFO] confusion matrix for file 
[[52880     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [47120     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[799496      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [ 72350      0      0      0      0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2015-12-31_181648_113.log.part09_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1359 (0.2718%)
[INFO] ** orig:[0:99.9966%,2:0.0034%]
[INFO] ** type:[0:99.9996%,1:0.0004%]
[INFO] ** i/f_name:[2:99.9938%,3:0.0062%]
[INFO] ** i/f_dir:[1:99.9942%,0:0.0058%]
[INFO] ** src:[22:38.4204%,9:25.9634%,7:18.123%,1:17.486%,21:0.0034%,14:0.0028%,15:0.0006%,2:0.0004%]
[INFO] ** dst:[21:43.3316%,10:21.0518%,8:18.123%,9:17.486%,15:0.0062%,22:0.0008%,24:0.0002%,18:0.0002%,7:0.0002%]
[INFO] ** proto:[0:99.9934%,1:0.0062%,2:0.0004%]
[INFO] ** appi_name:[21:99.9934%,30:0.0062%,31:0.0002%,27:0.0002%]
[INFO] ** proxy_src_ip:[18:38.4204%,20:25.9634%,13:18.123%,6:17.486%,17:0.0062%,16:0.0006%,14:0.0004%]
[INFO] ** modbus_function_code:[0.02961:99.9934%,-33.760870000000004:0.0066%]
[INFO] ** modbus_function_description:[7:49.9972%,11:49.9962%,0:0.0066%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:25.9624%,1:21.0518%,5:18.1226%,4:17.4856%,2:17.3686%,0:0.009%]
[INFO] ** service:[0.0048200000000000005:99.9934%,-211.73542999999998:0.0062%,-186.43601999999998:0.0002%,-202.75898:0.0002%]
[INFO] ** s_port:[1.45442:25.9628%,-0.32151:21.0518%,-1.27613:18.1226%,-0.23351:17.4858%,-0.33484:17.3686%,-71.33197:0.0062%,-1.02014:0.0006%,-1.27347:0.0002%,11.862:0.0002%,1.45709:0.0002%,-0.24950999999999998:0.0002%,1.46509:0.0002%,1.47576:0.0002%,13.431270000000001:0.0002%,-1.2708:0.0002%]
[INFO] ** classification:[normal:73.9096%,Multi Stage Multi Point:26.0904%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 4 0 ... 4 4 4] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  7.579601599121093
tp :  52975.0
fp :  47025.0
tn :  352975.0
fn :  47025.0
accuracy :  0.8118999004364014
precision :  0.5297499895095825
recall :  0.5297499895095825
auc :  0.7060937285423279

y_eval {0: 52975, 4: 47025}
pred {0: 100000}
[INFO] confusion matrix for file 
[[52975     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [47025     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[852471      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [119375      0      0      0      0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [4 0 4 ... 0 4 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  7.570907634735107
tp :  53029.0
fp :  46971.0
tn :  353029.0
fn :  46971.0
accuracy :  0.8121159672737122
precision :  0.5302900075912476
recall :  0.5302900075912476
auc :  0.7064312696456909

y_eval {0: 53029, 4: 46971}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53029     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [46971     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[905500      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [166346      0      0      0      0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [4 4 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  5.876108306956897
tp :  63544.0
fp :  36456.0
tn :  363544.0
fn :  36456.0
accuracy :  0.8541760444641113
precision :  0.6354399919509888
recall :  0.6354399919509888
auc :  0.7721499800682068

y_eval {0: 63544, 4: 36456}
pred {0: 100000}
[INFO] confusion matrix for file 
[[63544     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [36456     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[969044      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [202802      0      0      0      0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00012930047237314285
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1069044       0       0       0       0]
 [ 101102       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00016812668105121702
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1169044       0       0       0       0]
 [ 101102       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2015-12-31_233049_114.log.part11_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1361 (0.2722%)
[INFO] ** orig:[0:99.9996%,2:0.0004%]
[INFO] ** type:[0:99.9994%,1:0.0004%,2:0.0002%]
[INFO] ** i/f_name:[2:99.9968%,3:0.0032%]
[INFO] ** i/f_dir:[1:99.9972%,0:0.0028%]
[INFO] ** src:[22:38.4512%,9:25.9642%,7:18.089%,1:17.4908%,14:0.0028%,11:0.0008%,21:0.0004%,15:0.0004%,2:0.0004%]
[INFO] ** dst:[21:43.3436%,10:21.0714%,8:18.0896%,9:17.4906%,15:0.0032%,22:0.001%,24:0.0002%,18:0.0002%,7:0.0002%]
[INFO] ** proto:[0:99.9964%,1:0.0032%,2:0.0004%]
[INFO] ** appi_name:[21:99.9956%,30:0.0032%,31:0.0002%,27:0.0002%,24:0.0002%,16:0.0002%,15:0.0002%,5:0.0002%]
[INFO] ** proxy_src_ip:[18:38.4512%,20:25.9642%,13:18.089%,6:17.4908%,17:0.0032%,10:0.0008%,16:0.0004%,14:0.0004%]
[INFO] ** modbus_function_code:[0.02961:99.9956%,-33.760870000000004:0.0042%,0.9188299999999999:0.0002%]
[INFO] ** modbus_function_description:[7:49.999%,11:49.9966%,0:0.0042%,15:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:25.9632%,1:21.0714%,5:18.0886%,4:17.4902%,2:17.3796%,0:0.007%]
[INFO] ** service:[0.0048200000000000005:99.9964%,-211.73542999999998:0.0032%,-186.43601999999998:0.0002%,-202.75898:0.0002%]
[INFO] ** s_port:[1.45442:25.9636%,-0.32151:21.0714%,-1.27613:18.0886%,-0.23351:17.4904%,-0.33484:17.3798%,-71.33197:0.0032%,6.286230000000001:0.0008%,1.45709:0.0004%,-1.02014:0.0004%,-1.27347:0.0002%,11.862:0.0002%,-0.24950999999999998:0.0002%,1.47576:0.0002%,-0.24151:0.0002%,13.431270000000001:0.0002%,-1.2708:0.0002%]
[INFO] ** classification:[normal:95.0874%,Single Stage Single Point:4.9126%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  7.844014129368589e-05
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1269044       0       0       0       0]
 [ 101102       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  8.83877829881385e-05
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1369044       0       0       0       0]
 [ 101102       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.6665663651422598
tp :  92639.0
fp :  7361.0
tn :  392639.0
fn :  7361.0
accuracy :  0.9705557823181152
precision :  0.9263899922370911
recall :  0.9263899922370911
auc :  0.9539936780929565

y_eval {0: 92639, 1: 7361}
pred {0: 100000}
[INFO] confusion matrix for file 
[[92639     0     0     0     0]
 [ 7361     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1461683       0       0       0       0]
 [ 108463       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.5407689183246345
tp :  82798.0
fp :  17202.0
tn :  382798.0
fn :  17202.0
accuracy :  0.9311922788619995
precision :  0.8279799818992615
recall :  0.8279799818992615
auc :  0.8924097418785095

y_eval {0: 82798, 1: 17202}
pred {0: 100000}
[INFO] confusion matrix for file 
[[82798     0     0     0     0]
 [17202     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1544481       0       0       0       0]
 [ 125665       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.0001674129912396893
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1644481       0       0       0       0]
 [ 125665       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-01_151435_117.log.part03_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1365 (0.273%)
[INFO] ** orig:[0:99.9976%,2:0.0024%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.9966%,3:0.0034%]
[INFO] ** i/f_dir:[1:99.9966%,0:0.0034%]
[INFO] ** src:[22:38.1462%,9:26.099%,7:18.1904%,1:17.5592%,21:0.0028%,14:0.001%,3:0.0006%,15:0.0004%,2:0.0004%]
[INFO] ** dst:[21:43.376%,10:20.8688%,8:18.1902%,9:17.5592%,15:0.0034%,22:0.0008%,18:0.0004%,16:0.0004%,6:0.0004%,24:0.0002%,2:0.0002%]
[INFO] ** proto:[0:99.9958%,1:0.0034%,2:0.0008%]
[INFO] ** appi_name:[21:99.9952%,30:0.0034%,7:0.0006%,31:0.0004%,26:0.0002%,22:0.0002%]
[INFO] ** proxy_src_ip:[18:38.1462%,20:26.099%,13:18.1904%,6:17.5592%,17:0.0034%,1:0.0006%,16:0.0004%,14:0.0004%,7:0.0004%]
[INFO] ** modbus_function_code:[0.02961:99.9952%,-33.760870000000004:0.0048%]
[INFO] ** modbus_function_description:[7:49.9978%,11:49.9974%,0:0.0048%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.0982%,1:20.8688%,5:18.19%,4:17.5588%,2:17.2772%,0:0.007%]
[INFO] ** service:[0.0048200000000000005:99.9952%,-211.73542999999998:0.0034%,-211.09762999999998:0.0006%,-186.43601999999998:0.0004%,-211.08346:0.0002%,-211.08818:0.0002%]
[INFO] ** s_port:[1.45442:26.0986%,-0.32151:20.8688%,-1.27613:18.1902%,-0.23351:17.559%,-0.33484:17.2774%,-71.33197:0.0034%,-1.02014:0.0004%,-71.14931:0.0002%,-0.24151:0.0002%,4.42897:0.0002%,-71.14798:0.0002%,1.47576:0.0002%,-1.27347:0.0002%,-0.78282:0.0002%,-2.92807:0.0002%,-4.88132:0.0002%,1.45709:0.0002%,9.18344:0.0002%]
[INFO] ** classification:[normal:84.2104%,Single Stage Single Point:15.7896%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.6639115612225956
tp :  70708.0
fp :  29292.0
tn :  370708.0
fn :  29292.0
accuracy :  0.8828315734863281
precision :  0.7070800065994263
recall :  0.7070800065994263
auc :  0.8169249892234802

y_eval {0: 70708, 1: 29292}
pred {0: 100000}
[INFO] confusion matrix for file 
[[70708     0     0     0     0]
 [29292     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1715189       0       0       0       0]
 [ 154957       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 1 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  3.2274133811950683
tp :  64215.0
fp :  35785.0
tn :  364215.0
fn :  35785.0
accuracy :  0.8568599820137024
precision :  0.6421499848365784
recall :  0.6421499848365784
auc :  0.7763437032699585

y_eval {0: 64215, 1: 35785}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64215     0     0     0     0]
 [35785     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1779404       0       0       0       0]
 [ 190742       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.2377876761095832
tp :  86129.0
fp :  13871.0
tn :  386129.0
fn :  13871.0
accuracy :  0.944516122341156
precision :  0.8612899780273438
recall :  0.8612899780273438
auc :  0.9133062362670898

y_eval {0: 86129, 1: 13871}
pred {0: 100000}
[INFO] confusion matrix for file 
[[86129     0     0     0     0]
 [13871     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1865533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00012901163062779234
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1965533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.000167444126191549
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2065533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-01_151435_117.log.part12_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1377 (0.2754%)
[INFO] ** orig:[0:99.9964%,2:0.0036%]
[INFO] ** type:[0:99.9994%,1:0.0004%,2:0.0002%]
[INFO] ** i/f_name:[2:99.996%,3:0.004%]
[INFO] ** i/f_dir:[1:99.9964%,0:0.0036%]
[INFO] ** src:[22:38.049%,9:26.1306%,7:18.2264%,1:17.587%,21:0.0036%,11:0.0014%,10:0.001%,14:0.0004%,15:0.0002%,8:0.0002%,4:0.0002%]
[INFO] ** dst:[21:43.355%,10:20.8256%,8:18.226%,9:17.5868%,15:0.004%,6:0.001%,22:0.0006%,25:0.0004%,24:0.0002%,18:0.0002%,7:0.0002%]
[INFO] ** proto:[0:99.9942%,1:0.004%,2:0.0018%]
[INFO] ** appi_name:[21:99.9932%,30:0.004%,22:0.0006%,26:0.0004%,0:0.0004%,31:0.0002%,27:0.0002%,24:0.0002%,16:0.0002%,15:0.0002%,5:0.0002%,3:0.0002%]
[INFO] ** proxy_src_ip:[18:38.049%,20:26.1306%,13:18.2264%,6:17.587%,17:0.004%,10:0.0014%,11:0.001%,21:0.0002%,16:0.0002%,0:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9932%,-33.760870000000004:0.0066%,0.9188299999999999:0.0002%]
[INFO] ** modbus_function_description:[7:49.9974%,11:49.9958%,0:0.0066%,15:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.13%,1:20.8244%,5:18.2258%,4:17.5864%,2:17.2242%,0:0.0092%]
[INFO] ** service:[0.0048200000000000005:99.9942%,-211.73542999999998:0.004%,-211.08818:0.0006%,-186.44547:0.0004%,-211.08346:0.0004%,-186.43601999999998:0.0002%,-202.75898:0.0002%]
[INFO] ** s_port:[1.45442:26.1304%,-0.32151:20.8246%,-1.27613:18.226%,-0.23351:17.5866%,-0.33484:17.2244%,-71.33197:0.004%,-6.49859:0.0008%,-71.14931:0.0006%,-0.24151:0.0004%,-64.19493:0.0004%,-71.14798:0.0004%,-68.79874000000001:0.0002%,-1.81611:0.0002%,1.47576:0.0002%,-1.27347:0.0002%,-61.95768:0.0002%,-1.02014:0.0002%,-1.2708:0.0002%]
[INFO] ** classification:[normal:97.1716%,Single Stage Single Point:2.8284%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  7.81211628811434e-05
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2165533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  8.94515582243912e-05
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2265533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00010832024296978488
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2365533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00013326948971953244
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2465533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 1 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.5076176574554294
tp :  85858.0
fp :  14142.0
tn :  385858.0
fn :  14142.0
accuracy :  0.9434319734573364
precision :  0.8585799932479858
recall :  0.8585799932479858
auc :  0.9113292694091797

y_eval {0: 85858, 1: 14142}
pred {0: 100000}
[INFO] confusion matrix for file 
[[85858     0     0     0     0]
 [14142     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2551391       0       0       0       0]
 [ 218755       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-01_151435_117.log.part13_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1365 (0.273%)
[INFO] ** orig:[0:99.9986%,2:0.0014%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.998%,3:0.002%]
[INFO] ** i/f_dir:[1:99.998%,0:0.002%]
[INFO] ** src:[22:38.1186%,9:26.0918%,7:18.2288%,1:17.558%,21:0.0018%,14:0.0006%,15:0.0004%]
[INFO] ** dst:[21:43.3702%,10:20.8392%,8:18.2288%,9:17.5578%,15:0.002%,22:0.0012%,24:0.0004%,18:0.0002%,6:0.0002%]
[INFO] ** proto:[0:99.9976%,1:0.002%,2:0.0004%]
[INFO] ** appi_name:[21:99.9976%,30:0.002%,31:0.0002%,22:0.0002%]
[INFO] ** proxy_src_ip:[18:38.1186%,20:26.0918%,13:18.2288%,6:17.558%,17:0.002%,16:0.0004%,7:0.0004%]
[INFO] ** modbus_function_code:[0.02961:99.9976%,-33.760870000000004:0.0024%]
[INFO] ** modbus_function_description:[7:49.9998%,11:49.9978%,0:0.0024%]
[INFO] ** modbus_transaction_id:65534 (13.1068%)
[INFO] ** scada_tag:[3:26.0906%,1:20.839%,5:18.2282%,4:17.5572%,2:17.2792%,0:0.0058%]
[INFO] ** service:[0.0048200000000000005:99.9976%,-211.73542999999998:0.002%,-186.43601999999998:0.0002%,-211.08818:0.0002%]
[INFO] ** s_port:[1.45442:26.0908%,-0.32151:20.8392%,-1.27613:18.2284%,-0.23351:17.5576%,-0.33484:17.2794%,-71.33197:0.002%,1.45709:0.0006%,-1.27347:0.0004%,-1.02014:0.0004%,-0.24950999999999998:0.0002%,1.46509:0.0002%,1.47576:0.0002%,4.42897:0.0002%,-0.24151:0.0002%,-71.14931:0.0002%]
[INFO] ** classification:[normal:87.5394%,Single Stage Single Point:12.4606%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 1 0 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  5.128791603851318
tp :  53028.0
fp :  46972.0
tn :  353028.0
fn :  46972.0
accuracy :  0.8121117949485779
precision :  0.5302799940109253
recall :  0.5302799940109253
auc :  0.7064250111579895

y_eval {0: 53028, 1: 46972}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53028     0     0     0     0]
 [46972     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2604419       0       0       0       0]
 [ 265727       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.6713641466681612
tp :  84669.0
fp :  15331.0
tn :  384669.0
fn :  15331.0
accuracy :  0.9386759996414185
precision :  0.8466899991035461
recall :  0.8466899991035461
auc :  0.904181182384491

y_eval {0: 84669, 1: 15331}
pred {0: 100000}
[INFO] confusion matrix for file 
[[84669     0     0     0     0]
 [15331     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2689088       0       0       0       0]
 [ 281058       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00010547649215441197
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2789088       0       0       0       0]
 [ 281058       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00012958252178505063
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2889088       0       0       0       0]
 [ 281058       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00016764043413568288
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2989088       0       0       0       0]
 [ 281058       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-01_203011_118.log.part06_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1366 (0.2732%)
[INFO] ** orig:[0:99.9988%,2:0.0008%,1:0.0004%]
[INFO] ** type:[0:99.9986%,1:0.001%,2:0.0004%]
[INFO] ** i/f_name:[2:99.998%,3:0.002%]
[INFO] ** i/f_dir:[1:99.9982%,0:0.0018%]
[INFO] ** src:[22:38.138%,9:26.0904%,7:18.1762%,1:17.5892%,10:0.0018%,11:0.0016%,14:0.0012%,21:0.0008%,15:0.0006%,4:0.0002%]
[INFO] ** dst:[21:43.3838%,10:20.845%,8:18.1758%,9:17.589%,15:0.002%,22:0.0014%,6:0.0014%,25:0.0004%,24:0.0004%,18:0.0004%,7:0.0004%]
[INFO] ** proto:[0:99.9954%,2:0.0026%,1:0.002%]
[INFO] ** appi_name:[21:99.9944%,30:0.002%,26:0.0008%,22:0.0006%,31:0.0004%,27:0.0004%,15:0.0004%,0:0.0004%,24:0.0002%,16:0.0002%,5:0.0002%]
[INFO] ** proxy_src_ip:[18:38.138%,20:26.0904%,13:18.1762%,6:17.5892%,17:0.002%,11:0.0018%,10:0.0016%,16:0.0006%,21:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9944%,-33.760870000000004:0.0052%,0.9188299999999999:0.0004%]
[INFO] ** modbus_function_description:[7:49.998%,11:49.9964%,0:0.0052%,15:0.0004%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.0894%,1:20.8438%,5:18.1758%,4:17.5888%,2:17.294%,0:0.0082%]
[INFO] ** service:[0.0048200000000000005:99.9954%,-211.73542999999998:0.002%,-211.08346:0.0008%,-211.08818:0.0006%,-186.44547:0.0004%,-186.43601999999998:0.0004%,-202.75898:0.0004%]
[INFO] ** s_port:[1.45442:26.0898%,-0.32151:20.844%,-1.27613:18.1758%,-0.23351:17.589%,-0.33484:17.294%,-71.33197:0.002%,-6.46392:0.0008%,-71.14798:0.0008%,1.45709:0.0006%,-71.14931:0.0006%,-1.02014:0.0006%,-1.27347:0.0004%,-68.79874000000001:0.0004%,-64.19493:0.0004%,-1.81611:0.0004%,-6.49859:0.0002%,-0.24151:0.0002%]
[INFO] ** classification:[normal:90.7904%,Single Stage Multi Point:5.7378%,Single Stage Single Point:3.4718%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  7.904274075990542e-05
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3089088       0       0       0       0]
 [ 281058       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  8.940723898122087e-05
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3189088       0       0       0       0]
 [ 281058       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00010670751052675769
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3289088       0       0       0       0]
 [ 281058       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.8737760288980208
tp :  82641.0
fp :  17359.0
tn :  382641.0
fn :  17359.0
accuracy :  0.9305639863014221
precision :  0.8264099955558777
recall :  0.8264099955558777
auc :  0.8914299011230469

y_eval {0: 82641, 1: 17359}
pred {0: 100000}
[INFO] confusion matrix for file 
[[82641     0     0     0     0]
 [17359     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[3371729       0       0       0       0]
 [ 298417       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 2 2] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  4.624278609803785
tp :  71311.0
fp :  28689.0
tn :  371311.0
fn :  28689.0
accuracy :  0.8852440714836121
precision :  0.7131100296974182
recall :  0.7131100296974182
auc :  0.8200352787971497

y_eval {0: 71311, 2: 28689}
pred {0: 100000}
[INFO] confusion matrix for file 
[[71311     0     0     0     0]
 [    0     0     0     0     0]
 [28689     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[3443040       0       0       0       0]
 [ 298417       0       0       0       0]
 [  55741       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-01_203011_118.log.part07_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1366 (0.2732%)
[INFO] ** orig:[0:99.9996%,2:0.0004%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.9994%,3:0.0006%]
[INFO] ** i/f_dir:[1:99.9994%,0:0.0006%]
[INFO] ** src:[22:38.0718%,9:26.1174%,7:18.2344%,1:17.5754%,21:0.0008%,14:0.0002%]
[INFO] ** dst:[21:43.3758%,10:20.813%,8:18.2342%,9:17.5754%,15:0.0006%,22:0.0004%,24:0.0002%,18:0.0002%,6:0.0002%]
[INFO] ** proto:[0:99.999%,1:0.0006%,2:0.0004%]
[INFO] ** appi_name:[21:99.999%,30:0.0006%,31:0.0002%,22:0.0002%]
[INFO] ** proxy_src_ip:[18:38.0718%,20:26.1174%,13:18.2344%,6:17.5754%,17:0.0006%,7:0.0004%]
[INFO] ** modbus_function_code:[0.02961:99.999%,-33.760870000000004:0.001%]
[INFO] ** modbus_function_description:[7:49.9996%,11:49.9994%,0:0.001%]
[INFO] ** modbus_transaction_id:65301 (13.0602%)
[INFO] ** scada_tag:[3:26.1164%,1:20.813%,5:18.2338%,4:17.575%,2:17.2586%,0:0.0032%]
[INFO] ** service:[0.0048200000000000005:99.999%,-211.73542999999998:0.0006%,-186.43601999999998:0.0002%,-211.08818:0.0002%]
[INFO] ** s_port:[1.45442:26.1168%,-0.32151:20.813%,-1.27613:18.234%,-0.23351:17.5752%,-0.33484:17.2588%,-71.33197:0.0006%,-1.27347:0.0002%,1.45709:0.0002%,1.46509:0.0002%,1.47576:0.0002%,4.42897:0.0002%,-0.24151:0.0002%,-71.14931:0.0002%,-1.2708:0.0002%]
[INFO] ** classification:[normal:89.2092%,Single Stage Multi Point:10.7908%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [2 0 0 ... 2 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  7.5712215576171875
tp :  53027.0
fp :  46973.0
tn :  353027.0
fn :  46973.0
accuracy :  0.8121080994606018
precision :  0.530269980430603
recall :  0.530269980430603
auc :  0.7064187526702881

y_eval {0: 53027, 2: 46973}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53027     0     0     0     0]
 [    0     0     0     0     0]
 [46973     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[3496067       0       0       0       0]
 [ 298417       0       0       0       0]
 [ 102714       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 2 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.1252910187054659
tp :  93019.0
fp :  6981.0
tn :  393019.0
fn :  6981.0
accuracy :  0.9720759987831116
precision :  0.9301900267601013
recall :  0.9301900267601013
auc :  0.9563688039779663

y_eval {0: 93019, 2: 6981}
pred {0: 100000}
[INFO] confusion matrix for file 
[[93019     0     0     0     0]
 [    0     0     0     0     0]
 [ 6981     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[3589086       0       0       0       0]
 [ 298417       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00010527226270642132
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3689086       0       0       0       0]
 [ 298417       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00013279674558434634
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3789086       0       0       0       0]
 [ 298417       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00017150851376354694
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3889086       0       0       0       0]
 [ 298417       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-02_014558_119.log.part06_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1366 (0.2732%)
[INFO] ** orig:[0:99.997%,2:0.003%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.9964%,3:0.0036%]
[INFO] ** i/f_dir:[1:99.9964%,0:0.0036%]
[INFO] ** src:[22:38.0288%,9:26.1242%,7:18.2114%,1:17.6294%,21:0.003%,2:0.0008%,14:0.0006%,3:0.0006%,15:0.0004%,4:0.0004%,11:0.0002%,8:0.0002%]
[INFO] ** dst:[21:43.357%,10:20.7952%,8:18.2116%,9:17.629%,15:0.0036%,22:0.0012%,16:0.0008%,19:0.0004%,17:0.0004%,6:0.0004%,26:0.0002%,24:0.0002%]
[INFO] ** proto:[0:99.9958%,1:0.0036%,2:0.0006%]
[INFO] ** appi_name:[21:99.9942%,30:0.0036%,17:0.0008%,22:0.0004%,28:0.0002%,26:0.0002%,23:0.0002%,18:0.0002%,7:0.0002%]
[INFO] ** proxy_src_ip:[18:38.0288%,20:26.1242%,13:18.2114%,6:17.6294%,17:0.0036%,14:0.0008%,1:0.0006%,21:0.0004%,16:0.0004%,10:0.0002%,0:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9942%,-33.760870000000004:0.0058%]
[INFO] ** modbus_function_description:[7:49.9974%,11:49.9968%,0:0.0058%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.123%,1:20.7952%,5:18.211%,4:17.6288%,2:17.2336%,0:0.0084%]
[INFO] ** service:[0.0048200000000000005:99.9942%,-211.73542999999998:0.0036%,-205.44247:0.0008%,-211.07873999999998:0.0004%,-211.08818:0.0004%,-211.09762999999998:0.0002%,-211.08346:0.0002%,-185.9872:0.0002%]
[INFO] ** s_port:[1.45442:26.1234%,-0.32151:20.7952%,-1.27613:18.2112%,-0.23351:17.629%,-0.33484:17.2336%,-71.33197:0.0036%,1.45709:0.0006%,9.89942:0.0004%,-1.02014:0.0004%,-71.14931:0.0004%,-58.035180000000004:0.0002%,-5.1466400000000005:0.0002%,-0.24151:0.0002%,-5.08665:0.0002%,1.46509:0.0002%,-71.14798:0.0002%,-0.24950999999999998:0.0002%,2.05573:0.0002%,-43.76509:0.0002%,-1.27347:0.0002%,-58.032509999999995:0.0002%]
[INFO] ** classification:[normal:81.41%,Single Stage Single Point:18.59%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 1 0 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  3.5596808170077625
tp :  67398.0
fp :  32602.0
tn :  367398.0
fn :  32602.0
accuracy :  0.869592010974884
precision :  0.6739799976348877
recall :  0.6739799976348877
auc :  0.7962374687194824

y_eval {0: 67398, 1: 32602}
pred {0: 100000}
[INFO] confusion matrix for file 
[[67398     0     0     0     0]
 [32602     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[3956484       0       0       0       0]
 [ 331019       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 1 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  5.109266693115234
tp :  53052.0
fp :  46948.0
tn :  353052.0
fn :  46948.0
accuracy :  0.812208354473114
precision :  0.5305200219154358
recall :  0.5305200219154358
auc :  0.7065749764442444

y_eval {0: 53052, 1: 46948}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53052     0     0     0     0]
 [46948     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[4009536       0       0       0       0]
 [ 377967       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.4551515570885618
tp :  86600.0
fp :  13400.0
tn :  386600.0
fn :  13400.0
accuracy :  0.946399986743927
precision :  0.8659999966621399
recall :  0.8659999966621399
auc :  0.9162499308586121

y_eval {0: 86600, 1: 13400}
pred {0: 100000}
[INFO] confusion matrix for file 
[[86600     0     0     0     0]
 [13400     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[4096136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.0001282945387298241
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4196136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00017107136365957559
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4296136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-02_121729_121.log.part12_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1368 (0.2736%)
[INFO] ** orig:[0:99.9986%,1:0.0008%,2:0.0006%]
[INFO] ** type:[0:99.9984%,1:0.0014%,2:0.0002%]
[INFO] ** i/f_name:[2:99.9978%,3:0.0022%]
[INFO] ** i/f_dir:[1:99.998%,0:0.002%]
[INFO] ** src:[22:38.1136%,9:26.1176%,7:18.2158%,1:17.5472%,14:0.0016%,11:0.0014%,10:0.001%,21:0.0006%,15:0.0004%,2:0.0004%,4:0.0002%,3:0.0002%]
[INFO] ** dst:[21:43.4022%,10:20.8284%,8:18.2156%,9:17.547%,15:0.0022%,22:0.002%,6:0.0008%,26:0.0004%,25:0.0004%,19:0.0004%,24:0.0002%,18:0.0002%,7:0.0002%]
[INFO] ** proto:[0:99.996%,1:0.0022%,2:0.0018%]
[INFO] ** appi_name:[21:99.9946%,30:0.0022%,22:0.0006%,26:0.0004%,0:0.0004%,31:0.0002%,27:0.0002%,24:0.0002%,23:0.0002%,18:0.0002%,16:0.0002%,15:0.0002%,14:0.0002%,5:0.0002%]
[INFO] ** proxy_src_ip:[18:38.1136%,20:26.1176%,13:18.2158%,6:17.5472%,17:0.0022%,10:0.0014%,11:0.001%,16:0.0004%,14:0.0004%,21:0.0002%,1:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9946%,-33.760870000000004:0.0052%,0.9188299999999999:0.0002%]
[INFO] ** modbus_function_description:[7:49.9984%,11:49.9962%,0:0.0052%,15:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.1164%,1:20.8284%,5:18.2154%,4:17.5466%,2:17.285%,0:0.0082%]
[INFO] ** service:[0.0048200000000000005:99.9954%,-211.73542999999998:0.0022%,-211.08818:0.0006%,-186.44547:0.0004%,-211.08346:0.0004%,-211.07873999999998:0.0004%,-186.42657:0.0002%,-186.43601999999998:0.0002%,-202.75898:0.0002%]
[INFO] ** s_port:[1.45442:26.1168%,-0.32151:20.8284%,-1.27613:18.2154%,-0.23351:17.5468%,-0.33484:17.2852%,-71.33197:0.0022%,-10.59042:0.0008%,-71.14931:0.0006%,-64.19493:0.0004%,-1.02014:0.0004%,-0.24151:0.0004%,-71.14798:0.0004%,1.45709:0.0004%,10.54739:0.0004%,1.47576:0.0002%,1.46509:0.0002%,-1.27347:0.0002%,-68.79874000000001:0.0002%,13.34061:0.0002%,-1.2708:0.0002%,15.264529999999999:0.0002%]
[INFO] ** classification:[normal:99.9996%,Single Stage Multi Point:0.0004%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  7.886732844635844e-05
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4396136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  8.9283989102114e-05
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4496136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.0001033910790225491
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4596136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.0001313051915494725
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4696136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.0004882450353121385
tp :  99998.0
fp :  2.0
tn :  399998.0
fn :  2.0
accuracy :  0.9999920129776001
precision :  0.9999799728393555
recall :  0.9999799728393555
auc :  0.9999874830245972

y_eval {0: 99998, 2: 2}
pred {0: 100000}
[INFO] confusion matrix for file 
[[99998     0     0     0     0]
 [    0     0     0     0     0]
 [    2     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[4796134       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109697       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-02_121729_121.log.part13_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1368 (0.2736%)
[INFO] ** orig:[0:99.9996%,2:0.0004%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.9994%,3:0.0006%]
[INFO] ** i/f_dir:[1:99.9994%,0:0.0006%]
[INFO] ** src:[22:38.162%,9:26.1664%,7:18.0742%,1:17.5958%,21:0.0008%,17:0.0002%,15:0.0002%,14:0.0002%,8:0.0002%]
[INFO] ** dst:[21:43.4352%,10:20.8932%,8:18.0744%,9:17.5952%,22:0.0006%,18:0.0006%,15:0.0006%,6:0.0002%]
[INFO] ** proto:[0:99.9986%,2:0.0008%,1:0.0006%]
[INFO] ** appi_name:[21:99.9986%,31:0.0006%,30:0.0006%,22:0.0002%]
[INFO] ** proxy_src_ip:[18:38.162%,20:26.1664%,13:18.0742%,6:17.5958%,17:0.0006%,7:0.0004%,16:0.0002%,2:0.0002%,0:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9986%,-33.760870000000004:0.0014%]
[INFO] ** modbus_function_description:[7:49.9998%,11:49.9988%,0:0.0014%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.166%,1:20.893%,5:18.0738%,4:17.5948%,2:17.2688%,0:0.0036%]
[INFO] ** service:[0.0048200000000000005:99.9986%,-211.73542999999998:0.0006%,-186.43601999999998:0.0006%,-211.08818:0.0002%]
[INFO] ** s_port:[1.45442:26.1662%,-0.32151:20.8932%,-1.27613:18.074%,-0.23351:17.5952%,-0.33484:17.2688%,-71.33197:0.0006%,15.43653:0.0004%,-0.24151:0.0004%,-0.24950999999999998:0.0002%,1.46509:0.0002%,4.42897:0.0002%,-71.14931:0.0002%,-1.02014:0.0002%,-1.2708:0.0002%]
[INFO] ** classification:[normal:92.8338%,Multi Stage Single Point:7.1662%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  7.788178049959243e-05
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4896134       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109697       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.8159391415000543
tp :  88734.0
fp :  11266.0
tn :  388734.0
fn :  11266.0
accuracy :  0.954935610294342
precision :  0.8873400092124939
recall :  0.8873400092124939
auc :  0.9295876026153564

y_eval {0: 88734, 3: 11266}
pred {0: 100000}
[INFO] confusion matrix for file 
[[88734     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [11266     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[4984868       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109697       0       0       0       0]
 [  11266       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.2194277609751094
tp :  92435.0
fp :  7565.0
tn :  392435.0
fn :  7565.0
accuracy :  0.9697398543357849
precision :  0.9243500232696533
recall :  0.9243500232696533
auc :  0.9527187943458557

y_eval {0: 92435, 3: 7565}
pred {0: 100000}
[INFO] confusion matrix for file 
[[92435     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [ 7565     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[5077303       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109697       0       0       0       0]
 [  18831       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00012985246451571584
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5177303       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109697       0       0       0       0]
 [  18831       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.7402132094968574
tp :  83000.0
fp :  17000.0
tn :  383000.0
fn :  17000.0
accuracy :  0.9319998621940613
precision :  0.8299999833106995
recall :  0.8299999833106995
auc :  0.8933857679367065

y_eval {0: 83000, 3: 17000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[83000     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [17000     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[5260303       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109697       0       0       0       0]
 [  35831       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-02_121729_121.log.part14_sorted-labeled.csv
[INFO] process dataset, shape: (439824, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (439824, 17)

[INFO] analyzing data
[INFO] 439824 rows
[INFO] ** unixtime:1201 (0.27306%)
[INFO] ** orig:[0:99.99955%,2:0.00045%]
[INFO] ** type:[0:99.99977%,1:0.00023%]
[INFO] ** i/f_name:[2:99.99864%,3:0.00136%]
[INFO] ** i/f_dir:[1:99.99886%,0:0.00114%]
[INFO] ** src:[22:38.09456%,9:26.09703%,7:18.22161%,1:17.58408%,14:0.00091%,21:0.00068%,15:0.00068%,4:0.00023%,3:0.00023%]
[INFO] ** dst:[21:43.35416%,10:20.83674%,8:18.22115%,9:17.58385%,22:0.00159%,15:0.00136%,24:0.00045%,25:0.00023%,6:0.00023%,2:0.00023%]
[INFO] ** proto:[0:99.99818%,1:0.00136%,2:0.00045%]
[INFO] ** appi_name:[21:99.99795%,30:0.00136%,26:0.00023%,8:0.00023%,0:0.00023%]
[INFO] ** proxy_src_ip:[18:38.09456%,20:26.09703%,13:18.22161%,6:17.58408%,17:0.00136%,16:0.00068%,21:0.00023%,7:0.00023%,1:0.00023%]
[INFO] ** modbus_function_code:[0.02961:99.99795%,-33.760870000000004:0.00205%]
[INFO] ** modbus_function_description:[7:49.99955%,11:49.99841%,0:0.00205%]
[INFO] ** modbus_transaction_id:65536 (14.90051%)
[INFO] ** scada_tag:[3:26.09612%,1:20.83652%,5:18.22092%,4:17.5834%,2:17.25758%,0:0.00546%]
[INFO] ** service:[0.0048200000000000005:99.99795%,-211.73542999999998:0.00136%,-186.44547:0.00023%,-211.08346:0.00023%,-211.35747999999998:0.00023%]
[INFO] ** s_port:[1.45442:26.09635%,-0.32151:20.83674%,-1.27613:18.22115%,-0.23351:17.58362%,-0.33484:17.25781%,-71.33197:0.00136%,-1.02014:0.00068%,-1.27347:0.00045%,1.45709:0.00045%,-0.24151:0.00045%,-71.14798:0.00023%,1.47576:0.00023%,-64.19493:0.00023%,-1.2708:0.00023%]
[INFO] ** classification:[normal:93.34597%,Single Stage Single Point:4.48861%,Multi Stage Single Point:2.16541%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [3 0 0 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.876783751255041
tp :  86777.0
fp :  13223.0
tn :  386777.0
fn :  13223.0
accuracy :  0.9471081495285034
precision :  0.8677700161933899
recall :  0.8677700161933899
auc :  0.9173561930656433

y_eval {0: 86777, 1: 3699, 3: 9524}
pred {0: 100000}
[INFO] confusion matrix for file 
[[86777     0     0     0     0]
 [ 3699     0     0     0     0]
 [    0     0     0     0     0]
 [ 9524     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[5347080       0       0       0       0]
 [ 395066       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.4723131567222532
tp :  83957.0
fp :  16043.0
tn :  383957.0
fn :  16043.0
accuracy :  0.9358279705047607
precision :  0.8395699858665466
recall :  0.8395699858665466
auc :  0.8997312784194946

y_eval {0: 83957, 1: 16043}
pred {0: 100000}
[INFO] confusion matrix for file 
[[83957     0     0     0     0]
 [16043     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[5431037       0       0       0       0]
 [ 411109       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00011499569498701021
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5531037       0       0       0       0]
 [ 411109       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00014789587564300745
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5631037       0       0       0       0]
 [ 411109       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/439824
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-02_172943_122.log.part03_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1376 (0.2752%)
[INFO] ** orig:[0:99.9976%,2:0.002%,1:0.0004%]
[INFO] ** type:[0:99.9988%,1:0.001%,2:0.0002%]
[INFO] ** i/f_name:[2:99.9944%,3:0.0056%]
[INFO] ** i/f_dir:[1:99.9946%,0:0.0054%]
[INFO] ** src:[22:38.2234%,9:26.124%,7:18.075%,1:17.571%,14:0.0036%,21:0.0022%,2:0.0004%,11:0.0002%,10:0.0002%]
[INFO] ** dst:[21:43.4342%,10:20.913%,8:18.0748%,9:17.5708%,15:0.0056%,22:0.0006%,25:0.0004%,24:0.0002%,18:0.0002%,7:0.0002%]
[INFO] ** proto:[0:99.9936%,1:0.0056%,2:0.0008%]
[INFO] ** appi_name:[21:99.9934%,30:0.0056%,0:0.0004%,31:0.0002%,27:0.0002%,15:0.0002%]
[INFO] ** proxy_src_ip:[18:38.2234%,20:26.124%,13:18.075%,6:17.571%,17:0.0056%,14:0.0004%,11:0.0002%,10:0.0002%,7:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9934%,-33.760870000000004:0.0064%,0.9188299999999999:0.0002%]
[INFO] ** modbus_function_description:[7:49.997%,11:49.9964%,0:0.0064%,15:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.1234%,1:20.9128%,5:18.0748%,4:17.5704%,2:17.3102%,0:0.0084%]
[INFO] ** service:[0.0048200000000000005:99.9936%,-211.73542999999998:0.0056%,-186.44547:0.0004%,-186.43601999999998:0.0002%,-202.75898:0.0002%]
[INFO] ** s_port:[1.45442:26.1238%,-0.32151:20.913%,-1.27613:18.0748%,-0.23351:17.5706%,-0.33484:17.3104%,-71.33197:0.0056%,-0.24151:0.0004%,-64.19493:0.0004%,-1.27347:0.0002%,-10.59042:0.0002%,11.862:0.0002%,1.47576:0.0002%,13.431270000000001:0.0002%]
[INFO] ** classification:[normal:94.9296%,Single Stage Single Point:5.0704%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  7.774368517566472e-05
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5731037       0       0       0       0]
 [ 411109       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  8.856704847421497e-05
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5831037       0       0       0       0]
 [ 411109       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00010767885625828057
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5931037       0       0       0       0]
 [ 411109       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00013053929281886667
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[6031037       0       0       0       0]
 [ 411109       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  2.1592294920613524
tp :  74648.0
fp :  25352.0
tn :  374648.0
fn :  25352.0
accuracy :  0.898591935634613
precision :  0.7464799880981445
recall :  0.7464799880981445
auc :  0.8449454307556152

y_eval {0: 74648, 1: 25352}
pred {0: 100000}
[INFO] confusion matrix for file 
[[74648     0     0     0     0]
 [25352     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6105685       0       0       0       0]
 [ 436461       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-02_172943_122.log.part04_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1377 (0.2754%)
[INFO] ** orig:[0:99.995%,2:0.005%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.9944%,3:0.0056%]
[INFO] ** i/f_dir:[1:99.9944%,0:0.0056%]
[INFO] ** src:[22:38.203%,9:26.1368%,7:18.1014%,1:17.5508%,21:0.005%,3:0.0008%,15:0.0006%,14:0.0006%,4:0.0004%,2:0.0004%,8:0.0002%]
[INFO] ** dst:[21:43.4462%,10:20.893%,8:18.1012%,9:17.5504%,15:0.0056%,22:0.0016%,16:0.0008%,6:0.0006%,17:0.0004%,24:0.0002%]
[INFO] ** proto:[0:99.9938%,1:0.0056%,2:0.0006%]
[INFO] ** appi_name:[21:99.9926%,30:0.0056%,17:0.0008%,26:0.0004%,28:0.0002%,22:0.0002%,7:0.0002%]
[INFO] ** proxy_src_ip:[18:38.203%,20:26.1368%,13:18.1014%,6:17.5508%,17:0.0056%,1:0.0008%,16:0.0006%,21:0.0004%,14:0.0004%,0:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9926%,-33.760870000000004:0.0074%]
[INFO] ** modbus_function_description:[7:49.9972%,11:49.9954%,0:0.0074%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.1358%,1:20.8928%,5:18.1008%,4:17.55%,2:17.31%,0:0.0106%]
[INFO] ** service:[0.0048200000000000005:99.9926%,-211.73542999999998:0.0056%,-205.44247:0.0008%,-211.08346:0.0004%,-211.09762999999998:0.0002%,-185.9872:0.0002%,-211.08818:0.0002%]
[INFO] ** s_port:[1.45442:26.136%,-0.32151:20.893%,-1.27613:18.101%,-0.23351:17.5502%,-0.33484:17.31%,-71.33197:0.0056%,1.45709:0.0006%,-1.02014:0.0006%,-71.14798:0.0004%,-0.24151:0.0004%,-5.1466400000000005:0.0002%,-58.035180000000004:0.0002%,-1.2708:0.0002%,-71.14931:0.0002%,1.47576:0.0002%,-1.27347:0.0002%,-5.08665:0.0002%,-0.24950999999999998:0.0002%,2.05573:0.0002%,-43.76509:0.0002%,-58.032509999999995:0.0002%]
[INFO] ** classification:[normal:64.3482%,Single Stage Single Point:35.6518%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  3.235315911102295
tp :  64457.0
fp :  35543.0
tn :  364457.0
fn :  35543.0
accuracy :  0.8578283786773682
precision :  0.644569993019104
recall :  0.644569993019104
auc :  0.7778562307357788

y_eval {0: 64457, 1: 35543}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64457     0     0     0     0]
 [35543     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6170142       0       0       0       0]
 [ 472004       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  3.1915840549468992
tp :  64588.0
fp :  35412.0
tn :  364588.0
fn :  35412.0
accuracy :  0.8583521246910095
precision :  0.6458799839019775
recall :  0.6458799839019775
auc :  0.7786750197410583

y_eval {0: 64588, 1: 35412}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64588     0     0     0     0]
 [35412     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6234730       0       0       0       0]
 [ 507416       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 1 0 ... 1 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  3.169933316421509
tp :  64276.0
fp :  35724.0
tn :  364276.0
fn :  35724.0
accuracy :  0.8571043610572815
precision :  0.6427599787712097
recall :  0.6427599787712097
auc :  0.7767249941825867

y_eval {0: 64276, 1: 35724}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64276     0     0     0     0]
 [35724     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6299006       0       0       0       0]
 [ 543140       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 1 1 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
lossUsing TensorFlow backend.
 :  3.1138712574005125
tp :  64281.0
fp :  35719.0
tn :  364281.0
fn :  35719.0
accuracy :  0.8571242690086365
precision :  0.6428099870681763
recall :  0.6428099870681763
auc :  0.7777419090270996

y_eval {0: 64281, 1: 35719}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64281     0     0     0     0]
 [35719     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6363287       0       0       0       0]
 [ 578859       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 0 ... 1 1 1] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  3.0639187191009523
tp :  64139.0
fp :  35861.0
tn :  364139.0
fn :  35861.0
accuracy :  0.8565559983253479
precision :  0.6413900256156921
recall :  0.6413900256156921
auc :  0.7805851697921753

y_eval {0: 64139, 1: 35861}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64139     0     0     0     0]
 [35861     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6427426       0       0       0       0]
 [ 614720       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.2/eval/2016-01-02_172943_122.log.part05_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 17)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** unixtime:1367 (0.2734%)
[INFO] ** orig:[0:99.9992%,2:0.0008%]
[INFO] ** type:[0:100.0%]
[INFO] ** i/f_name:[2:99.9984%,3:0.0016%]
[INFO] ** i/f_dir:[1:99.9984%,0:0.0016%]
[INFO] ** src:[22:38.0648%,9:26.1164%,7:18.2044%,1:17.6118%,21:0.001%,14:0.0008%,3:0.0004%,2:0.0004%]
[INFO] ** dst:[21:43.368%,10:20.8128%,8:18.2044%,9:17.6114%,15:0.0016%,22:0.0006%,16:0.0004%,24:0.0002%,18:0.0002%,6:0.0002%,2:0.0002%]
[INFO] ** proto:[0:99.998%,1:0.0016%,2:0.0004%]
[INFO] ** appi_name:[21:99.9974%,30:0.0016%,7:0.0006%,31:0.0002%,22:0.0002%]
[INFO] ** proxy_src_ip:[18:38.0648%,20:26.1164%,13:18.2044%,6:17.6118%,17:0.0016%,14:0.0004%,1:0.0004%,7:0.0002%]
[INFO] ** modbus_function_code:[0.02961:99.9974%,-33.760870000000004:0.0026%]
[INFO] ** modbus_function_description:[7:49.9992%,11:49.9982%,0:0.0026%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[3:26.1154%,1:20.8126%,5:18.204%,4:17.6112%,2:17.2518%,0:0.005%]
[INFO] ** service:[0.0048200000000000005:99.9974%,-211.73542999999998:0.0016%,-211.09762999999998:0.0006%,-186.43601999999998:0.0002%,-211.08818:0.0002%]
[INFO] ** s_port:[1.45442:26.1158%,-0.32151:20.8128%,-1.27613:18.204%,-0.23351:17.6114%,-0.33484:17.252%,-71.33197:0.0016%,1.45709:0.0004%,-1.2708:0.0002%,-71.14931:0.0002%,-0.24151:0.0002%,-2.02544:0.0002%,1.46509:0.0002%,10.73138:0.0002%,-0.24950999999999998:0.0002%,14.88321:0.0002%,-1.27347:0.0002%,-2.81074:0.0002%]
[INFO] ** classification:[normal:97.0224%,Single Stage Single Point:2.9776%]
[33mencode_numeric_zscore unixtime[0m
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [1 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  1.3568303338658065
tp :  85112.0
fp :  14888.0
tn :  385112.0
fn :  14888.0
accuracy :  0.9404480457305908
precision :  0.8511199951171875
recall :  0.8511199951171875
auc :  0.9069499969482422

y_eval {0: 85112, 1: 14888}
pred {0: 100000}
[INFO] confusion matrix for file 
[[85112     0     0     0     0]
 [14888     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6512538       0       0       0       0]
 [ 629608       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  8.861325773177669e-05
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[6612538       0       0       0       0]
 [ 629608       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00010687856225995347
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[6712538       0       0       0       0]
 [ 629608       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.0001284840425825678
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[6812538       0       0       0       0]
 [ 629608       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 16)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.00017199557041749358
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[6912538       0       0       0       0]
 [ 629608       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
--- 135.98361039161682 seconds ---
