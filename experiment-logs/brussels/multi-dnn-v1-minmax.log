2020-02-06 20:35:21.545179: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-02-06 20:35:21.545231: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-02-06 20:35:21.545238: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-02-06 20:35:22.036620: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-02-06 20:35:22.036639: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-02-06 20:35:22.036653: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (brussels): /proc/driver/nvidia/version does not exist
2020-02-06 20:35:22.036756: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-06 20:35:22.057785: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3312000000 Hz
2020-02-06 20:35:22.057972: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x44199a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-06 20:35:22.057983: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow backend.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
=============================
        TRAINING v0.4
=============================
Date: 2020-02-06 20:35:22.031505
[33m[INFO] using Sequential Dense layers[0m
[INFO] adding core layer 0
[INFO] created DNN
[33m[INFO] epoch 1/10[0m
[33m[INFO] loading file 1-1/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.1715 - tp: 75071.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 4929.0000 - accuracy: 0.9877 - precision: 1.0000 - recall: 0.9384 - auc: 0.9999 - val_loss: 0.0151 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0230 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0061 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0310 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9982 - val_loss: 2.8458 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.7064
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9126 - tp: 40594.0000 - fp: 37281.0000 - tn: 282719.0000 - fn: 39406.0000 - accuracy: 0.8083 - precision: 0.5213 - recall: 0.5074 - auc: 0.8710 - val_loss: 0.7030 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7157 - tp: 42415.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37585.0000 - accuracy: 0.8121 - precision: 0.5303 - recall: 0.5302 - auc: 0.8827 - val_loss: 0.6976 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[33m[INFO] loading file 2-2/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7077 - tp: 42435.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37565.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5304 - auc: 0.8824 - val_loss: 0.6956 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 70589.0000 - val_fn: 9411.0000 - val_accuracy: 0.8118 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-001-files-1-2
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4525 - tp: 67619.0000 - fp: 12381.0000 - tn: 307619.0000 - fn: 12381.0000 - accuracy: 0.9381 - precision: 0.8452 - recall: 0.8452 - auc: 0.9610 - val_loss: 0.1647 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-1-2
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3210 - tp: 72432.0000 - fp: 7568.0000 - tn: 312432.0000 - fn: 7568.0000 - accuracy: 0.9622 - precision: 0.9054 - recall: 0.9054 - auc: 0.9763 - val_loss: 1.1752 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 70593.0000 - val_fn: 9407.0000 - val_accuracy: 0.8119 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-001-files-1-2
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7253 - tp: 42056.0000 - fp: 37801.0000 - tn: 282199.0000 - fn: 37944.0000 - accuracy: 0.8106 - precision: 0.5266 - recall: 0.5257 - auc: 0.8818 - val_loss: 0.6937 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 70602.0000 - val_fn: 9398.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-001-files-1-2
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4535 - tp: 67360.0000 - fp: 12640.0000 - tn: 307360.0000 - fn: 12640.0000 - accuracy: 0.9368 - precision: 0.8420 - recall: 0.8420 - auc: 0.9602 - val_loss: 0.1770 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-1-2
[33m[INFO] loading file 3-3/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7013 - tp: 45236.0000 - fp: 34764.0000 - tn: 285236.0000 - fn: 34764.0000 - accuracy: 0.8262 - precision: 0.5655 - recall: 0.5655 - auc: 0.8915 - val_loss: 0.6955 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 70571.0000 - val_fn: 9429.0000 - val_accuracy: 0.8114 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.8821
[INFO] saving weights to checkpoints/dnn-epoch-001-files-2-3
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5991 - tp: 57751.0000 - fp: 22249.0000 - tn: 297751.0000 - fn: 22249.0000 - accuracy: 0.8888 - precision: 0.7219 - recall: 0.7219 - auc: 0.9304 - val_loss: 0.3403 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-2-3
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0532 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0082 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-2-3
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0141 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0037 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-2-3
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0086 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0023 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-2-3
[33m[INFO] loading file 4-4/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0062 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0017 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-3-4
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0050 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0013 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-3-4
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0041 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0011 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-3-4
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4088 - tp: 71528.0000 - fp: 8472.0000 - tn: 311528.0000 - fn: 8472.0000 - accuracy: 0.9576 - precision: 0.8941 - recall: 0.8941 - auc: 0.9708 - val_loss: 1.5375 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 67806.0000 - val_fn: 12194.0000 - val_accuracy: 0.7561 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.8476
[INFO] saving weights to checkpoints/dnn-epoch-001-files-3-4
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6243 - tp: 56887.0000 - fp: 23113.0000 - tn: 296887.0000 - fn: 23113.0000 - accuracy: 0.8844 - precision: 0.7111 - recall: 0.7111 - auc: 0.9278 - val_loss: 0.3365 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-3-4
[33m[INFO] loading file 5-5/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5304 - tp: 62445.0000 - fp: 17555.0000 - tn: 302445.0000 - fn: 17555.0000 - accuracy: 0.9122 - precision: 0.7806 - recall: 0.7806 - auc: 0.9448 - val_loss: 0.7005 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-001-files-4-5
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6589 - tp: 51316.0000 - fp: 28684.0000 - tn: 291316.0000 - fn: 28684.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9100 - val_loss: 0.5232 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 77052.0000 - val_fn: 2948.0000 - val_accuracy: 0.9410 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.9632
[INFO] saving weights to checkpoints/dnn-epoch-001-files-4-5
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0595 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0078 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-4-5
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0035 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-4-5
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0086 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0022 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-4-5
[33m[INFO] loading file 6-6/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0062 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0016 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-5-6
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0012 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-5-6
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0040 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.9836e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-5-6
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0034 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.5554 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 75632.0000 - val_fn: 4368.0000 - val_accuracy: 0.9126 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.8635
[INFO] saving weights to checkpoints/dnn-epoch-001-files-5-6
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8149 - tp: 51195.0000 - fp: 28805.0000 - tn: 291195.0000 - fn: 28805.0000 - accuracy: 0.8560 - precision: 0.6399 - recall: 0.6399 - auc: 0.9075 - val_loss: 0.6551 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 72768.0000 - val_fn: 7232.0000 - val_accuracy: 0.8554 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.9096
[INFO] saving weights to checkpoints/dnn-epoch-001-files-5-6
[33m[INFO] loading file 7-7/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6564 - tp: 51210.0000 - fp: 28790.0000 - tn: 291210.0000 - fn: 28790.0000 - accuracy: 0.8561 - precision: 0.6401 - recall: 0.6401 - auc: 0.9100 - val_loss: 0.6541 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 72803.0000 - val_fn: 7197.0000 - val_accuracy: 0.8561 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.9100
[INFO] saving weights to checkpoints/dnn-epoch-001-files-6-7
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6553 - tp: 51338.0000 - fp: 28662.0000 - tn: 291338.0000 - fn: 28662.0000 - accuracy: 0.8567 - precision: 0.6417 - recall: 0.6417 - auc: 0.9103 - val_loss: 0.6524 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-6-7
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4822 - tp: 65370.0000 - fp: 14630.0000 - tn: 305370.0000 - fn: 14630.0000 - accuracy: 0.9268 - precision: 0.8171 - recall: 0.8171 - auc: 0.9542 - val_loss: 0.2027 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-6-7
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0422 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0085 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-6-7
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0127 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0039 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-6-7
[33m[INFO] loading file 8-8/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0078 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0025 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-7-8
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0018 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-7-8
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0046 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0014 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-7-8
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3440 - tp: 73166.0000 - fp: 6834.0000 - tn: 313166.0000 - fn: 6834.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9762 - val_loss: 0.5473 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 76368.0000 - val_fn: 3632.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-001-files-7-8
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4874 - tp: 65505.0000 - fp: 14495.0000 - tn: 305505.0000 - fn: 14495.0000 - accuracy: 0.9275 - precision: 0.8188 - recall: 0.8188 - auc: 0.9545 - val_loss: 0.4736 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 76383.0000 - val_fn: 3617.0000 - val_accuracy: 0.9277 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.9548
[INFO] saving weights to checkpoints/dnn-epoch-001-files-7-8
[33m[INFO] loading file 9-9/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4790 - tp: 65300.0000 - fp: 14700.0000 - tn: 305300.0000 - fn: 14700.0000 - accuracy: 0.9265 - precision: 0.8163 - recall: 0.8163 - auc: 0.9542 - val_loss: 0.4806 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 76283.0000 - val_fn: 3717.0000 - val_accuracy: 0.9257 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.9535
[INFO] saving weights to checkpoints/dnn-epoch-001-files-8-9
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0945 - tp: 78936.0000 - fp: 1064.0000 - tn: 318936.0000 - fn: 1064.0000 - accuracy: 0.9947 - precision: 0.9867 - recall: 0.9867 - auc: 0.9966 - val_loss: 0.0213 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-8-9
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0165 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0064 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-8-9
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0088 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0036 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-8-9
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0061 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0024 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-8-9
[33m[INFO] loading file 10-10/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0047 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0018 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-9-10
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0091 - tp: 79936.0000 - fp: 64.0000 - tn: 319936.0000 - fn: 64.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 0.9996 - val_loss: 2.2991 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.7763
[INFO] saving weights to checkpoints/dnn-epoch-001-files-9-10
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7286 - tp: 56672.0000 - fp: 23328.0000 - tn: 296672.0000 - fn: 23328.0000 - accuracy: 0.8834 - precision: 0.7084 - recall: 0.7084 - auc: 0.9251 - val_loss: 0.3143 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-9-10
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0500 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0083 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-9-10
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0132 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0038 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-9-10
[33m[INFO] loading file 11-11/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0081 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0024 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-10-11
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0017 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-10-11
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0046 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0013 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-10-11
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0038 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0011 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-10-11
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0032 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.0308e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-10-11
[33m[INFO] loading file 12-12/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0028 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.7575e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-11-12
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0025 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2119 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 76689.0000 - val_fn: 3311.0000 - val_accuracy: 0.9338 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8965
[INFO] saving weights to checkpoints/dnn-epoch-001-files-11-12
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8308 - tp: 51328.0000 - fp: 28672.0000 - tn: 291328.0000 - fn: 28672.0000 - accuracy: 0.8566 - precision: 0.6416 - recall: 0.6416 - auc: 0.9064 - val_loss: 0.5644 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 75792.0000 - val_fn: 4208.0000 - val_accuracy: 0.9158 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.9474
[INFO] saving weights to checkpoints/dnn-epoch-001-files-11-12
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0576 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0081 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-11-12
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0137 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0036 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-11-12
[33m[INFO] loading file 13-13/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0082 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0023 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-12-13
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0059 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0016 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-12-13
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0046 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6473 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 75075.0000 - val_fn: 4925.0000 - val_accuracy: 0.9015 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.8461
[INFO] saving weights to checkpoints/dnn-epoch-001-files-12-13
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7892 - tp: 51313.0000 - fp: 28687.0000 - tn: 291313.0000 - fn: 28687.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9078 - val_loss: 0.6518 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-001-files-12-13
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6540 - tp: 51356.0000 - fp: 28644.0000 - tn: 291356.0000 - fn: 28644.0000 - accuracy: 0.8568 - precision: 0.6420 - recall: 0.6420 - auc: 0.9107 - val_loss: 0.6521 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-12-13
[33m[INFO] loading file 14-14/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5284 - tp: 62543.0000 - fp: 17457.0000 - tn: 302543.0000 - fn: 17457.0000 - accuracy: 0.9127 - precision: 0.7818 - recall: 0.7818 - auc: 0.9450 - val_loss: 0.2444 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-13-14
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0455 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0085 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-13-14
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0128 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0039 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-13-14
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0079 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0025 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-13-14
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0057 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0018 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-13-14
[33m[INFO] loading file 15-15/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0046 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0014 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-14-15
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0039 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0011 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-14-15
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0032 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.4941e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-14-15
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0028 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.2330 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 71586.0000 - val_fn: 8414.0000 - val_accuracy: 0.8317 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.7371
[INFO] saving weights to checkpoints/dnn-epoch-001-files-14-15
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.3895 - tp: 42561.0000 - fp: 37439.0000 - tn: 282561.0000 - fn: 37439.0000 - accuracy: 0.8128 - precision: 0.5320 - recall: 0.5320 - auc: 0.8338 - val_loss: 0.7277 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 70627.0000 - val_fn: 9373.0000 - val_accuracy: 0.8125 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-001-files-14-15
[33m[INFO] loading file 16-16/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7161 - tp: 42492.0000 - fp: 37508.0000 - tn: 282492.0000 - fn: 37508.0000 - accuracy: 0.8125 - precision: 0.5311 - recall: 0.5311 - auc: 0.8827 - val_loss: 0.7091 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 70618.0000 - val_fn: 9382.0000 - val_accuracy: 0.8124 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-001-files-15-16
[INFO] processing batch 100000-200000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6001 - tp: 58381.0000 - fp: 21619.0000 - tn: 298381.0000 - fn: 21619.0000 - accuracy: 0.8919 - precision: 0.7298 - recall: 0.7298 - auc: 0.9326 - val_loss: 0.3169 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-15-16
[INFO] processing batch 200000-300000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0646 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0218 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-15-16
[INFO] processing batch 300000-400000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0154 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0113 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-15-16
[INFO] processing batch 400000-500000/439690
[33m[INFO] loading file 17-17/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0093 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0077 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-16-17
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0067 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0059 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-16-17
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0053 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0047 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-16-17
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8172 - tp: 68607.0000 - fp: 11393.0000 - tn: 308607.0000 - fn: 11393.0000 - accuracy: 0.9430 - precision: 0.8576 - recall: 0.8576 - auc: 0.9176 - val_loss: 0.6104 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 76369.0000 - val_fn: 3631.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-001-files-16-17
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5231 - tp: 65526.0000 - fp: 14474.0000 - tn: 305526.0000 - fn: 14474.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.9549 - val_loss: 0.3210 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 78648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9730 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9831
[INFO] saving weights to checkpoints/dnn-epoch-001-files-16-17
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 18-18/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3408 - tp: 72130.0000 - fp: 7870.0000 - tn: 312130.0000 - fn: 7870.0000 - accuracy: 0.9607 - precision: 0.9016 - recall: 0.9016 - auc: 0.9752 - val_loss: 0.9731 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 72369.0000 - val_fn: 7631.0000 - val_accuracy: 0.8474 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.9046
[INFO] saving weights to checkpoints/dnn-epoch-001-files-17-18
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6982 - tp: 49699.0000 - fp: 30301.0000 - tn: 289699.0000 - fn: 30301.0000 - accuracy: 0.8485 - precision: 0.6212 - recall: 0.6212 - auc: 0.9055 - val_loss: 0.6802 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 72357.0000 - val_fn: 7643.0000 - val_accuracy: 0.8471 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.9045
[INFO] saving weights to checkpoints/dnn-epoch-001-files-17-18
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6774 - tp: 49541.0000 - fp: 30459.0000 - tn: 289541.0000 - fn: 30459.0000 - accuracy: 0.8477 - precision: 0.6193 - recall: 0.6193 - auc: 0.9045 - val_loss: 0.6753 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 72397.0000 - val_fn: 7603.0000 - val_accuracy: 0.8479 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.9050
[INFO] saving weights to checkpoints/dnn-epoch-001-files-17-18
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2752 - tp: 74509.0000 - fp: 5491.0000 - tn: 314509.0000 - fn: 5491.0000 - accuracy: 0.9726 - precision: 0.9314 - recall: 0.9314 - auc: 0.9828 - val_loss: 0.0766 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-17-18
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0336 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0176 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-17-18
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 19-19/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0131 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0100 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-18-19
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0084 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0071 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-18-19
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0062 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0055 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-18-19
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6504 - tp: 69321.0000 - fp: 10679.0000 - tn: 309321.0000 - fn: 10679.0000 - accuracy: 0.9466 - precision: 0.8665 - recall: 0.8665 - auc: 0.9374 - val_loss: 1.5835 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 67882.0000 - val_fn: 12118.0000 - val_accuracy: 0.7576 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.8485
[INFO] saving weights to checkpoints/dnn-epoch-001-files-18-19
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7467 - tp: 44598.0000 - fp: 32874.0000 - tn: 287126.0000 - fn: 35402.0000 - accuracy: 0.8293 - precision: 0.5757 - recall: 0.5575 - auc: 0.8909 - val_loss: 0.9795 - val_tp: 0.0000e+00 - val_fp: 20000.0000 - val_tn: 60000.0000 - val_fn: 20000.0000 - val_accuracy: 0.6000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7500
[INFO] saving weights to checkpoints/dnn-epoch-001-files-18-19
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 20-20/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.1064 - tp: 78464.0000 - fp: 1248.0000 - tn: 318752.0000 - fn: 1536.0000 - accuracy: 0.9930 - precision: 0.9843 - recall: 0.9808 - auc: 0.9998 - val_loss: 0.1241 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 79491.0000 - val_fn: 509.0000 - val_accuracy: 0.9898 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9936
[INFO] saving weights to checkpoints/dnn-epoch-001-files-19-20
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5211 - tp: 65427.0000 - fp: 14573.0000 - tn: 305427.0000 - fn: 14573.0000 - accuracy: 0.9271 - precision: 0.8178 - recall: 0.8178 - auc: 0.9542 - val_loss: 0.4848 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 76357.0000 - val_fn: 3643.0000 - val_accuracy: 0.9271 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.9545
[INFO] saving weights to checkpoints/dnn-epoch-001-files-19-20
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4852 - tp: 65351.0000 - fp: 14649.0000 - tn: 305351.0000 - fn: 14649.0000 - accuracy: 0.9268 - precision: 0.8169 - recall: 0.8169 - auc: 0.9540 - val_loss: 0.4816 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 76371.0000 - val_fn: 3629.0000 - val_accuracy: 0.9274 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-001-files-19-20
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2114 - tp: 76024.0000 - fp: 3976.0000 - tn: 316024.0000 - fn: 3976.0000 - accuracy: 0.9801 - precision: 0.9503 - recall: 0.9503 - auc: 0.9875 - val_loss: 0.0576 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-19-20
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0287 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0163 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-19-20
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 21-21/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539688, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0123 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0096 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-20-21
[INFO] processing batch 100000-200000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0080 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-20-21
[INFO] processing batch 200000-300000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0060 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0053 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-20-21
[INFO] processing batch 300000-400000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0043 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-20-21
[INFO] processing batch 400000-500000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0040 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0037 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-20-21
[INFO] processing batch 500000-600000/539688
[33m[INFO] loading file 22-22/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.2565 - tp: 55006.0000 - fp: 24994.0000 - tn: 295006.0000 - fn: 24994.0000 - accuracy: 0.8750 - precision: 0.6876 - recall: 0.6876 - auc: 0.8570 - val_loss: 0.8026 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-001-files-21-22
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7288 - tp: 42398.0000 - fp: 37602.0000 - tn: 282398.0000 - fn: 37602.0000 - accuracy: 0.8120 - precision: 0.5300 - recall: 0.5300 - auc: 0.8822 - val_loss: 0.7155 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.8816
[INFO] saving weights to checkpoints/dnn-epoch-001-files-21-22
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7104 - tp: 42369.0000 - fp: 37631.0000 - tn: 282369.0000 - fn: 37631.0000 - accuracy: 0.8118 - precision: 0.5296 - recall: 0.5296 - auc: 0.8823 - val_loss: 0.7067 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 70623.0000 - val_fn: 9377.0000 - val_accuracy: 0.8125 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-001-files-21-22
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7045 - tp: 42452.0000 - fp: 37548.0000 - tn: 282452.0000 - fn: 37548.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5307 - auc: 0.8826 - val_loss: 0.7030 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 70601.0000 - val_fn: 9399.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-001-files-21-22
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7016 - tp: 42382.0000 - fp: 37618.0000 - tn: 282382.0000 - fn: 37618.0000 - accuracy: 0.8119 - precision: 0.5298 - recall: 0.5298 - auc: 0.8823 - val_loss: 0.7005 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-001-files-21-22
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 23-23/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6548 - tp: 52270.0000 - fp: 27730.0000 - tn: 292270.0000 - fn: 27730.0000 - accuracy: 0.8614 - precision: 0.6534 - recall: 0.6534 - auc: 0.9128 - val_loss: 0.4304 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-22-23
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0721 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0217 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-22-23
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0152 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0111 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-22-23
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0090 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0075 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-22-23
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0065 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0057 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-22-23
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 24-24/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0051 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0046 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-23-24
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0042 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0038 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-23-24
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0036 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0033 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-23-24
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-23-24
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2730 - tp: 75698.0000 - fp: 4302.0000 - tn: 315698.0000 - fn: 4302.0000 - accuracy: 0.9785 - precision: 0.9462 - recall: 0.9462 - auc: 0.9803 - val_loss: 1.3892 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 72912.0000 - val_fn: 7088.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-001-files-23-24
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 25-25/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7220 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9106 - val_loss: 0.6574 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-001-files-24-25
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6563 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9105 - val_loss: 0.6553 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-001-files-24-25
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6559 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9107 - val_loss: 0.6562 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-001-files-24-25
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6553 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9106 - val_loss: 0.6561 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-001-files-24-25
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6552 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6550 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-24-25
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 26-26/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6545 - tp: 51523.0000 - fp: 28477.0000 - tn: 291523.0000 - fn: 28477.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9109 - val_loss: 1.6485 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.8310
[INFO] saving weights to checkpoints/dnn-epoch-001-files-25-26
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.2302 - tp: 51579.0000 - fp: 28421.0000 - tn: 291579.0000 - fn: 28421.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.8490 - val_loss: 0.7026 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-25-26
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6833 - tp: 51462.0000 - fp: 28538.0000 - tn: 291462.0000 - fn: 28538.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9104 - val_loss: 0.6714 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-001-files-25-26
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6681 - tp: 51506.0000 - fp: 28494.0000 - tn: 291506.0000 - fn: 28494.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9108 - val_loss: 0.6631 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 72936.0000 - val_fn: 7064.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-001-files-25-26
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6632 - tp: 51474.0000 - fp: 28526.0000 - tn: 291474.0000 - fn: 28526.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.6593 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 72945.0000 - val_fn: 7055.0000 - val_accuracy: 0.8589 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.9118
[INFO] saving weights to checkpoints/dnn-epoch-001-files-25-26
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 27-27/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (479817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6610 - tp: 51419.0000 - fp: 28581.0000 - tn: 291419.0000 - fn: 28581.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9102 - val_loss: 0.6608 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-001-files-26-27
[INFO] processing batch 100000-200000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6588 - tp: 51485.0000 - fp: 28515.0000 - tn: 291485.0000 - fn: 28515.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6568 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 72918.0000 - val_fn: 7082.0000 - val_accuracy: 0.8584 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-001-files-26-27
[INFO] processing batch 200000-300000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6570 - tp: 51583.0000 - fp: 28417.0000 - tn: 291583.0000 - fn: 28417.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9112 - val_loss: 0.6575 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-26-27
[INFO] processing batch 300000-400000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6576 - tp: 51396.0000 - fp: 28604.0000 - tn: 291396.0000 - fn: 28604.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9104 - val_loss: 0.6571 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 72851.0000 - val_fn: 7149.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-001-files-26-27
[INFO] processing batch 400000-500000/479817
[33m[INFO] loading file 28-28/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6563 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6560 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-27-28
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6564 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9104 - val_loss: 0.6559 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-27-28
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6556 - tp: 51458.0000 - fp: 28542.0000 - tn: 291458.0000 - fn: 28542.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9105 - val_loss: 0.6552 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-27-28
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6552 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9106 - val_loss: 0.6539 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-001-files-27-28
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6545 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6551 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-27-28
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 29-29/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6547 - tp: 51460.0000 - fp: 28540.0000 - tn: 291460.0000 - fn: 28540.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9112 - val_loss: 0.6549 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-28-29
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6540 - tp: 51527.0000 - fp: 28473.0000 - tn: 291527.0000 - fn: 28473.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6549 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-001-files-28-29
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6541 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6522 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-001-files-28-29
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6534 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9111 - val_loss: 0.6543 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-28-29
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6537 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-28-29
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 30-30/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6534 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6539 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-29-30
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51450.0000 - fp: 28550.0000 - tn: 291450.0000 - fn: 28550.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9109 - val_loss: 0.6540 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-29-30
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6535 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6539 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-29-30
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9112 - val_loss: 0.6532 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-001-files-29-30
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9112 - val_loss: 0.6533 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 72870.0000 - val_fn: 7130.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-29-30
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 31-31/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9105 - val_loss: 0.6518 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 72921.0000 - val_fn: 7079.0000 - val_accuracy: 0.8584 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-001-files-30-31
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51524.0000 - fp: 28476.0000 - tn: 291524.0000 - fn: 28476.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6522 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 72902.0000 - val_fn: 7098.0000 - val_accuracy: 0.8580 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-001-files-30-31
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6535 - tp: 51428.0000 - fp: 28572.0000 - tn: 291428.0000 - fn: 28572.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9108 - val_loss: 0.6529 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-30-31
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6525 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-30-31
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9107 - val_loss: 0.6523 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 72893.0000 - val_fn: 7107.0000 - val_accuracy: 0.8579 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-001-files-30-31
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 32-32/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6524 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-31-32
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51531.0000 - fp: 28469.0000 - tn: 291531.0000 - fn: 28469.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6527 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-31-32
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51576.0000 - fp: 28424.0000 - tn: 291576.0000 - fn: 28424.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9108 - val_loss: 0.6522 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-31-32
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51489.0000 - fp: 28511.0000 - tn: 291489.0000 - fn: 28511.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6529 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-31-32
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6530 - tp: 51449.0000 - fp: 28551.0000 - tn: 291449.0000 - fn: 28551.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9105 - val_loss: 0.6528 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-31-32
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 33-33/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6525 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-32-33
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9107 - val_loss: 0.6528 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-32-33
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51404.0000 - fp: 28596.0000 - tn: 291404.0000 - fn: 28596.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9103 - val_loss: 0.6529 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-32-33
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51552.0000 - fp: 28448.0000 - tn: 291552.0000 - fn: 28448.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9112 - val_loss: 0.6521 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-32-33
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51594.0000 - fp: 28406.0000 - tn: 291594.0000 - fn: 28406.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9109 - val_loss: 0.6508 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-001-files-32-33
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 34-34/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9106 - val_loss: 0.6533 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-001-files-33-34
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9107 - val_loss: 0.6527 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-33-34
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51588.0000 - fp: 28412.0000 - tn: 291588.0000 - fn: 28412.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9112 - val_loss: 0.6523 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-001-files-33-34
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6530 - tp: 51408.0000 - fp: 28592.0000 - tn: 291408.0000 - fn: 28592.0000 - accuracy: 0.8570 - precision: 0.6426 - recall: 0.6426 - auc: 0.9103 - val_loss: 0.6535 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 72834.0000 - val_fn: 7166.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-001-files-33-34
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9108 - val_loss: 0.6522 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-001-files-33-34
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 35-35/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51520.0000 - fp: 28480.0000 - tn: 291520.0000 - fn: 28480.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9108 - val_loss: 0.6528 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-34-35
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6522 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-001-files-34-35
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6523 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6517 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-34-35
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51521.0000 - fp: 28479.0000 - tn: 291521.0000 - fn: 28479.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9107 - val_loss: 0.6528 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-34-35
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51570.0000 - fp: 28430.0000 - tn: 291570.0000 - fn: 28430.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9109 - val_loss: 0.6523 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-34-35
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 36-36/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6522 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-35-36
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51644.0000 - fp: 28356.0000 - tn: 291644.0000 - fn: 28356.0000 - accuracy: 0.8582 - precision: 0.6456 - recall: 0.6456 - auc: 0.9113 - val_loss: 0.6515 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 72895.0000 - val_fn: 7105.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-001-files-35-36
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9104 - val_loss: 0.6507 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 72933.0000 - val_fn: 7067.0000 - val_accuracy: 0.8587 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-001-files-35-36
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51415.0000 - fp: 28585.0000 - tn: 291415.0000 - fn: 28585.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9104 - val_loss: 0.6521 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 72878.0000 - val_fn: 7122.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-001-files-35-36
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9111 - val_loss: 0.6526 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-35-36
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 37-37/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51413.0000 - fp: 28587.0000 - tn: 291413.0000 - fn: 28587.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9104 - val_loss: 0.6527 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-36-37
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51456.0000 - fp: 28544.0000 - tn: 291456.0000 - fn: 28544.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9106 - val_loss: 0.6512 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-001-files-36-37
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51565.0000 - fp: 28435.0000 - tn: 291565.0000 - fn: 28435.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6522 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-36-37
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51512.0000 - fp: 28488.0000 - tn: 291512.0000 - fn: 28488.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6517 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 72888.0000 - val_fn: 7112.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-36-37
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51528.0000 - fp: 28472.0000 - tn: 291528.0000 - fn: 28472.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9107 - val_loss: 0.6513 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 72899.0000 - val_fn: 7101.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-001-files-36-37
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 38-38/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51513.0000 - fp: 28487.0000 - tn: 291513.0000 - fn: 28487.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6503 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-001-files-37-38
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51589.0000 - fp: 28411.0000 - tn: 291589.0000 - fn: 28411.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9111 - val_loss: 0.6530 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-001-files-37-38
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51481.0000 - fp: 28519.0000 - tn: 291481.0000 - fn: 28519.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9111 - val_loss: 0.6525 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-37-38
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51549.0000 - fp: 28451.0000 - tn: 291549.0000 - fn: 28451.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9109 - val_loss: 0.6514 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 72898.0000 - val_fn: 7102.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-001-files-37-38
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9109 - val_loss: 0.6523 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 72866.0000 - val_fn: 7134.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-37-38
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 39-39/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9111 - val_loss: 0.6528 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 72847.0000 - val_fn: 7153.0000 - val_accuracy: 0.8569 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-001-files-38-39
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51597.0000 - fp: 28403.0000 - tn: 291597.0000 - fn: 28403.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9112 - val_loss: 0.6509 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 72910.0000 - val_fn: 7090.0000 - val_accuracy: 0.8582 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-001-files-38-39
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51631.0000 - fp: 28369.0000 - tn: 291631.0000 - fn: 28369.0000 - accuracy: 0.8582 - precision: 0.6454 - recall: 0.6454 - auc: 0.9112 - val_loss: 0.6514 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-001-files-38-39
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6521 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-38-39
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6519 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-38-39
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 40-40/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51418.0000 - fp: 28582.0000 - tn: 291418.0000 - fn: 28582.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9107 - val_loss: 0.6529 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-001-files-39-40
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51491.0000 - fp: 28509.0000 - tn: 291491.0000 - fn: 28509.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6523 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-39-40
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9113 - val_loss: 0.6507 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 72916.0000 - val_fn: 7084.0000 - val_accuracy: 0.8583 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-001-files-39-40
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6530 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 72838.0000 - val_fn: 7162.0000 - val_accuracy: 0.8568 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-001-files-39-40
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51432.0000 - fp: 28568.0000 - tn: 291432.0000 - fn: 28568.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9104 - val_loss: 0.6526 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-001-files-39-40
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 41-41/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6523 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-40-41
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51515.0000 - fp: 28485.0000 - tn: 291515.0000 - fn: 28485.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9107 - val_loss: 0.6521 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-40-41
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9109 - val_loss: 0.6519 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-001-files-40-41
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51587.0000 - fp: 28413.0000 - tn: 291587.0000 - fn: 28413.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9112 - val_loss: 0.6523 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-40-41
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9109 - val_loss: 0.6500 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 72937.0000 - val_fn: 7063.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-001-files-40-41
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 42-42/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9106 - val_loss: 0.6533 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 72826.0000 - val_fn: 7174.0000 - val_accuracy: 0.8565 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-001-files-41-42
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51511.0000 - fp: 28489.0000 - tn: 291511.0000 - fn: 28489.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.6517 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 72882.0000 - val_fn: 7118.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-001-files-41-42
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51499.0000 - fp: 28501.0000 - tn: 291499.0000 - fn: 28501.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6524 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 72853.0000 - val_fn: 7147.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-41-42
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6506 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 72917.0000 - val_fn: 7083.0000 - val_accuracy: 0.8583 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-001-files-41-42
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51584.0000 - fp: 28416.0000 - tn: 291584.0000 - fn: 28416.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9111 - val_loss: 0.6518 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-41-42
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 43-43/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9110 - val_loss: 0.6518 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-42-43
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9104 - val_loss: 0.6533 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 72824.0000 - val_fn: 7176.0000 - val_accuracy: 0.8565 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-001-files-42-43
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51387.0000 - fp: 28613.0000 - tn: 291387.0000 - fn: 28613.0000 - accuracy: 0.8569 - precision: 0.6423 - recall: 0.6423 - auc: 0.9106 - val_loss: 0.6512 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-001-files-42-43
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9112 - val_loss: 0.6527 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-001-files-42-43
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9110 - val_loss: 0.6494 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 72952.0000 - val_fn: 7048.0000 - val_accuracy: 0.8590 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.9119
[INFO] saving weights to checkpoints/dnn-epoch-001-files-42-43
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 44-44/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9104 - val_loss: 0.6524 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-43-44
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6523 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-43-44
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51543.0000 - fp: 28457.0000 - tn: 291543.0000 - fn: 28457.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9111 - val_loss: 0.6523 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-43-44
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6523 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9103 - val_loss: 0.6514 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 72891.0000 - val_fn: 7109.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-43-44
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51537.0000 - fp: 28463.0000 - tn: 291537.0000 - fn: 28463.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9107 - val_loss: 0.6521 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-43-44
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 45-45/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51620.0000 - fp: 28380.0000 - tn: 291620.0000 - fn: 28380.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9110 - val_loss: 0.6520 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-44-45
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51538.0000 - fp: 28462.0000 - tn: 291538.0000 - fn: 28462.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6515 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-44-45
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51564.0000 - fp: 28436.0000 - tn: 291564.0000 - fn: 28436.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.6509 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 72904.0000 - val_fn: 7096.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-001-files-44-45
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51590.0000 - fp: 28410.0000 - tn: 291590.0000 - fn: 28410.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9115 - val_loss: 0.6526 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-001-files-44-45
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51395.0000 - fp: 28605.0000 - tn: 291395.0000 - fn: 28605.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9106 - val_loss: 0.6511 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-001-files-44-45
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 46-46/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9107 - val_loss: 0.6506 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 72913.0000 - val_fn: 7087.0000 - val_accuracy: 0.8583 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-001-files-45-46
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51464.0000 - fp: 28536.0000 - tn: 291464.0000 - fn: 28536.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9105 - val_loss: 0.6515 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 72883.0000 - val_fn: 7117.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-001-files-45-46
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9106 - val_loss: 0.6514 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-45-46
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6501 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-001-files-45-46
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51569.0000 - fp: 28431.0000 - tn: 291569.0000 - fn: 28431.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6517 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-45-46
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 47-47/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51601.0000 - fp: 28399.0000 - tn: 291601.0000 - fn: 28399.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9112 - val_loss: 0.6512 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-46-47
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51559.0000 - fp: 28441.0000 - tn: 291559.0000 - fn: 28441.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-46-47
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6532 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 72822.0000 - val_fn: 7178.0000 - val_accuracy: 0.8564 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-001-files-46-47
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9105 - val_loss: 0.6515 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 72881.0000 - val_fn: 7119.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-001-files-46-47
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6506 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 72909.0000 - val_fn: 7091.0000 - val_accuracy: 0.8582 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-001-files-46-47
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 48-48/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9112 - val_loss: 0.6530 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 72830.0000 - val_fn: 7170.0000 - val_accuracy: 0.8566 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-001-files-47-48
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6516 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 72879.0000 - val_fn: 7121.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-001-files-47-48
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51547.0000 - fp: 28453.0000 - tn: 291547.0000 - fn: 28453.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9102 - val_loss: 0.6506 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-001-files-47-48
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6520 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-47-48
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51606.0000 - fp: 28394.0000 - tn: 291606.0000 - fn: 28394.0000 - accuracy: 0.8580 - precision: 0.6451 - recall: 0.6451 - auc: 0.9111 - val_loss: 0.6508 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 72905.0000 - val_fn: 7095.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-001-files-47-48
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 49-49/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9108 - val_loss: 0.6519 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-48-49
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51430.0000 - fp: 28570.0000 - tn: 291430.0000 - fn: 28570.0000 - accuracy: 0.8571 - precision: 0.6429 - recall: 0.6429 - auc: 0.9110 - val_loss: 0.6503 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 72924.0000 - val_fn: 7076.0000 - val_accuracy: 0.8585 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-001-files-48-49
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51469.0000 - fp: 28531.0000 - tn: 291469.0000 - fn: 28531.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9106 - val_loss: 0.6530 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-001-files-48-49
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6503 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 72922.0000 - val_fn: 7078.0000 - val_accuracy: 0.8584 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-001-files-48-49
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51495.0000 - fp: 28505.0000 - tn: 291495.0000 - fn: 28505.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9112 - val_loss: 0.6512 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-48-49
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 50-50/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6531 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 72823.0000 - val_fn: 7177.0000 - val_accuracy: 0.8565 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-001-files-49-50
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51482.0000 - fp: 28518.0000 - tn: 291482.0000 - fn: 28518.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6511 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-49-50
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51433.0000 - fp: 28567.0000 - tn: 291433.0000 - fn: 28567.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9104 - val_loss: 0.6524 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-001-files-49-50
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51461.0000 - fp: 28539.0000 - tn: 291461.0000 - fn: 28539.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9109 - val_loss: 0.6513 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-49-50
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51467.0000 - fp: 28533.0000 - tn: 291467.0000 - fn: 28533.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9110 - val_loss: 0.6521 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-49-50
[INFO] processing batch 500000-600000/519975
[33m[LOSS] 0.652138144493103[0m
[33m[INFO] epoch 2/10[0m
[33m[INFO] loading file 1-1/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0709 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0227 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9993 - val_loss: 2.2983 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.8826
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8376 - tp: 42447.0000 - fp: 37553.0000 - tn: 282447.0000 - fn: 37553.0000 - accuracy: 0.8122 - precision: 0.5306 - recall: 0.5306 - auc: 0.8829 - val_loss: 0.6916 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6917 - tp: 42438.0000 - fp: 37562.0000 - tn: 282438.0000 - fn: 37562.0000 - accuracy: 0.8122 - precision: 0.5305 - recall: 0.5305 - auc: 0.8828 - val_loss: 0.6918 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[33m[INFO] loading file 2-2/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6917 - tp: 42435.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37565.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5304 - auc: 0.8825 - val_loss: 0.6920 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 70589.0000 - val_fn: 9411.0000 - val_accuracy: 0.8118 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-002-files-1-2
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4433 - tp: 67619.0000 - fp: 12381.0000 - tn: 307619.0000 - fn: 12381.0000 - accuracy: 0.9381 - precision: 0.8452 - recall: 0.8452 - auc: 0.9611 - val_loss: 0.1733 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-1-2
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3149 - tp: 72432.0000 - fp: 7568.0000 - tn: 312432.0000 - fn: 7568.0000 - accuracy: 0.9622 - precision: 0.9054 - recall: 0.9054 - auc: 0.9764 - val_loss: 1.1656 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 70593.0000 - val_fn: 9407.0000 - val_accuracy: 0.8119 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-002-files-1-2
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7175 - tp: 42321.0000 - fp: 37679.0000 - tn: 282321.0000 - fn: 37679.0000 - accuracy: 0.8116 - precision: 0.5290 - recall: 0.5290 - auc: 0.8823 - val_loss: 0.6918 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 70602.0000 - val_fn: 9398.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-002-files-1-2
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4478 - tp: 67360.0000 - fp: 12640.0000 - tn: 307360.0000 - fn: 12640.0000 - accuracy: 0.9368 - precision: 0.8420 - recall: 0.8420 - auc: 0.9607 - val_loss: 0.1710 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-1-2
[33m[INFO] loading file 3-3/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6958 - tp: 45236.0000 - fp: 34764.0000 - tn: 285236.0000 - fn: 34764.0000 - accuracy: 0.8262 - precision: 0.5655 - recall: 0.5655 - auc: 0.8914 - val_loss: 0.6944 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 70571.0000 - val_fn: 9429.0000 - val_accuracy: 0.8114 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.8821
[INFO] saving weights to checkpoints/dnn-epoch-002-files-2-3
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5939 - tp: 57751.0000 - fp: 22249.0000 - tn: 297751.0000 - fn: 22249.0000 - accuracy: 0.8888 - precision: 0.7219 - recall: 0.7219 - auc: 0.9306 - val_loss: 0.3247 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-2-3
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0625 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0200 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-2-3
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0139 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-2-3
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0082 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0067 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-2-3
[33m[INFO] loading file 4-4/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-3-4
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0046 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-3-4
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-3-4
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4220 - tp: 71528.0000 - fp: 8472.0000 - tn: 311528.0000 - fn: 8472.0000 - accuracy: 0.9576 - precision: 0.8941 - recall: 0.8941 - auc: 0.9705 - val_loss: 1.5082 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 67806.0000 - val_fn: 12194.0000 - val_accuracy: 0.7561 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.8476
[INFO] saving weights to checkpoints/dnn-epoch-002-files-3-4
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6126 - tp: 56887.0000 - fp: 23113.0000 - tn: 296887.0000 - fn: 23113.0000 - accuracy: 0.8844 - precision: 0.7111 - recall: 0.7111 - auc: 0.9278 - val_loss: 0.3420 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-3-4
[33m[INFO] loading file 5-5/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5273 - tp: 62445.0000 - fp: 17555.0000 - tn: 302445.0000 - fn: 17555.0000 - accuracy: 0.9122 - precision: 0.7806 - recall: 0.7806 - auc: 0.9449 - val_loss: 0.6997 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-002-files-4-5
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6551 - tp: 51316.0000 - fp: 28684.0000 - tn: 291316.0000 - fn: 28684.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9105 - val_loss: 0.5284 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 77052.0000 - val_fn: 2948.0000 - val_accuracy: 0.9410 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.9632
[INFO] saving weights to checkpoints/dnn-epoch-002-files-4-5
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0709 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-4-5
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-4-5
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0083 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-4-5
[33m[INFO] loading file 6-6/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0059 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-5-6
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-5-6
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-5-6
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2811 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 75632.0000 - val_fn: 4368.0000 - val_accuracy: 0.9126 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.8635
[INFO] saving weights to checkpoints/dnn-epoch-002-files-5-6
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8437 - tp: 51195.0000 - fp: 28805.0000 - tn: 291195.0000 - fn: 28805.0000 - accuracy: 0.8560 - precision: 0.6399 - recall: 0.6399 - auc: 0.9059 - val_loss: 0.6547 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 72768.0000 - val_fn: 7232.0000 - val_accuracy: 0.8554 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.9096
[INFO] saving weights to checkpoints/dnn-epoch-002-files-5-6
[33m[INFO] loading file 7-7/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6537 - tp: 51210.0000 - fp: 28790.0000 - tn: 291210.0000 - fn: 28790.0000 - accuracy: 0.8560 - precision: 0.6401 - recall: 0.6401 - auc: 0.9098 - val_loss: 0.6537 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 72803.0000 - val_fn: 7197.0000 - val_accuracy: 0.8561 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.9100
[INFO] saving weights to checkpoints/dnn-epoch-002-files-6-7
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51338.0000 - fp: 28662.0000 - tn: 291338.0000 - fn: 28662.0000 - accuracy: 0.8567 - precision: 0.6417 - recall: 0.6417 - auc: 0.9104 - val_loss: 0.6521 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-6-7
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4801 - tp: 65370.0000 - fp: 14630.0000 - tn: 305370.0000 - fn: 14630.0000 - accuracy: 0.9268 - precision: 0.8171 - recall: 0.8171 - auc: 0.9543 - val_loss: 0.2100 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-6-7
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0520 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0192 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-6-7
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0135 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0099 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-6-7
[33m[INFO] loading file 8-8/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0081 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0066 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-7-8
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-7-8
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0040 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-7-8
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3561 - tp: 73166.0000 - fp: 6834.0000 - tn: 313166.0000 - fn: 6834.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9768 - val_loss: 0.5536 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 76368.0000 - val_fn: 3632.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-002-files-7-8
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4811 - tp: 65505.0000 - fp: 14495.0000 - tn: 305505.0000 - fn: 14495.0000 - accuracy: 0.9275 - precision: 0.8188 - recall: 0.8188 - auc: 0.9546 - val_loss: 0.4729 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 76383.0000 - val_fn: 3617.0000 - val_accuracy: 0.9277 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.9548
[INFO] saving weights to checkpoints/dnn-epoch-002-files-7-8
[33m[INFO] loading file 9-9/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4773 - tp: 65300.0000 - fp: 14700.0000 - tn: 305300.0000 - fn: 14700.0000 - accuracy: 0.9265 - precision: 0.8163 - recall: 0.8163 - auc: 0.9542 - val_loss: 0.4804 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 76283.0000 - val_fn: 3717.0000 - val_accuracy: 0.9257 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.9535
[INFO] saving weights to checkpoints/dnn-epoch-002-files-8-9
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0976 - tp: 78936.0000 - fp: 1064.0000 - tn: 318936.0000 - fn: 1064.0000 - accuracy: 0.9947 - precision: 0.9867 - recall: 0.9867 - auc: 0.9967 - val_loss: 0.0268 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-8-9
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0171 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0116 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-8-9
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0092 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0074 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-8-9
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0063 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0054 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-8-9
[33m[INFO] loading file 10-10/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0043 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-9-10
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0084 - tp: 79936.0000 - fp: 64.0000 - tn: 319936.0000 - fn: 64.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 0.9995 - val_loss: 2.0147 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.7763
[INFO] saving weights to checkpoints/dnn-epoch-002-files-9-10
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7570 - tp: 56672.0000 - fp: 23328.0000 - tn: 296672.0000 - fn: 23328.0000 - accuracy: 0.8834 - precision: 0.7084 - recall: 0.7084 - auc: 0.9242 - val_loss: 0.3354 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-9-10
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0633 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0200 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-9-10
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0140 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-9-10
[33m[INFO] loading file 11-11/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0082 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0067 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-10-11
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-10-11
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-10-11
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-10-11
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-10-11
[33m[INFO] loading file 12-12/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0027 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0025 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-11-12
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0024 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0134 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 76689.0000 - val_fn: 3311.0000 - val_accuracy: 0.9338 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8965
[INFO] saving weights to checkpoints/dnn-epoch-002-files-11-12
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8649 - tp: 51328.0000 - fp: 28672.0000 - tn: 291328.0000 - fn: 28672.0000 - accuracy: 0.8566 - precision: 0.6416 - recall: 0.6416 - auc: 0.9042 - val_loss: 0.5681 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 75792.0000 - val_fn: 4208.0000 - val_accuracy: 0.9158 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.9474
[INFO] saving weights to checkpoints/dnn-epoch-002-files-11-12
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0713 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-11-12
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-11-12
[33m[INFO] loading file 13-13/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0083 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-12-13
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0059 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-12-13
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3615 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 75075.0000 - val_fn: 4925.0000 - val_accuracy: 0.9015 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.8461
[INFO] saving weights to checkpoints/dnn-epoch-002-files-12-13
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8172 - tp: 51313.0000 - fp: 28687.0000 - tn: 291313.0000 - fn: 28687.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9087 - val_loss: 0.6515 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-002-files-12-13
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51356.0000 - fp: 28644.0000 - tn: 291356.0000 - fn: 28644.0000 - accuracy: 0.8568 - precision: 0.6420 - recall: 0.6420 - auc: 0.9103 - val_loss: 0.6519 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-12-13
[33m[INFO] loading file 14-14/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5273 - tp: 62543.0000 - fp: 17457.0000 - tn: 302543.0000 - fn: 17457.0000 - accuracy: 0.9127 - precision: 0.7818 - recall: 0.7818 - auc: 0.9457 - val_loss: 0.2497 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-13-14
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0560 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0195 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-13-14
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0137 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0100 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-13-14
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0081 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0067 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-13-14
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-13-14
[33m[INFO] loading file 15-15/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0046 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0040 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-14-15
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0038 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-14-15
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-14-15
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0027 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.8617 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 71586.0000 - val_fn: 8414.0000 - val_accuracy: 0.8317 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.7371
[INFO] saving weights to checkpoints/dnn-epoch-002-files-14-15
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.8299 - tp: 42561.0000 - fp: 37439.0000 - tn: 282561.0000 - fn: 37439.0000 - accuracy: 0.8128 - precision: 0.5320 - recall: 0.5320 - auc: 0.8065 - val_loss: 0.7342 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 70627.0000 - val_fn: 9373.0000 - val_accuracy: 0.8125 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-002-files-14-15
[33m[INFO] loading file 16-16/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7177 - tp: 42492.0000 - fp: 37508.0000 - tn: 282492.0000 - fn: 37508.0000 - accuracy: 0.8125 - precision: 0.5311 - recall: 0.5311 - auc: 0.8826 - val_loss: 0.7087 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 70618.0000 - val_fn: 9382.0000 - val_accuracy: 0.8124 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-002-files-15-16
[INFO] processing batch 100000-200000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5997 - tp: 58381.0000 - fp: 21619.0000 - tn: 298381.0000 - fn: 21619.0000 - accuracy: 0.8919 - precision: 0.7298 - recall: 0.7298 - auc: 0.9323 - val_loss: 0.3276 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-15-16
[INFO] processing batch 200000-300000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0653 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0217 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-15-16
[INFO] processing batch 300000-400000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0153 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0112 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-15-16
[INFO] processing batch 400000-500000/439690
[33m[INFO] loading file 17-17/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0092 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0076 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-16-17
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0066 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0058 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-16-17
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0052 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0047 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-16-17
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9904 - tp: 68607.0000 - fp: 11393.0000 - tn: 308607.0000 - fn: 11393.0000 - accuracy: 0.9430 - precision: 0.8576 - recall: 0.8576 - auc: 0.9006 - val_loss: 0.7585 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 76369.0000 - val_fn: 3631.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9092
[INFO] saving weights to checkpoints/dnn-epoch-002-files-16-17
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5635 - tp: 65526.0000 - fp: 14474.0000 - tn: 305526.0000 - fn: 14474.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.9516 - val_loss: 0.3267 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 78648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9730 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9831
[INFO] saving weights to checkpoints/dnn-epoch-002-files-16-17
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 18-18/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3448 - tp: 72130.0000 - fp: 7870.0000 - tn: 312130.0000 - fn: 7870.0000 - accuracy: 0.9606 - precision: 0.9016 - recall: 0.9016 - auc: 0.9752 - val_loss: 0.9863 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 72369.0000 - val_fn: 7631.0000 - val_accuracy: 0.8474 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.9046
[INFO] saving weights to checkpoints/dnn-epoch-002-files-17-18
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7023 - tp: 49699.0000 - fp: 30301.0000 - tn: 289699.0000 - fn: 30301.0000 - accuracy: 0.8485 - precision: 0.6212 - recall: 0.6212 - auc: 0.9053 - val_loss: 0.6817 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 72357.0000 - val_fn: 7643.0000 - val_accuracy: 0.8471 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.9045
[INFO] saving weights to checkpoints/dnn-epoch-002-files-17-18
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6785 - tp: 49541.0000 - fp: 30459.0000 - tn: 289541.0000 - fn: 30459.0000 - accuracy: 0.8477 - precision: 0.6193 - recall: 0.6193 - auc: 0.9043 - val_loss: 0.6761 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 72397.0000 - val_fn: 7603.0000 - val_accuracy: 0.8479 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.9050
[INFO] saving weights to checkpoints/dnn-epoch-002-files-17-18
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2753 - tp: 74509.0000 - fp: 5491.0000 - tn: 314509.0000 - fn: 5491.0000 - accuracy: 0.9725 - precision: 0.9314 - recall: 0.9314 - auc: 0.9828 - val_loss: 0.0781 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-17-18
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0340 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0178 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-17-18
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 19-19/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0132 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-18-19
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0084 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0071 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-18-19
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0062 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0055 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-18-19
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6457 - tp: 69321.0000 - fp: 10679.0000 - tn: 309321.0000 - fn: 10679.0000 - accuracy: 0.9466 - precision: 0.8665 - recall: 0.8665 - auc: 0.9385 - val_loss: 1.5680 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 67882.0000 - val_fn: 12118.0000 - val_accuracy: 0.7576 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.8485
[INFO] saving weights to checkpoints/dnn-epoch-002-files-18-19
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7451 - tp: 44347.0000 - fp: 32453.0000 - tn: 287547.0000 - fn: 35653.0000 - accuracy: 0.8297 - precision: 0.5774 - recall: 0.5543 - auc: 0.8911 - val_loss: 0.9795 - val_tp: 0.0000e+00 - val_fp: 20000.0000 - val_tn: 60000.0000 - val_fn: 20000.0000 - val_accuracy: 0.6000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7500
[INFO] saving weights to checkpoints/dnn-epoch-002-files-18-19
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 20-20/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.1064 - tp: 78496.0000 - fp: 1248.0000 - tn: 318752.0000 - fn: 1504.0000 - accuracy: 0.9931 - precision: 0.9843 - recall: 0.9812 - auc: 0.9998 - val_loss: 0.1241 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 79491.0000 - val_fn: 509.0000 - val_accuracy: 0.9898 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9936
[INFO] saving weights to checkpoints/dnn-epoch-002-files-19-20
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5207 - tp: 65427.0000 - fp: 14573.0000 - tn: 305427.0000 - fn: 14573.0000 - accuracy: 0.9271 - precision: 0.8178 - recall: 0.8178 - auc: 0.9543 - val_loss: 0.4848 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 76357.0000 - val_fn: 3643.0000 - val_accuracy: 0.9271 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.9545
[INFO] saving weights to checkpoints/dnn-epoch-002-files-19-20
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4851 - tp: 65351.0000 - fp: 14649.0000 - tn: 305351.0000 - fn: 14649.0000 - accuracy: 0.9268 - precision: 0.8169 - recall: 0.8169 - auc: 0.9540 - val_loss: 0.4816 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 76371.0000 - val_fn: 3629.0000 - val_accuracy: 0.9274 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-002-files-19-20
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2110 - tp: 76024.0000 - fp: 3976.0000 - tn: 316024.0000 - fn: 3976.0000 - accuracy: 0.9801 - precision: 0.9503 - recall: 0.9503 - auc: 0.9875 - val_loss: 0.0576 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-19-20
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0287 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0163 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-19-20
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 21-21/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539688, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0123 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0096 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-20-21
[INFO] processing batch 100000-200000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0080 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-20-21
[INFO] processing batch 200000-300000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0060 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0053 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-20-21
[INFO] processing batch 300000-400000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0043 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-20-21
[INFO] processing batch 400000-500000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0040 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0037 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-20-21
[INFO] processing batch 500000-600000/539688
[33m[INFO] loading file 22-22/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.3341 - tp: 55006.0000 - fp: 24994.0000 - tn: 295006.0000 - fn: 24994.0000 - accuracy: 0.8750 - precision: 0.6876 - recall: 0.6876 - auc: 0.8475 - val_loss: 0.8139 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-002-files-21-22
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7325 - tp: 42398.0000 - fp: 37602.0000 - tn: 282398.0000 - fn: 37602.0000 - accuracy: 0.8120 - precision: 0.5300 - recall: 0.5300 - auc: 0.8821 - val_loss: 0.7173 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.8816
[INFO] saving weights to checkpoints/dnn-epoch-002-files-21-22
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7115 - tp: 42369.0000 - fp: 37631.0000 - tn: 282369.0000 - fn: 37631.0000 - accuracy: 0.8118 - precision: 0.5296 - recall: 0.5296 - auc: 0.8828 - val_loss: 0.7075 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 70623.0000 - val_fn: 9377.0000 - val_accuracy: 0.8125 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-002-files-21-22
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7052 - tp: 42452.0000 - fp: 37548.0000 - tn: 282452.0000 - fn: 37548.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5307 - auc: 0.8824 - val_loss: 0.7033 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 70601.0000 - val_fn: 9399.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-002-files-21-22
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7020 - tp: 42382.0000 - fp: 37618.0000 - tn: 282382.0000 - fn: 37618.0000 - accuracy: 0.8119 - precision: 0.5298 - recall: 0.5298 - auc: 0.8825 - val_loss: 0.7008 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-002-files-21-22
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 23-23/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6548 - tp: 52270.0000 - fp: 27730.0000 - tn: 292270.0000 - fn: 27730.0000 - accuracy: 0.8613 - precision: 0.6534 - recall: 0.6534 - auc: 0.9132 - val_loss: 0.4351 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-22-23
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0725 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0218 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-22-23
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0152 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0111 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-22-23
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0091 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0075 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-22-23
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0065 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0057 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-22-23
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 24-24/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0051 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0046 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-23-24
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0042 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0038 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-23-24
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0036 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0033 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-23-24
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-23-24
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2731 - tp: 75698.0000 - fp: 4302.0000 - tn: 315698.0000 - fn: 4302.0000 - accuracy: 0.9785 - precision: 0.9462 - recall: 0.9462 - auc: 0.9803 - val_loss: 1.3889 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 72912.0000 - val_fn: 7088.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-002-files-23-24
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 25-25/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7217 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9113 - val_loss: 0.6575 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-002-files-24-25
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6564 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6554 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-002-files-24-25
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6560 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9106 - val_loss: 0.6563 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-002-files-24-25
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6554 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6562 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-002-files-24-25
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6553 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9107 - val_loss: 0.6551 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-24-25
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 26-26/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6546 - tp: 51523.0000 - fp: 28477.0000 - tn: 291523.0000 - fn: 28477.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9107 - val_loss: 1.6333 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.8310
[INFO] saving weights to checkpoints/dnn-epoch-002-files-25-26
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.2145 - tp: 51579.0000 - fp: 28421.0000 - tn: 291579.0000 - fn: 28421.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.8512 - val_loss: 0.7019 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-25-26
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6829 - tp: 51462.0000 - fp: 28538.0000 - tn: 291462.0000 - fn: 28538.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9105 - val_loss: 0.6712 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-002-files-25-26
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6679 - tp: 51506.0000 - fp: 28494.0000 - tn: 291506.0000 - fn: 28494.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6630 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 72936.0000 - val_fn: 7064.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-002-files-25-26
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6631 - tp: 51474.0000 - fp: 28526.0000 - tn: 291474.0000 - fn: 28526.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9107 - val_loss: 0.6592 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 72945.0000 - val_fn: 7055.0000 - val_accuracy: 0.8589 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.9118
[INFO] saving weights to checkpoints/dnn-epoch-002-files-25-26
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 27-27/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (479817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6609 - tp: 51419.0000 - fp: 28581.0000 - tn: 291419.0000 - fn: 28581.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9109 - val_loss: 0.6607 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-002-files-26-27
[INFO] processing batch 100000-200000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6588 - tp: 51485.0000 - fp: 28515.0000 - tn: 291485.0000 - fn: 28515.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9105 - val_loss: 0.6568 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 72918.0000 - val_fn: 7082.0000 - val_accuracy: 0.8584 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-002-files-26-27
[INFO] processing batch 200000-300000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6569 - tp: 51583.0000 - fp: 28417.0000 - tn: 291583.0000 - fn: 28417.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9109 - val_loss: 0.6575 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-26-27
[INFO] processing batch 300000-400000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6575 - tp: 51396.0000 - fp: 28604.0000 - tn: 291396.0000 - fn: 28604.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9102 - val_loss: 0.6571 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 72851.0000 - val_fn: 7149.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-002-files-26-27
[INFO] processing batch 400000-500000/479817
[33m[INFO] loading file 28-28/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6563 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6559 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-27-28
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6564 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9103 - val_loss: 0.6558 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-27-28
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6555 - tp: 51458.0000 - fp: 28542.0000 - tn: 291458.0000 - fn: 28542.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9113 - val_loss: 0.6552 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-27-28
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6552 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9107 - val_loss: 0.6539 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-002-files-27-28
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6545 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9105 - val_loss: 0.6551 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-27-28
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 29-29/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6547 - tp: 51460.0000 - fp: 28540.0000 - tn: 291460.0000 - fn: 28540.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9109 - val_loss: 0.6550 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-28-29
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6540 - tp: 51527.0000 - fp: 28473.0000 - tn: 291527.0000 - fn: 28473.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6549 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-002-files-28-29
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6541 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6523 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-002-files-28-29
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6534 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9110 - val_loss: 0.6544 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-28-29
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6536 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-28-29
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 30-30/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6534 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9112 - val_loss: 0.6540 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-29-30
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51450.0000 - fp: 28550.0000 - tn: 291450.0000 - fn: 28550.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9106 - val_loss: 0.6541 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-29-30
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6535 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6539 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-29-30
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6532 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-002-files-29-30
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9111 - val_loss: 0.6533 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 72870.0000 - val_fn: 7130.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-29-30
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 31-31/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 72921.0000 - val_fn: 7079.0000 - val_accuracy: 0.8584 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-002-files-30-31
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51524.0000 - fp: 28476.0000 - tn: 291524.0000 - fn: 28476.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6522 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 72902.0000 - val_fn: 7098.0000 - val_accuracy: 0.8580 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-002-files-30-31
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6535 - tp: 51428.0000 - fp: 28572.0000 - tn: 291428.0000 - fn: 28572.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9107 - val_loss: 0.6529 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-30-31
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9104 - val_loss: 0.6525 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-30-31
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6523 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 72893.0000 - val_fn: 7107.0000 - val_accuracy: 0.8579 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-002-files-30-31
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 32-32/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6523 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-31-32
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51531.0000 - fp: 28469.0000 - tn: 291531.0000 - fn: 28469.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6527 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-31-32
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51576.0000 - fp: 28424.0000 - tn: 291576.0000 - fn: 28424.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9112 - val_loss: 0.6522 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-31-32
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51489.0000 - fp: 28511.0000 - tn: 291489.0000 - fn: 28511.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6529 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-31-32
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6530 - tp: 51449.0000 - fp: 28551.0000 - tn: 291449.0000 - fn: 28551.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9108 - val_loss: 0.6528 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-31-32
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 33-33/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6525 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-32-33
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6528 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-32-33
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51404.0000 - fp: 28596.0000 - tn: 291404.0000 - fn: 28596.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9104 - val_loss: 0.6528 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-32-33
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51552.0000 - fp: 28448.0000 - tn: 291552.0000 - fn: 28448.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9109 - val_loss: 0.6521 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-32-33
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51594.0000 - fp: 28406.0000 - tn: 291594.0000 - fn: 28406.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9111 - val_loss: 0.6508 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-002-files-32-33
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 34-34/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9105 - val_loss: 0.6533 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-002-files-33-34
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9104 - val_loss: 0.6526 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-33-34
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51588.0000 - fp: 28412.0000 - tn: 291588.0000 - fn: 28412.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9111 - val_loss: 0.6524 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-002-files-33-34
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6530 - tp: 51408.0000 - fp: 28592.0000 - tn: 291408.0000 - fn: 28592.0000 - accuracy: 0.8570 - precision: 0.6426 - recall: 0.6426 - auc: 0.9104 - val_loss: 0.6535 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 72834.0000 - val_fn: 7166.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-002-files-33-34
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6523 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-002-files-33-34
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 35-35/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51520.0000 - fp: 28480.0000 - tn: 291520.0000 - fn: 28480.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9113 - val_loss: 0.6529 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-34-35
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6522 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-002-files-34-35
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9111 - val_loss: 0.6518 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-34-35
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51521.0000 - fp: 28479.0000 - tn: 291521.0000 - fn: 28479.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9107 - val_loss: 0.6528 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-34-35
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51570.0000 - fp: 28430.0000 - tn: 291570.0000 - fn: 28430.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9109 - val_loss: 0.6523 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-34-35
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 36-36/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6522 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-35-36
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51644.0000 - fp: 28356.0000 - tn: 291644.0000 - fn: 28356.0000 - accuracy: 0.8582 - precision: 0.6456 - recall: 0.6456 - auc: 0.9113 - val_loss: 0.6516 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 72895.0000 - val_fn: 7105.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-002-files-35-36
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9104 - val_loss: 0.6504 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 72933.0000 - val_fn: 7067.0000 - val_accuracy: 0.8587 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-002-files-35-36
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51415.0000 - fp: 28585.0000 - tn: 291415.0000 - fn: 28585.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9104 - val_loss: 0.6520 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 72878.0000 - val_fn: 7122.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-002-files-35-36
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9105 - val_loss: 0.6527 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-35-36
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 37-37/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51413.0000 - fp: 28587.0000 - tn: 291413.0000 - fn: 28587.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9105 - val_loss: 0.6528 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-36-37
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51456.0000 - fp: 28544.0000 - tn: 291456.0000 - fn: 28544.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9106 - val_loss: 0.6513 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-002-files-36-37
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51565.0000 - fp: 28435.0000 - tn: 291565.0000 - fn: 28435.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9106 - val_loss: 0.6522 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-36-37
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51512.0000 - fp: 28488.0000 - tn: 291512.0000 - fn: 28488.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6516 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 72888.0000 - val_fn: 7112.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-36-37
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51528.0000 - fp: 28472.0000 - tn: 291528.0000 - fn: 28472.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9107 - val_loss: 0.6513 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 72899.0000 - val_fn: 7101.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-002-files-36-37
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 38-38/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51513.0000 - fp: 28487.0000 - tn: 291513.0000 - fn: 28487.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9106 - val_loss: 0.6503 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-002-files-37-38
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51589.0000 - fp: 28411.0000 - tn: 291589.0000 - fn: 28411.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9115 - val_loss: 0.6530 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-002-files-37-38
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51481.0000 - fp: 28519.0000 - tn: 291481.0000 - fn: 28519.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9110 - val_loss: 0.6526 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-37-38
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51549.0000 - fp: 28451.0000 - tn: 291549.0000 - fn: 28451.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9110 - val_loss: 0.6513 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 72898.0000 - val_fn: 7102.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-002-files-37-38
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9109 - val_loss: 0.6522 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 72866.0000 - val_fn: 7134.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-37-38
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 39-39/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6529 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 72847.0000 - val_fn: 7153.0000 - val_accuracy: 0.8569 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-002-files-38-39
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51597.0000 - fp: 28403.0000 - tn: 291597.0000 - fn: 28403.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9113 - val_loss: 0.6509 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 72910.0000 - val_fn: 7090.0000 - val_accuracy: 0.8582 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-002-files-38-39
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51631.0000 - fp: 28369.0000 - tn: 291631.0000 - fn: 28369.0000 - accuracy: 0.8582 - precision: 0.6454 - recall: 0.6454 - auc: 0.9112 - val_loss: 0.6514 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-002-files-38-39
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6521 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-38-39
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6519 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-38-39
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 40-40/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51418.0000 - fp: 28582.0000 - tn: 291418.0000 - fn: 28582.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9105 - val_loss: 0.6528 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-002-files-39-40
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51491.0000 - fp: 28509.0000 - tn: 291491.0000 - fn: 28509.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6523 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-39-40
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9108 - val_loss: 0.6507 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 72916.0000 - val_fn: 7084.0000 - val_accuracy: 0.8583 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-002-files-39-40
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9106 - val_loss: 0.6529 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 72838.0000 - val_fn: 7162.0000 - val_accuracy: 0.8568 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-002-files-39-40
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51432.0000 - fp: 28568.0000 - tn: 291432.0000 - fn: 28568.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9108 - val_loss: 0.6526 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-002-files-39-40
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 41-41/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9108 - val_loss: 0.6523 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-40-41
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51515.0000 - fp: 28485.0000 - tn: 291515.0000 - fn: 28485.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9107 - val_loss: 0.6521 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-40-41
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9106 - val_loss: 0.6518 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-002-files-40-41
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51587.0000 - fp: 28413.0000 - tn: 291587.0000 - fn: 28413.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9111 - val_loss: 0.6524 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-40-41
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9107 - val_loss: 0.6500 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 72937.0000 - val_fn: 7063.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-002-files-40-41
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 42-42/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9106 - val_loss: 0.6533 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 72826.0000 - val_fn: 7174.0000 - val_accuracy: 0.8565 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-002-files-41-42
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51511.0000 - fp: 28489.0000 - tn: 291511.0000 - fn: 28489.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.6516 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 72882.0000 - val_fn: 7118.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-002-files-41-42
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51499.0000 - fp: 28501.0000 - tn: 291499.0000 - fn: 28501.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6525 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 72853.0000 - val_fn: 7147.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-41-42
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6507 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 72917.0000 - val_fn: 7083.0000 - val_accuracy: 0.8583 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-002-files-41-42
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51584.0000 - fp: 28416.0000 - tn: 291584.0000 - fn: 28416.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9112 - val_loss: 0.6518 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-41-42
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 43-43/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9111 - val_loss: 0.6518 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-42-43
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6534 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 72824.0000 - val_fn: 7176.0000 - val_accuracy: 0.8565 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-002-files-42-43
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51387.0000 - fp: 28613.0000 - tn: 291387.0000 - fn: 28613.0000 - accuracy: 0.8569 - precision: 0.6423 - recall: 0.6423 - auc: 0.9106 - val_loss: 0.6512 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-002-files-42-43
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9107 - val_loss: 0.6527 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-002-files-42-43
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9113 - val_loss: 0.6495 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 72952.0000 - val_fn: 7048.0000 - val_accuracy: 0.8590 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.9119
[INFO] saving weights to checkpoints/dnn-epoch-002-files-42-43
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 44-44/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9105 - val_loss: 0.6523 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-43-44
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6523 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-43-44
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51543.0000 - fp: 28457.0000 - tn: 291543.0000 - fn: 28457.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9113 - val_loss: 0.6523 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-43-44
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6523 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9108 - val_loss: 0.6513 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 72891.0000 - val_fn: 7109.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-43-44
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51537.0000 - fp: 28463.0000 - tn: 291537.0000 - fn: 28463.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9112 - val_loss: 0.6523 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-43-44
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 45-45/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51620.0000 - fp: 28380.0000 - tn: 291620.0000 - fn: 28380.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9113 - val_loss: 0.6519 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-44-45
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51538.0000 - fp: 28462.0000 - tn: 291538.0000 - fn: 28462.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9109 - val_loss: 0.6515 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-44-45
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51564.0000 - fp: 28436.0000 - tn: 291564.0000 - fn: 28436.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.6509 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 72904.0000 - val_fn: 7096.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-002-files-44-45
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51590.0000 - fp: 28410.0000 - tn: 291590.0000 - fn: 28410.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9113 - val_loss: 0.6526 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-002-files-44-45
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51395.0000 - fp: 28605.0000 - tn: 291395.0000 - fn: 28605.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9103 - val_loss: 0.6511 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-002-files-44-45
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 46-46/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6506 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 72913.0000 - val_fn: 7087.0000 - val_accuracy: 0.8583 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-002-files-45-46
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51464.0000 - fp: 28536.0000 - tn: 291464.0000 - fn: 28536.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9107 - val_loss: 0.6515 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 72883.0000 - val_fn: 7117.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-002-files-45-46
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9113 - val_loss: 0.6516 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-45-46
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9111 - val_loss: 0.6502 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-002-files-45-46
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51569.0000 - fp: 28431.0000 - tn: 291569.0000 - fn: 28431.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9111 - val_loss: 0.6518 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-45-46
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 47-47/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51601.0000 - fp: 28399.0000 - tn: 291601.0000 - fn: 28399.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9115 - val_loss: 0.6512 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-46-47
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51559.0000 - fp: 28441.0000 - tn: 291559.0000 - fn: 28441.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9109 - val_loss: 0.6519 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-46-47
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9105 - val_loss: 0.6533 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 72822.0000 - val_fn: 7178.0000 - val_accuracy: 0.8564 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-002-files-46-47
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6515 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 72881.0000 - val_fn: 7119.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-002-files-46-47
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9112 - val_loss: 0.6506 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 72909.0000 - val_fn: 7091.0000 - val_accuracy: 0.8582 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-002-files-46-47
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 48-48/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6530 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 72830.0000 - val_fn: 7170.0000 - val_accuracy: 0.8566 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-002-files-47-48
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6515 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 72879.0000 - val_fn: 7121.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-002-files-47-48
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51547.0000 - fp: 28453.0000 - tn: 291547.0000 - fn: 28453.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9107 - val_loss: 0.6506 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-002-files-47-48
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9108 - val_loss: 0.6520 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-47-48
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51606.0000 - fp: 28394.0000 - tn: 291606.0000 - fn: 28394.0000 - accuracy: 0.8580 - precision: 0.6451 - recall: 0.6451 - auc: 0.9113 - val_loss: 0.6508 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 72905.0000 - val_fn: 7095.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-002-files-47-48
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 49-49/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9114 - val_loss: 0.6519 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-48-49
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51430.0000 - fp: 28570.0000 - tn: 291430.0000 - fn: 28570.0000 - accuracy: 0.8571 - precision: 0.6429 - recall: 0.6429 - auc: 0.9108 - val_loss: 0.6502 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 72924.0000 - val_fn: 7076.0000 - val_accuracy: 0.8585 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-002-files-48-49
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51469.0000 - fp: 28531.0000 - tn: 291469.0000 - fn: 28531.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6530 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-002-files-48-49
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6502 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 72922.0000 - val_fn: 7078.0000 - val_accuracy: 0.8584 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-002-files-48-49
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51495.0000 - fp: 28505.0000 - tn: 291495.0000 - fn: 28505.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6512 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-48-49
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 50-50/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6531 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 72823.0000 - val_fn: 7177.0000 - val_accuracy: 0.8565 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-002-files-49-50
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51482.0000 - fp: 28518.0000 - tn: 291482.0000 - fn: 28518.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9104 - val_loss: 0.6511 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-49-50
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51433.0000 - fp: 28567.0000 - tn: 291433.0000 - fn: 28567.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9106 - val_loss: 0.6525 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-002-files-49-50
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51461.0000 - fp: 28539.0000 - tn: 291461.0000 - fn: 28539.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6512 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-49-50
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51467.0000 - fp: 28533.0000 - tn: 291467.0000 - fn: 28533.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9109 - val_loss: 0.6521 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-49-50
[INFO] processing batch 500000-600000/519975
[33m[LOSS] 0.652146178150177[0m
[33m[INFO] epoch 3/10[0m
[33m[INFO] loading file 1-1/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0707 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0227 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9993 - val_loss: 2.2979 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.8826
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8374 - tp: 42447.0000 - fp: 37553.0000 - tn: 282447.0000 - fn: 37553.0000 - accuracy: 0.8122 - precision: 0.5306 - recall: 0.5306 - auc: 0.8828 - val_loss: 0.6916 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6917 - tp: 42438.0000 - fp: 37562.0000 - tn: 282438.0000 - fn: 37562.0000 - accuracy: 0.8122 - precision: 0.5305 - recall: 0.5305 - auc: 0.8825 - val_loss: 0.6917 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[33m[INFO] loading file 2-2/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6917 - tp: 42435.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37565.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5304 - auc: 0.8827 - val_loss: 0.6918 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 70589.0000 - val_fn: 9411.0000 - val_accuracy: 0.8118 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-003-files-1-2
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4428 - tp: 67619.0000 - fp: 12381.0000 - tn: 307619.0000 - fn: 12381.0000 - accuracy: 0.9381 - precision: 0.8452 - recall: 0.8452 - auc: 0.9610 - val_loss: 0.1708 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-1-2
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3149 - tp: 72432.0000 - fp: 7568.0000 - tn: 312432.0000 - fn: 7568.0000 - accuracy: 0.9622 - precision: 0.9054 - recall: 0.9054 - auc: 0.9762 - val_loss: 1.1619 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 70593.0000 - val_fn: 9407.0000 - val_accuracy: 0.8119 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-003-files-1-2
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7173 - tp: 42321.0000 - fp: 37679.0000 - tn: 282321.0000 - fn: 37679.0000 - accuracy: 0.8116 - precision: 0.5290 - recall: 0.5290 - auc: 0.8820 - val_loss: 0.6918 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 70602.0000 - val_fn: 9398.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-003-files-1-2
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4475 - tp: 67360.0000 - fp: 12640.0000 - tn: 307360.0000 - fn: 12640.0000 - accuracy: 0.9368 - precision: 0.8420 - recall: 0.8420 - auc: 0.9604 - val_loss: 0.1767 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-1-2
[33m[INFO] loading file 3-3/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6948 - tp: 45236.0000 - fp: 34764.0000 - tn: 285236.0000 - fn: 34764.0000 - accuracy: 0.8262 - precision: 0.5655 - recall: 0.5655 - auc: 0.8913 - val_loss: 0.6947 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 70571.0000 - val_fn: 9429.0000 - val_accuracy: 0.8114 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.8821
[INFO] saving weights to checkpoints/dnn-epoch-003-files-2-3
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5938 - tp: 57751.0000 - fp: 22249.0000 - tn: 297751.0000 - fn: 22249.0000 - accuracy: 0.8888 - precision: 0.7219 - recall: 0.7219 - auc: 0.9305 - val_loss: 0.3217 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-2-3
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0622 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0200 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-2-3
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0139 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-2-3
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0082 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0067 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-2-3
[33m[INFO] loading file 4-4/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-3-4
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0046 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-3-4
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-3-4
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4225 - tp: 71528.0000 - fp: 8472.0000 - tn: 311528.0000 - fn: 8472.0000 - accuracy: 0.9576 - precision: 0.8941 - recall: 0.8941 - auc: 0.9702 - val_loss: 1.5156 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 67806.0000 - val_fn: 12194.0000 - val_accuracy: 0.7561 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.8476
[INFO] saving weights to checkpoints/dnn-epoch-003-files-3-4
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6129 - tp: 56887.0000 - fp: 23113.0000 - tn: 296887.0000 - fn: 23113.0000 - accuracy: 0.8844 - precision: 0.7111 - recall: 0.7111 - auc: 0.9278 - val_loss: 0.3430 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-3-4
[33m[INFO] loading file 5-5/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5272 - tp: 62445.0000 - fp: 17555.0000 - tn: 302445.0000 - fn: 17555.0000 - accuracy: 0.9122 - precision: 0.7806 - recall: 0.7806 - auc: 0.9450 - val_loss: 0.7036 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-003-files-4-5
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6554 - tp: 51316.0000 - fp: 28684.0000 - tn: 291316.0000 - fn: 28684.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9103 - val_loss: 0.5285 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 77052.0000 - val_fn: 2948.0000 - val_accuracy: 0.9410 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.9632
[INFO] saving weights to checkpoints/dnn-epoch-003-files-4-5
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0709 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-4-5
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-4-5
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0083 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-4-5
[33m[INFO] loading file 6-6/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0059 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-5-6
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-5-6
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-5-6
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2811 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 75632.0000 - val_fn: 4368.0000 - val_accuracy: 0.9126 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.8635
[INFO] saving weights to checkpoints/dnn-epoch-003-files-5-6
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8464 - tp: 51195.0000 - fp: 28805.0000 - tn: 291195.0000 - fn: 28805.0000 - accuracy: 0.8560 - precision: 0.6399 - recall: 0.6399 - auc: 0.9052 - val_loss: 0.6547 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 72768.0000 - val_fn: 7232.0000 - val_accuracy: 0.8554 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.9096
[INFO] saving weights to checkpoints/dnn-epoch-003-files-5-6
[33m[INFO] loading file 7-7/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6537 - tp: 51210.0000 - fp: 28790.0000 - tn: 291210.0000 - fn: 28790.0000 - accuracy: 0.8561 - precision: 0.6401 - recall: 0.6401 - auc: 0.9099 - val_loss: 0.6537 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 72803.0000 - val_fn: 7197.0000 - val_accuracy: 0.8561 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.9100
[INFO] saving weights to checkpoints/dnn-epoch-003-files-6-7
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51338.0000 - fp: 28662.0000 - tn: 291338.0000 - fn: 28662.0000 - accuracy: 0.8567 - precision: 0.6417 - recall: 0.6417 - auc: 0.9102 - val_loss: 0.6520 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-6-7
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4799 - tp: 65370.0000 - fp: 14630.0000 - tn: 305370.0000 - fn: 14630.0000 - accuracy: 0.9269 - precision: 0.8171 - recall: 0.8171 - auc: 0.9543 - val_loss: 0.1999 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-6-7
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0509 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0191 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-6-7
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0135 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0099 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-6-7
[33m[INFO] loading file 8-8/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0080 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0066 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-7-8
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0057 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-7-8
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0040 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-7-8
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3564 - tp: 73166.0000 - fp: 6834.0000 - tn: 313166.0000 - fn: 6834.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9766 - val_loss: 0.5534 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 76368.0000 - val_fn: 3632.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-003-files-7-8
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4811 - tp: 65505.0000 - fp: 14495.0000 - tn: 305505.0000 - fn: 14495.0000 - accuracy: 0.9275 - precision: 0.8188 - recall: 0.8188 - auc: 0.9546 - val_loss: 0.4729 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 76383.0000 - val_fn: 3617.0000 - val_accuracy: 0.9277 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.9548
[INFO] saving weights to checkpoints/dnn-epoch-003-files-7-8
[33m[INFO] loading file 9-9/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4773 - tp: 65300.0000 - fp: 14700.0000 - tn: 305300.0000 - fn: 14700.0000 - accuracy: 0.9265 - precision: 0.8163 - recall: 0.8163 - auc: 0.9542 - val_loss: 0.4804 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 76283.0000 - val_fn: 3717.0000 - val_accuracy: 0.9257 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.9535
[INFO] saving weights to checkpoints/dnn-epoch-003-files-8-9
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0980 - tp: 78936.0000 - fp: 1064.0000 - tn: 318936.0000 - fn: 1064.0000 - accuracy: 0.9947 - precision: 0.9867 - recall: 0.9867 - auc: 0.9966 - val_loss: 0.0270 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-8-9
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0172 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0116 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-8-9
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0092 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0074 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-8-9
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0063 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0054 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-8-9
[33m[INFO] loading file 10-10/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0043 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-9-10
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0084 - tp: 79936.0000 - fp: 64.0000 - tn: 319936.0000 - fn: 64.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 0.9995 - val_loss: 2.0143 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.7763
[INFO] saving weights to checkpoints/dnn-epoch-003-files-9-10
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7562 - tp: 56672.0000 - fp: 23328.0000 - tn: 296672.0000 - fn: 23328.0000 - accuracy: 0.8834 - precision: 0.7084 - recall: 0.7084 - auc: 0.9245 - val_loss: 0.3377 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-9-10
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0635 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0201 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-9-10
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0140 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-9-10
[33m[INFO] loading file 11-11/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0082 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0067 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-10-11
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-10-11
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-10-11
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-10-11
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-10-11
[33m[INFO] loading file 12-12/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0027 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0025 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-11-12
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0024 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0134 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 76689.0000 - val_fn: 3311.0000 - val_accuracy: 0.9338 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8965
[INFO] saving weights to checkpoints/dnn-epoch-003-files-11-12
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8651 - tp: 51328.0000 - fp: 28672.0000 - tn: 291328.0000 - fn: 28672.0000 - accuracy: 0.8566 - precision: 0.6416 - recall: 0.6416 - auc: 0.9041 - val_loss: 0.5646 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 75792.0000 - val_fn: 4208.0000 - val_accuracy: 0.9158 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.9474
[INFO] saving weights to checkpoints/dnn-epoch-003-files-11-12
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0707 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0204 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-11-12
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-11-12
[33m[INFO] loading file 13-13/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0083 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-12-13
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0059 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-12-13
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3615 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 75075.0000 - val_fn: 4925.0000 - val_accuracy: 0.9015 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.8461
[INFO] saving weights to checkpoints/dnn-epoch-003-files-12-13
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8175 - tp: 51313.0000 - fp: 28687.0000 - tn: 291313.0000 - fn: 28687.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9086 - val_loss: 0.6516 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-003-files-12-13
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51356.0000 - fp: 28644.0000 - tn: 291356.0000 - fn: 28644.0000 - accuracy: 0.8568 - precision: 0.6420 - recall: 0.6420 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-12-13
[33m[INFO] loading file 14-14/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5270 - tp: 62543.0000 - fp: 17457.0000 - tn: 302543.0000 - fn: 17457.0000 - accuracy: 0.9127 - precision: 0.7818 - recall: 0.7818 - auc: 0.9455 - val_loss: 0.2471 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-13-14
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0557 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0195 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-13-14
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0137 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0100 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-13-14
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0081 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0067 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-13-14
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-13-14
[33m[INFO] loading file 15-15/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0046 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0040 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-14-15
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0038 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-14-15
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-14-15
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0027 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.8648 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 71586.0000 - val_fn: 8414.0000 - val_accuracy: 0.8317 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.7371
[INFO] saving weights to checkpoints/dnn-epoch-003-files-14-15
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.8325 - tp: 42561.0000 - fp: 37439.0000 - tn: 282561.0000 - fn: 37439.0000 - accuracy: 0.8128 - precision: 0.5320 - recall: 0.5320 - auc: 0.8062 - val_loss: 0.7341 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 70627.0000 - val_fn: 9373.0000 - val_accuracy: 0.8125 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-003-files-14-15
[33m[INFO] loading file 16-16/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7177 - tp: 42492.0000 - fp: 37508.0000 - tn: 282492.0000 - fn: 37508.0000 - accuracy: 0.8125 - precision: 0.5311 - recall: 0.5311 - auc: 0.8826 - val_loss: 0.7087 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 70618.0000 - val_fn: 9382.0000 - val_accuracy: 0.8124 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-003-files-15-16
[INFO] processing batch 100000-200000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5997 - tp: 58381.0000 - fp: 21619.0000 - tn: 298381.0000 - fn: 21619.0000 - accuracy: 0.8919 - precision: 0.7298 - recall: 0.7298 - auc: 0.9326 - val_loss: 0.3219 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-15-16
[INFO] processing batch 200000-300000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0648 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0217 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-15-16
[INFO] processing batch 300000-400000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0153 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0112 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-15-16
[INFO] processing batch 400000-500000/439690
[33m[INFO] loading file 17-17/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0092 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0076 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-16-17
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0066 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0058 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-16-17
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0052 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0047 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-16-17
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9902 - tp: 68607.0000 - fp: 11393.0000 - tn: 308607.0000 - fn: 11393.0000 - accuracy: 0.9430 - precision: 0.8576 - recall: 0.8576 - auc: 0.9007 - val_loss: 0.7577 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 76369.0000 - val_fn: 3631.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9092
[INFO] saving weights to checkpoints/dnn-epoch-003-files-16-17
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5637 - tp: 65526.0000 - fp: 14474.0000 - tn: 305526.0000 - fn: 14474.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.9516 - val_loss: 0.3277 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 78648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9730 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9831
[INFO] saving weights to checkpoints/dnn-epoch-003-files-16-17
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 18-18/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3448 - tp: 72130.0000 - fp: 7870.0000 - tn: 312130.0000 - fn: 7870.0000 - accuracy: 0.9606 - precision: 0.9016 - recall: 0.9016 - auc: 0.9754 - val_loss: 0.9850 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 72369.0000 - val_fn: 7631.0000 - val_accuracy: 0.8474 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.9046
[INFO] saving weights to checkpoints/dnn-epoch-003-files-17-18
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7016 - tp: 49699.0000 - fp: 30301.0000 - tn: 289699.0000 - fn: 30301.0000 - accuracy: 0.8485 - precision: 0.6212 - recall: 0.6212 - auc: 0.9053 - val_loss: 0.6819 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 72357.0000 - val_fn: 7643.0000 - val_accuracy: 0.8471 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.9045
[INFO] saving weights to checkpoints/dnn-epoch-003-files-17-18
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6785 - tp: 49541.0000 - fp: 30459.0000 - tn: 289541.0000 - fn: 30459.0000 - accuracy: 0.8477 - precision: 0.6193 - recall: 0.6193 - auc: 0.9050 - val_loss: 0.6762 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 72397.0000 - val_fn: 7603.0000 - val_accuracy: 0.8479 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.9050
[INFO] saving weights to checkpoints/dnn-epoch-003-files-17-18
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2745 - tp: 74509.0000 - fp: 5491.0000 - tn: 314509.0000 - fn: 5491.0000 - accuracy: 0.9725 - precision: 0.9314 - recall: 0.9314 - auc: 0.9830 - val_loss: 0.0757 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-17-18
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0335 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0176 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-17-18
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 19-19/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0131 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-18-19
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0084 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0071 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-18-19
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0062 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0055 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-18-19
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6458 - tp: 69321.0000 - fp: 10679.0000 - tn: 309321.0000 - fn: 10679.0000 - accuracy: 0.9466 - precision: 0.8665 - recall: 0.8665 - auc: 0.9384 - val_loss: 1.5615 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 67882.0000 - val_fn: 12118.0000 - val_accuracy: 0.7576 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.8485
[INFO] saving weights to checkpoints/dnn-epoch-003-files-18-19
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7452 - tp: 44424.0000 - fp: 32696.0000 - tn: 287304.0000 - fn: 35576.0000 - accuracy: 0.8293 - precision: 0.5760 - recall: 0.5553 - auc: 0.8909 - val_loss: 0.9673 - val_tp: 0.0000e+00 - val_fp: 20000.0000 - val_tn: 60000.0000 - val_fn: 20000.0000 - val_accuracy: 0.6000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7500
[INFO] saving weights to checkpoints/dnn-epoch-003-files-18-19
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 20-20/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.1058 - tp: 78528.0000 - fp: 1184.0000 - tn: 318816.0000 - fn: 1472.0000 - accuracy: 0.9934 - precision: 0.9851 - recall: 0.9816 - auc: 0.9999 - val_loss: 0.1241 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 79491.0000 - val_fn: 509.0000 - val_accuracy: 0.9898 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9936
[INFO] saving weights to checkpoints/dnn-epoch-003-files-19-20
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5197 - tp: 65427.0000 - fp: 14573.0000 - tn: 305427.0000 - fn: 14573.0000 - accuracy: 0.9271 - precision: 0.8178 - recall: 0.8178 - auc: 0.9550 - val_loss: 0.4848 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 76357.0000 - val_fn: 3643.0000 - val_accuracy: 0.9271 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.9545
[INFO] saving weights to checkpoints/dnn-epoch-003-files-19-20
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4851 - tp: 65351.0000 - fp: 14649.0000 - tn: 305351.0000 - fn: 14649.0000 - accuracy: 0.9268 - precision: 0.8169 - recall: 0.8169 - auc: 0.9542 - val_loss: 0.4816 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 76371.0000 - val_fn: 3629.0000 - val_accuracy: 0.9274 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-003-files-19-20
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2115 - tp: 76024.0000 - fp: 3976.0000 - tn: 316024.0000 - fn: 3976.0000 - accuracy: 0.9801 - precision: 0.9503 - recall: 0.9503 - auc: 0.9874 - val_loss: 0.0585 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-19-20
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0289 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0164 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-19-20
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 21-21/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539688, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0124 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0096 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-20-21
[INFO] processing batch 100000-200000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0080 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-20-21
[INFO] processing batch 200000-300000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0060 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0053 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-20-21
[INFO] processing batch 300000-400000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0043 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-20-21
[INFO] processing batch 400000-500000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0040 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0037 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-20-21
[INFO] processing batch 500000-600000/539688
[33m[INFO] loading file 22-22/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.3349 - tp: 55006.0000 - fp: 24994.0000 - tn: 295006.0000 - fn: 24994.0000 - accuracy: 0.8750 - precision: 0.6876 - recall: 0.6876 - auc: 0.8469 - val_loss: 0.8126 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-003-files-21-22
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7320 - tp: 42398.0000 - fp: 37602.0000 - tn: 282398.0000 - fn: 37602.0000 - accuracy: 0.8120 - precision: 0.5300 - recall: 0.5300 - auc: 0.8825 - val_loss: 0.7172 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.8816
[INFO] saving weights to checkpoints/dnn-epoch-003-files-21-22
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7115 - tp: 42369.0000 - fp: 37631.0000 - tn: 282369.0000 - fn: 37631.0000 - accuracy: 0.8118 - precision: 0.5296 - recall: 0.5296 - auc: 0.8822 - val_loss: 0.7074 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 70623.0000 - val_fn: 9377.0000 - val_accuracy: 0.8125 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-003-files-21-22
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7052 - tp: 42452.0000 - fp: 37548.0000 - tn: 282452.0000 - fn: 37548.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5307 - auc: 0.8823 - val_loss: 0.7033 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 70601.0000 - val_fn: 9399.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-003-files-21-22
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7020 - tp: 42382.0000 - fp: 37618.0000 - tn: 282382.0000 - fn: 37618.0000 - accuracy: 0.8119 - precision: 0.5298 - recall: 0.5298 - auc: 0.8824 - val_loss: 0.7008 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-003-files-21-22
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 23-23/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6551 - tp: 52270.0000 - fp: 27730.0000 - tn: 292270.0000 - fn: 27730.0000 - accuracy: 0.8614 - precision: 0.6534 - recall: 0.6534 - auc: 0.9130 - val_loss: 0.4429 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-22-23
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0730 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0218 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-22-23
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0152 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0111 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-22-23
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0091 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0075 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-22-23
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0065 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0057 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-22-23
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 24-24/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0051 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0046 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-23-24
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0042 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0038 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-23-24
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0036 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0033 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-23-24
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-23-24
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2732 - tp: 75698.0000 - fp: 4302.0000 - tn: 315698.0000 - fn: 4302.0000 - accuracy: 0.9785 - precision: 0.9462 - recall: 0.9462 - auc: 0.9802 - val_loss: 1.3920 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 72912.0000 - val_fn: 7088.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-003-files-23-24
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 25-25/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7228 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9106 - val_loss: 0.6576 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-003-files-24-25
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6564 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9113 - val_loss: 0.6554 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-003-files-24-25
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6560 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6563 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-003-files-24-25
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6554 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6562 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-003-files-24-25
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6553 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9110 - val_loss: 0.6551 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-24-25
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 26-26/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6546 - tp: 51523.0000 - fp: 28477.0000 - tn: 291523.0000 - fn: 28477.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9112 - val_loss: 1.6300 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.8310
[INFO] saving weights to checkpoints/dnn-epoch-003-files-25-26
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.2146 - tp: 51579.0000 - fp: 28421.0000 - tn: 291579.0000 - fn: 28421.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.8513 - val_loss: 0.7017 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-25-26
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6829 - tp: 51462.0000 - fp: 28538.0000 - tn: 291462.0000 - fn: 28538.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9106 - val_loss: 0.6711 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-003-files-25-26
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6680 - tp: 51506.0000 - fp: 28494.0000 - tn: 291506.0000 - fn: 28494.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9106 - val_loss: 0.6630 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 72936.0000 - val_fn: 7064.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-003-files-25-26
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6631 - tp: 51474.0000 - fp: 28526.0000 - tn: 291474.0000 - fn: 28526.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.6594 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 72945.0000 - val_fn: 7055.0000 - val_accuracy: 0.8589 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.9118
[INFO] saving weights to checkpoints/dnn-epoch-003-files-25-26
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 27-27/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (479817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6609 - tp: 51419.0000 - fp: 28581.0000 - tn: 291419.0000 - fn: 28581.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9107 - val_loss: 0.6607 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-003-files-26-27
[INFO] processing batch 100000-200000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6588 - tp: 51485.0000 - fp: 28515.0000 - tn: 291485.0000 - fn: 28515.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6567 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 72918.0000 - val_fn: 7082.0000 - val_accuracy: 0.8584 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-003-files-26-27
[INFO] processing batch 200000-300000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6569 - tp: 51583.0000 - fp: 28417.0000 - tn: 291583.0000 - fn: 28417.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9115 - val_loss: 0.6574 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-26-27
[INFO] processing batch 300000-400000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6575 - tp: 51396.0000 - fp: 28604.0000 - tn: 291396.0000 - fn: 28604.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9105 - val_loss: 0.6571 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 72851.0000 - val_fn: 7149.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-003-files-26-27
[INFO] processing batch 400000-500000/479817
[33m[INFO] loading file 28-28/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6563 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6560 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-27-28
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6564 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9106 - val_loss: 0.6558 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-27-28
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6556 - tp: 51458.0000 - fp: 28542.0000 - tn: 291458.0000 - fn: 28542.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9105 - val_loss: 0.6552 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-27-28
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6552 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9104 - val_loss: 0.6539 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-003-files-27-28
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6544 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6552 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-27-28
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 29-29/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6547 - tp: 51460.0000 - fp: 28540.0000 - tn: 291460.0000 - fn: 28540.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6548 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-28-29
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6540 - tp: 51527.0000 - fp: 28473.0000 - tn: 291527.0000 - fn: 28473.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6548 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-003-files-28-29
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6541 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6522 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-003-files-28-29
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6534 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9110 - val_loss: 0.6543 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-28-29
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6538 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-28-29
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 30-30/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6534 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9107 - val_loss: 0.6539 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-29-30
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6539 - tp: 51450.0000 - fp: 28550.0000 - tn: 291450.0000 - fn: 28550.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9104 - val_loss: 0.6540 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-29-30
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6535 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6539 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-29-30
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9107 - val_loss: 0.6531 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-003-files-29-30
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9112 - val_loss: 0.6533 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 72870.0000 - val_fn: 7130.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-29-30
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 31-31/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6518 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 72921.0000 - val_fn: 7079.0000 - val_accuracy: 0.8584 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-003-files-30-31
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51524.0000 - fp: 28476.0000 - tn: 291524.0000 - fn: 28476.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9105 - val_loss: 0.6522 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 72902.0000 - val_fn: 7098.0000 - val_accuracy: 0.8580 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-003-files-30-31
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6535 - tp: 51428.0000 - fp: 28572.0000 - tn: 291428.0000 - fn: 28572.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9104 - val_loss: 0.6529 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-30-31
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6526 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-30-31
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9111 - val_loss: 0.6523 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 72893.0000 - val_fn: 7107.0000 - val_accuracy: 0.8579 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-003-files-30-31
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 32-32/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9110 - val_loss: 0.6524 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-31-32
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51531.0000 - fp: 28469.0000 - tn: 291531.0000 - fn: 28469.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6527 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-31-32
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51576.0000 - fp: 28424.0000 - tn: 291576.0000 - fn: 28424.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9111 - val_loss: 0.6522 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-31-32
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51489.0000 - fp: 28511.0000 - tn: 291489.0000 - fn: 28511.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6530 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-31-32
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6530 - tp: 51449.0000 - fp: 28551.0000 - tn: 291449.0000 - fn: 28551.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9106 - val_loss: 0.6529 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-31-32
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 33-33/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9111 - val_loss: 0.6525 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-32-33
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9111 - val_loss: 0.6528 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-32-33
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51404.0000 - fp: 28596.0000 - tn: 291404.0000 - fn: 28596.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9105 - val_loss: 0.6529 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-32-33
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51552.0000 - fp: 28448.0000 - tn: 291552.0000 - fn: 28448.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9111 - val_loss: 0.6522 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-32-33
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51594.0000 - fp: 28406.0000 - tn: 291594.0000 - fn: 28406.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9114 - val_loss: 0.6508 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-003-files-32-33
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 34-34/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9107 - val_loss: 0.6534 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-003-files-33-34
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9105 - val_loss: 0.6527 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-33-34
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51588.0000 - fp: 28412.0000 - tn: 291588.0000 - fn: 28412.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9110 - val_loss: 0.6523 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-003-files-33-34
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6530 - tp: 51408.0000 - fp: 28592.0000 - tn: 291408.0000 - fn: 28592.0000 - accuracy: 0.8570 - precision: 0.6426 - recall: 0.6426 - auc: 0.9105 - val_loss: 0.6535 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 72834.0000 - val_fn: 7166.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-003-files-33-34
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9108 - val_loss: 0.6522 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-003-files-33-34
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 35-35/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51520.0000 - fp: 28480.0000 - tn: 291520.0000 - fn: 28480.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9107 - val_loss: 0.6528 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-34-35
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9105 - val_loss: 0.6522 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-003-files-34-35
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6523 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9111 - val_loss: 0.6517 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-34-35
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51521.0000 - fp: 28479.0000 - tn: 291521.0000 - fn: 28479.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9113 - val_loss: 0.6528 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-34-35
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51570.0000 - fp: 28430.0000 - tn: 291570.0000 - fn: 28430.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9109 - val_loss: 0.6523 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-34-35
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 36-36/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9106 - val_loss: 0.6522 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-35-36
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51644.0000 - fp: 28356.0000 - tn: 291644.0000 - fn: 28356.0000 - accuracy: 0.8582 - precision: 0.6456 - recall: 0.6456 - auc: 0.9116 - val_loss: 0.6516 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 72895.0000 - val_fn: 7105.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-003-files-35-36
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9105 - val_loss: 0.6504 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 72933.0000 - val_fn: 7067.0000 - val_accuracy: 0.8587 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-003-files-35-36
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51415.0000 - fp: 28585.0000 - tn: 291415.0000 - fn: 28585.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9107 - val_loss: 0.6521 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 72878.0000 - val_fn: 7122.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-003-files-35-36
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6528 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-35-36
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 37-37/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51413.0000 - fp: 28587.0000 - tn: 291413.0000 - fn: 28587.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9106 - val_loss: 0.6527 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-36-37
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51456.0000 - fp: 28544.0000 - tn: 291456.0000 - fn: 28544.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6512 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-003-files-36-37
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51565.0000 - fp: 28435.0000 - tn: 291565.0000 - fn: 28435.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9107 - val_loss: 0.6522 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-36-37
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51512.0000 - fp: 28488.0000 - tn: 291512.0000 - fn: 28488.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6516 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 72888.0000 - val_fn: 7112.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-36-37
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51528.0000 - fp: 28472.0000 - tn: 291528.0000 - fn: 28472.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6513 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 72899.0000 - val_fn: 7101.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-003-files-36-37
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 38-38/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51513.0000 - fp: 28487.0000 - tn: 291513.0000 - fn: 28487.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.6503 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-003-files-37-38
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51589.0000 - fp: 28411.0000 - tn: 291589.0000 - fn: 28411.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9109 - val_loss: 0.6530 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-003-files-37-38
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51481.0000 - fp: 28519.0000 - tn: 291481.0000 - fn: 28519.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6525 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-37-38
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51549.0000 - fp: 28451.0000 - tn: 291549.0000 - fn: 28451.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9111 - val_loss: 0.6513 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 72898.0000 - val_fn: 7102.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-003-files-37-38
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9113 - val_loss: 0.6522 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 72866.0000 - val_fn: 7134.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-37-38
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 39-39/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6528 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 72847.0000 - val_fn: 7153.0000 - val_accuracy: 0.8569 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-003-files-38-39
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51597.0000 - fp: 28403.0000 - tn: 291597.0000 - fn: 28403.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9112 - val_loss: 0.6509 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 72910.0000 - val_fn: 7090.0000 - val_accuracy: 0.8582 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-003-files-38-39
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51631.0000 - fp: 28369.0000 - tn: 291631.0000 - fn: 28369.0000 - accuracy: 0.8582 - precision: 0.6454 - recall: 0.6454 - auc: 0.9109 - val_loss: 0.6514 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-003-files-38-39
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6521 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-38-39
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6519 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-38-39
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 40-40/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51418.0000 - fp: 28582.0000 - tn: 291418.0000 - fn: 28582.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9103 - val_loss: 0.6528 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-003-files-39-40
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51491.0000 - fp: 28509.0000 - tn: 291491.0000 - fn: 28509.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6523 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-39-40
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9111 - val_loss: 0.6507 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 72916.0000 - val_fn: 7084.0000 - val_accuracy: 0.8583 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-003-files-39-40
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9112 - val_loss: 0.6529 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 72838.0000 - val_fn: 7162.0000 - val_accuracy: 0.8568 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-003-files-39-40
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51432.0000 - fp: 28568.0000 - tn: 291432.0000 - fn: 28568.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9105 - val_loss: 0.6526 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-003-files-39-40
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 41-41/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6523 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-40-41
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51515.0000 - fp: 28485.0000 - tn: 291515.0000 - fn: 28485.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6520 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-40-41
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9109 - val_loss: 0.6518 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-003-files-40-41
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51587.0000 - fp: 28413.0000 - tn: 291587.0000 - fn: 28413.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9110 - val_loss: 0.6523 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-40-41
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9109 - val_loss: 0.6500 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 72937.0000 - val_fn: 7063.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-003-files-40-41
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 42-42/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6534 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 72826.0000 - val_fn: 7174.0000 - val_accuracy: 0.8565 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-003-files-41-42
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51511.0000 - fp: 28489.0000 - tn: 291511.0000 - fn: 28489.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.6516 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 72882.0000 - val_fn: 7118.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-003-files-41-42
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51499.0000 - fp: 28501.0000 - tn: 291499.0000 - fn: 28501.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9106 - val_loss: 0.6524 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 72853.0000 - val_fn: 7147.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-41-42
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9104 - val_loss: 0.6506 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 72917.0000 - val_fn: 7083.0000 - val_accuracy: 0.8583 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-003-files-41-42
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51584.0000 - fp: 28416.0000 - tn: 291584.0000 - fn: 28416.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9113 - val_loss: 0.6518 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-41-42
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 43-43/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9113 - val_loss: 0.6518 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-42-43
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9107 - val_loss: 0.6534 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 72824.0000 - val_fn: 7176.0000 - val_accuracy: 0.8565 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-003-files-42-43
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6527 - tp: 51387.0000 - fp: 28613.0000 - tn: 291387.0000 - fn: 28613.0000 - accuracy: 0.8569 - precision: 0.6423 - recall: 0.6423 - auc: 0.9103 - val_loss: 0.6511 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-003-files-42-43
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6527 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-003-files-42-43
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9109 - val_loss: 0.6494 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 72952.0000 - val_fn: 7048.0000 - val_accuracy: 0.8590 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.9119
[INFO] saving weights to checkpoints/dnn-epoch-003-files-42-43
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 44-44/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9107 - val_loss: 0.6524 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-43-44
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9104 - val_loss: 0.6523 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-43-44
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51543.0000 - fp: 28457.0000 - tn: 291543.0000 - fn: 28457.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9108 - val_loss: 0.6523 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-43-44
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6523 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6513 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 72891.0000 - val_fn: 7109.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-43-44
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51537.0000 - fp: 28463.0000 - tn: 291537.0000 - fn: 28463.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9108 - val_loss: 0.6521 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-43-44
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 45-45/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51620.0000 - fp: 28380.0000 - tn: 291620.0000 - fn: 28380.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9113 - val_loss: 0.6519 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-44-45
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51538.0000 - fp: 28462.0000 - tn: 291538.0000 - fn: 28462.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9106 - val_loss: 0.6514 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-44-45
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51564.0000 - fp: 28436.0000 - tn: 291564.0000 - fn: 28436.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9108 - val_loss: 0.6508 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 72904.0000 - val_fn: 7096.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-003-files-44-45
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51590.0000 - fp: 28410.0000 - tn: 291590.0000 - fn: 28410.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9111 - val_loss: 0.6526 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-003-files-44-45
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51395.0000 - fp: 28605.0000 - tn: 291395.0000 - fn: 28605.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9104 - val_loss: 0.6511 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-003-files-44-45
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 46-46/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6506 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 72913.0000 - val_fn: 7087.0000 - val_accuracy: 0.8583 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-003-files-45-46
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51464.0000 - fp: 28536.0000 - tn: 291464.0000 - fn: 28536.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9104 - val_loss: 0.6515 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 72883.0000 - val_fn: 7117.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-003-files-45-46
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9112 - val_loss: 0.6514 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-45-46
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9107 - val_loss: 0.6502 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-003-files-45-46
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51569.0000 - fp: 28431.0000 - tn: 291569.0000 - fn: 28431.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9114 - val_loss: 0.6517 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-45-46
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 47-47/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51601.0000 - fp: 28399.0000 - tn: 291601.0000 - fn: 28399.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9114 - val_loss: 0.6512 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-46-47
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51559.0000 - fp: 28441.0000 - tn: 291559.0000 - fn: 28441.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9111 - val_loss: 0.6518 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-46-47
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.6533 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 72822.0000 - val_fn: 7178.0000 - val_accuracy: 0.8564 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-003-files-46-47
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9106 - val_loss: 0.6515 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 72881.0000 - val_fn: 7119.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-003-files-46-47
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6507 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 72909.0000 - val_fn: 7091.0000 - val_accuracy: 0.8582 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-003-files-46-47
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 48-48/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6530 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 72830.0000 - val_fn: 7170.0000 - val_accuracy: 0.8566 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-003-files-47-48
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6516 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 72879.0000 - val_fn: 7121.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-003-files-47-48
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51547.0000 - fp: 28453.0000 - tn: 291547.0000 - fn: 28453.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9109 - val_loss: 0.6506 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-003-files-47-48
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9109 - val_loss: 0.6520 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-47-48
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51606.0000 - fp: 28394.0000 - tn: 291606.0000 - fn: 28394.0000 - accuracy: 0.8580 - precision: 0.6451 - recall: 0.6451 - auc: 0.9109 - val_loss: 0.6507 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 72905.0000 - val_fn: 7095.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-003-files-47-48
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 49-49/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9109 - val_loss: 0.6519 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-48-49
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51430.0000 - fp: 28570.0000 - tn: 291430.0000 - fn: 28570.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9104 - val_loss: 0.6502 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 72924.0000 - val_fn: 7076.0000 - val_accuracy: 0.8585 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-003-files-48-49
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51469.0000 - fp: 28531.0000 - tn: 291469.0000 - fn: 28531.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9106 - val_loss: 0.6530 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-003-files-48-49
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6503 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 72922.0000 - val_fn: 7078.0000 - val_accuracy: 0.8584 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-003-files-48-49
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51495.0000 - fp: 28505.0000 - tn: 291495.0000 - fn: 28505.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6512 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-48-49
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 50-50/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9108 - val_loss: 0.6532 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 72823.0000 - val_fn: 7177.0000 - val_accuracy: 0.8565 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-003-files-49-50
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51482.0000 - fp: 28518.0000 - tn: 291482.0000 - fn: 28518.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6511 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-49-50
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51433.0000 - fp: 28567.0000 - tn: 291433.0000 - fn: 28567.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9106 - val_loss: 0.6524 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-003-files-49-50
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51461.0000 - fp: 28539.0000 - tn: 291461.0000 - fn: 28539.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9106 - val_loss: 0.6512 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-49-50
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51467.0000 - fp: 28533.0000 - tn: 291467.0000 - fn: 28533.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9105 - val_loss: 0.6521 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-49-50
[INFO] processing batch 500000-600000/519975
[33m[LOSS] 0.6521363069534302[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6521363069534302  <  0.001
[33m[INFO] epoch 4/10[0m
[33m[INFO] loading file 1-1/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0710 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-0-1
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-0-1
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0227 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9993 - val_loss: 2.2979 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.8826
[INFO] saving weights to checkpoints/dnn-epoch-004-files-0-1
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8395 - tp: 42447.0000 - fp: 37553.0000 - tn: 282447.0000 - fn: 37553.0000 - accuracy: 0.8122 - precision: 0.5306 - recall: 0.5306 - auc: 0.8819 - val_loss: 0.6916 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-004-files-0-1
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6917 - tp: 42438.0000 - fp: 37562.0000 - tn: 282438.0000 - fn: 37562.0000 - accuracy: 0.8122 - precision: 0.5305 - recall: 0.5305 - auc: 0.8827 - val_loss: 0.6918 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-004-files-0-1
[33m[INFO] loading file 2-2/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6917 - tp: 42435.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37565.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5304 - auc: 0.8820 - val_loss: 0.6918 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 70589.0000 - val_fn: 9411.0000 - val_accuracy: 0.8118 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-004-files-1-2
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4426 - tp: 67619.0000 - fp: 12381.0000 - tn: 307619.0000 - fn: 12381.0000 - accuracy: 0.9381 - precision: 0.8452 - recall: 0.8452 - auc: 0.9612 - val_loss: 0.1685 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-1-2
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3148 - tp: 72432.0000 - fp: 7568.0000 - tn: 312432.0000 - fn: 7568.0000 - accuracy: 0.9622 - precision: 0.9054 - recall: 0.9054 - auc: 0.9763 - val_loss: 1.1580 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 70593.0000 - val_fn: 9407.0000 - val_accuracy: 0.8119 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-004-files-1-2
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7163 - tp: 42321.0000 - fp: 37679.0000 - tn: 282321.0000 - fn: 37679.0000 - accuracy: 0.8116 - precision: 0.5290 - recall: 0.5290 - auc: 0.8821 - val_loss: 0.6917 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 70602.0000 - val_fn: 9398.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-004-files-1-2
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4475 - tp: 67360.0000 - fp: 12640.0000 - tn: 307360.0000 - fn: 12640.0000 - accuracy: 0.9368 - precision: 0.8420 - recall: 0.8420 - auc: 0.9605 - val_loss: 0.1734 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-1-2
[33m[INFO] loading file 3-3/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6954 - tp: 45236.0000 - fp: 34764.0000 - tn: 285236.0000 - fn: 34764.0000 - accuracy: 0.8262 - precision: 0.5655 - recall: 0.5655 - auc: 0.8916 - val_loss: 0.6935 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 70571.0000 - val_fn: 9429.0000 - val_accuracy: 0.8114 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.8821
[INFO] saving weights to checkpoints/dnn-epoch-004-files-2-3
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5940 - tp: 57751.0000 - fp: 22249.0000 - tn: 297751.0000 - fn: 22249.0000 - accuracy: 0.8888 - precision: 0.7219 - recall: 0.7219 - auc: 0.9305 - val_loss: 0.3253 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-2-3
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0625 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0200 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-2-3
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0139 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-2-3
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0082 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0067 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-2-3
[33m[INFO] loading file 4-4/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-3-4
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0046 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-3-4
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-3-4
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4222 - tp: 71528.0000 - fp: 8472.0000 - tn: 311528.0000 - fn: 8472.0000 - accuracy: 0.9576 - precision: 0.8941 - recall: 0.8941 - auc: 0.9704 - val_loss: 1.5046 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 67806.0000 - val_fn: 12194.0000 - val_accuracy: 0.7561 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.8476
[INFO] saving weights to checkpoints/dnn-epoch-004-files-3-4
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6121 - tp: 56887.0000 - fp: 23113.0000 - tn: 296887.0000 - fn: 23113.0000 - accuracy: 0.8844 - precision: 0.7111 - recall: 0.7111 - auc: 0.9279 - val_loss: 0.3435 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-3-4
[33m[INFO] loading file 5-5/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5272 - tp: 62445.0000 - fp: 17555.0000 - tn: 302445.0000 - fn: 17555.0000 - accuracy: 0.9122 - precision: 0.7806 - recall: 0.7806 - auc: 0.9454 - val_loss: 0.6978 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-004-files-4-5
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6551 - tp: 51316.0000 - fp: 28684.0000 - tn: 291316.0000 - fn: 28684.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9104 - val_loss: 0.5361 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 77052.0000 - val_fn: 2948.0000 - val_accuracy: 0.9410 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.9632
[INFO] saving weights to checkpoints/dnn-epoch-004-files-4-5
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0717 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-4-5
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-4-5
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0083 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-4-5
[33m[INFO] loading file 6-6/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0059 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-5-6
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-5-6
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-5-6
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2810 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 75632.0000 - val_fn: 4368.0000 - val_accuracy: 0.9126 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.8635
[INFO] saving weights to checkpoints/dnn-epoch-004-files-5-6
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8460 - tp: 51195.0000 - fp: 28805.0000 - tn: 291195.0000 - fn: 28805.0000 - accuracy: 0.8560 - precision: 0.6399 - recall: 0.6399 - auc: 0.9052 - val_loss: 0.6547 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 72768.0000 - val_fn: 7232.0000 - val_accuracy: 0.8554 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.9096
[INFO] saving weights to checkpoints/dnn-epoch-004-files-5-6
[33m[INFO] loading file 7-7/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6537 - tp: 51210.0000 - fp: 28790.0000 - tn: 291210.0000 - fn: 28790.0000 - accuracy: 0.8561 - precision: 0.6401 - recall: 0.6401 - auc: 0.9096 - val_loss: 0.6537 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 72803.0000 - val_fn: 7197.0000 - val_accuracy: 0.8561 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.9100
[INFO] saving weights to checkpoints/dnn-epoch-004-files-6-7
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51338.0000 - fp: 28662.0000 - tn: 291338.0000 - fn: 28662.0000 - accuracy: 0.8567 - precision: 0.6417 - recall: 0.6417 - auc: 0.9100 - val_loss: 0.6520 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-6-7
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4801 - tp: 65370.0000 - fp: 14630.0000 - tn: 305370.0000 - fn: 14630.0000 - accuracy: 0.9269 - precision: 0.8171 - recall: 0.8171 - auc: 0.9541 - val_loss: 0.2044 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-6-7
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0514 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0191 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-6-7
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0135 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0099 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-6-7
[33m[INFO] loading file 8-8/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0080 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0066 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-7-8
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0057 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-7-8
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0040 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-7-8
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3566 - tp: 73166.0000 - fp: 6834.0000 - tn: 313166.0000 - fn: 6834.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9765 - val_loss: 0.5542 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 76368.0000 - val_fn: 3632.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-004-files-7-8
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4815 - tp: 65505.0000 - fp: 14495.0000 - tn: 305505.0000 - fn: 14495.0000 - accuracy: 0.9275 - precision: 0.8188 - recall: 0.8188 - auc: 0.9543 - val_loss: 0.4729 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 76383.0000 - val_fn: 3617.0000 - val_accuracy: 0.9277 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.9548
[INFO] saving weights to checkpoints/dnn-epoch-004-files-7-8
[33m[INFO] loading file 9-9/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4773 - tp: 65300.0000 - fp: 14700.0000 - tn: 305300.0000 - fn: 14700.0000 - accuracy: 0.9265 - precision: 0.8163 - recall: 0.8163 - auc: 0.9539 - val_loss: 0.4804 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 76283.0000 - val_fn: 3717.0000 - val_accuracy: 0.9257 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.9535
[INFO] saving weights to checkpoints/dnn-epoch-004-files-8-9
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0982 - tp: 78936.0000 - fp: 1064.0000 - tn: 318936.0000 - fn: 1064.0000 - accuracy: 0.9947 - precision: 0.9867 - recall: 0.9867 - auc: 0.9966 - val_loss: 0.0269 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-8-9
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0172 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0116 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-8-9
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0092 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0074 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-8-9
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0063 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0054 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-8-9
[33m[INFO] loading file 10-10/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0043 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-9-10
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0084 - tp: 79936.0000 - fp: 64.0000 - tn: 319936.0000 - fn: 64.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 0.9995 - val_loss: 2.0142 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.7763
[INFO] saving weights to checkpoints/dnn-epoch-004-files-9-10
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7558 - tp: 56672.0000 - fp: 23328.0000 - tn: 296672.0000 - fn: 23328.0000 - accuracy: 0.8834 - precision: 0.7084 - recall: 0.7084 - auc: 0.9246 - val_loss: 0.3514 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-9-10
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0645 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0201 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-9-10
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0140 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-9-10
[33m[INFO] loading file 11-11/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0082 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-10-11
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-10-11
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-10-11
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-10-11
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-10-11
[33m[INFO] loading file 12-12/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0027 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0025 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-11-12
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0024 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0134 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 76689.0000 - val_fn: 3311.0000 - val_accuracy: 0.9338 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8965
[INFO] saving weights to checkpoints/dnn-epoch-004-files-11-12
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8647 - tp: 51328.0000 - fp: 28672.0000 - tn: 291328.0000 - fn: 28672.0000 - accuracy: 0.8566 - precision: 0.6416 - recall: 0.6416 - auc: 0.9043 - val_loss: 0.5640 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 75792.0000 - val_fn: 4208.0000 - val_accuracy: 0.9158 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.9474
[INFO] saving weights to checkpoints/dnn-epoch-004-files-11-12
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0706 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0204 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-11-12
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-11-12
[33m[INFO] loading file 13-13/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0083 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-12-13
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0059 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-12-13
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3615 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 75075.0000 - val_fn: 4925.0000 - val_accuracy: 0.9015 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.8461
[INFO] saving weights to checkpoints/dnn-epoch-004-files-12-13
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8170 - tp: 51313.0000 - fp: 28687.0000 - tn: 291313.0000 - fn: 28687.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9087 - val_loss: 0.6516 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-004-files-12-13
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51356.0000 - fp: 28644.0000 - tn: 291356.0000 - fn: 28644.0000 - accuracy: 0.8568 - precision: 0.6420 - recall: 0.6420 - auc: 0.9103 - val_loss: 0.6518 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-12-13
[33m[INFO] loading file 14-14/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5272 - tp: 62543.0000 - fp: 17457.0000 - tn: 302543.0000 - fn: 17457.0000 - accuracy: 0.9127 - precision: 0.7818 - recall: 0.7818 - auc: 0.9457 - val_loss: 0.2464 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-13-14
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0557 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0195 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-13-14
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0137 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0100 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-13-14
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0081 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0067 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-13-14
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-13-14
[33m[INFO] loading file 15-15/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0046 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0040 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-14-15
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0038 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-14-15
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-14-15
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0027 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.8648 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 71586.0000 - val_fn: 8414.0000 - val_accuracy: 0.8317 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.7371
[INFO] saving weights to checkpoints/dnn-epoch-004-files-14-15
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.8329 - tp: 42561.0000 - fp: 37439.0000 - tn: 282561.0000 - fn: 37439.0000 - accuracy: 0.8128 - precision: 0.5320 - recall: 0.5320 - auc: 0.8059 - val_loss: 0.7342 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 70627.0000 - val_fn: 9373.0000 - val_accuracy: 0.8125 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-004-files-14-15
[33m[INFO] loading file 16-16/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7177 - tp: 42492.0000 - fp: 37508.0000 - tn: 282492.0000 - fn: 37508.0000 - accuracy: 0.8125 - precision: 0.5311 - recall: 0.5311 - auc: 0.8826 - val_loss: 0.7087 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 70618.0000 - val_fn: 9382.0000 - val_accuracy: 0.8124 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-004-files-15-16
[INFO] processing batch 100000-200000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5998 - tp: 58381.0000 - fp: 21619.0000 - tn: 298381.0000 - fn: 21619.0000 - accuracy: 0.8919 - precision: 0.7298 - recall: 0.7298 - auc: 0.9324 - val_loss: 0.3240 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-15-16
[INFO] processing batch 200000-300000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0650 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0217 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-15-16
[INFO] processing batch 300000-400000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0153 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0112 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-15-16
[INFO] processing batch 400000-500000/439690
[33m[INFO] loading file 17-17/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0092 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0076 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-16-17
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0066 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0058 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-16-17
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0052 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0047 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-16-17
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9904 - tp: 68607.0000 - fp: 11393.0000 - tn: 308607.0000 - fn: 11393.0000 - accuracy: 0.9430 - precision: 0.8576 - recall: 0.8576 - auc: 0.9004 - val_loss: 0.7584 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 76369.0000 - val_fn: 3631.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9092
[INFO] saving weights to checkpoints/dnn-epoch-004-files-16-17
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5638 - tp: 65526.0000 - fp: 14474.0000 - tn: 305526.0000 - fn: 14474.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.9516 - val_loss: 0.3285 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 78648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9730 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9831
[INFO] saving weights to checkpoints/dnn-epoch-004-files-16-17
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 18-18/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3448 - tp: 72130.0000 - fp: 7870.0000 - tn: 312130.0000 - fn: 7870.0000 - accuracy: 0.9607 - precision: 0.9016 - recall: 0.9016 - auc: 0.9755 - val_loss: 0.9907 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 72369.0000 - val_fn: 7631.0000 - val_accuracy: 0.8474 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.9046
[INFO] saving weights to checkpoints/dnn-epoch-004-files-17-18
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7021 - tp: 49699.0000 - fp: 30301.0000 - tn: 289699.0000 - fn: 30301.0000 - accuracy: 0.8485 - precision: 0.6212 - recall: 0.6212 - auc: 0.9052 - val_loss: 0.6817 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 72357.0000 - val_fn: 7643.0000 - val_accuracy: 0.8471 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.9045
[INFO] saving weights to checkpoints/dnn-epoch-004-files-17-18
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6784 - tp: 49541.0000 - fp: 30459.0000 - tn: 289541.0000 - fn: 30459.0000 - accuracy: 0.8477 - precision: 0.6193 - recall: 0.6193 - auc: 0.9052 - val_loss: 0.6761 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 72397.0000 - val_fn: 7603.0000 - val_accuracy: 0.8479 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.9050
[INFO] saving weights to checkpoints/dnn-epoch-004-files-17-18
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2758 - tp: 74509.0000 - fp: 5491.0000 - tn: 314509.0000 - fn: 5491.0000 - accuracy: 0.9725 - precision: 0.9314 - recall: 0.9314 - auc: 0.9826 - val_loss: 0.0785 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-17-18
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0341 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0178 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-17-18
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 19-19/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0132 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-18-19
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0084 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0071 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-18-19
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0062 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0055 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-18-19
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6457 - tp: 69321.0000 - fp: 10679.0000 - tn: 309321.0000 - fn: 10679.0000 - accuracy: 0.9466 - precision: 0.8665 - recall: 0.8665 - auc: 0.9384 - val_loss: 1.5655 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 67882.0000 - val_fn: 12118.0000 - val_accuracy: 0.7576 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.8485
[INFO] saving weights to checkpoints/dnn-epoch-004-files-18-19
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7452 - tp: 44587.0000 - fp: 32757.0000 - tn: 287243.0000 - fn: 35413.0000 - accuracy: 0.8296 - precision: 0.5765 - recall: 0.5573 - auc: 0.8909 - val_loss: 0.9617 - val_tp: 0.0000e+00 - val_fp: 20000.0000 - val_tn: 60000.0000 - val_fn: 20000.0000 - val_accuracy: 0.6000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7500
[INFO] saving weights to checkpoints/dnn-epoch-004-files-18-19
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 20-20/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.1055 - tp: 78560.0000 - fp: 1152.0000 - tn: 318848.0000 - fn: 1440.0000 - accuracy: 0.9935 - precision: 0.9855 - recall: 0.9820 - auc: 0.9999 - val_loss: 0.1241 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 79491.0000 - val_fn: 509.0000 - val_accuracy: 0.9898 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9936
[INFO] saving weights to checkpoints/dnn-epoch-004-files-19-20
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5202 - tp: 65427.0000 - fp: 14573.0000 - tn: 305427.0000 - fn: 14573.0000 - accuracy: 0.9271 - precision: 0.8178 - recall: 0.8178 - auc: 0.9546 - val_loss: 0.4848 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 76357.0000 - val_fn: 3643.0000 - val_accuracy: 0.9271 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.9545
[INFO] saving weights to checkpoints/dnn-epoch-004-files-19-20
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4851 - tp: 65351.0000 - fp: 14649.0000 - tn: 305351.0000 - fn: 14649.0000 - accuracy: 0.9268 - precision: 0.8169 - recall: 0.8169 - auc: 0.9542 - val_loss: 0.4816 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 76371.0000 - val_fn: 3629.0000 - val_accuracy: 0.9274 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-004-files-19-20
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2110 - tp: 76024.0000 - fp: 3976.0000 - tn: 316024.0000 - fn: 3976.0000 - accuracy: 0.9801 - precision: 0.9503 - recall: 0.9503 - auc: 0.9878 - val_loss: 0.0561 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-19-20
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0282 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0162 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-19-20
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 21-21/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539688, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0123 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0095 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-20-21
[INFO] processing batch 100000-200000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0080 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-20-21
[INFO] processing batch 200000-300000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0060 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0053 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-20-21
[INFO] processing batch 300000-400000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0043 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-20-21
[INFO] processing batch 400000-500000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0040 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0037 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-20-21
[INFO] processing batch 500000-600000/539688
[33m[INFO] loading file 22-22/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.3343 - tp: 55006.0000 - fp: 24994.0000 - tn: 295006.0000 - fn: 24994.0000 - accuracy: 0.8750 - precision: 0.6876 - recall: 0.6876 - auc: 0.8473 - val_loss: 0.8130 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-004-files-21-22
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7323 - tp: 42398.0000 - fp: 37602.0000 - tn: 282398.0000 - fn: 37602.0000 - accuracy: 0.8120 - precision: 0.5300 - recall: 0.5300 - auc: 0.8820 - val_loss: 0.7174 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.8816
[INFO] saving weights to checkpoints/dnn-epoch-004-files-21-22
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7115 - tp: 42369.0000 - fp: 37631.0000 - tn: 282369.0000 - fn: 37631.0000 - accuracy: 0.8118 - precision: 0.5296 - recall: 0.5296 - auc: 0.8824 - val_loss: 0.7075 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 70623.0000 - val_fn: 9377.0000 - val_accuracy: 0.8125 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-004-files-21-22
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7052 - tp: 42452.0000 - fp: 37548.0000 - tn: 282452.0000 - fn: 37548.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5307 - auc: 0.8827 - val_loss: 0.7033 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 70601.0000 - val_fn: 9399.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-004-files-21-22
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7020 - tp: 42382.0000 - fp: 37618.0000 - tn: 282382.0000 - fn: 37618.0000 - accuracy: 0.8119 - precision: 0.5298 - recall: 0.5298 - auc: 0.8825 - val_loss: 0.7008 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-004-files-21-22
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 23-23/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6548 - tp: 52270.0000 - fp: 27730.0000 - tn: 292270.0000 - fn: 27730.0000 - accuracy: 0.8613 - precision: 0.6534 - recall: 0.6534 - auc: 0.9135 - val_loss: 0.4408 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-22-23
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0728 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0218 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-22-23
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0152 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0111 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-22-23
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0091 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0075 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-22-23
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0065 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0057 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-22-23
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 24-24/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0051 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0046 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-23-24
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0042 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0038 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-23-24
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0036 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0033 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-23-24
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-23-24
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2732 - tp: 75698.0000 - fp: 4302.0000 - tn: 315698.0000 - fn: 4302.0000 - accuracy: 0.9785 - precision: 0.9462 - recall: 0.9462 - auc: 0.9802 - val_loss: 1.3900 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 72912.0000 - val_fn: 7088.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-004-files-23-24
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 25-25/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7219 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6575 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-004-files-24-25
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6565 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6554 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-004-files-24-25
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6560 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9105 - val_loss: 0.6563 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-004-files-24-25
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6554 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9106 - val_loss: 0.6561 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-004-files-24-25
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6553 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9107 - val_loss: 0.6551 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-24-25
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 26-26/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6546 - tp: 51523.0000 - fp: 28477.0000 - tn: 291523.0000 - fn: 28477.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9109 - val_loss: 1.6349 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.8310
[INFO] saving weights to checkpoints/dnn-epoch-004-files-25-26
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.2142 - tp: 51579.0000 - fp: 28421.0000 - tn: 291579.0000 - fn: 28421.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.8514 - val_loss: 0.7019 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-25-26
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6829 - tp: 51462.0000 - fp: 28538.0000 - tn: 291462.0000 - fn: 28538.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9106 - val_loss: 0.6712 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-004-files-25-26
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6680 - tp: 51506.0000 - fp: 28494.0000 - tn: 291506.0000 - fn: 28494.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9107 - val_loss: 0.6630 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 72936.0000 - val_fn: 7064.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-004-files-25-26
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6631 - tp: 51474.0000 - fp: 28526.0000 - tn: 291474.0000 - fn: 28526.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9113 - val_loss: 0.6592 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 72945.0000 - val_fn: 7055.0000 - val_accuracy: 0.8589 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.9118
[INFO] saving weights to checkpoints/dnn-epoch-004-files-25-26
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 27-27/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (479817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6609 - tp: 51419.0000 - fp: 28581.0000 - tn: 291419.0000 - fn: 28581.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9108 - val_loss: 0.6607 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-004-files-26-27
[INFO] processing batch 100000-200000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6588 - tp: 51485.0000 - fp: 28515.0000 - tn: 291485.0000 - fn: 28515.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6567 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 72918.0000 - val_fn: 7082.0000 - val_accuracy: 0.8584 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-004-files-26-27
[INFO] processing batch 200000-300000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6569 - tp: 51583.0000 - fp: 28417.0000 - tn: 291583.0000 - fn: 28417.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9112 - val_loss: 0.6575 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-26-27
[INFO] processing batch 300000-400000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6575 - tp: 51396.0000 - fp: 28604.0000 - tn: 291396.0000 - fn: 28604.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9107 - val_loss: 0.6572 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 72851.0000 - val_fn: 7149.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-004-files-26-27
[INFO] processing batch 400000-500000/479817
[33m[INFO] loading file 28-28/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6563 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6559 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-27-28
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6564 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9106 - val_loss: 0.6559 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-27-28
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6555 - tp: 51458.0000 - fp: 28542.0000 - tn: 291458.0000 - fn: 28542.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9110 - val_loss: 0.6553 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-27-28
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6552 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6539 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-004-files-27-28
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6545 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9107 - val_loss: 0.6551 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-27-28
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 29-29/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6547 - tp: 51460.0000 - fp: 28540.0000 - tn: 291460.0000 - fn: 28540.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9106 - val_loss: 0.6548 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-28-29
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6540 - tp: 51527.0000 - fp: 28473.0000 - tn: 291527.0000 - fn: 28473.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9114 - val_loss: 0.6550 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-004-files-28-29
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6541 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6522 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-004-files-28-29
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6534 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9111 - val_loss: 0.6543 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-28-29
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6536 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-28-29
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 30-30/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6534 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6540 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-29-30
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51450.0000 - fp: 28550.0000 - tn: 291450.0000 - fn: 28550.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9105 - val_loss: 0.6541 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-29-30
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6535 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6539 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-29-30
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6531 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-004-files-29-30
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9109 - val_loss: 0.6533 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 72870.0000 - val_fn: 7130.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-29-30
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 31-31/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6517 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 72921.0000 - val_fn: 7079.0000 - val_accuracy: 0.8584 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-004-files-30-31
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51524.0000 - fp: 28476.0000 - tn: 291524.0000 - fn: 28476.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6522 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 72902.0000 - val_fn: 7098.0000 - val_accuracy: 0.8580 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-004-files-30-31
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6535 - tp: 51428.0000 - fp: 28572.0000 - tn: 291428.0000 - fn: 28572.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6530 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-30-31
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6525 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-30-31
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9106 - val_loss: 0.6523 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 72893.0000 - val_fn: 7107.0000 - val_accuracy: 0.8579 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-004-files-30-31
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 32-32/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9110 - val_loss: 0.6526 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-31-32
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51531.0000 - fp: 28469.0000 - tn: 291531.0000 - fn: 28469.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6527 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-31-32
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51576.0000 - fp: 28424.0000 - tn: 291576.0000 - fn: 28424.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9113 - val_loss: 0.6522 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-31-32
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6527 - tp: 51489.0000 - fp: 28511.0000 - tn: 291489.0000 - fn: 28511.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9113 - val_loss: 0.6530 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-31-32
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6530 - tp: 51449.0000 - fp: 28551.0000 - tn: 291449.0000 - fn: 28551.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9102 - val_loss: 0.6528 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-31-32
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 33-33/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6525 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-32-33
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9111 - val_loss: 0.6528 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-32-33
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51404.0000 - fp: 28596.0000 - tn: 291404.0000 - fn: 28596.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9104 - val_loss: 0.6529 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-32-33
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51552.0000 - fp: 28448.0000 - tn: 291552.0000 - fn: 28448.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9111 - val_loss: 0.6521 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-32-33
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51594.0000 - fp: 28406.0000 - tn: 291594.0000 - fn: 28406.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9112 - val_loss: 0.6508 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-004-files-32-33
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 34-34/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6534 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-004-files-33-34
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9106 - val_loss: 0.6526 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-33-34
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51588.0000 - fp: 28412.0000 - tn: 291588.0000 - fn: 28412.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9114 - val_loss: 0.6525 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-004-files-33-34
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6530 - tp: 51408.0000 - fp: 28592.0000 - tn: 291408.0000 - fn: 28592.0000 - accuracy: 0.8570 - precision: 0.6426 - recall: 0.6426 - auc: 0.9109 - val_loss: 0.6538 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 72834.0000 - val_fn: 7166.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-004-files-33-34
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9110 - val_loss: 0.6523 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-004-files-33-34
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 35-35/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51520.0000 - fp: 28480.0000 - tn: 291520.0000 - fn: 28480.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9108 - val_loss: 0.6528 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-34-35
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6523 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-004-files-34-35
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6523 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6517 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-34-35
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51521.0000 - fp: 28479.0000 - tn: 291521.0000 - fn: 28479.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9107 - val_loss: 0.6528 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-34-35
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51570.0000 - fp: 28430.0000 - tn: 291570.0000 - fn: 28430.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6523 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-34-35
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 36-36/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6522 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-35-36
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51644.0000 - fp: 28356.0000 - tn: 291644.0000 - fn: 28356.0000 - accuracy: 0.8582 - precision: 0.6456 - recall: 0.6456 - auc: 0.9112 - val_loss: 0.6515 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 72895.0000 - val_fn: 7105.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-004-files-35-36
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9106 - val_loss: 0.6505 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 72933.0000 - val_fn: 7067.0000 - val_accuracy: 0.8587 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-004-files-35-36
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51415.0000 - fp: 28585.0000 - tn: 291415.0000 - fn: 28585.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9108 - val_loss: 0.6520 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 72878.0000 - val_fn: 7122.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-004-files-35-36
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9106 - val_loss: 0.6527 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-35-36
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 37-37/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51413.0000 - fp: 28587.0000 - tn: 291413.0000 - fn: 28587.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9106 - val_loss: 0.6527 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-36-37
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51456.0000 - fp: 28544.0000 - tn: 291456.0000 - fn: 28544.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9107 - val_loss: 0.6513 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-004-files-36-37
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51565.0000 - fp: 28435.0000 - tn: 291565.0000 - fn: 28435.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.6522 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-36-37
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51512.0000 - fp: 28488.0000 - tn: 291512.0000 - fn: 28488.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6517 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 72888.0000 - val_fn: 7112.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-36-37
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51528.0000 - fp: 28472.0000 - tn: 291528.0000 - fn: 28472.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9113 - val_loss: 0.6514 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 72899.0000 - val_fn: 7101.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-004-files-36-37
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 38-38/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51513.0000 - fp: 28487.0000 - tn: 291513.0000 - fn: 28487.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9106 - val_loss: 0.6503 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-004-files-37-38
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51589.0000 - fp: 28411.0000 - tn: 291589.0000 - fn: 28411.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9111 - val_loss: 0.6530 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-004-files-37-38
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51481.0000 - fp: 28519.0000 - tn: 291481.0000 - fn: 28519.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6525 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-37-38
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51549.0000 - fp: 28451.0000 - tn: 291549.0000 - fn: 28451.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9110 - val_loss: 0.6513 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 72898.0000 - val_fn: 7102.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-004-files-37-38
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9110 - val_loss: 0.6522 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 72866.0000 - val_fn: 7134.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-37-38
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 39-39/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9111 - val_loss: 0.6528 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 72847.0000 - val_fn: 7153.0000 - val_accuracy: 0.8569 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-004-files-38-39
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51597.0000 - fp: 28403.0000 - tn: 291597.0000 - fn: 28403.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9112 - val_loss: 0.6509 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 72910.0000 - val_fn: 7090.0000 - val_accuracy: 0.8582 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-004-files-38-39
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51631.0000 - fp: 28369.0000 - tn: 291631.0000 - fn: 28369.0000 - accuracy: 0.8582 - precision: 0.6454 - recall: 0.6454 - auc: 0.9115 - val_loss: 0.6514 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-004-files-38-39
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6522 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-38-39
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6519 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-38-39
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 40-40/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51418.0000 - fp: 28582.0000 - tn: 291418.0000 - fn: 28582.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9106 - val_loss: 0.6528 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-004-files-39-40
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51491.0000 - fp: 28509.0000 - tn: 291491.0000 - fn: 28509.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6523 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-39-40
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9110 - val_loss: 0.6506 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 72916.0000 - val_fn: 7084.0000 - val_accuracy: 0.8583 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-004-files-39-40
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9111 - val_loss: 0.6530 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 72838.0000 - val_fn: 7162.0000 - val_accuracy: 0.8568 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-004-files-39-40
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51432.0000 - fp: 28568.0000 - tn: 291432.0000 - fn: 28568.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9108 - val_loss: 0.6526 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-004-files-39-40
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 41-41/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9107 - val_loss: 0.6523 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-40-41
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51515.0000 - fp: 28485.0000 - tn: 291515.0000 - fn: 28485.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9107 - val_loss: 0.6521 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-40-41
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9106 - val_loss: 0.6518 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-004-files-40-41
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51587.0000 - fp: 28413.0000 - tn: 291587.0000 - fn: 28413.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9111 - val_loss: 0.6523 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-40-41
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9108 - val_loss: 0.6500 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 72937.0000 - val_fn: 7063.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-004-files-40-41
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 42-42/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6535 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 72826.0000 - val_fn: 7174.0000 - val_accuracy: 0.8565 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-004-files-41-42
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51511.0000 - fp: 28489.0000 - tn: 291511.0000 - fn: 28489.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6516 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 72882.0000 - val_fn: 7118.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-004-files-41-42
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51499.0000 - fp: 28501.0000 - tn: 291499.0000 - fn: 28501.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9104 - val_loss: 0.6525 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 72853.0000 - val_fn: 7147.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-41-42
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6506 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 72917.0000 - val_fn: 7083.0000 - val_accuracy: 0.8583 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-004-files-41-42
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51584.0000 - fp: 28416.0000 - tn: 291584.0000 - fn: 28416.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9110 - val_loss: 0.6518 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-41-42
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 43-43/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9111 - val_loss: 0.6519 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-42-43
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6533 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 72824.0000 - val_fn: 7176.0000 - val_accuracy: 0.8565 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-004-files-42-43
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51387.0000 - fp: 28613.0000 - tn: 291387.0000 - fn: 28613.0000 - accuracy: 0.8569 - precision: 0.6423 - recall: 0.6423 - auc: 0.9104 - val_loss: 0.6512 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-004-files-42-43
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9108 - val_loss: 0.6527 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-004-files-42-43
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9114 - val_loss: 0.6494 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 72952.0000 - val_fn: 7048.0000 - val_accuracy: 0.8590 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.9119
[INFO] saving weights to checkpoints/dnn-epoch-004-files-42-43
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 44-44/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9105 - val_loss: 0.6523 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-43-44
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6523 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-43-44
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51543.0000 - fp: 28457.0000 - tn: 291543.0000 - fn: 28457.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9110 - val_loss: 0.6524 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-43-44
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6523 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6513 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 72891.0000 - val_fn: 7109.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-43-44
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51537.0000 - fp: 28463.0000 - tn: 291537.0000 - fn: 28463.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6522 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-43-44
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 45-45/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51620.0000 - fp: 28380.0000 - tn: 291620.0000 - fn: 28380.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9111 - val_loss: 0.6520 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-44-45
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51538.0000 - fp: 28462.0000 - tn: 291538.0000 - fn: 28462.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6515 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-44-45
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51564.0000 - fp: 28436.0000 - tn: 291564.0000 - fn: 28436.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9108 - val_loss: 0.6509 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 72904.0000 - val_fn: 7096.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-004-files-44-45
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51590.0000 - fp: 28410.0000 - tn: 291590.0000 - fn: 28410.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9110 - val_loss: 0.6526 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-004-files-44-45
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51395.0000 - fp: 28605.0000 - tn: 291395.0000 - fn: 28605.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9107 - val_loss: 0.6511 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-004-files-44-45
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 46-46/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6506 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 72913.0000 - val_fn: 7087.0000 - val_accuracy: 0.8583 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-004-files-45-46
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51464.0000 - fp: 28536.0000 - tn: 291464.0000 - fn: 28536.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9109 - val_loss: 0.6515 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 72883.0000 - val_fn: 7117.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-004-files-45-46
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6514 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-45-46
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9108 - val_loss: 0.6501 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-004-files-45-46
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51569.0000 - fp: 28431.0000 - tn: 291569.0000 - fn: 28431.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9109 - val_loss: 0.6518 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-45-46
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 47-47/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51601.0000 - fp: 28399.0000 - tn: 291601.0000 - fn: 28399.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9110 - val_loss: 0.6512 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-46-47
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51559.0000 - fp: 28441.0000 - tn: 291559.0000 - fn: 28441.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9108 - val_loss: 0.6519 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-46-47
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6533 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 72822.0000 - val_fn: 7178.0000 - val_accuracy: 0.8564 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-004-files-46-47
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9105 - val_loss: 0.6515 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 72881.0000 - val_fn: 7119.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-004-files-46-47
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6507 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 72909.0000 - val_fn: 7091.0000 - val_accuracy: 0.8582 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-004-files-46-47
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 48-48/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9107 - val_loss: 0.6531 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 72830.0000 - val_fn: 7170.0000 - val_accuracy: 0.8566 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-004-files-47-48
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6516 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 72879.0000 - val_fn: 7121.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-004-files-47-48
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51547.0000 - fp: 28453.0000 - tn: 291547.0000 - fn: 28453.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9109 - val_loss: 0.6506 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-004-files-47-48
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.6520 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-47-48
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51606.0000 - fp: 28394.0000 - tn: 291606.0000 - fn: 28394.0000 - accuracy: 0.8580 - precision: 0.6451 - recall: 0.6451 - auc: 0.9109 - val_loss: 0.6507 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 72905.0000 - val_fn: 7095.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-004-files-47-48
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 49-49/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9115 - val_loss: 0.6519 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-48-49
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51430.0000 - fp: 28570.0000 - tn: 291430.0000 - fn: 28570.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9102 - val_loss: 0.6502 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 72924.0000 - val_fn: 7076.0000 - val_accuracy: 0.8585 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-004-files-48-49
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51469.0000 - fp: 28531.0000 - tn: 291469.0000 - fn: 28531.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6531 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-004-files-48-49
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6502 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 72922.0000 - val_fn: 7078.0000 - val_accuracy: 0.8584 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-004-files-48-49
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51495.0000 - fp: 28505.0000 - tn: 291495.0000 - fn: 28505.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9114 - val_loss: 0.6513 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-48-49
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 50-50/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9106 - val_loss: 0.6532 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 72823.0000 - val_fn: 7177.0000 - val_accuracy: 0.8565 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-004-files-49-50
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51482.0000 - fp: 28518.0000 - tn: 291482.0000 - fn: 28518.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6511 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-49-50
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51433.0000 - fp: 28567.0000 - tn: 291433.0000 - fn: 28567.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9103 - val_loss: 0.6524 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-004-files-49-50
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51461.0000 - fp: 28539.0000 - tn: 291461.0000 - fn: 28539.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6512 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-49-50
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51467.0000 - fp: 28533.0000 - tn: 291467.0000 - fn: 28533.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9107 - val_loss: 0.6522 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-49-50
[INFO] processing batch 500000-600000/519975
[33m[LOSS] 0.6521586559295655[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6521586559295655  <  0.001
[33m[INFO] epoch 5/10[0m
[33m[INFO] loading file 1-1/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0706 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-0-1
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-0-1
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0227 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9993 - val_loss: 2.2976 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.8826
[INFO] saving weights to checkpoints/dnn-epoch-005-files-0-1
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8376 - tp: 42447.0000 - fp: 37553.0000 - tn: 282447.0000 - fn: 37553.0000 - accuracy: 0.8122 - precision: 0.5306 - recall: 0.5306 - auc: 0.8826 - val_loss: 0.6916 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-005-files-0-1
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6917 - tp: 42438.0000 - fp: 37562.0000 - tn: 282438.0000 - fn: 37562.0000 - accuracy: 0.8122 - precision: 0.5305 - recall: 0.5305 - auc: 0.8823 - val_loss: 0.6917 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-005-files-0-1
[33m[INFO] loading file 2-2/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6917 - tp: 42435.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37565.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5304 - auc: 0.8825 - val_loss: 0.6918 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 70589.0000 - val_fn: 9411.0000 - val_accuracy: 0.8118 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-005-files-1-2
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4427 - tp: 67619.0000 - fp: 12381.0000 - tn: 307619.0000 - fn: 12381.0000 - accuracy: 0.9381 - precision: 0.8452 - recall: 0.8452 - auc: 0.9612 - val_loss: 0.1727 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-1-2
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3149 - tp: 72432.0000 - fp: 7568.0000 - tn: 312432.0000 - fn: 7568.0000 - accuracy: 0.9622 - precision: 0.9054 - recall: 0.9054 - auc: 0.9765 - val_loss: 1.1668 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 70593.0000 - val_fn: 9407.0000 - val_accuracy: 0.8119 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-005-files-1-2
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7165 - tp: 42321.0000 - fp: 37679.0000 - tn: 282321.0000 - fn: 37679.0000 - accuracy: 0.8116 - precision: 0.5290 - recall: 0.5290 - auc: 0.8825 - val_loss: 0.6917 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 70602.0000 - val_fn: 9398.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-005-files-1-2
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4477 - tp: 67360.0000 - fp: 12640.0000 - tn: 307360.0000 - fn: 12640.0000 - accuracy: 0.9368 - precision: 0.8420 - recall: 0.8420 - auc: 0.9604 - val_loss: 0.1724 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-1-2
[33m[INFO] loading file 3-3/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6956 - tp: 45236.0000 - fp: 34764.0000 - tn: 285236.0000 - fn: 34764.0000 - accuracy: 0.8262 - precision: 0.5655 - recall: 0.5655 - auc: 0.8913 - val_loss: 0.6949 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 70571.0000 - val_fn: 9429.0000 - val_accuracy: 0.8114 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.8821
[INFO] saving weights to checkpoints/dnn-epoch-005-files-2-3
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5938 - tp: 57751.0000 - fp: 22249.0000 - tn: 297751.0000 - fn: 22249.0000 - accuracy: 0.8888 - precision: 0.7219 - recall: 0.7219 - auc: 0.9306 - val_loss: 0.3171 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-2-3
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0619 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0200 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-2-3
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0139 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-2-3
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0082 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0067 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-2-3
[33m[INFO] loading file 4-4/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-3-4
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0046 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-3-4
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-3-4
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4227 - tp: 71528.0000 - fp: 8472.0000 - tn: 311528.0000 - fn: 8472.0000 - accuracy: 0.9576 - precision: 0.8941 - recall: 0.8941 - auc: 0.9701 - val_loss: 1.5219 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 67806.0000 - val_fn: 12194.0000 - val_accuracy: 0.7561 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.8476
[INFO] saving weights to checkpoints/dnn-epoch-005-files-3-4
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6126 - tp: 56887.0000 - fp: 23113.0000 - tn: 296887.0000 - fn: 23113.0000 - accuracy: 0.8844 - precision: 0.7111 - recall: 0.7111 - auc: 0.9281 - val_loss: 0.3457 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-3-4
[33m[INFO] loading file 5-5/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5272 - tp: 62445.0000 - fp: 17555.0000 - tn: 302445.0000 - fn: 17555.0000 - accuracy: 0.9122 - precision: 0.7806 - recall: 0.7806 - auc: 0.9453 - val_loss: 0.6984 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-005-files-4-5
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6551 - tp: 51316.0000 - fp: 28684.0000 - tn: 291316.0000 - fn: 28684.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9104 - val_loss: 0.5320 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 77052.0000 - val_fn: 2948.0000 - val_accuracy: 0.9410 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.9632
[INFO] saving weights to checkpoints/dnn-epoch-005-files-4-5
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0713 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-4-5
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-4-5
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0083 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-4-5
[33m[INFO] loading file 6-6/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0059 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-5-6
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-5-6
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-5-6
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2811 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 75632.0000 - val_fn: 4368.0000 - val_accuracy: 0.9126 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.8635
[INFO] saving weights to checkpoints/dnn-epoch-005-files-5-6
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8460 - tp: 51195.0000 - fp: 28805.0000 - tn: 291195.0000 - fn: 28805.0000 - accuracy: 0.8560 - precision: 0.6399 - recall: 0.6399 - auc: 0.9052 - val_loss: 0.6548 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 72768.0000 - val_fn: 7232.0000 - val_accuracy: 0.8554 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.9096
[INFO] saving weights to checkpoints/dnn-epoch-005-files-5-6
[33m[INFO] loading file 7-7/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6537 - tp: 51210.0000 - fp: 28790.0000 - tn: 291210.0000 - fn: 28790.0000 - accuracy: 0.8561 - precision: 0.6401 - recall: 0.6401 - auc: 0.9102 - val_loss: 0.6537 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 72803.0000 - val_fn: 7197.0000 - val_accuracy: 0.8561 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.9100
[INFO] saving weights to checkpoints/dnn-epoch-005-files-6-7
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51338.0000 - fp: 28662.0000 - tn: 291338.0000 - fn: 28662.0000 - accuracy: 0.8567 - precision: 0.6417 - recall: 0.6417 - auc: 0.9106 - val_loss: 0.6522 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-6-7
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4802 - tp: 65370.0000 - fp: 14630.0000 - tn: 305370.0000 - fn: 14630.0000 - accuracy: 0.9268 - precision: 0.8171 - recall: 0.8171 - auc: 0.9542 - val_loss: 0.2032 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-6-7
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0513 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0191 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-6-7
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0135 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0099 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-6-7
[33m[INFO] loading file 8-8/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0080 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0066 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-7-8
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0057 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-7-8
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0040 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-7-8
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3560 - tp: 73166.0000 - fp: 6834.0000 - tn: 313166.0000 - fn: 6834.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9770 - val_loss: 0.5508 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 76368.0000 - val_fn: 3632.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-005-files-7-8
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4810 - tp: 65505.0000 - fp: 14495.0000 - tn: 305505.0000 - fn: 14495.0000 - accuracy: 0.9275 - precision: 0.8188 - recall: 0.8188 - auc: 0.9544 - val_loss: 0.4730 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 76383.0000 - val_fn: 3617.0000 - val_accuracy: 0.9277 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.9548
[INFO] saving weights to checkpoints/dnn-epoch-005-files-7-8
[33m[INFO] loading file 9-9/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4773 - tp: 65300.0000 - fp: 14700.0000 - tn: 305300.0000 - fn: 14700.0000 - accuracy: 0.9265 - precision: 0.8163 - recall: 0.8163 - auc: 0.9543 - val_loss: 0.4804 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 76283.0000 - val_fn: 3717.0000 - val_accuracy: 0.9257 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.9535
[INFO] saving weights to checkpoints/dnn-epoch-005-files-8-9
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0976 - tp: 78936.0000 - fp: 1064.0000 - tn: 318936.0000 - fn: 1064.0000 - accuracy: 0.9947 - precision: 0.9867 - recall: 0.9867 - auc: 0.9968 - val_loss: 0.0266 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-8-9
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0171 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0116 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-8-9
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0092 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0074 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-8-9
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0063 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0054 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-8-9
[33m[INFO] loading file 10-10/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0043 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-9-10
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0084 - tp: 79936.0000 - fp: 64.0000 - tn: 319936.0000 - fn: 64.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 0.9995 - val_loss: 2.0150 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.7763
[INFO] saving weights to checkpoints/dnn-epoch-005-files-9-10
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7567 - tp: 56672.0000 - fp: 23328.0000 - tn: 296672.0000 - fn: 23328.0000 - accuracy: 0.8834 - precision: 0.7084 - recall: 0.7084 - auc: 0.9244 - val_loss: 0.3463 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-9-10
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0641 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0201 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-9-10
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0140 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-9-10
[33m[INFO] loading file 11-11/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0082 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-10-11
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-10-11
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-10-11
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-10-11
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-10-11
[33m[INFO] loading file 12-12/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0027 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0025 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-11-12
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0024 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0134 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 76689.0000 - val_fn: 3311.0000 - val_accuracy: 0.9338 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8965
[INFO] saving weights to checkpoints/dnn-epoch-005-files-11-12
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8649 - tp: 51328.0000 - fp: 28672.0000 - tn: 291328.0000 - fn: 28672.0000 - accuracy: 0.8566 - precision: 0.6416 - recall: 0.6416 - auc: 0.9044 - val_loss: 0.5691 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 75792.0000 - val_fn: 4208.0000 - val_accuracy: 0.9158 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.9474
[INFO] saving weights to checkpoints/dnn-epoch-005-files-11-12
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0715 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-11-12
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-11-12
[33m[INFO] loading file 13-13/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0083 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-12-13
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0059 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-12-13
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3614 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 75075.0000 - val_fn: 4925.0000 - val_accuracy: 0.9015 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.8461
[INFO] saving weights to checkpoints/dnn-epoch-005-files-12-13
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8165 - tp: 51313.0000 - fp: 28687.0000 - tn: 291313.0000 - fn: 28687.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9088 - val_loss: 0.6516 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-005-files-12-13
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51356.0000 - fp: 28644.0000 - tn: 291356.0000 - fn: 28644.0000 - accuracy: 0.8568 - precision: 0.6420 - recall: 0.6420 - auc: 0.9103 - val_loss: 0.6518 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-12-13
[33m[INFO] loading file 14-14/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5274 - tp: 62543.0000 - fp: 17457.0000 - tn: 302543.0000 - fn: 17457.0000 - accuracy: 0.9127 - precision: 0.7818 - recall: 0.7818 - auc: 0.9452 - val_loss: 0.2465 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-13-14
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0557 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0195 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-13-14
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0137 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0100 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-13-14
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0081 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0067 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-13-14
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-13-14
[33m[INFO] loading file 15-15/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0046 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0040 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-14-15
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0038 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-14-15
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-14-15
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0027 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.8647 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 71586.0000 - val_fn: 8414.0000 - val_accuracy: 0.8317 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.7371
[INFO] saving weights to checkpoints/dnn-epoch-005-files-14-15
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.8326 - tp: 42561.0000 - fp: 37439.0000 - tn: 282561.0000 - fn: 37439.0000 - accuracy: 0.8128 - precision: 0.5320 - recall: 0.5320 - auc: 0.8061 - val_loss: 0.7341 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 70627.0000 - val_fn: 9373.0000 - val_accuracy: 0.8125 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-005-files-14-15
[33m[INFO] loading file 16-16/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7177 - tp: 42492.0000 - fp: 37508.0000 - tn: 282492.0000 - fn: 37508.0000 - accuracy: 0.8125 - precision: 0.5311 - recall: 0.5311 - auc: 0.8825 - val_loss: 0.7087 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 70618.0000 - val_fn: 9382.0000 - val_accuracy: 0.8124 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-005-files-15-16
[INFO] processing batch 100000-200000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5996 - tp: 58381.0000 - fp: 21619.0000 - tn: 298381.0000 - fn: 21619.0000 - accuracy: 0.8919 - precision: 0.7298 - recall: 0.7298 - auc: 0.9323 - val_loss: 0.3219 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-15-16
[INFO] processing batch 200000-300000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0648 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0217 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-15-16
[INFO] processing batch 300000-400000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0153 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0112 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-15-16
[INFO] processing batch 400000-500000/439690
[33m[INFO] loading file 17-17/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0092 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0076 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-16-17
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0066 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0058 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-16-17
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0052 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0047 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-16-17
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9905 - tp: 68607.0000 - fp: 11393.0000 - tn: 308607.0000 - fn: 11393.0000 - accuracy: 0.9430 - precision: 0.8576 - recall: 0.8576 - auc: 0.9003 - val_loss: 0.7594 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 76369.0000 - val_fn: 3631.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9092
[INFO] saving weights to checkpoints/dnn-epoch-005-files-16-17
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5641 - tp: 65526.0000 - fp: 14474.0000 - tn: 305526.0000 - fn: 14474.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.9513 - val_loss: 0.3249 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 78648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9730 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9831
[INFO] saving weights to checkpoints/dnn-epoch-005-files-16-17
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 18-18/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3446 - tp: 72130.0000 - fp: 7870.0000 - tn: 312130.0000 - fn: 7870.0000 - accuracy: 0.9607 - precision: 0.9016 - recall: 0.9016 - auc: 0.9752 - val_loss: 0.9844 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 72369.0000 - val_fn: 7631.0000 - val_accuracy: 0.8474 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.9046
[INFO] saving weights to checkpoints/dnn-epoch-005-files-17-18
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7019 - tp: 49699.0000 - fp: 30301.0000 - tn: 289699.0000 - fn: 30301.0000 - accuracy: 0.8485 - precision: 0.6212 - recall: 0.6212 - auc: 0.9054 - val_loss: 0.6818 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 72357.0000 - val_fn: 7643.0000 - val_accuracy: 0.8471 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.9045
[INFO] saving weights to checkpoints/dnn-epoch-005-files-17-18
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6785 - tp: 49541.0000 - fp: 30459.0000 - tn: 289541.0000 - fn: 30459.0000 - accuracy: 0.8477 - precision: 0.6193 - recall: 0.6193 - auc: 0.9048 - val_loss: 0.6761 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 72397.0000 - val_fn: 7603.0000 - val_accuracy: 0.8479 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.9050
[INFO] saving weights to checkpoints/dnn-epoch-005-files-17-18
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2751 - tp: 74509.0000 - fp: 5491.0000 - tn: 314509.0000 - fn: 5491.0000 - accuracy: 0.9725 - precision: 0.9314 - recall: 0.9314 - auc: 0.9828 - val_loss: 0.0776 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-17-18
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0339 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0177 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-17-18
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 19-19/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0132 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-18-19
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0084 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0071 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-18-19
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0062 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0055 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-18-19
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6461 - tp: 69321.0000 - fp: 10679.0000 - tn: 309321.0000 - fn: 10679.0000 - accuracy: 0.9466 - precision: 0.8665 - recall: 0.8665 - auc: 0.9383 - val_loss: 1.5690 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 67882.0000 - val_fn: 12118.0000 - val_accuracy: 0.7576 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.8485
[INFO] saving weights to checkpoints/dnn-epoch-005-files-18-19
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7452 - tp: 44896.0000 - fp: 32960.0000 - tn: 287040.0000 - fn: 35104.0000 - accuracy: 0.8298 - precision: 0.5767 - recall: 0.5612 - auc: 0.8911 - val_loss: 0.9772 - val_tp: 0.0000e+00 - val_fp: 20000.0000 - val_tn: 60000.0000 - val_fn: 20000.0000 - val_accuracy: 0.6000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7500
[INFO] saving weights to checkpoints/dnn-epoch-005-files-18-19
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 20-20/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.1063 - tp: 78496.0000 - fp: 1216.0000 - tn: 318784.0000 - fn: 1504.0000 - accuracy: 0.9932 - precision: 0.9847 - recall: 0.9812 - auc: 0.9998 - val_loss: 0.1241 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 79491.0000 - val_fn: 509.0000 - val_accuracy: 0.9898 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9936
[INFO] saving weights to checkpoints/dnn-epoch-005-files-19-20
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5202 - tp: 65427.0000 - fp: 14573.0000 - tn: 305427.0000 - fn: 14573.0000 - accuracy: 0.9271 - precision: 0.8178 - recall: 0.8178 - auc: 0.9545 - val_loss: 0.4847 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 76357.0000 - val_fn: 3643.0000 - val_accuracy: 0.9271 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.9545
[INFO] saving weights to checkpoints/dnn-epoch-005-files-19-20
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4851 - tp: 65351.0000 - fp: 14649.0000 - tn: 305351.0000 - fn: 14649.0000 - accuracy: 0.9268 - precision: 0.8169 - recall: 0.8169 - auc: 0.9542 - val_loss: 0.4816 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 76371.0000 - val_fn: 3629.0000 - val_accuracy: 0.9274 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-005-files-19-20
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2115 - tp: 76024.0000 - fp: 3976.0000 - tn: 316024.0000 - fn: 3976.0000 - accuracy: 0.9801 - precision: 0.9503 - recall: 0.9503 - auc: 0.9876 - val_loss: 0.0572 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-19-20
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0286 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0163 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-19-20
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 21-21/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539688, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0123 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0095 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-20-21
[INFO] processing batch 100000-200000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0080 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-20-21
[INFO] processing batch 200000-300000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0060 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0053 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-20-21
[INFO] processing batch 300000-400000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0043 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-20-21
[INFO] processing batch 400000-500000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0040 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0037 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-20-21
[INFO] processing batch 500000-600000/539688
[33m[INFO] loading file 22-22/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.3345 - tp: 55006.0000 - fp: 24994.0000 - tn: 295006.0000 - fn: 24994.0000 - accuracy: 0.8750 - precision: 0.6876 - recall: 0.6876 - auc: 0.8472 - val_loss: 0.8126 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-005-files-21-22
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7321 - tp: 42398.0000 - fp: 37602.0000 - tn: 282398.0000 - fn: 37602.0000 - accuracy: 0.8120 - precision: 0.5300 - recall: 0.5300 - auc: 0.8824 - val_loss: 0.7172 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.8816
[INFO] saving weights to checkpoints/dnn-epoch-005-files-21-22
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7115 - tp: 42369.0000 - fp: 37631.0000 - tn: 282369.0000 - fn: 37631.0000 - accuracy: 0.8118 - precision: 0.5296 - recall: 0.5296 - auc: 0.8825 - val_loss: 0.7075 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 70623.0000 - val_fn: 9377.0000 - val_accuracy: 0.8125 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-005-files-21-22
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7052 - tp: 42452.0000 - fp: 37548.0000 - tn: 282452.0000 - fn: 37548.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5307 - auc: 0.8823 - val_loss: 0.7033 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 70601.0000 - val_fn: 9399.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-005-files-21-22
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7020 - tp: 42382.0000 - fp: 37618.0000 - tn: 282382.0000 - fn: 37618.0000 - accuracy: 0.8119 - precision: 0.5298 - recall: 0.5298 - auc: 0.8825 - val_loss: 0.7008 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-005-files-21-22
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 23-23/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6549 - tp: 52270.0000 - fp: 27730.0000 - tn: 292270.0000 - fn: 27730.0000 - accuracy: 0.8613 - precision: 0.6534 - recall: 0.6534 - auc: 0.9137 - val_loss: 0.4236 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-22-23
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0717 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0217 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-22-23
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0152 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0111 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-22-23
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0090 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0075 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-22-23
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0065 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0057 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-22-23
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 24-24/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0051 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0046 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-23-24
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0042 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0038 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-23-24
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0036 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0033 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-23-24
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-23-24
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2733 - tp: 75698.0000 - fp: 4302.0000 - tn: 315698.0000 - fn: 4302.0000 - accuracy: 0.9785 - precision: 0.9462 - recall: 0.9462 - auc: 0.9801 - val_loss: 1.3931 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 72912.0000 - val_fn: 7088.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-005-files-23-24
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 25-25/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7217 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9112 - val_loss: 0.6575 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-005-files-24-25
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6564 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9111 - val_loss: 0.6555 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-005-files-24-25
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6560 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.6563 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-005-files-24-25
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6554 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9106 - val_loss: 0.6561 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-005-files-24-25
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6553 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9106 - val_loss: 0.6551 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-24-25
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 26-26/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6546 - tp: 51523.0000 - fp: 28477.0000 - tn: 291523.0000 - fn: 28477.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9108 - val_loss: 1.6330 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.8310
[INFO] saving weights to checkpoints/dnn-epoch-005-files-25-26
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.2140 - tp: 51579.0000 - fp: 28421.0000 - tn: 291579.0000 - fn: 28421.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.8514 - val_loss: 0.7018 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-25-26
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6829 - tp: 51462.0000 - fp: 28538.0000 - tn: 291462.0000 - fn: 28538.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6713 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-005-files-25-26
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6680 - tp: 51506.0000 - fp: 28494.0000 - tn: 291506.0000 - fn: 28494.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9106 - val_loss: 0.6630 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 72936.0000 - val_fn: 7064.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-005-files-25-26
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6631 - tp: 51474.0000 - fp: 28526.0000 - tn: 291474.0000 - fn: 28526.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9107 - val_loss: 0.6593 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 72945.0000 - val_fn: 7055.0000 - val_accuracy: 0.8589 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.9118
[INFO] saving weights to checkpoints/dnn-epoch-005-files-25-26
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 27-27/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (479817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6609 - tp: 51419.0000 - fp: 28581.0000 - tn: 291419.0000 - fn: 28581.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9102 - val_loss: 0.6607 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-005-files-26-27
[INFO] processing batch 100000-200000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6588 - tp: 51485.0000 - fp: 28515.0000 - tn: 291485.0000 - fn: 28515.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6567 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 72918.0000 - val_fn: 7082.0000 - val_accuracy: 0.8584 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-005-files-26-27
[INFO] processing batch 200000-300000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6570 - tp: 51583.0000 - fp: 28417.0000 - tn: 291583.0000 - fn: 28417.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9107 - val_loss: 0.6574 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-26-27
[INFO] processing batch 300000-400000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6575 - tp: 51396.0000 - fp: 28604.0000 - tn: 291396.0000 - fn: 28604.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9105 - val_loss: 0.6571 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 72851.0000 - val_fn: 7149.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-005-files-26-27
[INFO] processing batch 400000-500000/479817
[33m[INFO] loading file 28-28/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6563 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6560 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-27-28
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6564 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9105 - val_loss: 0.6558 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-27-28
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6556 - tp: 51458.0000 - fp: 28542.0000 - tn: 291458.0000 - fn: 28542.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9104 - val_loss: 0.6552 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-27-28
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6552 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9107 - val_loss: 0.6539 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-005-files-27-28
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6545 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9107 - val_loss: 0.6552 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-27-28
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 29-29/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6547 - tp: 51460.0000 - fp: 28540.0000 - tn: 291460.0000 - fn: 28540.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6549 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-28-29
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6540 - tp: 51527.0000 - fp: 28473.0000 - tn: 291527.0000 - fn: 28473.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6548 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-005-files-28-29
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6541 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6522 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-005-files-28-29
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6534 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9110 - val_loss: 0.6543 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-28-29
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6536 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-28-29
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 30-30/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6534 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6539 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-29-30
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6539 - tp: 51450.0000 - fp: 28550.0000 - tn: 291450.0000 - fn: 28550.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9105 - val_loss: 0.6540 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-29-30
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6535 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6539 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-29-30
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6531 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-005-files-29-30
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9112 - val_loss: 0.6533 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 72870.0000 - val_fn: 7130.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-29-30
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 31-31/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6517 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 72921.0000 - val_fn: 7079.0000 - val_accuracy: 0.8584 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-005-files-30-31
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51524.0000 - fp: 28476.0000 - tn: 291524.0000 - fn: 28476.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6522 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 72902.0000 - val_fn: 7098.0000 - val_accuracy: 0.8580 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-005-files-30-31
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6535 - tp: 51428.0000 - fp: 28572.0000 - tn: 291428.0000 - fn: 28572.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9106 - val_loss: 0.6530 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-30-31
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6525 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-30-31
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6523 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 72893.0000 - val_fn: 7107.0000 - val_accuracy: 0.8579 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-005-files-30-31
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 32-32/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9110 - val_loss: 0.6523 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-31-32
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51531.0000 - fp: 28469.0000 - tn: 291531.0000 - fn: 28469.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6527 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-31-32
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51576.0000 - fp: 28424.0000 - tn: 291576.0000 - fn: 28424.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9111 - val_loss: 0.6522 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-31-32
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51489.0000 - fp: 28511.0000 - tn: 291489.0000 - fn: 28511.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6530 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-31-32
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6530 - tp: 51449.0000 - fp: 28551.0000 - tn: 291449.0000 - fn: 28551.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9109 - val_loss: 0.6528 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-31-32
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 33-33/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6526 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-32-33
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9111 - val_loss: 0.6528 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-32-33
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51404.0000 - fp: 28596.0000 - tn: 291404.0000 - fn: 28596.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9106 - val_loss: 0.6529 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-32-33
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51552.0000 - fp: 28448.0000 - tn: 291552.0000 - fn: 28448.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9107 - val_loss: 0.6521 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-32-33
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51594.0000 - fp: 28406.0000 - tn: 291594.0000 - fn: 28406.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9109 - val_loss: 0.6508 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-005-files-32-33
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 34-34/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9106 - val_loss: 0.6533 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-005-files-33-34
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.6528 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-33-34
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51588.0000 - fp: 28412.0000 - tn: 291588.0000 - fn: 28412.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9110 - val_loss: 0.6523 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-005-files-33-34
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6530 - tp: 51408.0000 - fp: 28592.0000 - tn: 291408.0000 - fn: 28592.0000 - accuracy: 0.8570 - precision: 0.6426 - recall: 0.6426 - auc: 0.9107 - val_loss: 0.6535 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 72834.0000 - val_fn: 7166.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-005-files-33-34
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6522 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-005-files-33-34
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 35-35/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51520.0000 - fp: 28480.0000 - tn: 291520.0000 - fn: 28480.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6530 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-34-35
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6522 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-005-files-34-35
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6523 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6517 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-34-35
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51521.0000 - fp: 28479.0000 - tn: 291521.0000 - fn: 28479.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9108 - val_loss: 0.6528 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-34-35
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51570.0000 - fp: 28430.0000 - tn: 291570.0000 - fn: 28430.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9113 - val_loss: 0.6523 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-34-35
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 36-36/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6522 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-35-36
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51644.0000 - fp: 28356.0000 - tn: 291644.0000 - fn: 28356.0000 - accuracy: 0.8582 - precision: 0.6456 - recall: 0.6456 - auc: 0.9110 - val_loss: 0.6516 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 72895.0000 - val_fn: 7105.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-005-files-35-36
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9106 - val_loss: 0.6504 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 72933.0000 - val_fn: 7067.0000 - val_accuracy: 0.8587 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-005-files-35-36
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51415.0000 - fp: 28585.0000 - tn: 291415.0000 - fn: 28585.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9108 - val_loss: 0.6520 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 72878.0000 - val_fn: 7122.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-005-files-35-36
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6526 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-35-36
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 37-37/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51413.0000 - fp: 28587.0000 - tn: 291413.0000 - fn: 28587.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9106 - val_loss: 0.6527 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-36-37
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51456.0000 - fp: 28544.0000 - tn: 291456.0000 - fn: 28544.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9106 - val_loss: 0.6513 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-005-files-36-37
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51565.0000 - fp: 28435.0000 - tn: 291565.0000 - fn: 28435.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9111 - val_loss: 0.6522 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-36-37
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51512.0000 - fp: 28488.0000 - tn: 291512.0000 - fn: 28488.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6516 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 72888.0000 - val_fn: 7112.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-36-37
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51528.0000 - fp: 28472.0000 - tn: 291528.0000 - fn: 28472.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6513 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 72899.0000 - val_fn: 7101.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-005-files-36-37
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 38-38/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51513.0000 - fp: 28487.0000 - tn: 291513.0000 - fn: 28487.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9106 - val_loss: 0.6503 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-005-files-37-38
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51589.0000 - fp: 28411.0000 - tn: 291589.0000 - fn: 28411.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9109 - val_loss: 0.6530 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-005-files-37-38
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51481.0000 - fp: 28519.0000 - tn: 291481.0000 - fn: 28519.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6525 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-37-38
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51549.0000 - fp: 28451.0000 - tn: 291549.0000 - fn: 28451.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9107 - val_loss: 0.6513 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 72898.0000 - val_fn: 7102.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-005-files-37-38
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9109 - val_loss: 0.6523 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 72866.0000 - val_fn: 7134.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-37-38
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 39-39/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6528 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 72847.0000 - val_fn: 7153.0000 - val_accuracy: 0.8569 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-005-files-38-39
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51597.0000 - fp: 28403.0000 - tn: 291597.0000 - fn: 28403.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9110 - val_loss: 0.6509 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 72910.0000 - val_fn: 7090.0000 - val_accuracy: 0.8582 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-005-files-38-39
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51631.0000 - fp: 28369.0000 - tn: 291631.0000 - fn: 28369.0000 - accuracy: 0.8582 - precision: 0.6454 - recall: 0.6454 - auc: 0.9110 - val_loss: 0.6514 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-005-files-38-39
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9114 - val_loss: 0.6521 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-38-39
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6519 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-38-39
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 40-40/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51418.0000 - fp: 28582.0000 - tn: 291418.0000 - fn: 28582.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9103 - val_loss: 0.6528 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-005-files-39-40
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51491.0000 - fp: 28509.0000 - tn: 291491.0000 - fn: 28509.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6523 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-39-40
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9109 - val_loss: 0.6507 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 72916.0000 - val_fn: 7084.0000 - val_accuracy: 0.8583 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-005-files-39-40
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9111 - val_loss: 0.6531 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 72838.0000 - val_fn: 7162.0000 - val_accuracy: 0.8568 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-005-files-39-40
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51432.0000 - fp: 28568.0000 - tn: 291432.0000 - fn: 28568.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9107 - val_loss: 0.6526 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-005-files-39-40
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 41-41/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9107 - val_loss: 0.6523 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-40-41
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51515.0000 - fp: 28485.0000 - tn: 291515.0000 - fn: 28485.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6521 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-40-41
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-005-files-40-41
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51587.0000 - fp: 28413.0000 - tn: 291587.0000 - fn: 28413.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9111 - val_loss: 0.6523 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-40-41
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.6500 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 72937.0000 - val_fn: 7063.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-005-files-40-41
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 42-42/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9110 - val_loss: 0.6533 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 72826.0000 - val_fn: 7174.0000 - val_accuracy: 0.8565 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-005-files-41-42
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51511.0000 - fp: 28489.0000 - tn: 291511.0000 - fn: 28489.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6516 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 72882.0000 - val_fn: 7118.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-005-files-41-42
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51499.0000 - fp: 28501.0000 - tn: 291499.0000 - fn: 28501.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6524 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 72853.0000 - val_fn: 7147.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-41-42
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9106 - val_loss: 0.6505 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 72917.0000 - val_fn: 7083.0000 - val_accuracy: 0.8583 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-005-files-41-42
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51584.0000 - fp: 28416.0000 - tn: 291584.0000 - fn: 28416.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9113 - val_loss: 0.6519 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-41-42
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 43-43/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9114 - val_loss: 0.6518 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-42-43
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6533 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 72824.0000 - val_fn: 7176.0000 - val_accuracy: 0.8565 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-005-files-42-43
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51387.0000 - fp: 28613.0000 - tn: 291387.0000 - fn: 28613.0000 - accuracy: 0.8569 - precision: 0.6423 - recall: 0.6423 - auc: 0.9107 - val_loss: 0.6511 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-005-files-42-43
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6527 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-005-files-42-43
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9109 - val_loss: 0.6495 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 72952.0000 - val_fn: 7048.0000 - val_accuracy: 0.8590 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.9119
[INFO] saving weights to checkpoints/dnn-epoch-005-files-42-43
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 44-44/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9105 - val_loss: 0.6523 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-43-44
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6523 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-43-44
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51543.0000 - fp: 28457.0000 - tn: 291543.0000 - fn: 28457.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9111 - val_loss: 0.6523 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-43-44
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6523 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9108 - val_loss: 0.6513 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 72891.0000 - val_fn: 7109.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-43-44
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51537.0000 - fp: 28463.0000 - tn: 291537.0000 - fn: 28463.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9109 - val_loss: 0.6521 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-43-44
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 45-45/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51620.0000 - fp: 28380.0000 - tn: 291620.0000 - fn: 28380.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9116 - val_loss: 0.6521 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-44-45
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51538.0000 - fp: 28462.0000 - tn: 291538.0000 - fn: 28462.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9109 - val_loss: 0.6515 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-44-45
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51564.0000 - fp: 28436.0000 - tn: 291564.0000 - fn: 28436.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9114 - val_loss: 0.6508 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 72904.0000 - val_fn: 7096.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-005-files-44-45
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51590.0000 - fp: 28410.0000 - tn: 291590.0000 - fn: 28410.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9108 - val_loss: 0.6527 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-005-files-44-45
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51395.0000 - fp: 28605.0000 - tn: 291395.0000 - fn: 28605.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9105 - val_loss: 0.6511 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-005-files-44-45
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 46-46/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6506 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 72913.0000 - val_fn: 7087.0000 - val_accuracy: 0.8583 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-005-files-45-46
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51464.0000 - fp: 28536.0000 - tn: 291464.0000 - fn: 28536.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9107 - val_loss: 0.6515 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 72883.0000 - val_fn: 7117.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-005-files-45-46
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9108 - val_loss: 0.6514 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-45-46
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9111 - val_loss: 0.6501 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-005-files-45-46
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51569.0000 - fp: 28431.0000 - tn: 291569.0000 - fn: 28431.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.6518 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-45-46
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 47-47/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51601.0000 - fp: 28399.0000 - tn: 291601.0000 - fn: 28399.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9113 - val_loss: 0.6512 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-46-47
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51559.0000 - fp: 28441.0000 - tn: 291559.0000 - fn: 28441.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9109 - val_loss: 0.6518 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-46-47
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9110 - val_loss: 0.6532 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 72822.0000 - val_fn: 7178.0000 - val_accuracy: 0.8564 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-005-files-46-47
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6515 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 72881.0000 - val_fn: 7119.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-005-files-46-47
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6507 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 72909.0000 - val_fn: 7091.0000 - val_accuracy: 0.8582 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-005-files-46-47
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 48-48/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6530 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 72830.0000 - val_fn: 7170.0000 - val_accuracy: 0.8566 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-005-files-47-48
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6516 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 72879.0000 - val_fn: 7121.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-005-files-47-48
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51547.0000 - fp: 28453.0000 - tn: 291547.0000 - fn: 28453.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9108 - val_loss: 0.6506 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-005-files-47-48
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6520 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-47-48
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51606.0000 - fp: 28394.0000 - tn: 291606.0000 - fn: 28394.0000 - accuracy: 0.8580 - precision: 0.6451 - recall: 0.6451 - auc: 0.9115 - val_loss: 0.6508 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 72905.0000 - val_fn: 7095.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-005-files-47-48
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 49-49/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9109 - val_loss: 0.6519 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-48-49
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51430.0000 - fp: 28570.0000 - tn: 291430.0000 - fn: 28570.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9104 - val_loss: 0.6502 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 72924.0000 - val_fn: 7076.0000 - val_accuracy: 0.8585 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-005-files-48-49
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51469.0000 - fp: 28531.0000 - tn: 291469.0000 - fn: 28531.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9106 - val_loss: 0.6530 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-005-files-48-49
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9112 - val_loss: 0.6505 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 72922.0000 - val_fn: 7078.0000 - val_accuracy: 0.8584 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-005-files-48-49
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51495.0000 - fp: 28505.0000 - tn: 291495.0000 - fn: 28505.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9115 - val_loss: 0.6513 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-48-49
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 50-50/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9109 - val_loss: 0.6532 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 72823.0000 - val_fn: 7177.0000 - val_accuracy: 0.8565 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-005-files-49-50
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51482.0000 - fp: 28518.0000 - tn: 291482.0000 - fn: 28518.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6511 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-49-50
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51433.0000 - fp: 28567.0000 - tn: 291433.0000 - fn: 28567.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9106 - val_loss: 0.6524 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-005-files-49-50
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51461.0000 - fp: 28539.0000 - tn: 291461.0000 - fn: 28539.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9110 - val_loss: 0.6512 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-49-50
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51467.0000 - fp: 28533.0000 - tn: 291467.0000 - fn: 28533.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9106 - val_loss: 0.6521 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-49-50
[INFO] processing batch 500000-600000/519975
[33m[LOSS] 0.652139933681488[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.652139933681488  <  0.001
[33m[INFO] epoch 6/10[0m
[33m[INFO] loading file 1-1/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0711 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-0-1
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-0-1
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0227 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9993 - val_loss: 2.2971 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.8826
[INFO] saving weights to checkpoints/dnn-epoch-006-files-0-1
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8379 - tp: 42447.0000 - fp: 37553.0000 - tn: 282447.0000 - fn: 37553.0000 - accuracy: 0.8122 - precision: 0.5306 - recall: 0.5306 - auc: 0.8827 - val_loss: 0.6916 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-006-files-0-1
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6917 - tp: 42438.0000 - fp: 37562.0000 - tn: 282438.0000 - fn: 37562.0000 - accuracy: 0.8122 - precision: 0.5305 - recall: 0.5305 - auc: 0.8826 - val_loss: 0.6918 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-006-files-0-1
[33m[INFO] loading file 2-2/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6917 - tp: 42435.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37565.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5304 - auc: 0.8827 - val_loss: 0.6918 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 70589.0000 - val_fn: 9411.0000 - val_accuracy: 0.8118 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-006-files-1-2
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4428 - tp: 67619.0000 - fp: 12381.0000 - tn: 307619.0000 - fn: 12381.0000 - accuracy: 0.9381 - precision: 0.8452 - recall: 0.8452 - auc: 0.9613 - val_loss: 0.1693 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-1-2
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3148 - tp: 72432.0000 - fp: 7568.0000 - tn: 312432.0000 - fn: 7568.0000 - accuracy: 0.9622 - precision: 0.9054 - recall: 0.9054 - auc: 0.9764 - val_loss: 1.1560 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 70593.0000 - val_fn: 9407.0000 - val_accuracy: 0.8119 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-006-files-1-2
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7171 - tp: 42321.0000 - fp: 37679.0000 - tn: 282321.0000 - fn: 37679.0000 - accuracy: 0.8116 - precision: 0.5290 - recall: 0.5290 - auc: 0.8823 - val_loss: 0.6918 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 70602.0000 - val_fn: 9398.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-006-files-1-2
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4478 - tp: 67360.0000 - fp: 12640.0000 - tn: 307360.0000 - fn: 12640.0000 - accuracy: 0.9368 - precision: 0.8420 - recall: 0.8420 - auc: 0.9606 - val_loss: 0.1697 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-1-2
[33m[INFO] loading file 3-3/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6955 - tp: 45236.0000 - fp: 34764.0000 - tn: 285236.0000 - fn: 34764.0000 - accuracy: 0.8262 - precision: 0.5655 - recall: 0.5655 - auc: 0.8914 - val_loss: 0.6938 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 70571.0000 - val_fn: 9429.0000 - val_accuracy: 0.8114 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.8821
[INFO] saving weights to checkpoints/dnn-epoch-006-files-2-3
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5940 - tp: 57751.0000 - fp: 22249.0000 - tn: 297751.0000 - fn: 22249.0000 - accuracy: 0.8888 - precision: 0.7219 - recall: 0.7219 - auc: 0.9304 - val_loss: 0.3329 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-2-3
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0631 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0200 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-2-3
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0140 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-2-3
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0082 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-2-3
[33m[INFO] loading file 4-4/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-3-4
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0046 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-3-4
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-3-4
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4222 - tp: 71528.0000 - fp: 8472.0000 - tn: 311528.0000 - fn: 8472.0000 - accuracy: 0.9576 - precision: 0.8941 - recall: 0.8941 - auc: 0.9704 - val_loss: 1.5082 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 67806.0000 - val_fn: 12194.0000 - val_accuracy: 0.7561 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.8476
[INFO] saving weights to checkpoints/dnn-epoch-006-files-3-4
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6127 - tp: 56887.0000 - fp: 23113.0000 - tn: 296887.0000 - fn: 23113.0000 - accuracy: 0.8844 - precision: 0.7111 - recall: 0.7111 - auc: 0.9276 - val_loss: 0.3392 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-3-4
[33m[INFO] loading file 5-5/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5272 - tp: 62445.0000 - fp: 17555.0000 - tn: 302445.0000 - fn: 17555.0000 - accuracy: 0.9122 - precision: 0.7806 - recall: 0.7806 - auc: 0.9452 - val_loss: 0.7061 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-006-files-4-5
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6555 - tp: 51316.0000 - fp: 28684.0000 - tn: 291316.0000 - fn: 28684.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9104 - val_loss: 0.5265 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 77052.0000 - val_fn: 2948.0000 - val_accuracy: 0.9410 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.9632
[INFO] saving weights to checkpoints/dnn-epoch-006-files-4-5
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0707 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-4-5
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-4-5
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0083 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-4-5
[33m[INFO] loading file 6-6/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0059 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-5-6
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-5-6
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-5-6
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2811 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 75632.0000 - val_fn: 4368.0000 - val_accuracy: 0.9126 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.8635
[INFO] saving weights to checkpoints/dnn-epoch-006-files-5-6
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8463 - tp: 51195.0000 - fp: 28805.0000 - tn: 291195.0000 - fn: 28805.0000 - accuracy: 0.8560 - precision: 0.6399 - recall: 0.6399 - auc: 0.9052 - val_loss: 0.6547 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 72768.0000 - val_fn: 7232.0000 - val_accuracy: 0.8554 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.9096
[INFO] saving weights to checkpoints/dnn-epoch-006-files-5-6
[33m[INFO] loading file 7-7/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6537 - tp: 51210.0000 - fp: 28790.0000 - tn: 291210.0000 - fn: 28790.0000 - accuracy: 0.8561 - precision: 0.6401 - recall: 0.6401 - auc: 0.9098 - val_loss: 0.6537 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 72803.0000 - val_fn: 7197.0000 - val_accuracy: 0.8561 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.9100
[INFO] saving weights to checkpoints/dnn-epoch-006-files-6-7
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51338.0000 - fp: 28662.0000 - tn: 291338.0000 - fn: 28662.0000 - accuracy: 0.8567 - precision: 0.6417 - recall: 0.6417 - auc: 0.9102 - val_loss: 0.6520 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-6-7
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4802 - tp: 65370.0000 - fp: 14630.0000 - tn: 305370.0000 - fn: 14630.0000 - accuracy: 0.9268 - precision: 0.8171 - recall: 0.8171 - auc: 0.9539 - val_loss: 0.2069 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-6-7
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0517 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0191 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-6-7
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0135 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0099 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-6-7
[33m[INFO] loading file 8-8/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0080 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0066 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-7-8
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0057 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-7-8
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0040 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-7-8
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3565 - tp: 73166.0000 - fp: 6834.0000 - tn: 313166.0000 - fn: 6834.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9766 - val_loss: 0.5536 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 76368.0000 - val_fn: 3632.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-006-files-7-8
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4812 - tp: 65505.0000 - fp: 14495.0000 - tn: 305505.0000 - fn: 14495.0000 - accuracy: 0.9275 - precision: 0.8188 - recall: 0.8188 - auc: 0.9547 - val_loss: 0.4729 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 76383.0000 - val_fn: 3617.0000 - val_accuracy: 0.9277 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.9548
[INFO] saving weights to checkpoints/dnn-epoch-006-files-7-8
[33m[INFO] loading file 9-9/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4773 - tp: 65300.0000 - fp: 14700.0000 - tn: 305300.0000 - fn: 14700.0000 - accuracy: 0.9265 - precision: 0.8163 - recall: 0.8163 - auc: 0.9540 - val_loss: 0.4805 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 76283.0000 - val_fn: 3717.0000 - val_accuracy: 0.9257 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.9535
[INFO] saving weights to checkpoints/dnn-epoch-006-files-8-9
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0974 - tp: 78936.0000 - fp: 1064.0000 - tn: 318936.0000 - fn: 1064.0000 - accuracy: 0.9947 - precision: 0.9867 - recall: 0.9867 - auc: 0.9967 - val_loss: 0.0267 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-8-9
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0171 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0116 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-8-9
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0092 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0074 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-8-9
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0063 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0054 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-8-9
[33m[INFO] loading file 10-10/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0043 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-9-10
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0084 - tp: 79936.0000 - fp: 64.0000 - tn: 319936.0000 - fn: 64.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 0.9995 - val_loss: 2.0147 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.7763
[INFO] saving weights to checkpoints/dnn-epoch-006-files-9-10
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7552 - tp: 56672.0000 - fp: 23328.0000 - tn: 296672.0000 - fn: 23328.0000 - accuracy: 0.8834 - precision: 0.7084 - recall: 0.7084 - auc: 0.9248 - val_loss: 0.3473 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-9-10
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0642 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0201 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-9-10
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0140 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-9-10
[33m[INFO] loading file 11-11/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0082 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-10-11
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-10-11
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-10-11
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-10-11
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-10-11
[33m[INFO] loading file 12-12/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0027 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0025 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-11-12
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0024 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0134 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 76689.0000 - val_fn: 3311.0000 - val_accuracy: 0.9338 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8965
[INFO] saving weights to checkpoints/dnn-epoch-006-files-11-12
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8659 - tp: 51328.0000 - fp: 28672.0000 - tn: 291328.0000 - fn: 28672.0000 - accuracy: 0.8566 - precision: 0.6416 - recall: 0.6416 - auc: 0.9039 - val_loss: 0.5636 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 75792.0000 - val_fn: 4208.0000 - val_accuracy: 0.9158 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.9474
[INFO] saving weights to checkpoints/dnn-epoch-006-files-11-12
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0706 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0204 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-11-12
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-11-12
[33m[INFO] loading file 13-13/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0083 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-12-13
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0059 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-12-13
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3615 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 75075.0000 - val_fn: 4925.0000 - val_accuracy: 0.9015 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.8461
[INFO] saving weights to checkpoints/dnn-epoch-006-files-12-13
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8174 - tp: 51313.0000 - fp: 28687.0000 - tn: 291313.0000 - fn: 28687.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9086 - val_loss: 0.6515 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-006-files-12-13
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51356.0000 - fp: 28644.0000 - tn: 291356.0000 - fn: 28644.0000 - accuracy: 0.8568 - precision: 0.6420 - recall: 0.6420 - auc: 0.9104 - val_loss: 0.6518 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-12-13
[33m[INFO] loading file 14-14/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5273 - tp: 62543.0000 - fp: 17457.0000 - tn: 302543.0000 - fn: 17457.0000 - accuracy: 0.9127 - precision: 0.7818 - recall: 0.7818 - auc: 0.9454 - val_loss: 0.2502 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-13-14
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0560 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0195 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-13-14
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0137 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0100 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-13-14
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0081 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0067 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-13-14
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-13-14
[33m[INFO] loading file 15-15/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0046 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0040 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-14-15
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0038 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-14-15
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-14-15
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0027 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.8648 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 71586.0000 - val_fn: 8414.0000 - val_accuracy: 0.8317 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.7371
[INFO] saving weights to checkpoints/dnn-epoch-006-files-14-15
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.8320 - tp: 42561.0000 - fp: 37439.0000 - tn: 282561.0000 - fn: 37439.0000 - accuracy: 0.8128 - precision: 0.5320 - recall: 0.5320 - auc: 0.8063 - val_loss: 0.7343 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 70627.0000 - val_fn: 9373.0000 - val_accuracy: 0.8125 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-006-files-14-15
[33m[INFO] loading file 16-16/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7177 - tp: 42492.0000 - fp: 37508.0000 - tn: 282492.0000 - fn: 37508.0000 - accuracy: 0.8125 - precision: 0.5311 - recall: 0.5311 - auc: 0.8826 - val_loss: 0.7087 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 70618.0000 - val_fn: 9382.0000 - val_accuracy: 0.8124 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-006-files-15-16
[INFO] processing batch 100000-200000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5999 - tp: 58381.0000 - fp: 21619.0000 - tn: 298381.0000 - fn: 21619.0000 - accuracy: 0.8919 - precision: 0.7298 - recall: 0.7298 - auc: 0.9325 - val_loss: 0.3161 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-15-16
[INFO] processing batch 200000-300000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0643 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0217 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-15-16
[INFO] processing batch 300000-400000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0153 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0112 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-15-16
[INFO] processing batch 400000-500000/439690
[33m[INFO] loading file 17-17/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0092 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0076 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-16-17
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0066 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0058 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-16-17
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0052 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0047 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-16-17
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9900 - tp: 68607.0000 - fp: 11393.0000 - tn: 308607.0000 - fn: 11393.0000 - accuracy: 0.9430 - precision: 0.8576 - recall: 0.8576 - auc: 0.9010 - val_loss: 0.7575 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 76369.0000 - val_fn: 3631.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9092
[INFO] saving weights to checkpoints/dnn-epoch-006-files-16-17
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5643 - tp: 65526.0000 - fp: 14474.0000 - tn: 305526.0000 - fn: 14474.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.9512 - val_loss: 0.3266 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 78648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9730 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9831
[INFO] saving weights to checkpoints/dnn-epoch-006-files-16-17
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 18-18/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3446 - tp: 72130.0000 - fp: 7870.0000 - tn: 312130.0000 - fn: 7870.0000 - accuracy: 0.9606 - precision: 0.9016 - recall: 0.9016 - auc: 0.9755 - val_loss: 0.9864 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 72369.0000 - val_fn: 7631.0000 - val_accuracy: 0.8474 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.9046
[INFO] saving weights to checkpoints/dnn-epoch-006-files-17-18
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7015 - tp: 49699.0000 - fp: 30301.0000 - tn: 289699.0000 - fn: 30301.0000 - accuracy: 0.8485 - precision: 0.6212 - recall: 0.6212 - auc: 0.9056 - val_loss: 0.6818 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 72357.0000 - val_fn: 7643.0000 - val_accuracy: 0.8471 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.9045
[INFO] saving weights to checkpoints/dnn-epoch-006-files-17-18
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6785 - tp: 49541.0000 - fp: 30459.0000 - tn: 289541.0000 - fn: 30459.0000 - accuracy: 0.8477 - precision: 0.6193 - recall: 0.6193 - auc: 0.9048 - val_loss: 0.6761 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 72397.0000 - val_fn: 7603.0000 - val_accuracy: 0.8479 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.9050
[INFO] saving weights to checkpoints/dnn-epoch-006-files-17-18
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2753 - tp: 74509.0000 - fp: 5491.0000 - tn: 314509.0000 - fn: 5491.0000 - accuracy: 0.9725 - precision: 0.9314 - recall: 0.9314 - auc: 0.9828 - val_loss: 0.0777 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-17-18
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0339 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0177 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-17-18
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 19-19/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0132 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-18-19
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0084 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0071 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-18-19
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0062 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0055 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-18-19
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6462 - tp: 69321.0000 - fp: 10679.0000 - tn: 309321.0000 - fn: 10679.0000 - accuracy: 0.9466 - precision: 0.8665 - recall: 0.8665 - auc: 0.9382 - val_loss: 1.5718 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 67882.0000 - val_fn: 12118.0000 - val_accuracy: 0.7576 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.8485
[INFO] saving weights to checkpoints/dnn-epoch-006-files-18-19
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7455 - tp: 44502.0000 - fp: 32714.0000 - tn: 287286.0000 - fn: 35498.0000 - accuracy: 0.8295 - precision: 0.5763 - recall: 0.5563 - auc: 0.8913 - val_loss: 0.9908 - val_tp: 0.0000e+00 - val_fp: 20000.0000 - val_tn: 60000.0000 - val_fn: 20000.0000 - val_accuracy: 0.6000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7500
[INFO] saving weights to checkpoints/dnn-epoch-006-files-18-19
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 20-20/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.1069 - tp: 78432.0000 - fp: 1280.0000 - tn: 318720.0000 - fn: 1568.0000 - accuracy: 0.9929 - precision: 0.9839 - recall: 0.9804 - auc: 0.9998 - val_loss: 0.1241 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 79491.0000 - val_fn: 509.0000 - val_accuracy: 0.9898 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9936
[INFO] saving weights to checkpoints/dnn-epoch-006-files-19-20
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5203 - tp: 65427.0000 - fp: 14573.0000 - tn: 305427.0000 - fn: 14573.0000 - accuracy: 0.9271 - precision: 0.8178 - recall: 0.8178 - auc: 0.9546 - val_loss: 0.4847 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 76357.0000 - val_fn: 3643.0000 - val_accuracy: 0.9271 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.9545
[INFO] saving weights to checkpoints/dnn-epoch-006-files-19-20
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4851 - tp: 65351.0000 - fp: 14649.0000 - tn: 305351.0000 - fn: 14649.0000 - accuracy: 0.9268 - precision: 0.8169 - recall: 0.8169 - auc: 0.9540 - val_loss: 0.4816 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 76371.0000 - val_fn: 3629.0000 - val_accuracy: 0.9274 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-006-files-19-20
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2111 - tp: 76024.0000 - fp: 3976.0000 - tn: 316024.0000 - fn: 3976.0000 - accuracy: 0.9801 - precision: 0.9503 - recall: 0.9503 - auc: 0.9877 - val_loss: 0.0567 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-19-20
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0284 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0162 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-19-20
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 21-21/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539688, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0123 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0095 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-20-21
[INFO] processing batch 100000-200000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0080 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-20-21
[INFO] processing batch 200000-300000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0060 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0053 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-20-21
[INFO] processing batch 300000-400000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0043 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-20-21
[INFO] processing batch 400000-500000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0040 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0037 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-20-21
[INFO] processing batch 500000-600000/539688
[33m[INFO] loading file 22-22/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.3347 - tp: 55006.0000 - fp: 24994.0000 - tn: 295006.0000 - fn: 24994.0000 - accuracy: 0.8750 - precision: 0.6876 - recall: 0.6876 - auc: 0.8471 - val_loss: 0.8160 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-006-files-21-22
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7321 - tp: 42398.0000 - fp: 37602.0000 - tn: 282398.0000 - fn: 37602.0000 - accuracy: 0.8120 - precision: 0.5300 - recall: 0.5300 - auc: 0.8826 - val_loss: 0.7172 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.8816
[INFO] saving weights to checkpoints/dnn-epoch-006-files-21-22
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7115 - tp: 42369.0000 - fp: 37631.0000 - tn: 282369.0000 - fn: 37631.0000 - accuracy: 0.8118 - precision: 0.5296 - recall: 0.5296 - auc: 0.8823 - val_loss: 0.7074 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 70623.0000 - val_fn: 9377.0000 - val_accuracy: 0.8125 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-006-files-21-22
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7052 - tp: 42452.0000 - fp: 37548.0000 - tn: 282452.0000 - fn: 37548.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5307 - auc: 0.8825 - val_loss: 0.7033 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 70601.0000 - val_fn: 9399.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-006-files-21-22
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7020 - tp: 42382.0000 - fp: 37618.0000 - tn: 282382.0000 - fn: 37618.0000 - accuracy: 0.8119 - precision: 0.5298 - recall: 0.5298 - auc: 0.8823 - val_loss: 0.7007 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-006-files-21-22
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 23-23/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6549 - tp: 52270.0000 - fp: 27730.0000 - tn: 292270.0000 - fn: 27730.0000 - accuracy: 0.8614 - precision: 0.6534 - recall: 0.6534 - auc: 0.9130 - val_loss: 0.4289 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-22-23
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0720 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0217 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-22-23
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0152 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0111 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-22-23
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0090 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0075 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-22-23
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0065 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0057 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-22-23
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 24-24/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0051 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0046 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-23-24
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0042 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0038 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-23-24
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0036 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0033 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-23-24
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-23-24
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2731 - tp: 75698.0000 - fp: 4302.0000 - tn: 315698.0000 - fn: 4302.0000 - accuracy: 0.9785 - precision: 0.9462 - recall: 0.9462 - auc: 0.9802 - val_loss: 1.3909 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 72912.0000 - val_fn: 7088.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-006-files-23-24
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 25-25/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7231 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9105 - val_loss: 0.6575 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-006-files-24-25
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6565 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6554 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-006-files-24-25
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6560 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9104 - val_loss: 0.6563 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-006-files-24-25
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6554 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9107 - val_loss: 0.6561 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-006-files-24-25
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6553 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6551 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-24-25
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 26-26/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6546 - tp: 51523.0000 - fp: 28477.0000 - tn: 291523.0000 - fn: 28477.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9107 - val_loss: 1.6329 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.8310
[INFO] saving weights to checkpoints/dnn-epoch-006-files-25-26
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.2131 - tp: 51579.0000 - fp: 28421.0000 - tn: 291579.0000 - fn: 28421.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.8518 - val_loss: 0.7020 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-25-26
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6830 - tp: 51462.0000 - fp: 28538.0000 - tn: 291462.0000 - fn: 28538.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9107 - val_loss: 0.6712 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-006-files-25-26
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6680 - tp: 51506.0000 - fp: 28494.0000 - tn: 291506.0000 - fn: 28494.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9108 - val_loss: 0.6630 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 72936.0000 - val_fn: 7064.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-006-files-25-26
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6632 - tp: 51474.0000 - fp: 28526.0000 - tn: 291474.0000 - fn: 28526.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9104 - val_loss: 0.6592 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 72945.0000 - val_fn: 7055.0000 - val_accuracy: 0.8589 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.9118
[INFO] saving weights to checkpoints/dnn-epoch-006-files-25-26
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 27-27/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (479817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6609 - tp: 51419.0000 - fp: 28581.0000 - tn: 291419.0000 - fn: 28581.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9105 - val_loss: 0.6607 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-006-files-26-27
[INFO] processing batch 100000-200000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6588 - tp: 51485.0000 - fp: 28515.0000 - tn: 291485.0000 - fn: 28515.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6567 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 72918.0000 - val_fn: 7082.0000 - val_accuracy: 0.8584 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-006-files-26-27
[INFO] processing batch 200000-300000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6569 - tp: 51583.0000 - fp: 28417.0000 - tn: 291583.0000 - fn: 28417.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9111 - val_loss: 0.6575 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-26-27
[INFO] processing batch 300000-400000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6575 - tp: 51396.0000 - fp: 28604.0000 - tn: 291396.0000 - fn: 28604.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9102 - val_loss: 0.6571 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 72851.0000 - val_fn: 7149.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-006-files-26-27
[INFO] processing batch 400000-500000/479817
[33m[INFO] loading file 28-28/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6563 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6559 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-27-28
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6564 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9104 - val_loss: 0.6558 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-27-28
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6555 - tp: 51458.0000 - fp: 28542.0000 - tn: 291458.0000 - fn: 28542.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9114 - val_loss: 0.6555 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-27-28
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6552 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9107 - val_loss: 0.6540 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-006-files-27-28
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6545 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9106 - val_loss: 0.6551 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-27-28
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 29-29/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6547 - tp: 51460.0000 - fp: 28540.0000 - tn: 291460.0000 - fn: 28540.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6548 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-28-29
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6540 - tp: 51527.0000 - fp: 28473.0000 - tn: 291527.0000 - fn: 28473.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6549 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-006-files-28-29
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6541 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6522 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-006-files-28-29
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6534 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9108 - val_loss: 0.6543 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-28-29
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6536 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-28-29
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 30-30/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6534 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9112 - val_loss: 0.6539 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-29-30
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51450.0000 - fp: 28550.0000 - tn: 291450.0000 - fn: 28550.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9107 - val_loss: 0.6542 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-29-30
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6535 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6539 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-29-30
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9105 - val_loss: 0.6531 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-006-files-29-30
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9110 - val_loss: 0.6533 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 72870.0000 - val_fn: 7130.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-29-30
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 31-31/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6517 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 72921.0000 - val_fn: 7079.0000 - val_accuracy: 0.8584 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-006-files-30-31
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51524.0000 - fp: 28476.0000 - tn: 291524.0000 - fn: 28476.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6522 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 72902.0000 - val_fn: 7098.0000 - val_accuracy: 0.8580 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-006-files-30-31
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6535 - tp: 51428.0000 - fp: 28572.0000 - tn: 291428.0000 - fn: 28572.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9107 - val_loss: 0.6529 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-30-31
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6525 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-30-31
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6523 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 72893.0000 - val_fn: 7107.0000 - val_accuracy: 0.8579 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-006-files-30-31
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 32-32/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6523 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-31-32
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51531.0000 - fp: 28469.0000 - tn: 291531.0000 - fn: 28469.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6527 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-31-32
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51576.0000 - fp: 28424.0000 - tn: 291576.0000 - fn: 28424.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9109 - val_loss: 0.6522 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-31-32
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51489.0000 - fp: 28511.0000 - tn: 291489.0000 - fn: 28511.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6530 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-31-32
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6530 - tp: 51449.0000 - fp: 28551.0000 - tn: 291449.0000 - fn: 28551.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9104 - val_loss: 0.6528 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-31-32
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 33-33/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9106 - val_loss: 0.6526 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-32-33
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9106 - val_loss: 0.6528 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-32-33
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51404.0000 - fp: 28596.0000 - tn: 291404.0000 - fn: 28596.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9107 - val_loss: 0.6529 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-32-33
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51552.0000 - fp: 28448.0000 - tn: 291552.0000 - fn: 28448.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9110 - val_loss: 0.6521 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-32-33
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51594.0000 - fp: 28406.0000 - tn: 291594.0000 - fn: 28406.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9110 - val_loss: 0.6508 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-006-files-32-33
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 34-34/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6534 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-006-files-33-34
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9105 - val_loss: 0.6527 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-33-34
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51588.0000 - fp: 28412.0000 - tn: 291588.0000 - fn: 28412.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9111 - val_loss: 0.6523 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-006-files-33-34
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6530 - tp: 51408.0000 - fp: 28592.0000 - tn: 291408.0000 - fn: 28592.0000 - accuracy: 0.8570 - precision: 0.6426 - recall: 0.6426 - auc: 0.9104 - val_loss: 0.6536 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 72834.0000 - val_fn: 7166.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-006-files-33-34
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6522 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-006-files-33-34
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 35-35/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51520.0000 - fp: 28480.0000 - tn: 291520.0000 - fn: 28480.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9112 - val_loss: 0.6528 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-34-35
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6522 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-006-files-34-35
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6523 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6517 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-34-35
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51521.0000 - fp: 28479.0000 - tn: 291521.0000 - fn: 28479.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9105 - val_loss: 0.6528 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-34-35
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51570.0000 - fp: 28430.0000 - tn: 291570.0000 - fn: 28430.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9108 - val_loss: 0.6523 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-34-35
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 36-36/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6522 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-35-36
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51644.0000 - fp: 28356.0000 - tn: 291644.0000 - fn: 28356.0000 - accuracy: 0.8582 - precision: 0.6456 - recall: 0.6456 - auc: 0.9110 - val_loss: 0.6515 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 72895.0000 - val_fn: 7105.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-006-files-35-36
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9103 - val_loss: 0.6504 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 72933.0000 - val_fn: 7067.0000 - val_accuracy: 0.8587 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-006-files-35-36
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6527 - tp: 51415.0000 - fp: 28585.0000 - tn: 291415.0000 - fn: 28585.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9110 - val_loss: 0.6520 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 72878.0000 - val_fn: 7122.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-006-files-35-36
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6527 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-35-36
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 37-37/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51413.0000 - fp: 28587.0000 - tn: 291413.0000 - fn: 28587.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9107 - val_loss: 0.6527 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-36-37
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51456.0000 - fp: 28544.0000 - tn: 291456.0000 - fn: 28544.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9104 - val_loss: 0.6512 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-006-files-36-37
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51565.0000 - fp: 28435.0000 - tn: 291565.0000 - fn: 28435.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6522 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-36-37
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51512.0000 - fp: 28488.0000 - tn: 291512.0000 - fn: 28488.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.6517 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 72888.0000 - val_fn: 7112.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-36-37
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51528.0000 - fp: 28472.0000 - tn: 291528.0000 - fn: 28472.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6513 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 72899.0000 - val_fn: 7101.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-006-files-36-37
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 38-38/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51513.0000 - fp: 28487.0000 - tn: 291513.0000 - fn: 28487.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9107 - val_loss: 0.6503 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-006-files-37-38
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51589.0000 - fp: 28411.0000 - tn: 291589.0000 - fn: 28411.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9112 - val_loss: 0.6530 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-006-files-37-38
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51481.0000 - fp: 28519.0000 - tn: 291481.0000 - fn: 28519.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6525 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-37-38
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51549.0000 - fp: 28451.0000 - tn: 291549.0000 - fn: 28451.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9111 - val_loss: 0.6514 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 72898.0000 - val_fn: 7102.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-006-files-37-38
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9109 - val_loss: 0.6523 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 72866.0000 - val_fn: 7134.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-37-38
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 39-39/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9111 - val_loss: 0.6528 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 72847.0000 - val_fn: 7153.0000 - val_accuracy: 0.8569 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-006-files-38-39
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51597.0000 - fp: 28403.0000 - tn: 291597.0000 - fn: 28403.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9113 - val_loss: 0.6509 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 72910.0000 - val_fn: 7090.0000 - val_accuracy: 0.8582 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-006-files-38-39
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51631.0000 - fp: 28369.0000 - tn: 291631.0000 - fn: 28369.0000 - accuracy: 0.8582 - precision: 0.6454 - recall: 0.6454 - auc: 0.9109 - val_loss: 0.6514 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-006-files-38-39
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9106 - val_loss: 0.6521 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-38-39
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6519 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-38-39
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 40-40/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51418.0000 - fp: 28582.0000 - tn: 291418.0000 - fn: 28582.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9105 - val_loss: 0.6529 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-006-files-39-40
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51491.0000 - fp: 28509.0000 - tn: 291491.0000 - fn: 28509.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9111 - val_loss: 0.6524 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-39-40
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9109 - val_loss: 0.6507 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 72916.0000 - val_fn: 7084.0000 - val_accuracy: 0.8583 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-006-files-39-40
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9106 - val_loss: 0.6529 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 72838.0000 - val_fn: 7162.0000 - val_accuracy: 0.8568 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-006-files-39-40
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51432.0000 - fp: 28568.0000 - tn: 291432.0000 - fn: 28568.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9106 - val_loss: 0.6526 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-006-files-39-40
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 41-41/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9107 - val_loss: 0.6523 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-40-41
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51515.0000 - fp: 28485.0000 - tn: 291515.0000 - fn: 28485.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9107 - val_loss: 0.6521 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-40-41
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9108 - val_loss: 0.6519 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-006-files-40-41
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51587.0000 - fp: 28413.0000 - tn: 291587.0000 - fn: 28413.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9109 - val_loss: 0.6523 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-40-41
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6500 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 72937.0000 - val_fn: 7063.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-006-files-40-41
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 42-42/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6533 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 72826.0000 - val_fn: 7174.0000 - val_accuracy: 0.8565 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-006-files-41-42
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51511.0000 - fp: 28489.0000 - tn: 291511.0000 - fn: 28489.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6517 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 72882.0000 - val_fn: 7118.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-006-files-41-42
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51499.0000 - fp: 28501.0000 - tn: 291499.0000 - fn: 28501.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6524 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 72853.0000 - val_fn: 7147.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-41-42
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9112 - val_loss: 0.6505 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 72917.0000 - val_fn: 7083.0000 - val_accuracy: 0.8583 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-006-files-41-42
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51584.0000 - fp: 28416.0000 - tn: 291584.0000 - fn: 28416.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9110 - val_loss: 0.6518 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-41-42
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 43-43/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9110 - val_loss: 0.6518 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-42-43
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6533 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 72824.0000 - val_fn: 7176.0000 - val_accuracy: 0.8565 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-006-files-42-43
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51387.0000 - fp: 28613.0000 - tn: 291387.0000 - fn: 28613.0000 - accuracy: 0.8569 - precision: 0.6423 - recall: 0.6423 - auc: 0.9103 - val_loss: 0.6511 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-006-files-42-43
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9111 - val_loss: 0.6527 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-006-files-42-43
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9113 - val_loss: 0.6494 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 72952.0000 - val_fn: 7048.0000 - val_accuracy: 0.8590 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.9119
[INFO] saving weights to checkpoints/dnn-epoch-006-files-42-43
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 44-44/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9108 - val_loss: 0.6523 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-43-44
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6523 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-43-44
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51543.0000 - fp: 28457.0000 - tn: 291543.0000 - fn: 28457.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9107 - val_loss: 0.6524 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-43-44
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6523 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9108 - val_loss: 0.6513 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 72891.0000 - val_fn: 7109.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-43-44
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51537.0000 - fp: 28463.0000 - tn: 291537.0000 - fn: 28463.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6521 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-43-44
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 45-45/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51620.0000 - fp: 28380.0000 - tn: 291620.0000 - fn: 28380.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9112 - val_loss: 0.6519 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-44-45
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51538.0000 - fp: 28462.0000 - tn: 291538.0000 - fn: 28462.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9112 - val_loss: 0.6514 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-44-45
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51564.0000 - fp: 28436.0000 - tn: 291564.0000 - fn: 28436.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9111 - val_loss: 0.6509 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 72904.0000 - val_fn: 7096.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-006-files-44-45
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51590.0000 - fp: 28410.0000 - tn: 291590.0000 - fn: 28410.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9112 - val_loss: 0.6526 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-006-files-44-45
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51395.0000 - fp: 28605.0000 - tn: 291395.0000 - fn: 28605.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9111 - val_loss: 0.6511 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-006-files-44-45
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 46-46/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9114 - val_loss: 0.6506 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 72913.0000 - val_fn: 7087.0000 - val_accuracy: 0.8583 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-006-files-45-46
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51464.0000 - fp: 28536.0000 - tn: 291464.0000 - fn: 28536.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6517 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 72883.0000 - val_fn: 7117.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-006-files-45-46
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9112 - val_loss: 0.6514 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-45-46
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9108 - val_loss: 0.6502 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-006-files-45-46
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51569.0000 - fp: 28431.0000 - tn: 291569.0000 - fn: 28431.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9109 - val_loss: 0.6517 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-45-46
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 47-47/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51601.0000 - fp: 28399.0000 - tn: 291601.0000 - fn: 28399.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9109 - val_loss: 0.6512 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-46-47
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51559.0000 - fp: 28441.0000 - tn: 291559.0000 - fn: 28441.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-46-47
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6535 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 72822.0000 - val_fn: 7178.0000 - val_accuracy: 0.8564 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-006-files-46-47
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6515 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 72881.0000 - val_fn: 7119.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-006-files-46-47
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9112 - val_loss: 0.6508 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 72909.0000 - val_fn: 7091.0000 - val_accuracy: 0.8582 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-006-files-46-47
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 48-48/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6530 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 72830.0000 - val_fn: 7170.0000 - val_accuracy: 0.8566 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-006-files-47-48
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9103 - val_loss: 0.6516 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 72879.0000 - val_fn: 7121.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-006-files-47-48
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51547.0000 - fp: 28453.0000 - tn: 291547.0000 - fn: 28453.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9113 - val_loss: 0.6506 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-006-files-47-48
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9109 - val_loss: 0.6520 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-47-48
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51606.0000 - fp: 28394.0000 - tn: 291606.0000 - fn: 28394.0000 - accuracy: 0.8580 - precision: 0.6451 - recall: 0.6451 - auc: 0.9115 - val_loss: 0.6507 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 72905.0000 - val_fn: 7095.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-006-files-47-48
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 49-49/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9112 - val_loss: 0.6519 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-48-49
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51430.0000 - fp: 28570.0000 - tn: 291430.0000 - fn: 28570.0000 - accuracy: 0.8571 - precision: 0.6429 - recall: 0.6429 - auc: 0.9109 - val_loss: 0.6502 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 72924.0000 - val_fn: 7076.0000 - val_accuracy: 0.8585 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-006-files-48-49
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51469.0000 - fp: 28531.0000 - tn: 291469.0000 - fn: 28531.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.6531 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-006-files-48-49
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6502 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 72922.0000 - val_fn: 7078.0000 - val_accuracy: 0.8584 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-006-files-48-49
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51495.0000 - fp: 28505.0000 - tn: 291495.0000 - fn: 28505.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6512 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-48-49
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 50-50/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9110 - val_loss: 0.6532 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 72823.0000 - val_fn: 7177.0000 - val_accuracy: 0.8565 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-006-files-49-50
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51482.0000 - fp: 28518.0000 - tn: 291482.0000 - fn: 28518.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6512 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-49-50
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51433.0000 - fp: 28567.0000 - tn: 291433.0000 - fn: 28567.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9107 - val_loss: 0.6524 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-006-files-49-50
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51461.0000 - fp: 28539.0000 - tn: 291461.0000 - fn: 28539.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9107 - val_loss: 0.6512 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-49-50
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51467.0000 - fp: 28533.0000 - tn: 291467.0000 - fn: 28533.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9107 - val_loss: 0.6522 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-49-50
[INFO] processing batch 500000-600000/519975
[33m[LOSS] 0.652163251209259[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.652163251209259  <  0.001
[33m[INFO] epoch 7/10[0m
[33m[INFO] loading file 1-1/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0706 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-0-1
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-0-1
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0227 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9993 - val_loss: 2.2975 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.8826
[INFO] saving weights to checkpoints/dnn-epoch-007-files-0-1
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8371 - tp: 42447.0000 - fp: 37553.0000 - tn: 282447.0000 - fn: 37553.0000 - accuracy: 0.8122 - precision: 0.5306 - recall: 0.5306 - auc: 0.8829 - val_loss: 0.6916 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-007-files-0-1
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6917 - tp: 42438.0000 - fp: 37562.0000 - tn: 282438.0000 - fn: 37562.0000 - accuracy: 0.8122 - precision: 0.5305 - recall: 0.5305 - auc: 0.8824 - val_loss: 0.6917 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-007-files-0-1
[33m[INFO] loading file 2-2/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6917 - tp: 42435.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37565.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5304 - auc: 0.8822 - val_loss: 0.6918 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 70589.0000 - val_fn: 9411.0000 - val_accuracy: 0.8118 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-007-files-1-2
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4427 - tp: 67619.0000 - fp: 12381.0000 - tn: 307619.0000 - fn: 12381.0000 - accuracy: 0.9381 - precision: 0.8452 - recall: 0.8452 - auc: 0.9611 - val_loss: 0.1695 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-1-2
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3148 - tp: 72432.0000 - fp: 7568.0000 - tn: 312432.0000 - fn: 7568.0000 - accuracy: 0.9622 - precision: 0.9054 - recall: 0.9054 - auc: 0.9763 - val_loss: 1.1612 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 70593.0000 - val_fn: 9407.0000 - val_accuracy: 0.8119 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-007-files-1-2
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7170 - tp: 42321.0000 - fp: 37679.0000 - tn: 282321.0000 - fn: 37679.0000 - accuracy: 0.8116 - precision: 0.5290 - recall: 0.5290 - auc: 0.8822 - val_loss: 0.6917 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 70602.0000 - val_fn: 9398.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-007-files-1-2
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4474 - tp: 67360.0000 - fp: 12640.0000 - tn: 307360.0000 - fn: 12640.0000 - accuracy: 0.9368 - precision: 0.8420 - recall: 0.8420 - auc: 0.9606 - val_loss: 0.1712 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-1-2
[33m[INFO] loading file 3-3/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6957 - tp: 45236.0000 - fp: 34764.0000 - tn: 285236.0000 - fn: 34764.0000 - accuracy: 0.8262 - precision: 0.5655 - recall: 0.5655 - auc: 0.8915 - val_loss: 0.6941 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 70571.0000 - val_fn: 9429.0000 - val_accuracy: 0.8114 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.8821
[INFO] saving weights to checkpoints/dnn-epoch-007-files-2-3
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5940 - tp: 57751.0000 - fp: 22249.0000 - tn: 297751.0000 - fn: 22249.0000 - accuracy: 0.8888 - precision: 0.7219 - recall: 0.7219 - auc: 0.9303 - val_loss: 0.3247 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-2-3
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0625 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0200 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-2-3
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0139 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-2-3
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0082 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0067 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-2-3
[33m[INFO] loading file 4-4/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-3-4
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0046 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-3-4
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-3-4
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4227 - tp: 71528.0000 - fp: 8472.0000 - tn: 311528.0000 - fn: 8472.0000 - accuracy: 0.9576 - precision: 0.8941 - recall: 0.8941 - auc: 0.9702 - val_loss: 1.5092 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 67806.0000 - val_fn: 12194.0000 - val_accuracy: 0.7561 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.8476
[INFO] saving weights to checkpoints/dnn-epoch-007-files-3-4
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6126 - tp: 56887.0000 - fp: 23113.0000 - tn: 296887.0000 - fn: 23113.0000 - accuracy: 0.8844 - precision: 0.7111 - recall: 0.7111 - auc: 0.9277 - val_loss: 0.3400 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-3-4
[33m[INFO] loading file 5-5/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5272 - tp: 62445.0000 - fp: 17555.0000 - tn: 302445.0000 - fn: 17555.0000 - accuracy: 0.9122 - precision: 0.7806 - recall: 0.7806 - auc: 0.9450 - val_loss: 0.7010 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-007-files-4-5
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6554 - tp: 51316.0000 - fp: 28684.0000 - tn: 291316.0000 - fn: 28684.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9104 - val_loss: 0.5249 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 77052.0000 - val_fn: 2948.0000 - val_accuracy: 0.9410 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.9632
[INFO] saving weights to checkpoints/dnn-epoch-007-files-4-5
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0705 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0204 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-4-5
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-4-5
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0083 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-4-5
[33m[INFO] loading file 6-6/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0059 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-5-6
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-5-6
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-5-6
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2811 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 75632.0000 - val_fn: 4368.0000 - val_accuracy: 0.9126 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.8635
[INFO] saving weights to checkpoints/dnn-epoch-007-files-5-6
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8444 - tp: 51195.0000 - fp: 28805.0000 - tn: 291195.0000 - fn: 28805.0000 - accuracy: 0.8560 - precision: 0.6399 - recall: 0.6399 - auc: 0.9059 - val_loss: 0.6549 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 72768.0000 - val_fn: 7232.0000 - val_accuracy: 0.8554 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.9096
[INFO] saving weights to checkpoints/dnn-epoch-007-files-5-6
[33m[INFO] loading file 7-7/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6537 - tp: 51210.0000 - fp: 28790.0000 - tn: 291210.0000 - fn: 28790.0000 - accuracy: 0.8560 - precision: 0.6401 - recall: 0.6401 - auc: 0.9103 - val_loss: 0.6537 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 72803.0000 - val_fn: 7197.0000 - val_accuracy: 0.8561 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.9100
[INFO] saving weights to checkpoints/dnn-epoch-007-files-6-7
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51338.0000 - fp: 28662.0000 - tn: 291338.0000 - fn: 28662.0000 - accuracy: 0.8567 - precision: 0.6417 - recall: 0.6417 - auc: 0.9102 - val_loss: 0.6520 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-6-7
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4802 - tp: 65370.0000 - fp: 14630.0000 - tn: 305370.0000 - fn: 14630.0000 - accuracy: 0.9268 - precision: 0.8171 - recall: 0.8171 - auc: 0.9542 - val_loss: 0.1993 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-6-7
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0509 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0191 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-6-7
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0135 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0099 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-6-7
[33m[INFO] loading file 8-8/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0080 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0066 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-7-8
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0057 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-7-8
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0040 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-7-8
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3562 - tp: 73166.0000 - fp: 6834.0000 - tn: 313166.0000 - fn: 6834.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9768 - val_loss: 0.5522 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 76368.0000 - val_fn: 3632.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-007-files-7-8
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4810 - tp: 65505.0000 - fp: 14495.0000 - tn: 305505.0000 - fn: 14495.0000 - accuracy: 0.9275 - precision: 0.8188 - recall: 0.8188 - auc: 0.9544 - val_loss: 0.4729 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 76383.0000 - val_fn: 3617.0000 - val_accuracy: 0.9277 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.9548
[INFO] saving weights to checkpoints/dnn-epoch-007-files-7-8
[33m[INFO] loading file 9-9/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4773 - tp: 65300.0000 - fp: 14700.0000 - tn: 305300.0000 - fn: 14700.0000 - accuracy: 0.9265 - precision: 0.8163 - recall: 0.8163 - auc: 0.9540 - val_loss: 0.4804 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 76283.0000 - val_fn: 3717.0000 - val_accuracy: 0.9257 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.9535
[INFO] saving weights to checkpoints/dnn-epoch-007-files-8-9
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0976 - tp: 78936.0000 - fp: 1064.0000 - tn: 318936.0000 - fn: 1064.0000 - accuracy: 0.9947 - precision: 0.9867 - recall: 0.9867 - auc: 0.9967 - val_loss: 0.0267 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-8-9
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0171 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0116 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-8-9
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0092 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0074 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-8-9
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0063 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0054 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-8-9
[33m[INFO] loading file 10-10/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0043 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-9-10
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0084 - tp: 79936.0000 - fp: 64.0000 - tn: 319936.0000 - fn: 64.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 0.9995 - val_loss: 2.0147 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.7763
[INFO] saving weights to checkpoints/dnn-epoch-007-files-9-10
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7550 - tp: 56672.0000 - fp: 23328.0000 - tn: 296672.0000 - fn: 23328.0000 - accuracy: 0.8834 - precision: 0.7084 - recall: 0.7084 - auc: 0.9248 - val_loss: 0.3410 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-9-10
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0637 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0201 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-9-10
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0140 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-9-10
[33m[INFO] loading file 11-11/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0082 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-10-11
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-10-11
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-10-11
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-10-11
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-10-11
[33m[INFO] loading file 12-12/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0027 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0025 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-11-12
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0024 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0134 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 76689.0000 - val_fn: 3311.0000 - val_accuracy: 0.9338 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8965
[INFO] saving weights to checkpoints/dnn-epoch-007-files-11-12
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8663 - tp: 51328.0000 - fp: 28672.0000 - tn: 291328.0000 - fn: 28672.0000 - accuracy: 0.8566 - precision: 0.6416 - recall: 0.6416 - auc: 0.9038 - val_loss: 0.5627 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 75792.0000 - val_fn: 4208.0000 - val_accuracy: 0.9158 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.9474
[INFO] saving weights to checkpoints/dnn-epoch-007-files-11-12
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0704 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0204 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-11-12
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-11-12
[33m[INFO] loading file 13-13/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0083 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-12-13
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0059 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-12-13
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3616 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 75075.0000 - val_fn: 4925.0000 - val_accuracy: 0.9015 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.8461
[INFO] saving weights to checkpoints/dnn-epoch-007-files-12-13
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8163 - tp: 51313.0000 - fp: 28687.0000 - tn: 291313.0000 - fn: 28687.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9087 - val_loss: 0.6515 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-007-files-12-13
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51356.0000 - fp: 28644.0000 - tn: 291356.0000 - fn: 28644.0000 - accuracy: 0.8568 - precision: 0.6420 - recall: 0.6420 - auc: 0.9103 - val_loss: 0.6518 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-12-13
[33m[INFO] loading file 14-14/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5271 - tp: 62543.0000 - fp: 17457.0000 - tn: 302543.0000 - fn: 17457.0000 - accuracy: 0.9127 - precision: 0.7818 - recall: 0.7818 - auc: 0.9454 - val_loss: 0.2460 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-13-14
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0556 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0195 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-13-14
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0137 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0100 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-13-14
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0081 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0067 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-13-14
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-13-14
[33m[INFO] loading file 15-15/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0046 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0040 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-14-15
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0038 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-14-15
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-14-15
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0027 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.8647 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 71586.0000 - val_fn: 8414.0000 - val_accuracy: 0.8317 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.7371
[INFO] saving weights to checkpoints/dnn-epoch-007-files-14-15
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.8329 - tp: 42561.0000 - fp: 37439.0000 - tn: 282561.0000 - fn: 37439.0000 - accuracy: 0.8128 - precision: 0.5320 - recall: 0.5320 - auc: 0.8059 - val_loss: 0.7341 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 70627.0000 - val_fn: 9373.0000 - val_accuracy: 0.8125 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-007-files-14-15
[33m[INFO] loading file 16-16/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7177 - tp: 42492.0000 - fp: 37508.0000 - tn: 282492.0000 - fn: 37508.0000 - accuracy: 0.8125 - precision: 0.5311 - recall: 0.5311 - auc: 0.8824 - val_loss: 0.7087 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 70618.0000 - val_fn: 9382.0000 - val_accuracy: 0.8124 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-007-files-15-16
[INFO] processing batch 100000-200000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5996 - tp: 58381.0000 - fp: 21619.0000 - tn: 298381.0000 - fn: 21619.0000 - accuracy: 0.8919 - precision: 0.7298 - recall: 0.7298 - auc: 0.9325 - val_loss: 0.3200 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-15-16
[INFO] processing batch 200000-300000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0646 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0217 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-15-16
[INFO] processing batch 300000-400000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0153 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0112 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-15-16
[INFO] processing batch 400000-500000/439690
[33m[INFO] loading file 17-17/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0092 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0076 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-16-17
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0066 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0058 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-16-17
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0052 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0047 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-16-17
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9902 - tp: 68607.0000 - fp: 11393.0000 - tn: 308607.0000 - fn: 11393.0000 - accuracy: 0.9430 - precision: 0.8576 - recall: 0.8576 - auc: 0.9007 - val_loss: 0.7576 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 76369.0000 - val_fn: 3631.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9092
[INFO] saving weights to checkpoints/dnn-epoch-007-files-16-17
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5638 - tp: 65526.0000 - fp: 14474.0000 - tn: 305526.0000 - fn: 14474.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.9514 - val_loss: 0.3268 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 78648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9730 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9831
[INFO] saving weights to checkpoints/dnn-epoch-007-files-16-17
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 18-18/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3447 - tp: 72130.0000 - fp: 7870.0000 - tn: 312130.0000 - fn: 7870.0000 - accuracy: 0.9606 - precision: 0.9016 - recall: 0.9016 - auc: 0.9754 - val_loss: 0.9888 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 72369.0000 - val_fn: 7631.0000 - val_accuracy: 0.8474 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.9046
[INFO] saving weights to checkpoints/dnn-epoch-007-files-17-18
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7022 - tp: 49699.0000 - fp: 30301.0000 - tn: 289699.0000 - fn: 30301.0000 - accuracy: 0.8485 - precision: 0.6212 - recall: 0.6212 - auc: 0.9051 - val_loss: 0.6818 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 72357.0000 - val_fn: 7643.0000 - val_accuracy: 0.8471 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.9045
[INFO] saving weights to checkpoints/dnn-epoch-007-files-17-18
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6785 - tp: 49541.0000 - fp: 30459.0000 - tn: 289541.0000 - fn: 30459.0000 - accuracy: 0.8477 - precision: 0.6193 - recall: 0.6193 - auc: 0.9045 - val_loss: 0.6761 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 72397.0000 - val_fn: 7603.0000 - val_accuracy: 0.8479 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.9050
[INFO] saving weights to checkpoints/dnn-epoch-007-files-17-18
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2751 - tp: 74509.0000 - fp: 5491.0000 - tn: 314509.0000 - fn: 5491.0000 - accuracy: 0.9725 - precision: 0.9314 - recall: 0.9314 - auc: 0.9828 - val_loss: 0.0773 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-17-18
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0338 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0177 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-17-18
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 19-19/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0132 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-18-19
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0084 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0071 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-18-19
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0062 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0055 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-18-19
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6459 - tp: 69321.0000 - fp: 10679.0000 - tn: 309321.0000 - fn: 10679.0000 - accuracy: 0.9466 - precision: 0.8665 - recall: 0.8665 - auc: 0.9384 - val_loss: 1.5692 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 67882.0000 - val_fn: 12118.0000 - val_accuracy: 0.7576 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.8485
[INFO] saving weights to checkpoints/dnn-epoch-007-files-18-19
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7458 - tp: 44600.0000 - fp: 32872.0000 - tn: 287128.0000 - fn: 35400.0000 - accuracy: 0.8293 - precision: 0.5757 - recall: 0.5575 - auc: 0.8907 - val_loss: 0.9574 - val_tp: 0.0000e+00 - val_fp: 20000.0000 - val_tn: 60000.0000 - val_fn: 20000.0000 - val_accuracy: 0.6000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7500
[INFO] saving weights to checkpoints/dnn-epoch-007-files-18-19
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 20-20/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.1053 - tp: 78560.0000 - fp: 1152.0000 - tn: 318848.0000 - fn: 1440.0000 - accuracy: 0.9935 - precision: 0.9855 - recall: 0.9820 - auc: 0.9999 - val_loss: 0.1241 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 79491.0000 - val_fn: 509.0000 - val_accuracy: 0.9898 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9936
[INFO] saving weights to checkpoints/dnn-epoch-007-files-19-20
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5209 - tp: 65427.0000 - fp: 14573.0000 - tn: 305427.0000 - fn: 14573.0000 - accuracy: 0.9271 - precision: 0.8178 - recall: 0.8178 - auc: 0.9542 - val_loss: 0.4848 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 76357.0000 - val_fn: 3643.0000 - val_accuracy: 0.9271 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.9545
[INFO] saving weights to checkpoints/dnn-epoch-007-files-19-20
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4851 - tp: 65351.0000 - fp: 14649.0000 - tn: 305351.0000 - fn: 14649.0000 - accuracy: 0.9268 - precision: 0.8169 - recall: 0.8169 - auc: 0.9541 - val_loss: 0.4816 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 76371.0000 - val_fn: 3629.0000 - val_accuracy: 0.9274 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-007-files-19-20
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2110 - tp: 76024.0000 - fp: 3976.0000 - tn: 316024.0000 - fn: 3976.0000 - accuracy: 0.9801 - precision: 0.9503 - recall: 0.9503 - auc: 0.9875 - val_loss: 0.0575 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-19-20
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0286 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0163 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-19-20
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 21-21/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539688, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0123 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0096 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-20-21
[INFO] processing batch 100000-200000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0080 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-20-21
[INFO] processing batch 200000-300000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0060 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0053 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-20-21
[INFO] processing batch 300000-400000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0043 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-20-21
[INFO] processing batch 400000-500000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0040 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0037 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-20-21
[INFO] processing batch 500000-600000/539688
[33m[INFO] loading file 22-22/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.3341 - tp: 55006.0000 - fp: 24994.0000 - tn: 295006.0000 - fn: 24994.0000 - accuracy: 0.8750 - precision: 0.6876 - recall: 0.6876 - auc: 0.8472 - val_loss: 0.8139 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-007-files-21-22
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7321 - tp: 42398.0000 - fp: 37602.0000 - tn: 282398.0000 - fn: 37602.0000 - accuracy: 0.8120 - precision: 0.5300 - recall: 0.5300 - auc: 0.8827 - val_loss: 0.7172 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.8816
[INFO] saving weights to checkpoints/dnn-epoch-007-files-21-22
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7116 - tp: 42369.0000 - fp: 37631.0000 - tn: 282369.0000 - fn: 37631.0000 - accuracy: 0.8118 - precision: 0.5296 - recall: 0.5296 - auc: 0.8821 - val_loss: 0.7074 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 70623.0000 - val_fn: 9377.0000 - val_accuracy: 0.8125 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-007-files-21-22
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7052 - tp: 42452.0000 - fp: 37548.0000 - tn: 282452.0000 - fn: 37548.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5307 - auc: 0.8824 - val_loss: 0.7033 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 70601.0000 - val_fn: 9399.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-007-files-21-22
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7020 - tp: 42382.0000 - fp: 37618.0000 - tn: 282382.0000 - fn: 37618.0000 - accuracy: 0.8119 - precision: 0.5298 - recall: 0.5298 - auc: 0.8822 - val_loss: 0.7008 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-007-files-21-22
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 23-23/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6550 - tp: 52270.0000 - fp: 27730.0000 - tn: 292270.0000 - fn: 27730.0000 - accuracy: 0.8614 - precision: 0.6534 - recall: 0.6534 - auc: 0.9134 - val_loss: 0.4316 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-22-23
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0722 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0217 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-22-23
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0152 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0111 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-22-23
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0090 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0075 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-22-23
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0065 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0057 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-22-23
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 24-24/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0051 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0046 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-23-24
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0042 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0038 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-23-24
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0036 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0033 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-23-24
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-23-24
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2732 - tp: 75698.0000 - fp: 4302.0000 - tn: 315698.0000 - fn: 4302.0000 - accuracy: 0.9785 - precision: 0.9462 - recall: 0.9462 - auc: 0.9801 - val_loss: 1.3926 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 72912.0000 - val_fn: 7088.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-007-files-23-24
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 25-25/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7229 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6576 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-007-files-24-25
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6564 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6556 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-007-files-24-25
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6560 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9107 - val_loss: 0.6564 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-007-files-24-25
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6554 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9108 - val_loss: 0.6561 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-007-files-24-25
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6553 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9110 - val_loss: 0.6551 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-24-25
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 26-26/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6546 - tp: 51523.0000 - fp: 28477.0000 - tn: 291523.0000 - fn: 28477.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9109 - val_loss: 1.6336 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.8310
[INFO] saving weights to checkpoints/dnn-epoch-007-files-25-26
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.2138 - tp: 51579.0000 - fp: 28421.0000 - tn: 291579.0000 - fn: 28421.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.8515 - val_loss: 0.7018 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-25-26
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6829 - tp: 51462.0000 - fp: 28538.0000 - tn: 291462.0000 - fn: 28538.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9109 - val_loss: 0.6714 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-007-files-25-26
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6680 - tp: 51506.0000 - fp: 28494.0000 - tn: 291506.0000 - fn: 28494.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9107 - val_loss: 0.6630 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 72936.0000 - val_fn: 7064.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-007-files-25-26
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6631 - tp: 51474.0000 - fp: 28526.0000 - tn: 291474.0000 - fn: 28526.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.6592 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 72945.0000 - val_fn: 7055.0000 - val_accuracy: 0.8589 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.9118
[INFO] saving weights to checkpoints/dnn-epoch-007-files-25-26
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 27-27/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (479817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6609 - tp: 51419.0000 - fp: 28581.0000 - tn: 291419.0000 - fn: 28581.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9106 - val_loss: 0.6607 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-007-files-26-27
[INFO] processing batch 100000-200000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6588 - tp: 51485.0000 - fp: 28515.0000 - tn: 291485.0000 - fn: 28515.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9112 - val_loss: 0.6567 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 72918.0000 - val_fn: 7082.0000 - val_accuracy: 0.8584 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-007-files-26-27
[INFO] processing batch 200000-300000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6569 - tp: 51583.0000 - fp: 28417.0000 - tn: 291583.0000 - fn: 28417.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9113 - val_loss: 0.6575 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-26-27
[INFO] processing batch 300000-400000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6575 - tp: 51396.0000 - fp: 28604.0000 - tn: 291396.0000 - fn: 28604.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9107 - val_loss: 0.6571 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 72851.0000 - val_fn: 7149.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-007-files-26-27
[INFO] processing batch 400000-500000/479817
[33m[INFO] loading file 28-28/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6563 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6560 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-27-28
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6564 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9106 - val_loss: 0.6558 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-27-28
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6555 - tp: 51458.0000 - fp: 28542.0000 - tn: 291458.0000 - fn: 28542.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6552 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-27-28
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6552 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9105 - val_loss: 0.6539 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-007-files-27-28
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6544 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9112 - val_loss: 0.6552 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-27-28
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 29-29/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6547 - tp: 51460.0000 - fp: 28540.0000 - tn: 291460.0000 - fn: 28540.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9111 - val_loss: 0.6548 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-28-29
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6540 - tp: 51527.0000 - fp: 28473.0000 - tn: 291527.0000 - fn: 28473.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6549 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-007-files-28-29
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6541 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6522 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-007-files-28-29
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6534 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9108 - val_loss: 0.6543 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-28-29
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9104 - val_loss: 0.6536 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-28-29
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 30-30/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6534 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6540 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-29-30
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6539 - tp: 51450.0000 - fp: 28550.0000 - tn: 291450.0000 - fn: 28550.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9104 - val_loss: 0.6540 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-29-30
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6535 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6539 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-29-30
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6530 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9115 - val_loss: 0.6532 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-007-files-29-30
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9109 - val_loss: 0.6533 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 72870.0000 - val_fn: 7130.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-29-30
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 31-31/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9112 - val_loss: 0.6517 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 72921.0000 - val_fn: 7079.0000 - val_accuracy: 0.8584 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-007-files-30-31
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51524.0000 - fp: 28476.0000 - tn: 291524.0000 - fn: 28476.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6522 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 72902.0000 - val_fn: 7098.0000 - val_accuracy: 0.8580 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-007-files-30-31
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6535 - tp: 51428.0000 - fp: 28572.0000 - tn: 291428.0000 - fn: 28572.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9106 - val_loss: 0.6529 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-30-31
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6525 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-30-31
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9111 - val_loss: 0.6523 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 72893.0000 - val_fn: 7107.0000 - val_accuracy: 0.8579 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-007-files-30-31
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 32-32/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6523 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-31-32
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51531.0000 - fp: 28469.0000 - tn: 291531.0000 - fn: 28469.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9116 - val_loss: 0.6529 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-31-32
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51576.0000 - fp: 28424.0000 - tn: 291576.0000 - fn: 28424.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9111 - val_loss: 0.6522 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-31-32
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51489.0000 - fp: 28511.0000 - tn: 291489.0000 - fn: 28511.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9105 - val_loss: 0.6529 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-31-32
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6530 - tp: 51449.0000 - fp: 28551.0000 - tn: 291449.0000 - fn: 28551.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9107 - val_loss: 0.6528 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-31-32
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 33-33/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6525 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-32-33
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6529 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-32-33
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51404.0000 - fp: 28596.0000 - tn: 291404.0000 - fn: 28596.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9104 - val_loss: 0.6529 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-32-33
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51552.0000 - fp: 28448.0000 - tn: 291552.0000 - fn: 28448.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9110 - val_loss: 0.6521 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-32-33
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51594.0000 - fp: 28406.0000 - tn: 291594.0000 - fn: 28406.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9110 - val_loss: 0.6508 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-007-files-32-33
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 34-34/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9106 - val_loss: 0.6535 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-007-files-33-34
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6527 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-33-34
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51588.0000 - fp: 28412.0000 - tn: 291588.0000 - fn: 28412.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9113 - val_loss: 0.6525 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-007-files-33-34
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6530 - tp: 51408.0000 - fp: 28592.0000 - tn: 291408.0000 - fn: 28592.0000 - accuracy: 0.8570 - precision: 0.6426 - recall: 0.6426 - auc: 0.9106 - val_loss: 0.6535 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 72834.0000 - val_fn: 7166.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-007-files-33-34
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9106 - val_loss: 0.6522 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-007-files-33-34
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 35-35/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51520.0000 - fp: 28480.0000 - tn: 291520.0000 - fn: 28480.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9109 - val_loss: 0.6530 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-34-35
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6522 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-007-files-34-35
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6523 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6518 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-34-35
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51521.0000 - fp: 28479.0000 - tn: 291521.0000 - fn: 28479.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9106 - val_loss: 0.6528 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-34-35
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51570.0000 - fp: 28430.0000 - tn: 291570.0000 - fn: 28430.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9109 - val_loss: 0.6523 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-34-35
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 36-36/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6522 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-35-36
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51644.0000 - fp: 28356.0000 - tn: 291644.0000 - fn: 28356.0000 - accuracy: 0.8582 - precision: 0.6456 - recall: 0.6456 - auc: 0.9110 - val_loss: 0.6515 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 72895.0000 - val_fn: 7105.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-007-files-35-36
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9107 - val_loss: 0.6504 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 72933.0000 - val_fn: 7067.0000 - val_accuracy: 0.8587 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-007-files-35-36
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51415.0000 - fp: 28585.0000 - tn: 291415.0000 - fn: 28585.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9102 - val_loss: 0.6520 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 72878.0000 - val_fn: 7122.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-007-files-35-36
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6526 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-35-36
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 37-37/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51413.0000 - fp: 28587.0000 - tn: 291413.0000 - fn: 28587.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9102 - val_loss: 0.6527 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-36-37
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51456.0000 - fp: 28544.0000 - tn: 291456.0000 - fn: 28544.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6514 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-007-files-36-37
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51565.0000 - fp: 28435.0000 - tn: 291565.0000 - fn: 28435.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9111 - val_loss: 0.6522 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-36-37
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51512.0000 - fp: 28488.0000 - tn: 291512.0000 - fn: 28488.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6517 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 72888.0000 - val_fn: 7112.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-36-37
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51528.0000 - fp: 28472.0000 - tn: 291528.0000 - fn: 28472.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6513 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 72899.0000 - val_fn: 7101.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-007-files-36-37
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 38-38/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51513.0000 - fp: 28487.0000 - tn: 291513.0000 - fn: 28487.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9114 - val_loss: 0.6503 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-007-files-37-38
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51589.0000 - fp: 28411.0000 - tn: 291589.0000 - fn: 28411.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9111 - val_loss: 0.6530 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-007-files-37-38
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51481.0000 - fp: 28519.0000 - tn: 291481.0000 - fn: 28519.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6525 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-37-38
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51549.0000 - fp: 28451.0000 - tn: 291549.0000 - fn: 28451.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9114 - val_loss: 0.6514 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 72898.0000 - val_fn: 7102.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-007-files-37-38
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9108 - val_loss: 0.6523 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 72866.0000 - val_fn: 7134.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-37-38
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 39-39/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6528 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 72847.0000 - val_fn: 7153.0000 - val_accuracy: 0.8569 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-007-files-38-39
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51597.0000 - fp: 28403.0000 - tn: 291597.0000 - fn: 28403.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9108 - val_loss: 0.6510 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 72910.0000 - val_fn: 7090.0000 - val_accuracy: 0.8582 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-007-files-38-39
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51631.0000 - fp: 28369.0000 - tn: 291631.0000 - fn: 28369.0000 - accuracy: 0.8582 - precision: 0.6454 - recall: 0.6454 - auc: 0.9115 - val_loss: 0.6514 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-007-files-38-39
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6521 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-38-39
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6519 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-38-39
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 40-40/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51418.0000 - fp: 28582.0000 - tn: 291418.0000 - fn: 28582.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9103 - val_loss: 0.6529 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-007-files-39-40
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51491.0000 - fp: 28509.0000 - tn: 291491.0000 - fn: 28509.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6523 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-39-40
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9112 - val_loss: 0.6506 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 72916.0000 - val_fn: 7084.0000 - val_accuracy: 0.8583 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-007-files-39-40
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9111 - val_loss: 0.6530 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 72838.0000 - val_fn: 7162.0000 - val_accuracy: 0.8568 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-007-files-39-40
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51432.0000 - fp: 28568.0000 - tn: 291432.0000 - fn: 28568.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9105 - val_loss: 0.6527 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-007-files-39-40
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 41-41/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9106 - val_loss: 0.6523 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-40-41
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51515.0000 - fp: 28485.0000 - tn: 291515.0000 - fn: 28485.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.6520 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-40-41
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9107 - val_loss: 0.6518 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-007-files-40-41
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51587.0000 - fp: 28413.0000 - tn: 291587.0000 - fn: 28413.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9110 - val_loss: 0.6523 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-40-41
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6500 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 72937.0000 - val_fn: 7063.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-007-files-40-41
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 42-42/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6532 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 72826.0000 - val_fn: 7174.0000 - val_accuracy: 0.8565 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-007-files-41-42
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51511.0000 - fp: 28489.0000 - tn: 291511.0000 - fn: 28489.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6517 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 72882.0000 - val_fn: 7118.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-007-files-41-42
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51499.0000 - fp: 28501.0000 - tn: 291499.0000 - fn: 28501.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6525 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 72853.0000 - val_fn: 7147.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-41-42
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9106 - val_loss: 0.6506 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 72917.0000 - val_fn: 7083.0000 - val_accuracy: 0.8583 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-007-files-41-42
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51584.0000 - fp: 28416.0000 - tn: 291584.0000 - fn: 28416.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9112 - val_loss: 0.6518 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-41-42
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 43-43/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9113 - val_loss: 0.6518 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-42-43
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6534 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 72824.0000 - val_fn: 7176.0000 - val_accuracy: 0.8565 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-007-files-42-43
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6527 - tp: 51387.0000 - fp: 28613.0000 - tn: 291387.0000 - fn: 28613.0000 - accuracy: 0.8569 - precision: 0.6423 - recall: 0.6423 - auc: 0.9105 - val_loss: 0.6512 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-007-files-42-43
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9106 - val_loss: 0.6527 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-007-files-42-43
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9112 - val_loss: 0.6495 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 72952.0000 - val_fn: 7048.0000 - val_accuracy: 0.8590 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.9119
[INFO] saving weights to checkpoints/dnn-epoch-007-files-42-43
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 44-44/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9107 - val_loss: 0.6524 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-43-44
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9105 - val_loss: 0.6523 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-43-44
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51543.0000 - fp: 28457.0000 - tn: 291543.0000 - fn: 28457.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9110 - val_loss: 0.6523 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-43-44
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6523 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9108 - val_loss: 0.6513 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 72891.0000 - val_fn: 7109.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-43-44
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51537.0000 - fp: 28463.0000 - tn: 291537.0000 - fn: 28463.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9112 - val_loss: 0.6521 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-43-44
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 45-45/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51620.0000 - fp: 28380.0000 - tn: 291620.0000 - fn: 28380.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9111 - val_loss: 0.6519 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-44-45
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51538.0000 - fp: 28462.0000 - tn: 291538.0000 - fn: 28462.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6515 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-44-45
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51564.0000 - fp: 28436.0000 - tn: 291564.0000 - fn: 28436.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6509 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 72904.0000 - val_fn: 7096.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-007-files-44-45
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51590.0000 - fp: 28410.0000 - tn: 291590.0000 - fn: 28410.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9113 - val_loss: 0.6526 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-007-files-44-45
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51395.0000 - fp: 28605.0000 - tn: 291395.0000 - fn: 28605.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9104 - val_loss: 0.6511 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-007-files-44-45
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 46-46/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6506 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 72913.0000 - val_fn: 7087.0000 - val_accuracy: 0.8583 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-007-files-45-46
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51464.0000 - fp: 28536.0000 - tn: 291464.0000 - fn: 28536.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6515 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 72883.0000 - val_fn: 7117.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-007-files-45-46
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9106 - val_loss: 0.6514 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-45-46
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9111 - val_loss: 0.6501 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-007-files-45-46
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51569.0000 - fp: 28431.0000 - tn: 291569.0000 - fn: 28431.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9107 - val_loss: 0.6517 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-45-46
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 47-47/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51601.0000 - fp: 28399.0000 - tn: 291601.0000 - fn: 28399.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9113 - val_loss: 0.6512 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-46-47
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51559.0000 - fp: 28441.0000 - tn: 291559.0000 - fn: 28441.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9110 - val_loss: 0.6518 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-46-47
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9107 - val_loss: 0.6532 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 72822.0000 - val_fn: 7178.0000 - val_accuracy: 0.8564 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-007-files-46-47
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9111 - val_loss: 0.6516 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 72881.0000 - val_fn: 7119.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-007-files-46-47
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6506 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 72909.0000 - val_fn: 7091.0000 - val_accuracy: 0.8582 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-007-files-46-47
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 48-48/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9113 - val_loss: 0.6530 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 72830.0000 - val_fn: 7170.0000 - val_accuracy: 0.8566 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-007-files-47-48
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6515 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 72879.0000 - val_fn: 7121.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-007-files-47-48
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51547.0000 - fp: 28453.0000 - tn: 291547.0000 - fn: 28453.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9111 - val_loss: 0.6506 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-007-files-47-48
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9116 - val_loss: 0.6520 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-47-48
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51606.0000 - fp: 28394.0000 - tn: 291606.0000 - fn: 28394.0000 - accuracy: 0.8580 - precision: 0.6451 - recall: 0.6451 - auc: 0.9112 - val_loss: 0.6508 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 72905.0000 - val_fn: 7095.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-007-files-47-48
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 49-49/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9108 - val_loss: 0.6519 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-48-49
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51430.0000 - fp: 28570.0000 - tn: 291430.0000 - fn: 28570.0000 - accuracy: 0.8571 - precision: 0.6429 - recall: 0.6429 - auc: 0.9106 - val_loss: 0.6502 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 72924.0000 - val_fn: 7076.0000 - val_accuracy: 0.8585 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-007-files-48-49
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51469.0000 - fp: 28531.0000 - tn: 291469.0000 - fn: 28531.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6530 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-007-files-48-49
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6502 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 72922.0000 - val_fn: 7078.0000 - val_accuracy: 0.8584 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-007-files-48-49
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51495.0000 - fp: 28505.0000 - tn: 291495.0000 - fn: 28505.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6512 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-48-49
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 50-50/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9106 - val_loss: 0.6531 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 72823.0000 - val_fn: 7177.0000 - val_accuracy: 0.8565 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-007-files-49-50
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51482.0000 - fp: 28518.0000 - tn: 291482.0000 - fn: 28518.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6513 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-49-50
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51433.0000 - fp: 28567.0000 - tn: 291433.0000 - fn: 28567.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9103 - val_loss: 0.6524 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-007-files-49-50
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51461.0000 - fp: 28539.0000 - tn: 291461.0000 - fn: 28539.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9109 - val_loss: 0.6512 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-49-50
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51467.0000 - fp: 28533.0000 - tn: 291467.0000 - fn: 28533.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6521 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-49-50
[INFO] processing batch 500000-600000/519975
[33m[LOSS] 0.6521407356262207[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6521407356262207  <  0.001
[33m[INFO] epoch 8/10[0m
[33m[INFO] loading file 1-1/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0711 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-0-1
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-0-1
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0227 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9993 - val_loss: 2.2976 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.8826
[INFO] saving weights to checkpoints/dnn-epoch-008-files-0-1
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8375 - tp: 42447.0000 - fp: 37553.0000 - tn: 282447.0000 - fn: 37553.0000 - accuracy: 0.8122 - precision: 0.5306 - recall: 0.5306 - auc: 0.8826 - val_loss: 0.6916 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-008-files-0-1
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6917 - tp: 42438.0000 - fp: 37562.0000 - tn: 282438.0000 - fn: 37562.0000 - accuracy: 0.8122 - precision: 0.5305 - recall: 0.5305 - auc: 0.8827 - val_loss: 0.6917 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-008-files-0-1
[33m[INFO] loading file 2-2/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6917 - tp: 42435.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37565.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5304 - auc: 0.8827 - val_loss: 0.6918 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 70589.0000 - val_fn: 9411.0000 - val_accuracy: 0.8118 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-008-files-1-2
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4423 - tp: 67619.0000 - fp: 12381.0000 - tn: 307619.0000 - fn: 12381.0000 - accuracy: 0.9381 - precision: 0.8452 - recall: 0.8452 - auc: 0.9614 - val_loss: 0.1651 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-1-2
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3147 - tp: 72432.0000 - fp: 7568.0000 - tn: 312432.0000 - fn: 7568.0000 - accuracy: 0.9622 - precision: 0.9054 - recall: 0.9054 - auc: 0.9764 - val_loss: 1.1633 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 70593.0000 - val_fn: 9407.0000 - val_accuracy: 0.8119 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-008-files-1-2
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7176 - tp: 42321.0000 - fp: 37679.0000 - tn: 282321.0000 - fn: 37679.0000 - accuracy: 0.8116 - precision: 0.5290 - recall: 0.5290 - auc: 0.8821 - val_loss: 0.6917 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 70602.0000 - val_fn: 9398.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-008-files-1-2
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4476 - tp: 67360.0000 - fp: 12640.0000 - tn: 307360.0000 - fn: 12640.0000 - accuracy: 0.9368 - precision: 0.8420 - recall: 0.8420 - auc: 0.9604 - val_loss: 0.1703 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-1-2
[33m[INFO] loading file 3-3/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6960 - tp: 45236.0000 - fp: 34764.0000 - tn: 285236.0000 - fn: 34764.0000 - accuracy: 0.8262 - precision: 0.5655 - recall: 0.5655 - auc: 0.8911 - val_loss: 0.6944 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 70571.0000 - val_fn: 9429.0000 - val_accuracy: 0.8114 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.8821
[INFO] saving weights to checkpoints/dnn-epoch-008-files-2-3
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5940 - tp: 57751.0000 - fp: 22249.0000 - tn: 297751.0000 - fn: 22249.0000 - accuracy: 0.8888 - precision: 0.7219 - recall: 0.7219 - auc: 0.9300 - val_loss: 0.3254 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-2-3
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0625 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0200 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-2-3
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0139 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-2-3
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0082 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0067 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-2-3
[33m[INFO] loading file 4-4/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-3-4
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0046 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-3-4
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-3-4
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4227 - tp: 71528.0000 - fp: 8472.0000 - tn: 311528.0000 - fn: 8472.0000 - accuracy: 0.9576 - precision: 0.8941 - recall: 0.8941 - auc: 0.9701 - val_loss: 1.5247 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 67806.0000 - val_fn: 12194.0000 - val_accuracy: 0.7561 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.8476
[INFO] saving weights to checkpoints/dnn-epoch-008-files-3-4
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6128 - tp: 56887.0000 - fp: 23113.0000 - tn: 296887.0000 - fn: 23113.0000 - accuracy: 0.8844 - precision: 0.7111 - recall: 0.7111 - auc: 0.9278 - val_loss: 0.3443 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-3-4
[33m[INFO] loading file 5-5/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5273 - tp: 62445.0000 - fp: 17555.0000 - tn: 302445.0000 - fn: 17555.0000 - accuracy: 0.9122 - precision: 0.7806 - recall: 0.7806 - auc: 0.9449 - val_loss: 0.7023 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-008-files-4-5
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6554 - tp: 51316.0000 - fp: 28684.0000 - tn: 291316.0000 - fn: 28684.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9105 - val_loss: 0.5304 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 77052.0000 - val_fn: 2948.0000 - val_accuracy: 0.9410 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.9632
[INFO] saving weights to checkpoints/dnn-epoch-008-files-4-5
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0711 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-4-5
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-4-5
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0083 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-4-5
[33m[INFO] loading file 6-6/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0059 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-5-6
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-5-6
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-5-6
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2811 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 75632.0000 - val_fn: 4368.0000 - val_accuracy: 0.9126 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.8635
[INFO] saving weights to checkpoints/dnn-epoch-008-files-5-6
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8455 - tp: 51195.0000 - fp: 28805.0000 - tn: 291195.0000 - fn: 28805.0000 - accuracy: 0.8560 - precision: 0.6399 - recall: 0.6399 - auc: 0.9055 - val_loss: 0.6549 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 72768.0000 - val_fn: 7232.0000 - val_accuracy: 0.8554 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.9096
[INFO] saving weights to checkpoints/dnn-epoch-008-files-5-6
[33m[INFO] loading file 7-7/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6537 - tp: 51210.0000 - fp: 28790.0000 - tn: 291210.0000 - fn: 28790.0000 - accuracy: 0.8561 - precision: 0.6401 - recall: 0.6401 - auc: 0.9103 - val_loss: 0.6537 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 72803.0000 - val_fn: 7197.0000 - val_accuracy: 0.8561 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.9100
[INFO] saving weights to checkpoints/dnn-epoch-008-files-6-7
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51338.0000 - fp: 28662.0000 - tn: 291338.0000 - fn: 28662.0000 - accuracy: 0.8567 - precision: 0.6417 - recall: 0.6417 - auc: 0.9105 - val_loss: 0.6520 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-6-7
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4801 - tp: 65370.0000 - fp: 14630.0000 - tn: 305370.0000 - fn: 14630.0000 - accuracy: 0.9268 - precision: 0.8171 - recall: 0.8171 - auc: 0.9542 - val_loss: 0.2047 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-6-7
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0514 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0191 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-6-7
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0135 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0099 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-6-7
[33m[INFO] loading file 8-8/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0080 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0066 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-7-8
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0057 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-7-8
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0040 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-7-8
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3563 - tp: 73166.0000 - fp: 6834.0000 - tn: 313166.0000 - fn: 6834.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9766 - val_loss: 0.5534 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 76368.0000 - val_fn: 3632.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-008-files-7-8
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4809 - tp: 65505.0000 - fp: 14495.0000 - tn: 305505.0000 - fn: 14495.0000 - accuracy: 0.9275 - precision: 0.8188 - recall: 0.8188 - auc: 0.9548 - val_loss: 0.4729 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 76383.0000 - val_fn: 3617.0000 - val_accuracy: 0.9277 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.9548
[INFO] saving weights to checkpoints/dnn-epoch-008-files-7-8
[33m[INFO] loading file 9-9/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4773 - tp: 65300.0000 - fp: 14700.0000 - tn: 305300.0000 - fn: 14700.0000 - accuracy: 0.9265 - precision: 0.8163 - recall: 0.8163 - auc: 0.9540 - val_loss: 0.4804 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 76283.0000 - val_fn: 3717.0000 - val_accuracy: 0.9257 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.9535
[INFO] saving weights to checkpoints/dnn-epoch-008-files-8-9
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0975 - tp: 78936.0000 - fp: 1064.0000 - tn: 318936.0000 - fn: 1064.0000 - accuracy: 0.9947 - precision: 0.9867 - recall: 0.9867 - auc: 0.9966 - val_loss: 0.0268 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-8-9
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0172 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0116 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-8-9
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0092 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0074 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-8-9
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0063 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0054 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-8-9
[33m[INFO] loading file 10-10/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0043 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-9-10
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0084 - tp: 79936.0000 - fp: 64.0000 - tn: 319936.0000 - fn: 64.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 0.9995 - val_loss: 2.0146 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.7763
[INFO] saving weights to checkpoints/dnn-epoch-008-files-9-10
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7561 - tp: 56672.0000 - fp: 23328.0000 - tn: 296672.0000 - fn: 23328.0000 - accuracy: 0.8834 - precision: 0.7084 - recall: 0.7084 - auc: 0.9245 - val_loss: 0.3398 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-9-10
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0636 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0201 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-9-10
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0140 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-9-10
[33m[INFO] loading file 11-11/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0082 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-10-11
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-10-11
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-10-11
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-10-11
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-10-11
[33m[INFO] loading file 12-12/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0027 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0025 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-11-12
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0024 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0134 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 76689.0000 - val_fn: 3311.0000 - val_accuracy: 0.9338 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8965
[INFO] saving weights to checkpoints/dnn-epoch-008-files-11-12
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8656 - tp: 51328.0000 - fp: 28672.0000 - tn: 291328.0000 - fn: 28672.0000 - accuracy: 0.8566 - precision: 0.6416 - recall: 0.6416 - auc: 0.9041 - val_loss: 0.5688 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 75792.0000 - val_fn: 4208.0000 - val_accuracy: 0.9158 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.9474
[INFO] saving weights to checkpoints/dnn-epoch-008-files-11-12
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0714 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-11-12
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-11-12
[33m[INFO] loading file 13-13/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0083 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-12-13
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0059 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-12-13
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3614 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 75075.0000 - val_fn: 4925.0000 - val_accuracy: 0.9015 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.8461
[INFO] saving weights to checkpoints/dnn-epoch-008-files-12-13
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8170 - tp: 51313.0000 - fp: 28687.0000 - tn: 291313.0000 - fn: 28687.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9088 - val_loss: 0.6517 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-008-files-12-13
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51356.0000 - fp: 28644.0000 - tn: 291356.0000 - fn: 28644.0000 - accuracy: 0.8568 - precision: 0.6420 - recall: 0.6420 - auc: 0.9106 - val_loss: 0.6518 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-12-13
[33m[INFO] loading file 14-14/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5271 - tp: 62543.0000 - fp: 17457.0000 - tn: 302543.0000 - fn: 17457.0000 - accuracy: 0.9127 - precision: 0.7818 - recall: 0.7818 - auc: 0.9454 - val_loss: 0.2434 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-13-14
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0554 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0195 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-13-14
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0137 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0100 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-13-14
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0081 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0067 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-13-14
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-13-14
[33m[INFO] loading file 15-15/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0046 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0040 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-14-15
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0038 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-14-15
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-14-15
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0027 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.8649 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 71586.0000 - val_fn: 8414.0000 - val_accuracy: 0.8317 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.7371
[INFO] saving weights to checkpoints/dnn-epoch-008-files-14-15
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.8329 - tp: 42561.0000 - fp: 37439.0000 - tn: 282561.0000 - fn: 37439.0000 - accuracy: 0.8128 - precision: 0.5320 - recall: 0.5320 - auc: 0.8060 - val_loss: 0.7341 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 70627.0000 - val_fn: 9373.0000 - val_accuracy: 0.8125 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-008-files-14-15
[33m[INFO] loading file 16-16/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7177 - tp: 42492.0000 - fp: 37508.0000 - tn: 282492.0000 - fn: 37508.0000 - accuracy: 0.8125 - precision: 0.5311 - recall: 0.5311 - auc: 0.8826 - val_loss: 0.7087 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 70618.0000 - val_fn: 9382.0000 - val_accuracy: 0.8124 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-008-files-15-16
[INFO] processing batch 100000-200000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5997 - tp: 58381.0000 - fp: 21619.0000 - tn: 298381.0000 - fn: 21619.0000 - accuracy: 0.8919 - precision: 0.7298 - recall: 0.7298 - auc: 0.9325 - val_loss: 0.3225 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-15-16
[INFO] processing batch 200000-300000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0648 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0217 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-15-16
[INFO] processing batch 300000-400000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0153 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0112 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-15-16
[INFO] processing batch 400000-500000/439690
[33m[INFO] loading file 17-17/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0092 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0076 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-16-17
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0066 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0058 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-16-17
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0052 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0047 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-16-17
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9906 - tp: 68607.0000 - fp: 11393.0000 - tn: 308607.0000 - fn: 11393.0000 - accuracy: 0.9430 - precision: 0.8576 - recall: 0.8576 - auc: 0.9000 - val_loss: 0.7593 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 76369.0000 - val_fn: 3631.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9092
[INFO] saving weights to checkpoints/dnn-epoch-008-files-16-17
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5639 - tp: 65526.0000 - fp: 14474.0000 - tn: 305526.0000 - fn: 14474.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.9514 - val_loss: 0.3259 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 78648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9730 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9831
[INFO] saving weights to checkpoints/dnn-epoch-008-files-16-17
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 18-18/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3446 - tp: 72130.0000 - fp: 7870.0000 - tn: 312130.0000 - fn: 7870.0000 - accuracy: 0.9606 - precision: 0.9016 - recall: 0.9016 - auc: 0.9755 - val_loss: 0.9947 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 72369.0000 - val_fn: 7631.0000 - val_accuracy: 0.8474 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.9046
[INFO] saving weights to checkpoints/dnn-epoch-008-files-17-18
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7030 - tp: 49699.0000 - fp: 30301.0000 - tn: 289699.0000 - fn: 30301.0000 - accuracy: 0.8485 - precision: 0.6212 - recall: 0.6212 - auc: 0.9052 - val_loss: 0.6820 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 72357.0000 - val_fn: 7643.0000 - val_accuracy: 0.8471 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.9045
[INFO] saving weights to checkpoints/dnn-epoch-008-files-17-18
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6785 - tp: 49541.0000 - fp: 30459.0000 - tn: 289541.0000 - fn: 30459.0000 - accuracy: 0.8477 - precision: 0.6193 - recall: 0.6193 - auc: 0.9048 - val_loss: 0.6761 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 72397.0000 - val_fn: 7603.0000 - val_accuracy: 0.8479 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.9050
[INFO] saving weights to checkpoints/dnn-epoch-008-files-17-18
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2749 - tp: 74509.0000 - fp: 5491.0000 - tn: 314509.0000 - fn: 5491.0000 - accuracy: 0.9725 - precision: 0.9314 - recall: 0.9314 - auc: 0.9829 - val_loss: 0.0768 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-17-18
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0337 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0177 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-17-18
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 19-19/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0132 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-18-19
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0084 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0071 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-18-19
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0062 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0055 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-18-19
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6458 - tp: 69321.0000 - fp: 10679.0000 - tn: 309321.0000 - fn: 10679.0000 - accuracy: 0.9466 - precision: 0.8665 - recall: 0.8665 - auc: 0.9385 - val_loss: 1.5687 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 67882.0000 - val_fn: 12118.0000 - val_accuracy: 0.7576 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.8485
[INFO] saving weights to checkpoints/dnn-epoch-008-files-18-19
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7456 - tp: 44498.0000 - fp: 32718.0000 - tn: 287282.0000 - fn: 35502.0000 - accuracy: 0.8294 - precision: 0.5763 - recall: 0.5562 - auc: 0.8909 - val_loss: 0.9633 - val_tp: 0.0000e+00 - val_fp: 20000.0000 - val_tn: 60000.0000 - val_fn: 20000.0000 - val_accuracy: 0.6000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7500
[INFO] saving weights to checkpoints/dnn-epoch-008-files-18-19
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 20-20/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.1056 - tp: 78560.0000 - fp: 1184.0000 - tn: 318816.0000 - fn: 1440.0000 - accuracy: 0.9934 - precision: 0.9852 - recall: 0.9820 - auc: 0.9999 - val_loss: 0.1241 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 79491.0000 - val_fn: 509.0000 - val_accuracy: 0.9898 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9936
[INFO] saving weights to checkpoints/dnn-epoch-008-files-19-20
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5204 - tp: 65427.0000 - fp: 14573.0000 - tn: 305427.0000 - fn: 14573.0000 - accuracy: 0.9271 - precision: 0.8178 - recall: 0.8178 - auc: 0.9544 - val_loss: 0.4848 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 76357.0000 - val_fn: 3643.0000 - val_accuracy: 0.9271 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.9545
[INFO] saving weights to checkpoints/dnn-epoch-008-files-19-20
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4851 - tp: 65351.0000 - fp: 14649.0000 - tn: 305351.0000 - fn: 14649.0000 - accuracy: 0.9268 - precision: 0.8169 - recall: 0.8169 - auc: 0.9541 - val_loss: 0.4816 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 76371.0000 - val_fn: 3629.0000 - val_accuracy: 0.9274 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-008-files-19-20
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2113 - tp: 76024.0000 - fp: 3976.0000 - tn: 316024.0000 - fn: 3976.0000 - accuracy: 0.9801 - precision: 0.9503 - recall: 0.9503 - auc: 0.9874 - val_loss: 0.0581 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-19-20
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0288 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0163 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-19-20
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 21-21/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539688, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0123 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0096 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-20-21
[INFO] processing batch 100000-200000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0080 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-20-21
[INFO] processing batch 200000-300000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0060 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0053 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-20-21
[INFO] processing batch 300000-400000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0043 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-20-21
[INFO] processing batch 400000-500000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0040 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0037 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-20-21
[INFO] processing batch 500000-600000/539688
[33m[INFO] loading file 22-22/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.3362 - tp: 55006.0000 - fp: 24994.0000 - tn: 295006.0000 - fn: 24994.0000 - accuracy: 0.8750 - precision: 0.6876 - recall: 0.6876 - auc: 0.8464 - val_loss: 0.8145 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-008-files-21-22
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7322 - tp: 42398.0000 - fp: 37602.0000 - tn: 282398.0000 - fn: 37602.0000 - accuracy: 0.8120 - precision: 0.5300 - recall: 0.5300 - auc: 0.8822 - val_loss: 0.7171 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.8816
[INFO] saving weights to checkpoints/dnn-epoch-008-files-21-22
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7115 - tp: 42369.0000 - fp: 37631.0000 - tn: 282369.0000 - fn: 37631.0000 - accuracy: 0.8118 - precision: 0.5296 - recall: 0.5296 - auc: 0.8824 - val_loss: 0.7074 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 70623.0000 - val_fn: 9377.0000 - val_accuracy: 0.8125 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-008-files-21-22
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7052 - tp: 42452.0000 - fp: 37548.0000 - tn: 282452.0000 - fn: 37548.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5307 - auc: 0.8824 - val_loss: 0.7033 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 70601.0000 - val_fn: 9399.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-008-files-21-22
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7020 - tp: 42382.0000 - fp: 37618.0000 - tn: 282382.0000 - fn: 37618.0000 - accuracy: 0.8119 - precision: 0.5298 - recall: 0.5298 - auc: 0.8824 - val_loss: 0.7007 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-008-files-21-22
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 23-23/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6548 - tp: 52270.0000 - fp: 27730.0000 - tn: 292270.0000 - fn: 27730.0000 - accuracy: 0.8614 - precision: 0.6534 - recall: 0.6534 - auc: 0.9136 - val_loss: 0.4272 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-22-23
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0719 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0217 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-22-23
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0152 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0111 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-22-23
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0090 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0075 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-22-23
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0065 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0057 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-22-23
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 24-24/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0051 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0046 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-23-24
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0042 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0038 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-23-24
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0036 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0033 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-23-24
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-23-24
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2733 - tp: 75698.0000 - fp: 4302.0000 - tn: 315698.0000 - fn: 4302.0000 - accuracy: 0.9785 - precision: 0.9462 - recall: 0.9462 - auc: 0.9800 - val_loss: 1.3945 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 72912.0000 - val_fn: 7088.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-008-files-23-24
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 25-25/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7231 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9108 - val_loss: 0.6576 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-008-files-24-25
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6565 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6554 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-008-files-24-25
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6560 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.6563 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-008-files-24-25
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6554 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9114 - val_loss: 0.6562 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-008-files-24-25
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6553 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9106 - val_loss: 0.6551 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-24-25
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 26-26/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6546 - tp: 51523.0000 - fp: 28477.0000 - tn: 291523.0000 - fn: 28477.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9105 - val_loss: 1.6336 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.8310
[INFO] saving weights to checkpoints/dnn-epoch-008-files-25-26
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.2139 - tp: 51579.0000 - fp: 28421.0000 - tn: 291579.0000 - fn: 28421.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.8515 - val_loss: 0.7019 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-25-26
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6829 - tp: 51462.0000 - fp: 28538.0000 - tn: 291462.0000 - fn: 28538.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9106 - val_loss: 0.6712 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-008-files-25-26
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6680 - tp: 51506.0000 - fp: 28494.0000 - tn: 291506.0000 - fn: 28494.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6630 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 72936.0000 - val_fn: 7064.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-008-files-25-26
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6631 - tp: 51474.0000 - fp: 28526.0000 - tn: 291474.0000 - fn: 28526.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9106 - val_loss: 0.6594 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 72945.0000 - val_fn: 7055.0000 - val_accuracy: 0.8589 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.9118
[INFO] saving weights to checkpoints/dnn-epoch-008-files-25-26
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 27-27/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (479817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6609 - tp: 51419.0000 - fp: 28581.0000 - tn: 291419.0000 - fn: 28581.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9106 - val_loss: 0.6607 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-008-files-26-27
[INFO] processing batch 100000-200000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6588 - tp: 51485.0000 - fp: 28515.0000 - tn: 291485.0000 - fn: 28515.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6567 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 72918.0000 - val_fn: 7082.0000 - val_accuracy: 0.8584 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-008-files-26-27
[INFO] processing batch 200000-300000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6569 - tp: 51583.0000 - fp: 28417.0000 - tn: 291583.0000 - fn: 28417.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9112 - val_loss: 0.6574 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-26-27
[INFO] processing batch 300000-400000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6575 - tp: 51396.0000 - fp: 28604.0000 - tn: 291396.0000 - fn: 28604.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9109 - val_loss: 0.6572 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 72851.0000 - val_fn: 7149.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-008-files-26-27
[INFO] processing batch 400000-500000/479817
[33m[INFO] loading file 28-28/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6563 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6560 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-27-28
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6564 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9107 - val_loss: 0.6558 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-27-28
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6555 - tp: 51458.0000 - fp: 28542.0000 - tn: 291458.0000 - fn: 28542.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6552 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-27-28
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6552 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9109 - val_loss: 0.6539 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-008-files-27-28
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6544 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6551 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-27-28
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 29-29/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6547 - tp: 51460.0000 - fp: 28540.0000 - tn: 291460.0000 - fn: 28540.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9109 - val_loss: 0.6548 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-28-29
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6540 - tp: 51527.0000 - fp: 28473.0000 - tn: 291527.0000 - fn: 28473.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9112 - val_loss: 0.6551 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-008-files-28-29
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6541 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6522 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-008-files-28-29
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6534 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9108 - val_loss: 0.6543 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-28-29
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6536 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-28-29
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 30-30/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6534 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6539 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-29-30
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51450.0000 - fp: 28550.0000 - tn: 291450.0000 - fn: 28550.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9105 - val_loss: 0.6540 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-29-30
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6534 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9111 - val_loss: 0.6539 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-29-30
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6532 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-008-files-29-30
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9110 - val_loss: 0.6533 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 72870.0000 - val_fn: 7130.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-29-30
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 31-31/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6517 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 72921.0000 - val_fn: 7079.0000 - val_accuracy: 0.8584 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-008-files-30-31
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51524.0000 - fp: 28476.0000 - tn: 291524.0000 - fn: 28476.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9113 - val_loss: 0.6522 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 72902.0000 - val_fn: 7098.0000 - val_accuracy: 0.8580 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-008-files-30-31
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6535 - tp: 51428.0000 - fp: 28572.0000 - tn: 291428.0000 - fn: 28572.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9104 - val_loss: 0.6529 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-30-31
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6525 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-30-31
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9106 - val_loss: 0.6523 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 72893.0000 - val_fn: 7107.0000 - val_accuracy: 0.8579 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-008-files-30-31
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 32-32/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9112 - val_loss: 0.6526 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-31-32
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51531.0000 - fp: 28469.0000 - tn: 291531.0000 - fn: 28469.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9107 - val_loss: 0.6527 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-31-32
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51576.0000 - fp: 28424.0000 - tn: 291576.0000 - fn: 28424.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9109 - val_loss: 0.6522 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-31-32
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6527 - tp: 51489.0000 - fp: 28511.0000 - tn: 291489.0000 - fn: 28511.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6529 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-31-32
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6530 - tp: 51449.0000 - fp: 28551.0000 - tn: 291449.0000 - fn: 28551.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9105 - val_loss: 0.6528 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-31-32
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 33-33/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6525 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-32-33
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9113 - val_loss: 0.6528 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-32-33
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51404.0000 - fp: 28596.0000 - tn: 291404.0000 - fn: 28596.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9105 - val_loss: 0.6528 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-32-33
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51552.0000 - fp: 28448.0000 - tn: 291552.0000 - fn: 28448.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9109 - val_loss: 0.6522 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-32-33
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51594.0000 - fp: 28406.0000 - tn: 291594.0000 - fn: 28406.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9109 - val_loss: 0.6508 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-008-files-32-33
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 34-34/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9107 - val_loss: 0.6534 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-008-files-33-34
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9106 - val_loss: 0.6526 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-33-34
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51588.0000 - fp: 28412.0000 - tn: 291588.0000 - fn: 28412.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9115 - val_loss: 0.6523 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-008-files-33-34
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6530 - tp: 51408.0000 - fp: 28592.0000 - tn: 291408.0000 - fn: 28592.0000 - accuracy: 0.8570 - precision: 0.6426 - recall: 0.6426 - auc: 0.9106 - val_loss: 0.6535 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 72834.0000 - val_fn: 7166.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-008-files-33-34
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6522 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-008-files-33-34
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 35-35/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51520.0000 - fp: 28480.0000 - tn: 291520.0000 - fn: 28480.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9111 - val_loss: 0.6529 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-34-35
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9111 - val_loss: 0.6522 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-008-files-34-35
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6520 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-34-35
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51521.0000 - fp: 28479.0000 - tn: 291521.0000 - fn: 28479.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9108 - val_loss: 0.6528 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-34-35
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51570.0000 - fp: 28430.0000 - tn: 291570.0000 - fn: 28430.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.6524 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-34-35
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 36-36/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9105 - val_loss: 0.6522 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-35-36
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51644.0000 - fp: 28356.0000 - tn: 291644.0000 - fn: 28356.0000 - accuracy: 0.8582 - precision: 0.6456 - recall: 0.6456 - auc: 0.9113 - val_loss: 0.6516 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 72895.0000 - val_fn: 7105.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-008-files-35-36
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9102 - val_loss: 0.6504 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 72933.0000 - val_fn: 7067.0000 - val_accuracy: 0.8587 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-008-files-35-36
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51415.0000 - fp: 28585.0000 - tn: 291415.0000 - fn: 28585.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9105 - val_loss: 0.6521 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 72878.0000 - val_fn: 7122.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-008-files-35-36
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6526 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-35-36
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 37-37/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6527 - tp: 51413.0000 - fp: 28587.0000 - tn: 291413.0000 - fn: 28587.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9107 - val_loss: 0.6527 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-36-37
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51456.0000 - fp: 28544.0000 - tn: 291456.0000 - fn: 28544.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9111 - val_loss: 0.6512 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-008-files-36-37
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51565.0000 - fp: 28435.0000 - tn: 291565.0000 - fn: 28435.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9111 - val_loss: 0.6522 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-36-37
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51512.0000 - fp: 28488.0000 - tn: 291512.0000 - fn: 28488.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6517 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 72888.0000 - val_fn: 7112.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-36-37
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51528.0000 - fp: 28472.0000 - tn: 291528.0000 - fn: 28472.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9106 - val_loss: 0.6513 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 72899.0000 - val_fn: 7101.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-008-files-36-37
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 38-38/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51513.0000 - fp: 28487.0000 - tn: 291513.0000 - fn: 28487.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.6503 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-008-files-37-38
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51589.0000 - fp: 28411.0000 - tn: 291589.0000 - fn: 28411.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9110 - val_loss: 0.6530 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-008-files-37-38
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51481.0000 - fp: 28519.0000 - tn: 291481.0000 - fn: 28519.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9110 - val_loss: 0.6525 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-37-38
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51549.0000 - fp: 28451.0000 - tn: 291549.0000 - fn: 28451.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9110 - val_loss: 0.6513 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 72898.0000 - val_fn: 7102.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-008-files-37-38
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9107 - val_loss: 0.6522 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 72866.0000 - val_fn: 7134.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-37-38
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 39-39/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6528 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 72847.0000 - val_fn: 7153.0000 - val_accuracy: 0.8569 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-008-files-38-39
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51597.0000 - fp: 28403.0000 - tn: 291597.0000 - fn: 28403.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9109 - val_loss: 0.6509 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 72910.0000 - val_fn: 7090.0000 - val_accuracy: 0.8582 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-008-files-38-39
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51631.0000 - fp: 28369.0000 - tn: 291631.0000 - fn: 28369.0000 - accuracy: 0.8582 - precision: 0.6454 - recall: 0.6454 - auc: 0.9112 - val_loss: 0.6514 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-008-files-38-39
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6521 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-38-39
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6519 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-38-39
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 40-40/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51418.0000 - fp: 28582.0000 - tn: 291418.0000 - fn: 28582.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9104 - val_loss: 0.6529 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-008-files-39-40
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51491.0000 - fp: 28509.0000 - tn: 291491.0000 - fn: 28509.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6523 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-39-40
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9112 - val_loss: 0.6507 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 72916.0000 - val_fn: 7084.0000 - val_accuracy: 0.8583 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-008-files-39-40
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9113 - val_loss: 0.6529 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 72838.0000 - val_fn: 7162.0000 - val_accuracy: 0.8568 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-008-files-39-40
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51432.0000 - fp: 28568.0000 - tn: 291432.0000 - fn: 28568.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9106 - val_loss: 0.6526 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-008-files-39-40
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 41-41/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9107 - val_loss: 0.6523 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-40-41
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51515.0000 - fp: 28485.0000 - tn: 291515.0000 - fn: 28485.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6521 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-40-41
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9107 - val_loss: 0.6518 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-008-files-40-41
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51587.0000 - fp: 28413.0000 - tn: 291587.0000 - fn: 28413.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9112 - val_loss: 0.6523 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-40-41
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9108 - val_loss: 0.6501 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 72937.0000 - val_fn: 7063.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-008-files-40-41
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 42-42/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9107 - val_loss: 0.6532 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 72826.0000 - val_fn: 7174.0000 - val_accuracy: 0.8565 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-008-files-41-42
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51511.0000 - fp: 28489.0000 - tn: 291511.0000 - fn: 28489.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9112 - val_loss: 0.6516 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 72882.0000 - val_fn: 7118.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-008-files-41-42
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51499.0000 - fp: 28501.0000 - tn: 291499.0000 - fn: 28501.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9111 - val_loss: 0.6524 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 72853.0000 - val_fn: 7147.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-41-42
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6505 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 72917.0000 - val_fn: 7083.0000 - val_accuracy: 0.8583 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-008-files-41-42
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51584.0000 - fp: 28416.0000 - tn: 291584.0000 - fn: 28416.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9106 - val_loss: 0.6518 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-41-42
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 43-43/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9112 - val_loss: 0.6518 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-42-43
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6533 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 72824.0000 - val_fn: 7176.0000 - val_accuracy: 0.8565 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-008-files-42-43
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51387.0000 - fp: 28613.0000 - tn: 291387.0000 - fn: 28613.0000 - accuracy: 0.8569 - precision: 0.6423 - recall: 0.6423 - auc: 0.9108 - val_loss: 0.6515 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-008-files-42-43
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9109 - val_loss: 0.6527 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-008-files-42-43
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9113 - val_loss: 0.6495 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 72952.0000 - val_fn: 7048.0000 - val_accuracy: 0.8590 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.9119
[INFO] saving weights to checkpoints/dnn-epoch-008-files-42-43
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 44-44/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9108 - val_loss: 0.6523 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-43-44
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9106 - val_loss: 0.6523 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-43-44
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51543.0000 - fp: 28457.0000 - tn: 291543.0000 - fn: 28457.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9108 - val_loss: 0.6523 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-43-44
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6523 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6513 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 72891.0000 - val_fn: 7109.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-43-44
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51537.0000 - fp: 28463.0000 - tn: 291537.0000 - fn: 28463.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9114 - val_loss: 0.6521 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-43-44
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 45-45/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51620.0000 - fp: 28380.0000 - tn: 291620.0000 - fn: 28380.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9111 - val_loss: 0.6519 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-44-45
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51538.0000 - fp: 28462.0000 - tn: 291538.0000 - fn: 28462.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9104 - val_loss: 0.6514 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-44-45
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51564.0000 - fp: 28436.0000 - tn: 291564.0000 - fn: 28436.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.6508 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 72904.0000 - val_fn: 7096.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-008-files-44-45
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51590.0000 - fp: 28410.0000 - tn: 291590.0000 - fn: 28410.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9111 - val_loss: 0.6526 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-008-files-44-45
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51395.0000 - fp: 28605.0000 - tn: 291395.0000 - fn: 28605.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9108 - val_loss: 0.6511 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-008-files-44-45
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 46-46/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6506 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 72913.0000 - val_fn: 7087.0000 - val_accuracy: 0.8583 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-008-files-45-46
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51464.0000 - fp: 28536.0000 - tn: 291464.0000 - fn: 28536.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9113 - val_loss: 0.6515 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 72883.0000 - val_fn: 7117.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-008-files-45-46
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6514 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-45-46
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9108 - val_loss: 0.6501 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-008-files-45-46
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51569.0000 - fp: 28431.0000 - tn: 291569.0000 - fn: 28431.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.6518 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-45-46
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 47-47/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51601.0000 - fp: 28399.0000 - tn: 291601.0000 - fn: 28399.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9109 - val_loss: 0.6512 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-46-47
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51559.0000 - fp: 28441.0000 - tn: 291559.0000 - fn: 28441.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-46-47
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9105 - val_loss: 0.6533 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 72822.0000 - val_fn: 7178.0000 - val_accuracy: 0.8564 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-008-files-46-47
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6515 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 72881.0000 - val_fn: 7119.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-008-files-46-47
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6507 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 72909.0000 - val_fn: 7091.0000 - val_accuracy: 0.8582 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-008-files-46-47
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 48-48/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9106 - val_loss: 0.6530 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 72830.0000 - val_fn: 7170.0000 - val_accuracy: 0.8566 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-008-files-47-48
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6515 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 72879.0000 - val_fn: 7121.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-008-files-47-48
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51547.0000 - fp: 28453.0000 - tn: 291547.0000 - fn: 28453.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9110 - val_loss: 0.6506 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-008-files-47-48
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9111 - val_loss: 0.6521 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-47-48
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51606.0000 - fp: 28394.0000 - tn: 291606.0000 - fn: 28394.0000 - accuracy: 0.8580 - precision: 0.6451 - recall: 0.6451 - auc: 0.9115 - val_loss: 0.6507 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 72905.0000 - val_fn: 7095.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-008-files-47-48
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 49-49/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6520 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-48-49
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51430.0000 - fp: 28570.0000 - tn: 291430.0000 - fn: 28570.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9108 - val_loss: 0.6502 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 72924.0000 - val_fn: 7076.0000 - val_accuracy: 0.8585 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-008-files-48-49
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51469.0000 - fp: 28531.0000 - tn: 291469.0000 - fn: 28531.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9105 - val_loss: 0.6530 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-008-files-48-49
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6502 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 72922.0000 - val_fn: 7078.0000 - val_accuracy: 0.8584 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-008-files-48-49
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51495.0000 - fp: 28505.0000 - tn: 291495.0000 - fn: 28505.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6512 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-48-49
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 50-50/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9107 - val_loss: 0.6532 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 72823.0000 - val_fn: 7177.0000 - val_accuracy: 0.8565 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-008-files-49-50
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51482.0000 - fp: 28518.0000 - tn: 291482.0000 - fn: 28518.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6511 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-49-50
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51433.0000 - fp: 28567.0000 - tn: 291433.0000 - fn: 28567.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9108 - val_loss: 0.6524 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-008-files-49-50
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51461.0000 - fp: 28539.0000 - tn: 291461.0000 - fn: 28539.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6512 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-49-50
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51467.0000 - fp: 28533.0000 - tn: 291467.0000 - fn: 28533.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9107 - val_loss: 0.6522 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-49-50
[INFO] processing batch 500000-600000/519975
[33m[LOSS] 0.6521817790985107[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6521817790985107  <  0.001
[33m[INFO] epoch 9/10[0m
[33m[INFO] loading file 1-1/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0714 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-0-1
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-0-1
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0227 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9993 - val_loss: 2.2976 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.8826
[INFO] saving weights to checkpoints/dnn-epoch-009-files-0-1
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8369 - tp: 42447.0000 - fp: 37553.0000 - tn: 282447.0000 - fn: 37553.0000 - accuracy: 0.8122 - precision: 0.5306 - recall: 0.5306 - auc: 0.8829 - val_loss: 0.6916 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-009-files-0-1
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6917 - tp: 42438.0000 - fp: 37562.0000 - tn: 282438.0000 - fn: 37562.0000 - accuracy: 0.8122 - precision: 0.5305 - recall: 0.5305 - auc: 0.8826 - val_loss: 0.6918 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-009-files-0-1
[33m[INFO] loading file 2-2/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6917 - tp: 42435.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37565.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5304 - auc: 0.8823 - val_loss: 0.6918 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 70589.0000 - val_fn: 9411.0000 - val_accuracy: 0.8118 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-009-files-1-2
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4427 - tp: 67619.0000 - fp: 12381.0000 - tn: 307619.0000 - fn: 12381.0000 - accuracy: 0.9381 - precision: 0.8452 - recall: 0.8452 - auc: 0.9612 - val_loss: 0.1707 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-1-2
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3148 - tp: 72432.0000 - fp: 7568.0000 - tn: 312432.0000 - fn: 7568.0000 - accuracy: 0.9622 - precision: 0.9054 - recall: 0.9054 - auc: 0.9764 - val_loss: 1.1561 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 70593.0000 - val_fn: 9407.0000 - val_accuracy: 0.8119 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-009-files-1-2
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7164 - tp: 42321.0000 - fp: 37679.0000 - tn: 282321.0000 - fn: 37679.0000 - accuracy: 0.8116 - precision: 0.5290 - recall: 0.5290 - auc: 0.8821 - val_loss: 0.6917 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 70602.0000 - val_fn: 9398.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-009-files-1-2
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4474 - tp: 67360.0000 - fp: 12640.0000 - tn: 307360.0000 - fn: 12640.0000 - accuracy: 0.9368 - precision: 0.8420 - recall: 0.8420 - auc: 0.9606 - val_loss: 0.1712 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-1-2
[33m[INFO] loading file 3-3/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6957 - tp: 45236.0000 - fp: 34764.0000 - tn: 285236.0000 - fn: 34764.0000 - accuracy: 0.8262 - precision: 0.5655 - recall: 0.5655 - auc: 0.8910 - val_loss: 0.6948 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 70571.0000 - val_fn: 9429.0000 - val_accuracy: 0.8114 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.8821
[INFO] saving weights to checkpoints/dnn-epoch-009-files-2-3
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5938 - tp: 57751.0000 - fp: 22249.0000 - tn: 297751.0000 - fn: 22249.0000 - accuracy: 0.8888 - precision: 0.7219 - recall: 0.7219 - auc: 0.9306 - val_loss: 0.3342 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-2-3
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0632 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0200 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-2-3
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0140 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-2-3
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0082 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-2-3
[33m[INFO] loading file 4-4/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-3-4
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0046 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-3-4
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-3-4
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4221 - tp: 71528.0000 - fp: 8472.0000 - tn: 311528.0000 - fn: 8472.0000 - accuracy: 0.9576 - precision: 0.8941 - recall: 0.8941 - auc: 0.9705 - val_loss: 1.5030 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 67806.0000 - val_fn: 12194.0000 - val_accuracy: 0.7561 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.8476
[INFO] saving weights to checkpoints/dnn-epoch-009-files-3-4
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6120 - tp: 56887.0000 - fp: 23113.0000 - tn: 296887.0000 - fn: 23113.0000 - accuracy: 0.8844 - precision: 0.7111 - recall: 0.7111 - auc: 0.9280 - val_loss: 0.3439 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-3-4
[33m[INFO] loading file 5-5/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5271 - tp: 62445.0000 - fp: 17555.0000 - tn: 302445.0000 - fn: 17555.0000 - accuracy: 0.9122 - precision: 0.7806 - recall: 0.7806 - auc: 0.9452 - val_loss: 0.7013 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-009-files-4-5
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6554 - tp: 51316.0000 - fp: 28684.0000 - tn: 291316.0000 - fn: 28684.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9105 - val_loss: 0.5259 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 77052.0000 - val_fn: 2948.0000 - val_accuracy: 0.9410 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.9632
[INFO] saving weights to checkpoints/dnn-epoch-009-files-4-5
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0706 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0204 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-4-5
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-4-5
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0083 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-4-5
[33m[INFO] loading file 6-6/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0059 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-5-6
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-5-6
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-5-6
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2811 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 75632.0000 - val_fn: 4368.0000 - val_accuracy: 0.9126 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.8635
[INFO] saving weights to checkpoints/dnn-epoch-009-files-5-6
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8452 - tp: 51195.0000 - fp: 28805.0000 - tn: 291195.0000 - fn: 28805.0000 - accuracy: 0.8560 - precision: 0.6399 - recall: 0.6399 - auc: 0.9056 - val_loss: 0.6547 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 72768.0000 - val_fn: 7232.0000 - val_accuracy: 0.8554 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.9096
[INFO] saving weights to checkpoints/dnn-epoch-009-files-5-6
[33m[INFO] loading file 7-7/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6537 - tp: 51210.0000 - fp: 28790.0000 - tn: 291210.0000 - fn: 28790.0000 - accuracy: 0.8560 - precision: 0.6401 - recall: 0.6401 - auc: 0.9098 - val_loss: 0.6537 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 72803.0000 - val_fn: 7197.0000 - val_accuracy: 0.8561 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.9100
[INFO] saving weights to checkpoints/dnn-epoch-009-files-6-7
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51338.0000 - fp: 28662.0000 - tn: 291338.0000 - fn: 28662.0000 - accuracy: 0.8567 - precision: 0.6417 - recall: 0.6417 - auc: 0.9104 - val_loss: 0.6522 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-6-7
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4804 - tp: 65370.0000 - fp: 14630.0000 - tn: 305370.0000 - fn: 14630.0000 - accuracy: 0.9268 - precision: 0.8171 - recall: 0.8171 - auc: 0.9541 - val_loss: 0.2005 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-6-7
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0510 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0191 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-6-7
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0135 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0099 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-6-7
[33m[INFO] loading file 8-8/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0080 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0066 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-7-8
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0057 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-7-8
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0040 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-7-8
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3563 - tp: 73166.0000 - fp: 6834.0000 - tn: 313166.0000 - fn: 6834.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9767 - val_loss: 0.5528 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 76368.0000 - val_fn: 3632.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-009-files-7-8
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4809 - tp: 65505.0000 - fp: 14495.0000 - tn: 305505.0000 - fn: 14495.0000 - accuracy: 0.9275 - precision: 0.8188 - recall: 0.8188 - auc: 0.9548 - val_loss: 0.4730 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 76383.0000 - val_fn: 3617.0000 - val_accuracy: 0.9277 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.9548
[INFO] saving weights to checkpoints/dnn-epoch-009-files-7-8
[33m[INFO] loading file 9-9/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4773 - tp: 65300.0000 - fp: 14700.0000 - tn: 305300.0000 - fn: 14700.0000 - accuracy: 0.9265 - precision: 0.8163 - recall: 0.8163 - auc: 0.9539 - val_loss: 0.4804 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 76283.0000 - val_fn: 3717.0000 - val_accuracy: 0.9257 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.9535
[INFO] saving weights to checkpoints/dnn-epoch-009-files-8-9
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0978 - tp: 78936.0000 - fp: 1064.0000 - tn: 318936.0000 - fn: 1064.0000 - accuracy: 0.9947 - precision: 0.9867 - recall: 0.9867 - auc: 0.9966 - val_loss: 0.0269 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-8-9
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0172 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0116 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-8-9
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0092 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0074 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-8-9
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0063 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0054 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-8-9
[33m[INFO] loading file 10-10/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0043 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-9-10
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0084 - tp: 79936.0000 - fp: 64.0000 - tn: 319936.0000 - fn: 64.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 0.9995 - val_loss: 2.0143 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.7763
[INFO] saving weights to checkpoints/dnn-epoch-009-files-9-10
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7567 - tp: 56672.0000 - fp: 23328.0000 - tn: 296672.0000 - fn: 23328.0000 - accuracy: 0.8834 - precision: 0.7084 - recall: 0.7084 - auc: 0.9243 - val_loss: 0.3386 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-9-10
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0635 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0201 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-9-10
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0140 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-9-10
[33m[INFO] loading file 11-11/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0082 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-10-11
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-10-11
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-10-11
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-10-11
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-10-11
[33m[INFO] loading file 12-12/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0027 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0025 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-11-12
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0024 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0134 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 76689.0000 - val_fn: 3311.0000 - val_accuracy: 0.9338 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8965
[INFO] saving weights to checkpoints/dnn-epoch-009-files-11-12
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8643 - tp: 51328.0000 - fp: 28672.0000 - tn: 291328.0000 - fn: 28672.0000 - accuracy: 0.8566 - precision: 0.6416 - recall: 0.6416 - auc: 0.9043 - val_loss: 0.5675 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 75792.0000 - val_fn: 4208.0000 - val_accuracy: 0.9158 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.9474
[INFO] saving weights to checkpoints/dnn-epoch-009-files-11-12
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0712 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-11-12
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-11-12
[33m[INFO] loading file 13-13/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0083 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-12-13
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0059 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-12-13
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3615 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 75075.0000 - val_fn: 4925.0000 - val_accuracy: 0.9015 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.8461
[INFO] saving weights to checkpoints/dnn-epoch-009-files-12-13
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8171 - tp: 51313.0000 - fp: 28687.0000 - tn: 291313.0000 - fn: 28687.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9087 - val_loss: 0.6515 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-009-files-12-13
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51356.0000 - fp: 28644.0000 - tn: 291356.0000 - fn: 28644.0000 - accuracy: 0.8568 - precision: 0.6420 - recall: 0.6420 - auc: 0.9102 - val_loss: 0.6518 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-12-13
[33m[INFO] loading file 14-14/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5272 - tp: 62543.0000 - fp: 17457.0000 - tn: 302543.0000 - fn: 17457.0000 - accuracy: 0.9127 - precision: 0.7818 - recall: 0.7818 - auc: 0.9453 - val_loss: 0.2458 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-13-14
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0556 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0195 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-13-14
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0137 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0100 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-13-14
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0081 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0067 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-13-14
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-13-14
[33m[INFO] loading file 15-15/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0046 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0040 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-14-15
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0038 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-14-15
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-14-15
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0027 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.8648 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 71586.0000 - val_fn: 8414.0000 - val_accuracy: 0.8317 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.7371
[INFO] saving weights to checkpoints/dnn-epoch-009-files-14-15
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.8325 - tp: 42561.0000 - fp: 37439.0000 - tn: 282561.0000 - fn: 37439.0000 - accuracy: 0.8128 - precision: 0.5320 - recall: 0.5320 - auc: 0.8061 - val_loss: 0.7342 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 70627.0000 - val_fn: 9373.0000 - val_accuracy: 0.8125 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-009-files-14-15
[33m[INFO] loading file 16-16/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7177 - tp: 42492.0000 - fp: 37508.0000 - tn: 282492.0000 - fn: 37508.0000 - accuracy: 0.8125 - precision: 0.5311 - recall: 0.5311 - auc: 0.8828 - val_loss: 0.7087 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 70618.0000 - val_fn: 9382.0000 - val_accuracy: 0.8124 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-009-files-15-16
[INFO] processing batch 100000-200000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5998 - tp: 58381.0000 - fp: 21619.0000 - tn: 298381.0000 - fn: 21619.0000 - accuracy: 0.8919 - precision: 0.7298 - recall: 0.7298 - auc: 0.9326 - val_loss: 0.3163 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-15-16
[INFO] processing batch 200000-300000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0643 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0217 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-15-16
[INFO] processing batch 300000-400000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0153 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0112 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-15-16
[INFO] processing batch 400000-500000/439690
[33m[INFO] loading file 17-17/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0092 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0076 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-16-17
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0066 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0058 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-16-17
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0052 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0047 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-16-17
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9908 - tp: 68607.0000 - fp: 11393.0000 - tn: 308607.0000 - fn: 11393.0000 - accuracy: 0.9430 - precision: 0.8576 - recall: 0.8576 - auc: 0.8998 - val_loss: 0.7594 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 76369.0000 - val_fn: 3631.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9092
[INFO] saving weights to checkpoints/dnn-epoch-009-files-16-17
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5642 - tp: 65526.0000 - fp: 14474.0000 - tn: 305526.0000 - fn: 14474.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.9512 - val_loss: 0.3251 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 78648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9730 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9831
[INFO] saving weights to checkpoints/dnn-epoch-009-files-16-17
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 18-18/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3445 - tp: 72130.0000 - fp: 7870.0000 - tn: 312130.0000 - fn: 7870.0000 - accuracy: 0.9606 - precision: 0.9016 - recall: 0.9016 - auc: 0.9754 - val_loss: 0.9885 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 72369.0000 - val_fn: 7631.0000 - val_accuracy: 0.8474 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.9046
[INFO] saving weights to checkpoints/dnn-epoch-009-files-17-18
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7019 - tp: 49699.0000 - fp: 30301.0000 - tn: 289699.0000 - fn: 30301.0000 - accuracy: 0.8485 - precision: 0.6212 - recall: 0.6212 - auc: 0.9053 - val_loss: 0.6817 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 72357.0000 - val_fn: 7643.0000 - val_accuracy: 0.8471 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.9045
[INFO] saving weights to checkpoints/dnn-epoch-009-files-17-18
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6785 - tp: 49541.0000 - fp: 30459.0000 - tn: 289541.0000 - fn: 30459.0000 - accuracy: 0.8477 - precision: 0.6193 - recall: 0.6193 - auc: 0.9048 - val_loss: 0.6761 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 72397.0000 - val_fn: 7603.0000 - val_accuracy: 0.8479 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.9050
[INFO] saving weights to checkpoints/dnn-epoch-009-files-17-18
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2750 - tp: 74509.0000 - fp: 5491.0000 - tn: 314509.0000 - fn: 5491.0000 - accuracy: 0.9725 - precision: 0.9314 - recall: 0.9314 - auc: 0.9828 - val_loss: 0.0776 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-17-18
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0339 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0177 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-17-18
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 19-19/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0132 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-18-19
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0084 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0071 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-18-19
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0062 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0055 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-18-19
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6464 - tp: 69321.0000 - fp: 10679.0000 - tn: 309321.0000 - fn: 10679.0000 - accuracy: 0.9466 - precision: 0.8665 - recall: 0.8665 - auc: 0.9381 - val_loss: 1.5675 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 67882.0000 - val_fn: 12118.0000 - val_accuracy: 0.7576 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.8485
[INFO] saving weights to checkpoints/dnn-epoch-009-files-18-19
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7460 - tp: 44475.0000 - fp: 32837.0000 - tn: 287163.0000 - fn: 35525.0000 - accuracy: 0.8291 - precision: 0.5753 - recall: 0.5559 - auc: 0.8904 - val_loss: 0.9573 - val_tp: 0.0000e+00 - val_fp: 20000.0000 - val_tn: 60000.0000 - val_fn: 20000.0000 - val_accuracy: 0.6000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7500
[INFO] saving weights to checkpoints/dnn-epoch-009-files-18-19
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 20-20/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.1052 - tp: 78560.0000 - fp: 1152.0000 - tn: 318848.0000 - fn: 1440.0000 - accuracy: 0.9935 - precision: 0.9855 - recall: 0.9820 - auc: 0.9999 - val_loss: 0.1241 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 79491.0000 - val_fn: 509.0000 - val_accuracy: 0.9898 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9936
[INFO] saving weights to checkpoints/dnn-epoch-009-files-19-20
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5209 - tp: 65427.0000 - fp: 14573.0000 - tn: 305427.0000 - fn: 14573.0000 - accuracy: 0.9271 - precision: 0.8178 - recall: 0.8178 - auc: 0.9542 - val_loss: 0.4848 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 76357.0000 - val_fn: 3643.0000 - val_accuracy: 0.9271 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.9545
[INFO] saving weights to checkpoints/dnn-epoch-009-files-19-20
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4851 - tp: 65351.0000 - fp: 14649.0000 - tn: 305351.0000 - fn: 14649.0000 - accuracy: 0.9268 - precision: 0.8169 - recall: 0.8169 - auc: 0.9540 - val_loss: 0.4816 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 76371.0000 - val_fn: 3629.0000 - val_accuracy: 0.9274 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-009-files-19-20
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2112 - tp: 76024.0000 - fp: 3976.0000 - tn: 316024.0000 - fn: 3976.0000 - accuracy: 0.9801 - precision: 0.9503 - recall: 0.9503 - auc: 0.9877 - val_loss: 0.0573 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-19-20
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0286 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0163 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-19-20
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 21-21/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539688, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0123 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0096 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-20-21
[INFO] processing batch 100000-200000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0080 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-20-21
[INFO] processing batch 200000-300000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0060 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0053 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-20-21
[INFO] processing batch 300000-400000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0043 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-20-21
[INFO] processing batch 400000-500000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0040 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0037 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-20-21
[INFO] processing batch 500000-600000/539688
[33m[INFO] loading file 22-22/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.3340 - tp: 55006.0000 - fp: 24994.0000 - tn: 295006.0000 - fn: 24994.0000 - accuracy: 0.8750 - precision: 0.6876 - recall: 0.6876 - auc: 0.8472 - val_loss: 0.8179 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-009-files-21-22
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7323 - tp: 41829.0000 - fp: 37083.0000 - tn: 282917.0000 - fn: 38171.0000 - accuracy: 0.8119 - precision: 0.5301 - recall: 0.5229 - auc: 0.8826 - val_loss: 0.7173 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.8816
[INFO] saving weights to checkpoints/dnn-epoch-009-files-21-22
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7115 - tp: 42369.0000 - fp: 37631.0000 - tn: 282369.0000 - fn: 37631.0000 - accuracy: 0.8118 - precision: 0.5296 - recall: 0.5296 - auc: 0.8825 - val_loss: 0.7074 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 70623.0000 - val_fn: 9377.0000 - val_accuracy: 0.8125 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-009-files-21-22
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7051 - tp: 42452.0000 - fp: 37548.0000 - tn: 282452.0000 - fn: 37548.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5307 - auc: 0.8828 - val_loss: 0.7033 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 70601.0000 - val_fn: 9399.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-009-files-21-22
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7020 - tp: 42382.0000 - fp: 37618.0000 - tn: 282382.0000 - fn: 37618.0000 - accuracy: 0.8119 - precision: 0.5298 - recall: 0.5298 - auc: 0.8829 - val_loss: 0.7008 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-009-files-21-22
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 23-23/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6549 - tp: 52270.0000 - fp: 27730.0000 - tn: 292270.0000 - fn: 27730.0000 - accuracy: 0.8613 - precision: 0.6534 - recall: 0.6534 - auc: 0.9134 - val_loss: 0.4329 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-22-23
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0723 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0217 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-22-23
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0152 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0111 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-22-23
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0091 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0075 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-22-23
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0065 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0057 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-22-23
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 24-24/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0051 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0046 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-23-24
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0042 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0038 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-23-24
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0036 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0033 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-23-24
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-23-24
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2732 - tp: 75698.0000 - fp: 4302.0000 - tn: 315698.0000 - fn: 4302.0000 - accuracy: 0.9785 - precision: 0.9462 - recall: 0.9462 - auc: 0.9801 - val_loss: 1.3927 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 72912.0000 - val_fn: 7088.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-009-files-23-24
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 25-25/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7221 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6575 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-009-files-24-25
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6564 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9110 - val_loss: 0.6555 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-009-files-24-25
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6560 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6563 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-009-files-24-25
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6554 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6561 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-009-files-24-25
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6553 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6552 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-24-25
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 26-26/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6546 - tp: 51523.0000 - fp: 28477.0000 - tn: 291523.0000 - fn: 28477.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 1.6315 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.8310
[INFO] saving weights to checkpoints/dnn-epoch-009-files-25-26
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.2136 - tp: 51579.0000 - fp: 28421.0000 - tn: 291579.0000 - fn: 28421.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.8516 - val_loss: 0.7019 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-25-26
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6829 - tp: 51462.0000 - fp: 28538.0000 - tn: 291462.0000 - fn: 28538.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9106 - val_loss: 0.6713 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-009-files-25-26
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6679 - tp: 51506.0000 - fp: 28494.0000 - tn: 291506.0000 - fn: 28494.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9111 - val_loss: 0.6633 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 72936.0000 - val_fn: 7064.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-009-files-25-26
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6632 - tp: 51474.0000 - fp: 28526.0000 - tn: 291474.0000 - fn: 28526.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9106 - val_loss: 0.6593 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 72945.0000 - val_fn: 7055.0000 - val_accuracy: 0.8589 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.9118
[INFO] saving weights to checkpoints/dnn-epoch-009-files-25-26
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 27-27/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (479817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6609 - tp: 51419.0000 - fp: 28581.0000 - tn: 291419.0000 - fn: 28581.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9108 - val_loss: 0.6607 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-009-files-26-27
[INFO] processing batch 100000-200000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6588 - tp: 51485.0000 - fp: 28515.0000 - tn: 291485.0000 - fn: 28515.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6567 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 72918.0000 - val_fn: 7082.0000 - val_accuracy: 0.8584 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-009-files-26-27
[INFO] processing batch 200000-300000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6569 - tp: 51583.0000 - fp: 28417.0000 - tn: 291583.0000 - fn: 28417.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9112 - val_loss: 0.6574 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-26-27
[INFO] processing batch 300000-400000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6575 - tp: 51396.0000 - fp: 28604.0000 - tn: 291396.0000 - fn: 28604.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9106 - val_loss: 0.6571 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 72851.0000 - val_fn: 7149.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-009-files-26-27
[INFO] processing batch 400000-500000/479817
[33m[INFO] loading file 28-28/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6563 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6560 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-27-28
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6564 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9107 - val_loss: 0.6558 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-27-28
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6555 - tp: 51458.0000 - fp: 28542.0000 - tn: 291458.0000 - fn: 28542.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6553 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-27-28
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6552 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9109 - val_loss: 0.6540 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-009-files-27-28
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6544 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6552 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-27-28
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 29-29/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6547 - tp: 51460.0000 - fp: 28540.0000 - tn: 291460.0000 - fn: 28540.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6548 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-28-29
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6540 - tp: 51527.0000 - fp: 28473.0000 - tn: 291527.0000 - fn: 28473.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9106 - val_loss: 0.6548 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-009-files-28-29
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6541 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9104 - val_loss: 0.6522 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-009-files-28-29
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6534 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9108 - val_loss: 0.6543 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-28-29
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6536 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-28-29
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 30-30/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6534 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6540 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-29-30
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51450.0000 - fp: 28550.0000 - tn: 291450.0000 - fn: 28550.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9108 - val_loss: 0.6540 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-29-30
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6535 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6539 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-29-30
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6532 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-009-files-29-30
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9110 - val_loss: 0.6533 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 72870.0000 - val_fn: 7130.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-29-30
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 31-31/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6517 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 72921.0000 - val_fn: 7079.0000 - val_accuracy: 0.8584 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-009-files-30-31
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51524.0000 - fp: 28476.0000 - tn: 291524.0000 - fn: 28476.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6523 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 72902.0000 - val_fn: 7098.0000 - val_accuracy: 0.8580 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-009-files-30-31
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6535 - tp: 51428.0000 - fp: 28572.0000 - tn: 291428.0000 - fn: 28572.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9103 - val_loss: 0.6529 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-30-31
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6525 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-30-31
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.6523 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 72893.0000 - val_fn: 7107.0000 - val_accuracy: 0.8579 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-009-files-30-31
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 32-32/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6523 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-31-32
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51531.0000 - fp: 28469.0000 - tn: 291531.0000 - fn: 28469.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6527 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-31-32
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51576.0000 - fp: 28424.0000 - tn: 291576.0000 - fn: 28424.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9112 - val_loss: 0.6522 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-31-32
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51489.0000 - fp: 28511.0000 - tn: 291489.0000 - fn: 28511.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6529 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-31-32
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6530 - tp: 51449.0000 - fp: 28551.0000 - tn: 291449.0000 - fn: 28551.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9105 - val_loss: 0.6528 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-31-32
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 33-33/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.6526 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-32-33
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9113 - val_loss: 0.6529 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-32-33
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51404.0000 - fp: 28596.0000 - tn: 291404.0000 - fn: 28596.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9109 - val_loss: 0.6528 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-32-33
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51552.0000 - fp: 28448.0000 - tn: 291552.0000 - fn: 28448.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9110 - val_loss: 0.6521 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-32-33
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51594.0000 - fp: 28406.0000 - tn: 291594.0000 - fn: 28406.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9109 - val_loss: 0.6508 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-009-files-32-33
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 34-34/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6534 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-009-files-33-34
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9105 - val_loss: 0.6526 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-33-34
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51588.0000 - fp: 28412.0000 - tn: 291588.0000 - fn: 28412.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9115 - val_loss: 0.6523 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-009-files-33-34
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6530 - tp: 51408.0000 - fp: 28592.0000 - tn: 291408.0000 - fn: 28592.0000 - accuracy: 0.8570 - precision: 0.6426 - recall: 0.6426 - auc: 0.9106 - val_loss: 0.6535 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 72834.0000 - val_fn: 7166.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-009-files-33-34
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9108 - val_loss: 0.6522 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-009-files-33-34
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 35-35/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51520.0000 - fp: 28480.0000 - tn: 291520.0000 - fn: 28480.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9109 - val_loss: 0.6528 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-34-35
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6522 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-009-files-34-35
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6523 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6517 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-34-35
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51521.0000 - fp: 28479.0000 - tn: 291521.0000 - fn: 28479.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9111 - val_loss: 0.6529 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-34-35
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51570.0000 - fp: 28430.0000 - tn: 291570.0000 - fn: 28430.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9109 - val_loss: 0.6523 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-34-35
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 36-36/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9105 - val_loss: 0.6522 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-35-36
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51644.0000 - fp: 28356.0000 - tn: 291644.0000 - fn: 28356.0000 - accuracy: 0.8582 - precision: 0.6456 - recall: 0.6456 - auc: 0.9112 - val_loss: 0.6516 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 72895.0000 - val_fn: 7105.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-009-files-35-36
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9106 - val_loss: 0.6504 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 72933.0000 - val_fn: 7067.0000 - val_accuracy: 0.8587 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-009-files-35-36
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51415.0000 - fp: 28585.0000 - tn: 291415.0000 - fn: 28585.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9106 - val_loss: 0.6520 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 72878.0000 - val_fn: 7122.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-009-files-35-36
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9106 - val_loss: 0.6527 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-35-36
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 37-37/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51413.0000 - fp: 28587.0000 - tn: 291413.0000 - fn: 28587.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9104 - val_loss: 0.6527 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-36-37
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51456.0000 - fp: 28544.0000 - tn: 291456.0000 - fn: 28544.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9111 - val_loss: 0.6516 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-009-files-36-37
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51565.0000 - fp: 28435.0000 - tn: 291565.0000 - fn: 28435.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9111 - val_loss: 0.6522 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-36-37
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51512.0000 - fp: 28488.0000 - tn: 291512.0000 - fn: 28488.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6517 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 72888.0000 - val_fn: 7112.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-36-37
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51528.0000 - fp: 28472.0000 - tn: 291528.0000 - fn: 28472.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9105 - val_loss: 0.6513 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 72899.0000 - val_fn: 7101.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-009-files-36-37
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 38-38/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51513.0000 - fp: 28487.0000 - tn: 291513.0000 - fn: 28487.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.6503 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-009-files-37-38
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51589.0000 - fp: 28411.0000 - tn: 291589.0000 - fn: 28411.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9110 - val_loss: 0.6530 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-009-files-37-38
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51481.0000 - fp: 28519.0000 - tn: 291481.0000 - fn: 28519.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6525 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-37-38
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51549.0000 - fp: 28451.0000 - tn: 291549.0000 - fn: 28451.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9110 - val_loss: 0.6513 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 72898.0000 - val_fn: 7102.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-009-files-37-38
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9105 - val_loss: 0.6522 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 72866.0000 - val_fn: 7134.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-37-38
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 39-39/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6528 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 72847.0000 - val_fn: 7153.0000 - val_accuracy: 0.8569 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-009-files-38-39
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51597.0000 - fp: 28403.0000 - tn: 291597.0000 - fn: 28403.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9110 - val_loss: 0.6509 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 72910.0000 - val_fn: 7090.0000 - val_accuracy: 0.8582 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-009-files-38-39
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51631.0000 - fp: 28369.0000 - tn: 291631.0000 - fn: 28369.0000 - accuracy: 0.8582 - precision: 0.6454 - recall: 0.6454 - auc: 0.9112 - val_loss: 0.6514 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-009-files-38-39
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6521 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-38-39
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6519 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-38-39
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 40-40/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51418.0000 - fp: 28582.0000 - tn: 291418.0000 - fn: 28582.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9105 - val_loss: 0.6528 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-009-files-39-40
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51491.0000 - fp: 28509.0000 - tn: 291491.0000 - fn: 28509.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6523 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-39-40
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9110 - val_loss: 0.6507 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 72916.0000 - val_fn: 7084.0000 - val_accuracy: 0.8583 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-009-files-39-40
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9108 - val_loss: 0.6530 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 72838.0000 - val_fn: 7162.0000 - val_accuracy: 0.8568 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-009-files-39-40
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51432.0000 - fp: 28568.0000 - tn: 291432.0000 - fn: 28568.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9109 - val_loss: 0.6526 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-009-files-39-40
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 41-41/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6523 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-40-41
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51515.0000 - fp: 28485.0000 - tn: 291515.0000 - fn: 28485.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6521 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-40-41
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9103 - val_loss: 0.6519 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-009-files-40-41
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51587.0000 - fp: 28413.0000 - tn: 291587.0000 - fn: 28413.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9113 - val_loss: 0.6523 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-40-41
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9105 - val_loss: 0.6500 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 72937.0000 - val_fn: 7063.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-009-files-40-41
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 42-42/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9109 - val_loss: 0.6534 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 72826.0000 - val_fn: 7174.0000 - val_accuracy: 0.8565 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-009-files-41-42
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51511.0000 - fp: 28489.0000 - tn: 291511.0000 - fn: 28489.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6516 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 72882.0000 - val_fn: 7118.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-009-files-41-42
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51499.0000 - fp: 28501.0000 - tn: 291499.0000 - fn: 28501.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6525 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 72853.0000 - val_fn: 7147.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-41-42
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6506 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 72917.0000 - val_fn: 7083.0000 - val_accuracy: 0.8583 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-009-files-41-42
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51584.0000 - fp: 28416.0000 - tn: 291584.0000 - fn: 28416.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9106 - val_loss: 0.6518 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-41-42
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 43-43/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9108 - val_loss: 0.6519 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-42-43
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6533 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 72824.0000 - val_fn: 7176.0000 - val_accuracy: 0.8565 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-009-files-42-43
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51387.0000 - fp: 28613.0000 - tn: 291387.0000 - fn: 28613.0000 - accuracy: 0.8569 - precision: 0.6423 - recall: 0.6423 - auc: 0.9107 - val_loss: 0.6512 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-009-files-42-43
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6527 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-009-files-42-43
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9113 - val_loss: 0.6494 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 72952.0000 - val_fn: 7048.0000 - val_accuracy: 0.8590 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.9119
[INFO] saving weights to checkpoints/dnn-epoch-009-files-42-43
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 44-44/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9110 - val_loss: 0.6524 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-43-44
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6523 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-43-44
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51543.0000 - fp: 28457.0000 - tn: 291543.0000 - fn: 28457.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9109 - val_loss: 0.6523 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-43-44
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6523 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9109 - val_loss: 0.6516 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 72891.0000 - val_fn: 7109.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-43-44
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51537.0000 - fp: 28463.0000 - tn: 291537.0000 - fn: 28463.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6522 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-43-44
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 45-45/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51620.0000 - fp: 28380.0000 - tn: 291620.0000 - fn: 28380.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9111 - val_loss: 0.6519 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-44-45
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51538.0000 - fp: 28462.0000 - tn: 291538.0000 - fn: 28462.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9106 - val_loss: 0.6514 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-44-45
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51564.0000 - fp: 28436.0000 - tn: 291564.0000 - fn: 28436.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9108 - val_loss: 0.6509 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 72904.0000 - val_fn: 7096.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-009-files-44-45
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51590.0000 - fp: 28410.0000 - tn: 291590.0000 - fn: 28410.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9112 - val_loss: 0.6526 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-009-files-44-45
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51395.0000 - fp: 28605.0000 - tn: 291395.0000 - fn: 28605.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9108 - val_loss: 0.6511 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-009-files-44-45
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 46-46/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9107 - val_loss: 0.6506 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 72913.0000 - val_fn: 7087.0000 - val_accuracy: 0.8583 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-009-files-45-46
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51464.0000 - fp: 28536.0000 - tn: 291464.0000 - fn: 28536.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9110 - val_loss: 0.6515 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 72883.0000 - val_fn: 7117.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-009-files-45-46
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9108 - val_loss: 0.6514 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-45-46
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9111 - val_loss: 0.6501 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-009-files-45-46
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51569.0000 - fp: 28431.0000 - tn: 291569.0000 - fn: 28431.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9111 - val_loss: 0.6518 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-45-46
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 47-47/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51601.0000 - fp: 28399.0000 - tn: 291601.0000 - fn: 28399.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9112 - val_loss: 0.6512 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-46-47
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51559.0000 - fp: 28441.0000 - tn: 291559.0000 - fn: 28441.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9113 - val_loss: 0.6518 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-46-47
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6533 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 72822.0000 - val_fn: 7178.0000 - val_accuracy: 0.8564 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-009-files-46-47
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6515 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 72881.0000 - val_fn: 7119.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-009-files-46-47
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9105 - val_loss: 0.6506 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 72909.0000 - val_fn: 7091.0000 - val_accuracy: 0.8582 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-009-files-46-47
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 48-48/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6530 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 72830.0000 - val_fn: 7170.0000 - val_accuracy: 0.8566 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-009-files-47-48
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9105 - val_loss: 0.6515 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 72879.0000 - val_fn: 7121.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-009-files-47-48
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51547.0000 - fp: 28453.0000 - tn: 291547.0000 - fn: 28453.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9111 - val_loss: 0.6506 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-009-files-47-48
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9108 - val_loss: 0.6520 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-47-48
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51606.0000 - fp: 28394.0000 - tn: 291606.0000 - fn: 28394.0000 - accuracy: 0.8580 - precision: 0.6451 - recall: 0.6451 - auc: 0.9107 - val_loss: 0.6508 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 72905.0000 - val_fn: 7095.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-009-files-47-48
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 49-49/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6520 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-48-49
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51430.0000 - fp: 28570.0000 - tn: 291430.0000 - fn: 28570.0000 - accuracy: 0.8571 - precision: 0.6429 - recall: 0.6429 - auc: 0.9109 - val_loss: 0.6502 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 72924.0000 - val_fn: 7076.0000 - val_accuracy: 0.8585 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-009-files-48-49
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51469.0000 - fp: 28531.0000 - tn: 291469.0000 - fn: 28531.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6530 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-009-files-48-49
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6502 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 72922.0000 - val_fn: 7078.0000 - val_accuracy: 0.8584 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-009-files-48-49
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51495.0000 - fp: 28505.0000 - tn: 291495.0000 - fn: 28505.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9111 - val_loss: 0.6514 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-48-49
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 50-50/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6531 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 72823.0000 - val_fn: 7177.0000 - val_accuracy: 0.8565 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-009-files-49-50
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51482.0000 - fp: 28518.0000 - tn: 291482.0000 - fn: 28518.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9112 - val_loss: 0.6512 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-49-50
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51433.0000 - fp: 28567.0000 - tn: 291433.0000 - fn: 28567.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9106 - val_loss: 0.6524 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-009-files-49-50
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51461.0000 - fp: 28539.0000 - tn: 291461.0000 - fn: 28539.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6512 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-49-50
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51467.0000 - fp: 28533.0000 - tn: 291467.0000 - fn: 28533.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9106 - val_loss: 0.6521 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-49-50
[INFO] processing batch 500000-600000/519975
[33m[LOSS] 0.6521496291160583[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6521496291160583  <  0.001
[33m[INFO] epoch 10/10[0m
[33m[INFO] loading file 1-1/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0712 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-0-1
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-0-1
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0227 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9993 - val_loss: 2.2984 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.8826
[INFO] saving weights to checkpoints/dnn-epoch-010-files-0-1
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8384 - tp: 42447.0000 - fp: 37553.0000 - tn: 282447.0000 - fn: 37553.0000 - accuracy: 0.8122 - precision: 0.5306 - recall: 0.5306 - auc: 0.8825 - val_loss: 0.6916 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-010-files-0-1
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6917 - tp: 42438.0000 - fp: 37562.0000 - tn: 282438.0000 - fn: 37562.0000 - accuracy: 0.8122 - precision: 0.5305 - recall: 0.5305 - auc: 0.8823 - val_loss: 0.6917 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-010-files-0-1
[33m[INFO] loading file 2-2/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6917 - tp: 42435.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37565.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5304 - auc: 0.8825 - val_loss: 0.6918 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 70589.0000 - val_fn: 9411.0000 - val_accuracy: 0.8118 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-010-files-1-2
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4428 - tp: 67619.0000 - fp: 12381.0000 - tn: 307619.0000 - fn: 12381.0000 - accuracy: 0.9381 - precision: 0.8452 - recall: 0.8452 - auc: 0.9611 - val_loss: 0.1711 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-1-2
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3149 - tp: 72432.0000 - fp: 7568.0000 - tn: 312432.0000 - fn: 7568.0000 - accuracy: 0.9622 - precision: 0.9054 - recall: 0.9054 - auc: 0.9763 - val_loss: 1.1572 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 70593.0000 - val_fn: 9407.0000 - val_accuracy: 0.8119 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-010-files-1-2
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7168 - tp: 42321.0000 - fp: 37679.0000 - tn: 282321.0000 - fn: 37679.0000 - accuracy: 0.8116 - precision: 0.5290 - recall: 0.5290 - auc: 0.8823 - val_loss: 0.6917 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 70602.0000 - val_fn: 9398.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-010-files-1-2
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4475 - tp: 67360.0000 - fp: 12640.0000 - tn: 307360.0000 - fn: 12640.0000 - accuracy: 0.9368 - precision: 0.8420 - recall: 0.8420 - auc: 0.9606 - val_loss: 0.1697 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-1-2
[33m[INFO] loading file 3-3/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6959 - tp: 45236.0000 - fp: 34764.0000 - tn: 285236.0000 - fn: 34764.0000 - accuracy: 0.8262 - precision: 0.5655 - recall: 0.5655 - auc: 0.8912 - val_loss: 0.6943 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 70571.0000 - val_fn: 9429.0000 - val_accuracy: 0.8114 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.8821
[INFO] saving weights to checkpoints/dnn-epoch-010-files-2-3
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5939 - tp: 57751.0000 - fp: 22249.0000 - tn: 297751.0000 - fn: 22249.0000 - accuracy: 0.8888 - precision: 0.7219 - recall: 0.7219 - auc: 0.9303 - val_loss: 0.3300 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-2-3
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0629 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0200 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-2-3
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0140 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-2-3
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0082 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0067 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-2-3
[33m[INFO] loading file 4-4/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-3-4
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0046 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-3-4
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-3-4
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4225 - tp: 71528.0000 - fp: 8472.0000 - tn: 311528.0000 - fn: 8472.0000 - accuracy: 0.9576 - precision: 0.8941 - recall: 0.8941 - auc: 0.9702 - val_loss: 1.5162 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 67806.0000 - val_fn: 12194.0000 - val_accuracy: 0.7561 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.8476
[INFO] saving weights to checkpoints/dnn-epoch-010-files-3-4
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6130 - tp: 56887.0000 - fp: 23113.0000 - tn: 296887.0000 - fn: 23113.0000 - accuracy: 0.8844 - precision: 0.7111 - recall: 0.7111 - auc: 0.9272 - val_loss: 0.3371 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-3-4
[33m[INFO] loading file 5-5/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5271 - tp: 62445.0000 - fp: 17555.0000 - tn: 302445.0000 - fn: 17555.0000 - accuracy: 0.9122 - precision: 0.7806 - recall: 0.7806 - auc: 0.9450 - val_loss: 0.7001 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-010-files-4-5
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6555 - tp: 51316.0000 - fp: 28684.0000 - tn: 291316.0000 - fn: 28684.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9098 - val_loss: 0.5316 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 77052.0000 - val_fn: 2948.0000 - val_accuracy: 0.9410 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.9632
[INFO] saving weights to checkpoints/dnn-epoch-010-files-4-5
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0712 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-4-5
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-4-5
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0083 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-4-5
[33m[INFO] loading file 6-6/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0059 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-5-6
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-5-6
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-5-6
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2811 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 75632.0000 - val_fn: 4368.0000 - val_accuracy: 0.9126 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.8635
[INFO] saving weights to checkpoints/dnn-epoch-010-files-5-6
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8460 - tp: 51195.0000 - fp: 28805.0000 - tn: 291195.0000 - fn: 28805.0000 - accuracy: 0.8560 - precision: 0.6399 - recall: 0.6399 - auc: 0.9053 - val_loss: 0.6548 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 72768.0000 - val_fn: 7232.0000 - val_accuracy: 0.8554 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.9096
[INFO] saving weights to checkpoints/dnn-epoch-010-files-5-6
[33m[INFO] loading file 7-7/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6537 - tp: 51210.0000 - fp: 28790.0000 - tn: 291210.0000 - fn: 28790.0000 - accuracy: 0.8561 - precision: 0.6401 - recall: 0.6401 - auc: 0.9098 - val_loss: 0.6537 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 72803.0000 - val_fn: 7197.0000 - val_accuracy: 0.8561 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.9100
[INFO] saving weights to checkpoints/dnn-epoch-010-files-6-7
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51338.0000 - fp: 28662.0000 - tn: 291338.0000 - fn: 28662.0000 - accuracy: 0.8567 - precision: 0.6417 - recall: 0.6417 - auc: 0.9101 - val_loss: 0.6522 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-6-7
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4803 - tp: 65370.0000 - fp: 14630.0000 - tn: 305370.0000 - fn: 14630.0000 - accuracy: 0.9269 - precision: 0.8171 - recall: 0.8171 - auc: 0.9542 - val_loss: 0.1990 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-6-7
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0508 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0191 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-6-7
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0135 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0099 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-6-7
[33m[INFO] loading file 8-8/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0080 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0066 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-7-8
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0057 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-7-8
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0040 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-7-8
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3561 - tp: 73166.0000 - fp: 6834.0000 - tn: 313166.0000 - fn: 6834.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9768 - val_loss: 0.5520 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 76368.0000 - val_fn: 3632.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-010-files-7-8
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4809 - tp: 65505.0000 - fp: 14495.0000 - tn: 305505.0000 - fn: 14495.0000 - accuracy: 0.9275 - precision: 0.8188 - recall: 0.8188 - auc: 0.9548 - val_loss: 0.4729 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 76383.0000 - val_fn: 3617.0000 - val_accuracy: 0.9277 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.9548
[INFO] saving weights to checkpoints/dnn-epoch-010-files-7-8
[33m[INFO] loading file 9-9/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4773 - tp: 65300.0000 - fp: 14700.0000 - tn: 305300.0000 - fn: 14700.0000 - accuracy: 0.9265 - precision: 0.8163 - recall: 0.8163 - auc: 0.9540 - val_loss: 0.4805 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 76283.0000 - val_fn: 3717.0000 - val_accuracy: 0.9257 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.9535
[INFO] saving weights to checkpoints/dnn-epoch-010-files-8-9
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0973 - tp: 78936.0000 - fp: 1064.0000 - tn: 318936.0000 - fn: 1064.0000 - accuracy: 0.9947 - precision: 0.9867 - recall: 0.9867 - auc: 0.9967 - val_loss: 0.0268 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-8-9
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0171 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0116 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-8-9
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0092 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0074 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-8-9
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0063 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0054 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-8-9
[33m[INFO] loading file 10-10/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0043 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-9-10
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0084 - tp: 79936.0000 - fp: 64.0000 - tn: 319936.0000 - fn: 64.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 0.9995 - val_loss: 2.0145 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.7763
[INFO] saving weights to checkpoints/dnn-epoch-010-files-9-10
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7558 - tp: 56672.0000 - fp: 23328.0000 - tn: 296672.0000 - fn: 23328.0000 - accuracy: 0.8834 - precision: 0.7084 - recall: 0.7084 - auc: 0.9247 - val_loss: 0.3447 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-9-10
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0640 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0201 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-9-10
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0140 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-9-10
[33m[INFO] loading file 11-11/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0082 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-10-11
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-10-11
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-10-11
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-10-11
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-10-11
[33m[INFO] loading file 12-12/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0027 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0025 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-11-12
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0024 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0134 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 76689.0000 - val_fn: 3311.0000 - val_accuracy: 0.9338 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8965
[INFO] saving weights to checkpoints/dnn-epoch-010-files-11-12
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8656 - tp: 51328.0000 - fp: 28672.0000 - tn: 291328.0000 - fn: 28672.0000 - accuracy: 0.8566 - precision: 0.6416 - recall: 0.6416 - auc: 0.9038 - val_loss: 0.5659 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 75792.0000 - val_fn: 4208.0000 - val_accuracy: 0.9158 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.9474
[INFO] saving weights to checkpoints/dnn-epoch-010-files-11-12
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0709 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-11-12
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0142 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0102 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-11-12
[33m[INFO] loading file 13-13/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0083 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-12-13
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0059 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-12-13
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0045 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3615 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 75075.0000 - val_fn: 4925.0000 - val_accuracy: 0.9015 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.8461
[INFO] saving weights to checkpoints/dnn-epoch-010-files-12-13
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8176 - tp: 51313.0000 - fp: 28687.0000 - tn: 291313.0000 - fn: 28687.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9086 - val_loss: 0.6515 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-010-files-12-13
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51356.0000 - fp: 28644.0000 - tn: 291356.0000 - fn: 28644.0000 - accuracy: 0.8568 - precision: 0.6420 - recall: 0.6420 - auc: 0.9105 - val_loss: 0.6518 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-12-13
[33m[INFO] loading file 14-14/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5273 - tp: 62543.0000 - fp: 17457.0000 - tn: 302543.0000 - fn: 17457.0000 - accuracy: 0.9127 - precision: 0.7818 - recall: 0.7818 - auc: 0.9455 - val_loss: 0.2453 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-13-14
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0556 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0195 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-13-14
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0137 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0100 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-13-14
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0081 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0067 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-13-14
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0058 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-13-14
[33m[INFO] loading file 15-15/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0046 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0040 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-14-15
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0038 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-14-15
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-14-15
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0027 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.8648 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 71586.0000 - val_fn: 8414.0000 - val_accuracy: 0.8317 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.7371
[INFO] saving weights to checkpoints/dnn-epoch-010-files-14-15
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.8324 - tp: 42561.0000 - fp: 37439.0000 - tn: 282561.0000 - fn: 37439.0000 - accuracy: 0.8128 - precision: 0.5320 - recall: 0.5320 - auc: 0.8062 - val_loss: 0.7342 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 70627.0000 - val_fn: 9373.0000 - val_accuracy: 0.8125 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-010-files-14-15
[33m[INFO] loading file 16-16/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7177 - tp: 42492.0000 - fp: 37508.0000 - tn: 282492.0000 - fn: 37508.0000 - accuracy: 0.8125 - precision: 0.5311 - recall: 0.5311 - auc: 0.8827 - val_loss: 0.7087 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 70618.0000 - val_fn: 9382.0000 - val_accuracy: 0.8124 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-010-files-15-16
[INFO] processing batch 100000-200000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5999 - tp: 58381.0000 - fp: 21619.0000 - tn: 298381.0000 - fn: 21619.0000 - accuracy: 0.8919 - precision: 0.7298 - recall: 0.7298 - auc: 0.9322 - val_loss: 0.3231 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-15-16
[INFO] processing batch 200000-300000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0649 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0217 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-15-16
[INFO] processing batch 300000-400000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0153 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0112 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-15-16
[INFO] processing batch 400000-500000/439690
[33m[INFO] loading file 17-17/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0092 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0076 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-16-17
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0066 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0058 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-16-17
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0052 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0047 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-16-17
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9903 - tp: 68607.0000 - fp: 11393.0000 - tn: 308607.0000 - fn: 11393.0000 - accuracy: 0.9430 - precision: 0.8576 - recall: 0.8576 - auc: 0.9006 - val_loss: 0.7583 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 76369.0000 - val_fn: 3631.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9092
[INFO] saving weights to checkpoints/dnn-epoch-010-files-16-17
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5644 - tp: 65526.0000 - fp: 14474.0000 - tn: 305526.0000 - fn: 14474.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.9510 - val_loss: 0.3234 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 78648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9730 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9831
[INFO] saving weights to checkpoints/dnn-epoch-010-files-16-17
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 18-18/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3444 - tp: 72130.0000 - fp: 7870.0000 - tn: 312130.0000 - fn: 7870.0000 - accuracy: 0.9607 - precision: 0.9016 - recall: 0.9016 - auc: 0.9754 - val_loss: 0.9867 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 72369.0000 - val_fn: 7631.0000 - val_accuracy: 0.8474 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.9046
[INFO] saving weights to checkpoints/dnn-epoch-010-files-17-18
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7015 - tp: 49699.0000 - fp: 30301.0000 - tn: 289699.0000 - fn: 30301.0000 - accuracy: 0.8485 - precision: 0.6212 - recall: 0.6212 - auc: 0.9055 - val_loss: 0.6818 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 72357.0000 - val_fn: 7643.0000 - val_accuracy: 0.8471 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.9045
[INFO] saving weights to checkpoints/dnn-epoch-010-files-17-18
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6785 - tp: 49541.0000 - fp: 30459.0000 - tn: 289541.0000 - fn: 30459.0000 - accuracy: 0.8477 - precision: 0.6193 - recall: 0.6193 - auc: 0.9047 - val_loss: 0.6761 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 72397.0000 - val_fn: 7603.0000 - val_accuracy: 0.8479 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.9050
[INFO] saving weights to checkpoints/dnn-epoch-010-files-17-18
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2760 - tp: 74509.0000 - fp: 5491.0000 - tn: 314509.0000 - fn: 5491.0000 - accuracy: 0.9725 - precision: 0.9314 - recall: 0.9314 - auc: 0.9825 - val_loss: 0.0789 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-17-18
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0342 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0178 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-17-18
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 19-19/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0132 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0101 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-18-19
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0084 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0071 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-18-19
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0062 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0055 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-18-19
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6464 - tp: 69321.0000 - fp: 10679.0000 - tn: 309321.0000 - fn: 10679.0000 - accuracy: 0.9466 - precision: 0.8665 - recall: 0.8665 - auc: 0.9381 - val_loss: 1.5700 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 67882.0000 - val_fn: 12118.0000 - val_accuracy: 0.7576 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.8485
[INFO] saving weights to checkpoints/dnn-epoch-010-files-18-19
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7452 - tp: 44817.0000 - fp: 32879.0000 - tn: 287121.0000 - fn: 35183.0000 - accuracy: 0.8298 - precision: 0.5768 - recall: 0.5602 - auc: 0.8910 - val_loss: 0.9541 - val_tp: 0.0000e+00 - val_fp: 20000.0000 - val_tn: 60000.0000 - val_fn: 20000.0000 - val_accuracy: 0.6000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7500
[INFO] saving weights to checkpoints/dnn-epoch-010-files-18-19
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 20-20/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.1051 - tp: 78592.0000 - fp: 1120.0000 - tn: 318880.0000 - fn: 1408.0000 - accuracy: 0.9937 - precision: 0.9859 - recall: 0.9824 - auc: 0.9999 - val_loss: 0.1241 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 79491.0000 - val_fn: 509.0000 - val_accuracy: 0.9898 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9936
[INFO] saving weights to checkpoints/dnn-epoch-010-files-19-20
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5204 - tp: 65427.0000 - fp: 14573.0000 - tn: 305427.0000 - fn: 14573.0000 - accuracy: 0.9271 - precision: 0.8178 - recall: 0.8178 - auc: 0.9546 - val_loss: 0.4848 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 76357.0000 - val_fn: 3643.0000 - val_accuracy: 0.9271 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.9545
[INFO] saving weights to checkpoints/dnn-epoch-010-files-19-20
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4851 - tp: 65351.0000 - fp: 14649.0000 - tn: 305351.0000 - fn: 14649.0000 - accuracy: 0.9268 - precision: 0.8169 - recall: 0.8169 - auc: 0.9540 - val_loss: 0.4816 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 76371.0000 - val_fn: 3629.0000 - val_accuracy: 0.9274 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-010-files-19-20
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2112 - tp: 76024.0000 - fp: 3976.0000 - tn: 316024.0000 - fn: 3976.0000 - accuracy: 0.9801 - precision: 0.9503 - recall: 0.9503 - auc: 0.9877 - val_loss: 0.0569 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-19-20
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0285 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0162 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-19-20
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 21-21/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539688, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0123 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0095 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-20-21
[INFO] processing batch 100000-200000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0080 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0068 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-20-21
[INFO] processing batch 200000-300000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0060 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0053 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-20-21
[INFO] processing batch 300000-400000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0048 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0043 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-20-21
[INFO] processing batch 400000-500000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0040 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0037 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-20-21
[INFO] processing batch 500000-600000/539688
[33m[INFO] loading file 22-22/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.3346 - tp: 55006.0000 - fp: 24994.0000 - tn: 295006.0000 - fn: 24994.0000 - accuracy: 0.8750 - precision: 0.6876 - recall: 0.6876 - auc: 0.8472 - val_loss: 0.8131 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-010-files-21-22
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7323 - tp: 42398.0000 - fp: 37602.0000 - tn: 282398.0000 - fn: 37602.0000 - accuracy: 0.8120 - precision: 0.5300 - recall: 0.5300 - auc: 0.8820 - val_loss: 0.7172 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.8816
[INFO] saving weights to checkpoints/dnn-epoch-010-files-21-22
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7115 - tp: 42369.0000 - fp: 37631.0000 - tn: 282369.0000 - fn: 37631.0000 - accuracy: 0.8118 - precision: 0.5296 - recall: 0.5296 - auc: 0.8823 - val_loss: 0.7074 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 70623.0000 - val_fn: 9377.0000 - val_accuracy: 0.8125 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-010-files-21-22
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7052 - tp: 42452.0000 - fp: 37548.0000 - tn: 282452.0000 - fn: 37548.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5307 - auc: 0.8825 - val_loss: 0.7033 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 70601.0000 - val_fn: 9399.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-010-files-21-22
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7020 - tp: 42382.0000 - fp: 37618.0000 - tn: 282382.0000 - fn: 37618.0000 - accuracy: 0.8119 - precision: 0.5298 - recall: 0.5298 - auc: 0.8822 - val_loss: 0.7007 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-010-files-21-22
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 23-23/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6549 - tp: 52270.0000 - fp: 27730.0000 - tn: 292270.0000 - fn: 27730.0000 - accuracy: 0.8613 - precision: 0.6534 - recall: 0.6534 - auc: 0.9135 - val_loss: 0.4304 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-22-23
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0721 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0217 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-22-23
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0152 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0111 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-22-23
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0090 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0075 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-22-23
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0065 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0057 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-22-23
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 24-24/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0051 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0046 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-23-24
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0042 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0038 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-23-24
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0036 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0033 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-23-24
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0031 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0029 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-23-24
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2732 - tp: 75698.0000 - fp: 4302.0000 - tn: 315698.0000 - fn: 4302.0000 - accuracy: 0.9785 - precision: 0.9462 - recall: 0.9462 - auc: 0.9802 - val_loss: 1.3917 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 72912.0000 - val_fn: 7088.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-010-files-23-24
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 25-25/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7225 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6576 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-010-files-24-25
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6565 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6555 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-010-files-24-25
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6560 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6563 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-010-files-24-25
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6554 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9107 - val_loss: 0.6561 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-010-files-24-25
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6553 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.6551 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-24-25
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 26-26/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6546 - tp: 51523.0000 - fp: 28477.0000 - tn: 291523.0000 - fn: 28477.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9108 - val_loss: 1.6326 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.8310
[INFO] saving weights to checkpoints/dnn-epoch-010-files-25-26
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.2132 - tp: 51579.0000 - fp: 28421.0000 - tn: 291579.0000 - fn: 28421.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.8518 - val_loss: 0.7020 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-25-26
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6830 - tp: 51462.0000 - fp: 28538.0000 - tn: 291462.0000 - fn: 28538.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9107 - val_loss: 0.6712 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-010-files-25-26
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6680 - tp: 51506.0000 - fp: 28494.0000 - tn: 291506.0000 - fn: 28494.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6630 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 72936.0000 - val_fn: 7064.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-010-files-25-26
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6631 - tp: 51474.0000 - fp: 28526.0000 - tn: 291474.0000 - fn: 28526.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9112 - val_loss: 0.6593 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 72945.0000 - val_fn: 7055.0000 - val_accuracy: 0.8589 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.9118
[INFO] saving weights to checkpoints/dnn-epoch-010-files-25-26
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 27-27/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (479817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6609 - tp: 51419.0000 - fp: 28581.0000 - tn: 291419.0000 - fn: 28581.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9104 - val_loss: 0.6607 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-010-files-26-27
[INFO] processing batch 100000-200000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6588 - tp: 51485.0000 - fp: 28515.0000 - tn: 291485.0000 - fn: 28515.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9105 - val_loss: 0.6568 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 72918.0000 - val_fn: 7082.0000 - val_accuracy: 0.8584 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-010-files-26-27
[INFO] processing batch 200000-300000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6569 - tp: 51583.0000 - fp: 28417.0000 - tn: 291583.0000 - fn: 28417.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9112 - val_loss: 0.6575 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-26-27
[INFO] processing batch 300000-400000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6575 - tp: 51396.0000 - fp: 28604.0000 - tn: 291396.0000 - fn: 28604.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9108 - val_loss: 0.6571 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 72851.0000 - val_fn: 7149.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-010-files-26-27
[INFO] processing batch 400000-500000/479817
[33m[INFO] loading file 28-28/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6563 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6560 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-27-28
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6564 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9105 - val_loss: 0.6558 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-27-28
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6555 - tp: 51458.0000 - fp: 28542.0000 - tn: 291458.0000 - fn: 28542.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9109 - val_loss: 0.6552 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-27-28
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6552 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9105 - val_loss: 0.6539 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-010-files-27-28
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6545 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6551 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-27-28
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 29-29/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6547 - tp: 51460.0000 - fp: 28540.0000 - tn: 291460.0000 - fn: 28540.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9110 - val_loss: 0.6548 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-28-29
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6540 - tp: 51527.0000 - fp: 28473.0000 - tn: 291527.0000 - fn: 28473.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6549 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-010-files-28-29
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6541 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6522 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-010-files-28-29
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6534 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9112 - val_loss: 0.6543 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-28-29
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6537 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-28-29
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 30-30/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6534 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6540 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-29-30
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6539 - tp: 51450.0000 - fp: 28550.0000 - tn: 291450.0000 - fn: 28550.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9105 - val_loss: 0.6540 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-29-30
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6535 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6538 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-29-30
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6532 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-010-files-29-30
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9109 - val_loss: 0.6533 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 72870.0000 - val_fn: 7130.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-29-30
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 31-31/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9111 - val_loss: 0.6517 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 72921.0000 - val_fn: 7079.0000 - val_accuracy: 0.8584 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-010-files-30-31
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51524.0000 - fp: 28476.0000 - tn: 291524.0000 - fn: 28476.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6522 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 72902.0000 - val_fn: 7098.0000 - val_accuracy: 0.8580 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-010-files-30-31
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6535 - tp: 51428.0000 - fp: 28572.0000 - tn: 291428.0000 - fn: 28572.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9103 - val_loss: 0.6530 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-30-31
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6527 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-30-31
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6523 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 72893.0000 - val_fn: 7107.0000 - val_accuracy: 0.8579 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-010-files-30-31
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 32-32/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6523 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-31-32
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51531.0000 - fp: 28469.0000 - tn: 291531.0000 - fn: 28469.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6527 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-31-32
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51576.0000 - fp: 28424.0000 - tn: 291576.0000 - fn: 28424.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9110 - val_loss: 0.6523 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-31-32
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6527 - tp: 51489.0000 - fp: 28511.0000 - tn: 291489.0000 - fn: 28511.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6529 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-31-32
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6530 - tp: 51449.0000 - fp: 28551.0000 - tn: 291449.0000 - fn: 28551.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9105 - val_loss: 0.6528 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-31-32
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 33-33/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9106 - val_loss: 0.6526 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-32-33
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9106 - val_loss: 0.6528 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-32-33
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51404.0000 - fp: 28596.0000 - tn: 291404.0000 - fn: 28596.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9106 - val_loss: 0.6529 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-32-33
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51552.0000 - fp: 28448.0000 - tn: 291552.0000 - fn: 28448.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9109 - val_loss: 0.6522 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-32-33
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51594.0000 - fp: 28406.0000 - tn: 291594.0000 - fn: 28406.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9112 - val_loss: 0.6508 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-010-files-32-33
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 34-34/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9113 - val_loss: 0.6533 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-010-files-33-34
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.6527 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-33-34
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51588.0000 - fp: 28412.0000 - tn: 291588.0000 - fn: 28412.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9114 - val_loss: 0.6523 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-010-files-33-34
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6530 - tp: 51408.0000 - fp: 28592.0000 - tn: 291408.0000 - fn: 28592.0000 - accuracy: 0.8570 - precision: 0.6426 - recall: 0.6426 - auc: 0.9107 - val_loss: 0.6536 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 72834.0000 - val_fn: 7166.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-010-files-33-34
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9107 - val_loss: 0.6522 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-010-files-33-34
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 35-35/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51520.0000 - fp: 28480.0000 - tn: 291520.0000 - fn: 28480.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6528 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-34-35
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6522 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-010-files-34-35
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6523 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6517 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-34-35
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51521.0000 - fp: 28479.0000 - tn: 291521.0000 - fn: 28479.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9114 - val_loss: 0.6528 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-34-35
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51570.0000 - fp: 28430.0000 - tn: 291570.0000 - fn: 28430.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6524 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-34-35
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 36-36/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9111 - val_loss: 0.6522 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-35-36
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51644.0000 - fp: 28356.0000 - tn: 291644.0000 - fn: 28356.0000 - accuracy: 0.8582 - precision: 0.6456 - recall: 0.6456 - auc: 0.9112 - val_loss: 0.6516 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 72895.0000 - val_fn: 7105.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-010-files-35-36
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6529 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9103 - val_loss: 0.6504 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 72933.0000 - val_fn: 7067.0000 - val_accuracy: 0.8587 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-010-files-35-36
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51415.0000 - fp: 28585.0000 - tn: 291415.0000 - fn: 28585.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9104 - val_loss: 0.6520 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 72878.0000 - val_fn: 7122.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-010-files-35-36
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6527 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-35-36
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 37-37/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6527 - tp: 51413.0000 - fp: 28587.0000 - tn: 291413.0000 - fn: 28587.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9108 - val_loss: 0.6527 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-36-37
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51456.0000 - fp: 28544.0000 - tn: 291456.0000 - fn: 28544.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9109 - val_loss: 0.6512 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-010-files-36-37
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51565.0000 - fp: 28435.0000 - tn: 291565.0000 - fn: 28435.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9108 - val_loss: 0.6522 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-36-37
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51512.0000 - fp: 28488.0000 - tn: 291512.0000 - fn: 28488.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9107 - val_loss: 0.6516 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 72888.0000 - val_fn: 7112.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-36-37
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51528.0000 - fp: 28472.0000 - tn: 291528.0000 - fn: 28472.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6514 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 72899.0000 - val_fn: 7101.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-010-files-36-37
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 38-38/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51513.0000 - fp: 28487.0000 - tn: 291513.0000 - fn: 28487.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9107 - val_loss: 0.6503 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-010-files-37-38
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51589.0000 - fp: 28411.0000 - tn: 291589.0000 - fn: 28411.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9115 - val_loss: 0.6530 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-010-files-37-38
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51481.0000 - fp: 28519.0000 - tn: 291481.0000 - fn: 28519.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9105 - val_loss: 0.6526 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-37-38
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51549.0000 - fp: 28451.0000 - tn: 291549.0000 - fn: 28451.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9105 - val_loss: 0.6513 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 72898.0000 - val_fn: 7102.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-010-files-37-38
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9108 - val_loss: 0.6522 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 72866.0000 - val_fn: 7134.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-37-38
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 39-39/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6528 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 72847.0000 - val_fn: 7153.0000 - val_accuracy: 0.8569 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-010-files-38-39
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51597.0000 - fp: 28403.0000 - tn: 291597.0000 - fn: 28403.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9111 - val_loss: 0.6509 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 72910.0000 - val_fn: 7090.0000 - val_accuracy: 0.8582 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-010-files-38-39
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51631.0000 - fp: 28369.0000 - tn: 291631.0000 - fn: 28369.0000 - accuracy: 0.8582 - precision: 0.6454 - recall: 0.6454 - auc: 0.9111 - val_loss: 0.6514 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-010-files-38-39
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9105 - val_loss: 0.6521 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-38-39
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9112 - val_loss: 0.6519 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-38-39
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 40-40/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6526 - tp: 51418.0000 - fp: 28582.0000 - tn: 291418.0000 - fn: 28582.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9105 - val_loss: 0.6528 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-010-files-39-40
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51491.0000 - fp: 28509.0000 - tn: 291491.0000 - fn: 28509.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6523 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-39-40
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9109 - val_loss: 0.6506 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 72916.0000 - val_fn: 7084.0000 - val_accuracy: 0.8583 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-010-files-39-40
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9108 - val_loss: 0.6530 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 72838.0000 - val_fn: 7162.0000 - val_accuracy: 0.8568 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-010-files-39-40
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51432.0000 - fp: 28568.0000 - tn: 291432.0000 - fn: 28568.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9106 - val_loss: 0.6526 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-010-files-39-40
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 41-41/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9107 - val_loss: 0.6523 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-40-41
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51515.0000 - fp: 28485.0000 - tn: 291515.0000 - fn: 28485.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6520 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-40-41
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9106 - val_loss: 0.6519 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-010-files-40-41
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51587.0000 - fp: 28413.0000 - tn: 291587.0000 - fn: 28413.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9113 - val_loss: 0.6523 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-40-41
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9108 - val_loss: 0.6500 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 72937.0000 - val_fn: 7063.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-010-files-40-41
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 42-42/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9102 - val_loss: 0.6533 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 72826.0000 - val_fn: 7174.0000 - val_accuracy: 0.8565 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-010-files-41-42
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51511.0000 - fp: 28489.0000 - tn: 291511.0000 - fn: 28489.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6516 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 72882.0000 - val_fn: 7118.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-010-files-41-42
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51499.0000 - fp: 28501.0000 - tn: 291499.0000 - fn: 28501.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9106 - val_loss: 0.6525 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 72853.0000 - val_fn: 7147.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-41-42
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6505 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 72917.0000 - val_fn: 7083.0000 - val_accuracy: 0.8583 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-010-files-41-42
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51584.0000 - fp: 28416.0000 - tn: 291584.0000 - fn: 28416.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9110 - val_loss: 0.6518 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-41-42
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 43-43/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9112 - val_loss: 0.6518 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-42-43
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6533 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 72824.0000 - val_fn: 7176.0000 - val_accuracy: 0.8565 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-010-files-42-43
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6527 - tp: 51387.0000 - fp: 28613.0000 - tn: 291387.0000 - fn: 28613.0000 - accuracy: 0.8569 - precision: 0.6423 - recall: 0.6423 - auc: 0.9102 - val_loss: 0.6511 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-010-files-42-43
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9109 - val_loss: 0.6527 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-010-files-42-43
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9111 - val_loss: 0.6496 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 72952.0000 - val_fn: 7048.0000 - val_accuracy: 0.8590 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.9119
[INFO] saving weights to checkpoints/dnn-epoch-010-files-42-43
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 44-44/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9106 - val_loss: 0.6524 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-43-44
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9113 - val_loss: 0.6523 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-43-44
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51543.0000 - fp: 28457.0000 - tn: 291543.0000 - fn: 28457.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9108 - val_loss: 0.6523 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-43-44
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6523 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9107 - val_loss: 0.6513 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 72891.0000 - val_fn: 7109.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-43-44
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51537.0000 - fp: 28463.0000 - tn: 291537.0000 - fn: 28463.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6521 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-43-44
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 45-45/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51620.0000 - fp: 28380.0000 - tn: 291620.0000 - fn: 28380.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9111 - val_loss: 0.6519 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-44-45
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51538.0000 - fp: 28462.0000 - tn: 291538.0000 - fn: 28462.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9107 - val_loss: 0.6515 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-44-45
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51564.0000 - fp: 28436.0000 - tn: 291564.0000 - fn: 28436.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.6509 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 72904.0000 - val_fn: 7096.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-010-files-44-45
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51590.0000 - fp: 28410.0000 - tn: 291590.0000 - fn: 28410.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9118 - val_loss: 0.6528 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-010-files-44-45
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51395.0000 - fp: 28605.0000 - tn: 291395.0000 - fn: 28605.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9106 - val_loss: 0.6511 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-010-files-44-45
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 46-46/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9107 - val_loss: 0.6506 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 72913.0000 - val_fn: 7087.0000 - val_accuracy: 0.8583 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-010-files-45-46
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51464.0000 - fp: 28536.0000 - tn: 291464.0000 - fn: 28536.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6515 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 72883.0000 - val_fn: 7117.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-010-files-45-46
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9112 - val_loss: 0.6515 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-45-46
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9107 - val_loss: 0.6501 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-010-files-45-46
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51569.0000 - fp: 28431.0000 - tn: 291569.0000 - fn: 28431.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6517 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-45-46
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 47-47/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51601.0000 - fp: 28399.0000 - tn: 291601.0000 - fn: 28399.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9113 - val_loss: 0.6512 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-46-47
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51559.0000 - fp: 28441.0000 - tn: 291559.0000 - fn: 28441.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9107 - val_loss: 0.6518 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-46-47
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9107 - val_loss: 0.6533 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 72822.0000 - val_fn: 7178.0000 - val_accuracy: 0.8564 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-010-files-46-47
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6516 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 72881.0000 - val_fn: 7119.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-010-files-46-47
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6506 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 72909.0000 - val_fn: 7091.0000 - val_accuracy: 0.8582 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-010-files-46-47
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 48-48/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6530 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 72830.0000 - val_fn: 7170.0000 - val_accuracy: 0.8566 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-010-files-47-48
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9106 - val_loss: 0.6515 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 72879.0000 - val_fn: 7121.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-010-files-47-48
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51547.0000 - fp: 28453.0000 - tn: 291547.0000 - fn: 28453.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9112 - val_loss: 0.6506 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-010-files-47-48
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9108 - val_loss: 0.6520 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-47-48
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51606.0000 - fp: 28394.0000 - tn: 291606.0000 - fn: 28394.0000 - accuracy: 0.8580 - precision: 0.6451 - recall: 0.6451 - auc: 0.9117 - val_loss: 0.6508 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 72905.0000 - val_fn: 7095.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-010-files-47-48
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 49-49/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9113 - val_loss: 0.6519 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-48-49
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51430.0000 - fp: 28570.0000 - tn: 291430.0000 - fn: 28570.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9108 - val_loss: 0.6502 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 72924.0000 - val_fn: 7076.0000 - val_accuracy: 0.8585 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-010-files-48-49
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51469.0000 - fp: 28531.0000 - tn: 291469.0000 - fn: 28531.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.6530 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-010-files-48-49
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6502 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 72922.0000 - val_fn: 7078.0000 - val_accuracy: 0.8584 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-010-files-48-49
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51495.0000 - fp: 28505.0000 - tn: 291495.0000 - fn: 28505.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9111 - val_loss: 0.6512 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-48-49
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 50-50/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6531 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 72823.0000 - val_fn: 7177.0000 - val_accuracy: 0.8565 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-010-files-49-50
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51482.0000 - fp: 28518.0000 - tn: 291482.0000 - fn: 28518.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9110 - val_loss: 0.6511 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-49-50
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51433.0000 - fp: 28567.0000 - tn: 291433.0000 - fn: 28567.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9112 - val_loss: 0.6524 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-010-files-49-50
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51461.0000 - fp: 28539.0000 - tn: 291461.0000 - fn: 28539.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6512 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-49-50
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51467.0000 - fp: 28533.0000 - tn: 291467.0000 - fn: 28533.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9109 - val_loss: 0.6522 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
train.py:186: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version
of pandas will change to not sort by default.

To accept the future behavior, pass 'sort=False'.

To retain the current behavior and silence the warning, pass 'sort=True'.

  df = pd.concat(df_from_each_file, ignore_index=True)
[INFO] saving weights to checkpoints/dnn-epoch-010-files-49-50
[INFO] processing batch 500000-600000/519975
[33m[LOSS] 0.6521750632286072[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6521750632286072  <  0.001
--- 7189.337334156036 seconds ---
2020-02-06 22:35:12.242539: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-02-06 22:35:12.242583: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-02-06 22:35:12.242594: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-02-06 22:35:12.730698: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-02-06 22:35:12.730718: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-02-06 22:35:12.730732: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (brussels): /proc/driver/nvidia/version does not exist
2020-02-06 22:35:12.730838: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-06 22:35:12.753846: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3312000000 Hz
2020-02-06 22:35:12.754038: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4615d10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-06 22:35:12.754066: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow backend.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
=============================
        SCORING v0.4
=============================
Date: 2020-02-06 22:35:12.727612
[33m[INFO] using Sequential Dense layers[0m
[INFO] adding core layer 0
[INFO] created DNN
loading weights: checkpoints/*
loading file checkpoints/dnn-epoch-010-files-9-10
[33m[INFO] model summary:[0m
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 2)                 32        
_________________________________________________________________
dropout_1 (Dropout)          (None, 2)                 0         
_________________________________________________________________
dense_2 (Dense)              (None, 4)                 12        
_________________________________________________________________
dropout_2 (Dropout)          (None, 4)                 0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 10        
_________________________________________________________________
dropout_3 (Dropout)          (None, 2)                 0         
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 3         
_________________________________________________________________
dropout_4 (Dropout)          (None, 1)                 0         
_________________________________________________________________
dense_5 (Dense)              (None, 5)                 10        
=================================================================
Total params: 67
Trainable params: 67
Non-trainable params: 0
_________________________________________________________________
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2015-12-31_130240_112.log.part10_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9992%,0.0:0.0008%]
[INFO] ** type:[1.0:99.9984%,0.5:0.0014%,0.0:0.0002%]
[INFO] ** i/f_name:[0.0:99.9984%,0.5:0.0016%]
[INFO] ** i/f_dir:[0.0:99.9986%,1.0:0.0014%]
[INFO] ** src:[0.0666666667:38.114%,0.9333333333:26.0964%,0.6666666667:18.2424%,0.3333333333:17.543%,0.1333333333:0.0016%,0.0:0.0012%,0.2:0.001%,0.5333333333:0.0004%]
[INFO] ** dst:[0.1764705882:43.3686%,0.9411764706:20.8412%,0.8823529412000001:18.2422%,0.5294117647:17.5434%,0.2941176471:0.0016%,0.0:0.0014%,0.3529411765:0.0006%,0.5882352941:0.0004%,0.4705882353:0.0002%,0.23529411760000002:0.0002%,0.058823529400000005:0.0002%]
[INFO] ** proto:[0.5:99.997%,0.0:0.0016%,1.0:0.0014%]
[INFO] ** appi_name:[0.0:99.9962%,0.0384615385:0.0016%,0.9230769231:0.0004%,0.0769230769:0.0004%,0.3846153846:0.0002%,0.34615384619999995:0.0002%,0.4230769231:0.0002%,0.6153846154:0.0002%,0.3076923077:0.0002%,0.9615384615000001:0.0002%,0.5769230769:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.114%,0.0:26.0964%,0.9333333333:18.2424%,0.4:17.543%,0.5333333333:0.0016%,0.1333333333:0.0012%,0.0666666667:0.001%,0.6:0.0004%]
[INFO] ** modbus_function_code:[0.9743589744:99.9962%,0.0:0.0036%,1.0:0.0002%]
[INFO] ** modbus_function_description:[0.2:49.9988%,0.0:49.9974%,0.4:0.0036%,0.6:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:26.0954%,0.6:20.841%,0.8:18.242%,0.0:17.5424%,0.4:17.2726%,0.2:0.0066%]
[INFO] ** service:[0.7025755984000001:99.997%,0.0:0.0016%,0.0021633145999999997:0.0004%,0.08391465880000001:0.0004%,0.0297847659:0.0002%,0.08394601119999999:0.0002%,0.0021476384:0.0002%]
[INFO] ** s_port:[0.834280824:26.0956%,0.8139250565:20.8412%,0.8029830673999999:18.242%,0.8149336757:17.5424%,0.8137722355:17.2728%,0.0:0.0016%,0.7081881533:0.0008%,0.814841983:0.0006%,0.8059172320999999:0.0004%,0.8343113882:0.0004%,0.0021089309:0.0004%,0.0818051226:0.0004%,0.8030441959000001:0.0002%,0.8344030809:0.0002%,0.8345253376999999:0.0002%,0.0290360046:0.0002%,0.0020936488:0.0002%,0.8030136315999999:0.0002%,0.7806864723:0.0002%]
[INFO] ** classification:[normal:79.7796%,Single Stage Single Point:20.2204%]
[INFO] columns with count within 2-10 {'orig': 2, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'src': 8, 'proto': 3, 'proxy_src_ip': 8, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 7, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 1 1 ... 1 0 0] (100000,)
[INFO] Validation score: [33m0.64261[0m
[33m[INFO] metrics:[0m
loss :  1.652255562133789
tp :  64261.0
fp :  35739.0
tn :  364261.0
fn :  35739.0
accuracy :  0.857053279876709
precision :  0.6426100134849548
recall :  0.6426100134849548
auc :  0.9106525182723999

y_eval {0: 64261, 1: 35739}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64261     0     0     0     0]
 [35739     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[64261     0     0     0     0]
 [35739     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 1 1] (100000,)
[INFO] Validation score: [33m0.64231[0m
[33m[INFO] metrics:[0m
loss :  1.6536340046310425
tp :  64231.0
fp :  35769.0
tn :  364231.0
fn :  35769.0
accuracy :  0.856931746006012
precision :  0.6423100233078003
recall :  0.6423100233078003
auc :  0.9105774760246277

y_eval {0: 64231, 1: 35769}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64231     0     0     0     0]
 [35769     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[128492      0      0      0      0]
 [ 71508      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 1 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.70406[0m
[33m[INFO] metrics:[0m
loss :  1.369904887677729
tp :  70406.0
fp :  29594.0
tn :  370406.0
fn :  29594.0
accuracy :  0.8816267251968384
precision :  0.7040600180625916
recall :  0.7040600180625916
auc :  0.9260150194168091

y_eval {0: 70406, 1: 29594}
pred {0: 100000}
[INFO] confusion matrix for file 
[[70406     0     0     0     0]
 [29594     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[198898      0      0      0      0]
 [101102      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[298898      0      0      0      0]
 [101102      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[398898      0      0      0      0]
 [101102      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2015-12-31_181648_113.log.part08_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9948%,1.0:0.0052%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[0.0:99.9948%,0.5:0.0052%]
[INFO] ** i/f_dir:[0.0:99.9948%,1.0:0.0052%]
[INFO] ** src:[0.0666666667:38.4402%,0.9333333333:25.9738%,0.6666666667:18.1202%,0.3333333333:17.4598%,0.8:0.0052%,0.2666666667:0.0004%,0.5333333333:0.0002%,0.0:0.0002%]
[INFO] ** dst:[0.1764705882:43.345%,0.9411764706:21.0682%,0.8823529412000001:18.1202%,0.5294117647:17.4594%,0.2941176471:0.0052%,0.0:0.0012%,0.7647058823999999:0.0004%,1.0:0.0002%,0.23529411760000002:0.0002%]
[INFO] ** proto:[0.5:99.9946%,0.0:0.0052%,1.0:0.0002%]
[INFO] ** appi_name:[0.0:99.9942%,0.0384615385:0.0052%,0.4230769231:0.0002%,0.1538461538:0.0002%,0.4615384615:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.4402%,0.0:25.9738%,0.9333333333:18.1202%,0.4:17.4598%,0.5333333333:0.0052%,0.8:0.0004%,0.6:0.0002%,0.1333333333:0.0002%]
[INFO] ** modbus_function_code:[0.9743589744:99.9942%,0.0:0.0058%]
[INFO] ** modbus_function_description:[0.2:49.998%,0.0:49.9962%,0.4:0.0058%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:25.9726%,0.6:21.0682%,0.8:18.1198%,0.0:17.459%,0.4:17.3718%,0.2:0.0086%]
[INFO] ** service:[0.7025755984000001:99.9942%,0.0:0.0052%,0.0021789908:0.0004%,0.0021476384:0.0002%]
[INFO] ** s_port:[0.834280824:25.973%,0.8139250565:21.0682%,0.8029830673999999:18.12%,0.8149336757:17.4592%,0.8137722355:17.372%,0.0:0.0052%,0.814841983:0.0006%,0.8343113882:0.0004%,0.9137019378:0.0004%,0.8059172320999999:0.0002%,0.8030136315999999:0.0002%,0.8344030809:0.0002%,0.8345253376999999:0.0002%,0.0020936488:0.0002%]
[INFO] ** classification:[normal:80.1196%,Multi Stage Multi Point:14.47%,Single Stage Multi Point:5.4104%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 8, 'dst': 9, 'proto': 3, 'appi_name': 5, 'proxy_src_ip': 8, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 4, 'classification': 3}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.72948[0m
[33m[INFO] metrics:[0m
loss :  2.93570123932302
tp :  72948.0
fp :  27052.0
tn :  372948.0
fn :  27052.0
accuracy :  0.8917929530143738
precision :  0.7294800281524658
recall :  0.7294800281524658
auc :  0.7971100211143494

y_eval {0: 72948, 2: 27052}
pred {0: 100000}
[INFO] confusion matrix for file 
[[72948     0     0     0     0]
 [    0     0     0     0     0]
 [27052     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[471846      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[571846      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[671846      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.7477[0m
[33m[INFO] metrics:[0m
loss :  2.7600042450240254
tp :  74770.0
fp :  25230.0
tn :  374770.0
fn :  25230.0
accuracy :  0.8990800976753235
precision :  0.7476999759674072
recall :  0.7476999759674072
auc :  0.8107749819755554

y_eval {0: 74770, 4: 25230}
pred {0: 100000}
[INFO] confusion matrix for file 
[[74770     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [25230     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[746616      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [ 25230      0      0      0      0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 4 0 ... 4 0 0] (100000,)
[INFO] Validation score: [33m0.5288[0m
[33m[INFO] metrics:[0m
loss :  5.145854179077149
tp :  52880.0
fp :  47120.0
tn :  352880.0
fn :  47120.0
accuracy :  0.8115204572677612
precision :  0.5288000106811523
recall :  0.5288000106811523
auc :  0.646600067615509

y_eval {0: 52880, 4: 47120}
pred {0: 100000}
[INFO] confusion matrix for file 
[[52880     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [47120     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[799496      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [ 72350      0      0      0      0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2015-12-31_181648_113.log.part09_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9966%,1.0:0.0034%]
[INFO] ** type:[1.0:99.9996%,0.5:0.0004%]
[INFO] ** i/f_name:[0.0:99.9938%,0.5:0.0062%]
[INFO] ** i/f_dir:[0.0:99.9942%,1.0:0.0058%]
[INFO] ** src:[0.0666666667:38.4204%,0.9333333333:25.9634%,0.6666666667:18.123%,0.3333333333:17.486%,0.8:0.0034%,0.1333333333:0.0028%,0.5333333333:0.0006%,0.2666666667:0.0004%]
[INFO] ** dst:[0.1764705882:43.3316%,0.9411764706:21.0518%,0.8823529412000001:18.123%,0.5294117647:17.486%,0.2941176471:0.0062%,0.0:0.0008%,0.4705882353:0.0002%,0.23529411760000002:0.0002%,0.058823529400000005:0.0002%]
[INFO] ** proto:[0.5:99.9934%,0.0:0.0062%,1.0:0.0004%]
[INFO] ** appi_name:[0.0:99.9934%,0.0384615385:0.0062%,0.3076923077:0.0002%,0.9615384615000001:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.4204%,0.0:25.9634%,0.9333333333:18.123%,0.4:17.486%,0.5333333333:0.0062%,0.6:0.0006%,0.8:0.0004%]
[INFO] ** modbus_function_code:[0.9743589744:99.9934%,0.0:0.0066%]
[INFO] ** modbus_function_description:[0.2:49.9972%,0.0:49.9962%,0.4:0.0066%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:25.9624%,0.6:21.0518%,0.8:18.1226%,0.0:17.4856%,0.4:17.3686%,0.2:0.009%]
[INFO] ** service:[0.7025755984000001:99.9934%,0.0:0.0062%,0.0297847659:0.0002%,0.08394601119999999:0.0002%]
[INFO] ** s_port:[0.834280824:25.9628%,0.8139250565:21.0518%,0.8029830673999999:18.1226%,0.8149336757:17.4858%,0.8137722355:17.3686%,0.0:0.0062%,0.8059172320999999:0.0006%,0.9715599976:0.0002%,0.8030136315999999:0.0002%,0.8343113882:0.0002%,0.8147502904:0.0002%,0.8030441959000001:0.0002%,0.8344030809:0.0002%,0.9535729568000001:0.0002%,0.8345253376999999:0.0002%]
[INFO] ** classification:[normal:73.9096%,Multi Stage Multi Point:26.0904%]
[INFO] columns with count within 2-10 {'orig': 2, 'type': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 8, 'dst': 9, 'proto': 3, 'appi_name': 4, 'proxy_src_ip': 7, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 4, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 4 0 ... 4 4 4] (100000,)
[INFO] Validation score: [33m0.52975[0m
[33m[INFO] metrics:[0m
loss :  5.135499875259399
tp :  52975.0
fp :  47025.0
tn :  352975.0
fn :  47025.0
accuracy :  0.8118997812271118
precision :  0.5297499895095825
recall :  0.5297499895095825
auc :  0.6473124623298645

y_eval {0: 52975, 4: 47025}
pred {0: 100000}
[INFO] confusion matrix for file 
[[52975     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [47025     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[852471      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [119375      0      0      0      0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [4 0 4 ... 0 4 0] (100000,)
[INFO] Validation score: [33m0.53029[0m
[33m[INFO] metrics:[0m
loss :  5.129614262161255
tp :  53029.0
fp :  46971.0
tn :  353029.0
fn :  46971.0
accuracy :  0.812116801738739
precision :  0.5302900075912476
recall :  0.5302900075912476
auc :  0.6477175354957581

y_eval {0: 53029, 4: 46971}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53029     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [46971     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[905500      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [166346      0      0      0      0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [4 4 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.63544[0m
[33m[INFO] metrics:[0m
loss :  3.983556155280769
tp :  63544.0
fp :  36456.0
tn :  363544.0
fn :  36456.0
accuracy :  0.85417640209198
precision :  0.6354399919509888
recall :  0.6354399919509888
auc :  0.726580023765564

y_eval {0: 63544, 4: 36456}
pred {0: 100000}
[INFO] confusion matrix for file 
[[63544     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [36456     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[969044      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [202802      0      0      0      0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1069044       0       0       0       0]
 [ 101102       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1169044       0       0       0       0]
 [ 101102       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2015-12-31_233049_114.log.part11_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9996%,1.0:0.0004%]
[INFO] ** type:[1.0:99.9994%,0.5:0.0004%,0.0:0.0002%]
[INFO] ** i/f_name:[0.0:99.9968%,0.5:0.0032%]
[INFO] ** i/f_dir:[0.0:99.9972%,1.0:0.0028%]
[INFO] ** src:[0.0666666667:38.4512%,0.9333333333:25.9642%,0.6666666667:18.089%,0.3333333333:17.4908%,0.1333333333:0.0028%,0.0:0.0008%,0.2666666667:0.0004%,0.5333333333:0.0004%,0.8:0.0004%]
[INFO] ** dst:[0.1764705882:43.3436%,0.9411764706:21.0714%,0.8823529412000001:18.0896%,0.5294117647:17.4906%,0.2941176471:0.0032%,0.0:0.001%,0.4705882353:0.0002%,0.23529411760000002:0.0002%,0.058823529400000005:0.0002%]
[INFO] ** proto:[0.5:99.9964%,0.0:0.0032%,1.0:0.0004%]
[INFO] ** appi_name:[0.0:99.9956%,0.0384615385:0.0032%,0.3846153846:0.0002%,0.34615384619999995:0.0002%,0.6153846154:0.0002%,0.3076923077:0.0002%,0.9615384615000001:0.0002%,0.5769230769:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.4512%,0.0:25.9642%,0.9333333333:18.089%,0.4:17.4908%,0.5333333333:0.0032%,0.1333333333:0.0008%,0.6:0.0004%,0.8:0.0004%]
[INFO] ** modbus_function_code:[0.9743589744:99.9956%,0.0:0.0042%,1.0:0.0002%]
[INFO] ** modbus_function_description:[0.2:49.999%,0.0:49.9966%,0.4:0.0042%,0.6:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:25.9632%,0.6:21.0714%,0.8:18.0886%,0.0:17.4902%,0.4:17.3796%,0.2:0.007%]
[INFO] ** service:[0.7025755984000001:99.9964%,0.0:0.0032%,0.0297847659:0.0002%,0.08394601119999999:0.0002%]
[INFO] ** s_port:[0.834280824:25.9636%,0.8139250565:21.0714%,0.8029830673999999:18.0886%,0.8149336757:17.4904%,0.8137722355:17.3798%,0.0:0.0032%,0.8896631823000001:0.0008%,0.8059172320999999:0.0004%,0.8343113882:0.0004%,0.9715599976:0.0002%,0.8030136315999999:0.0002%,0.8147502904:0.0002%,0.8030441959000001:0.0002%,0.814841983:0.0002%,0.9535729568000001:0.0002%,0.8345253376999999:0.0002%]
[INFO] ** classification:[normal:95.0874%,Single Stage Single Point:4.9126%]
[INFO] columns with count within 2-10 {'orig': 2, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'src': 9, 'dst': 9, 'proto': 3, 'appi_name': 8, 'proxy_src_ip': 8, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 4, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1269044       0       0       0       0]
 [ 101102       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1369044       0       0       0       0]
 [ 101102       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.92639[0m
[33m[INFO] metrics:[0m
loss :  0.34834223764389755
tp :  92639.0
fp :  7361.0
tn :  392639.0
fn :  7361.0
accuracy :  0.9705646634101868
precision :  0.9263899922370911
recall :  0.9263899922370911
auc :  0.9815974831581116

y_eval {0: 92639, 1: 7361}
pred {0: 100000}
[INFO] confusion matrix for file 
[[92639     0     0     0     0]
 [ 7361     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1461683       0       0       0       0]
 [ 108463       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.82798[0m
[33m[INFO] metrics:[0m
loss :  0.8005168736922741
tp :  82798.0
fp :  17202.0
tn :  382798.0
fn :  17202.0
accuracy :  0.9312011003494263
precision :  0.8279799818992615
recall :  0.8279799818992615
auc :  0.9569950103759766

y_eval {0: 82798, 1: 17202}
pred {0: 100000}
[INFO] confusion matrix for file 
[[82798     0     0     0     0]
 [17202     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1544481       0       0       0       0]
 [ 125665       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1644481       0       0       0       0]
 [ 125665       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-01_151435_117.log.part03_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9976%,1.0:0.0024%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[0.0:99.9966%,0.5:0.0034%]
[INFO] ** i/f_dir:[0.0:99.9966%,1.0:0.0034%]
[INFO] ** src:[0.0666666667:38.1462%,0.9333333333:26.099%,0.6666666667:18.1904%,0.3333333333:17.5592%,0.8:0.0028%,0.1333333333:0.001%,1.0:0.0006%,0.2666666667:0.0004%,0.5333333333:0.0004%]
[INFO] ** dst:[0.1764705882:43.376%,0.9411764706:20.8688%,0.8823529412000001:18.1902%,0.5294117647:17.5592%,0.2941176471:0.0034%,0.0:0.0008%,0.3529411765:0.0004%,0.4705882353:0.0004%,0.6470588235:0.0004%,0.4117647059:0.0002%,0.23529411760000002:0.0002%]
[INFO] ** proto:[0.5:99.9958%,0.0:0.0034%,1.0:0.0008%]
[INFO] ** appi_name:[0.0:99.9952%,0.0384615385:0.0034%,0.5384615385:0.0006%,0.3076923077:0.0004%,0.4230769231:0.0002%,0.0769230769:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.1462%,0.0:26.099%,0.9333333333:18.1904%,0.4:17.5592%,0.5333333333:0.0034%,0.7333333333:0.0006%,0.6:0.0004%,0.4666666667:0.0004%,0.8:0.0004%]
[INFO] ** modbus_function_code:[0.9743589744:99.9952%,0.0:0.0048%]
[INFO] ** modbus_function_description:[0.2:49.9978%,0.0:49.9974%,0.4:0.0048%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:26.0982%,0.6:20.8688%,0.8:18.19%,0.0:17.5588%,0.4:17.2772%,0.2:0.007%]
[INFO] ** service:[0.7025755984000001:99.9952%,0.0:0.0034%,0.002116286:0.0006%,0.08394601119999999:0.0004%,0.0021633145999999997:0.0002%,0.0021476384:0.0002%]
[INFO] ** s_port:[0.834280824:26.0986%,0.8139250565:20.8688%,0.8029830673999999:18.1902%,0.8149336757:17.559%,0.8137722355:17.2774%,0.0:0.0034%,0.8059172320999999:0.0004%,0.8343113882:0.0002%,0.814841983:0.0002%,0.9228712024:0.0002%,0.0021089309:0.0002%,0.7616602481999999:0.0002%,0.8345253376999999:0.0002%,0.0020936488:0.0002%,0.8683752063:0.0002%,0.7840485359999999:0.0002%,0.8030136315999999:0.0002%,0.8086374473000001:0.0002%]
[INFO] ** classification:[normal:84.2104%,Single Stage Single Point:15.7896%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 9, 'proto': 3, 'appi_name': 6, 'proxy_src_ip': 9, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 6, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 1 0 0] (100000,)
[INFO] Validation score: [33m0.70708[0m
[33m[INFO] metrics:[0m
loss :  1.3560285795396567
tp :  70708.0
fp :  29292.0
tn :  370708.0
fn :  29292.0
accuracy :  0.8828411102294922
precision :  0.7070800065994263
recall :  0.7070800065994263
auc :  0.926770031452179

y_eval {0: 70708, 1: 29292}
pred {0: 100000}
[INFO] confusion matrix for file 
[[70708     0     0     0     0]
 [29292     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1715189       0       0       0       0]
 [ 154957       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [1 0 1 ... 1 0 0] (100000,)
[INFO] Validation score: [33m0.64215[0m
[33m[INFO] metrics:[0m
loss :  1.6543691728591918
tp :  64215.0
fp :  35785.0
tn :  364215.0
fn :  35785.0
accuracy :  0.856867790222168
precision :  0.6421499848365784
recall :  0.6421499848365784
auc :  0.9105375409126282

y_eval {0: 64215, 1: 35785}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64215     0     0     0     0]
 [35785     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1779404       0       0       0       0]
 [ 190742       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.86129[0m
[33m[INFO] metrics:[0m
loss :  0.6474639302480221
tp :  86129.0
fp :  13871.0
tn :  386129.0
fn :  13871.0
accuracy :  0.9445148706436157
precision :  0.8612899780273438
recall :  0.8612899780273438
auc :  0.9653224945068359

y_eval {0: 86129, 1: 13871}
pred {0: 100000}
[INFO] confusion matrix for file 
[[86129     0     0     0     0]
 [13871     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1865533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1965533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2065533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-01_151435_117.log.part12_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9964%,1.0:0.0036%]
[INFO] ** type:[1.0:99.9994%,0.5:0.0004%,0.0:0.0002%]
[INFO] ** i/f_name:[0.0:99.996%,0.5:0.004%]
[INFO] ** i/f_dir:[0.0:99.9964%,1.0:0.0036%]
[INFO] ** src:[0.0666666667:38.049%,0.9333333333:26.1306%,0.6666666667:18.2264%,0.3333333333:17.587%,0.8:0.0036%,0.0:0.0014%,0.2:0.001%,0.1333333333:0.0004%,0.5333333333:0.0002%,0.4:0.0002%,0.6:0.0002%]
[INFO] ** dst:[0.1764705882:43.355%,0.9411764706:20.8256%,0.8823529412000001:18.226%,0.5294117647:17.5868%,0.2941176471:0.004%,0.3529411765:0.001%,0.0:0.0006%,0.5882352941:0.0004%,0.4705882353:0.0002%,0.23529411760000002:0.0002%,0.058823529400000005:0.0002%]
[INFO] ** proto:[0.5:99.9942%,0.0:0.004%,1.0:0.0018%]
[INFO] ** appi_name:[0.0:99.9932%,0.0384615385:0.004%,0.4230769231:0.0006%,0.9230769231:0.0004%,0.0769230769:0.0004%,0.1923076923:0.0002%,0.34615384619999995:0.0002%,0.6153846154:0.0002%,0.3076923077:0.0002%,0.3846153846:0.0002%,0.9615384615000001:0.0002%,0.5769230769:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.049%,0.0:26.1306%,0.9333333333:18.2264%,0.4:17.587%,0.5333333333:0.004%,0.1333333333:0.0014%,0.0666666667:0.001%,1.0:0.0002%,0.6:0.0002%,0.3333333333:0.0002%]
[INFO] ** modbus_function_code:[0.9743589744:99.9932%,0.0:0.0066%,1.0:0.0002%]
[INFO] ** modbus_function_description:[0.2:49.9974%,0.0:49.9958%,0.4:0.0066%,0.6:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:26.13%,0.6:20.8244%,0.8:18.2258%,0.0:17.5864%,0.4:17.2242%,0.2:0.0092%]
[INFO] ** service:[0.7025755984000001:99.9942%,0.0:0.004%,0.0021476384:0.0006%,0.0021633145999999997:0.0004%,0.08391465880000001:0.0004%,0.0297847659:0.0002%,0.08394601119999999:0.0002%]
[INFO] ** s_port:[0.834280824:26.1304%,0.8139250565:20.8246%,0.8029830673999999:18.226%,0.8149336757:17.5866%,0.8137722355:17.2244%,0.0:0.004%,0.7431230515:0.0008%,0.0020936488:0.0006%,0.814841983:0.0004%,0.0021089309:0.0004%,0.0818051226:0.0004%,0.8030441959000001:0.0002%,0.7967938137999999:0.0002%,0.8345253376999999:0.0002%,0.0290360046:0.0002%,0.1074484993:0.0002%,0.8030136315999999:0.0002%,0.8059172320999999:0.0002%]
[INFO] ** classification:[normal:97.1716%,Single Stage Single Point:2.8284%]
[INFO] columns with count within 2-10 {'orig': 2, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'proto': 3, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 7, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2165533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2265533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2365533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2465533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 1 1] (100000,)
[INFO] Validation score: [33m0.85858[0m
[33m[INFO] metrics:[0m
loss :  0.6599158269429207
tp :  85858.0
fp :  14142.0
tn :  385858.0
fn :  14142.0
accuracy :  0.9434324502944946
precision :  0.8585799932479858
recall :  0.8585799932479858
auc :  0.9646449685096741

y_eval {0: 85858, 1: 14142}
pred {0: 100000}
[INFO] confusion matrix for file 
[[85858     0     0     0     0]
 [14142     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2551391       0       0       0       0]
 [ 218755       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-01_151435_117.log.part13_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9986%,1.0:0.0014%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[0.0:99.998%,0.5:0.002%]
[INFO] ** i/f_dir:[0.0:99.998%,1.0:0.002%]
[INFO] ** src:[0.0666666667:38.1186%,0.9333333333:26.0918%,0.6666666667:18.2288%,0.3333333333:17.558%,0.8:0.0018%,0.1333333333:0.0006%,0.5333333333:0.0004%]
[INFO] ** dst:[0.1764705882:43.3702%,0.9411764706:20.8392%,0.8823529412000001:18.2288%,0.5294117647:17.5578%,0.2941176471:0.002%,0.0:0.0012%,0.23529411760000002:0.0004%,0.3529411765:0.0002%,0.4705882353:0.0002%]
[INFO] ** proto:[0.5:99.9976%,0.0:0.002%,1.0:0.0004%]
[INFO] ** appi_name:[0.0:99.9976%,0.0384615385:0.002%,0.4230769231:0.0002%,0.3076923077:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.1186%,0.0:26.0918%,0.9333333333:18.2288%,0.4:17.558%,0.5333333333:0.002%,0.6:0.0004%,0.4666666667:0.0004%]
[INFO] ** modbus_function_code:[0.9743589744:99.9976%,0.0:0.0024%]
[INFO] ** modbus_function_description:[0.2:49.9998%,0.0:49.9978%,0.4:0.0024%]
[INFO] ** modbus_transaction_id:65534 (13.1068%)
[INFO] ** scada_tag:[1.0:26.0906%,0.6:20.839%,0.8:18.2282%,0.0:17.5572%,0.4:17.2792%,0.2:0.0058%]
[INFO] ** service:[0.7025755984000001:99.9976%,0.0:0.002%,0.08394601119999999:0.0002%,0.0021476384:0.0002%]
[INFO] ** s_port:[0.834280824:26.0908%,0.8139250565:20.8392%,0.8029830673999999:18.2284%,0.8149336757:17.5576%,0.8137722355:17.2794%,0.0:0.002%,0.8343113882:0.0006%,0.8059172320999999:0.0004%,0.8030136315999999:0.0004%,0.8147502904:0.0002%,0.814841983:0.0002%,0.8344030809:0.0002%,0.8345253376999999:0.0002%,0.0020936488:0.0002%,0.8683752063:0.0002%]
[INFO] ** classification:[normal:87.5394%,Single Stage Single Point:12.4606%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 7, 'dst': 9, 'proto': 3, 'appi_name': 4, 'proxy_src_ip': 7, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 4, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 1 0 ... 1 0 1] (100000,)
[INFO] Validation score: [33m0.53028[0m
[33m[INFO] metrics:[0m
loss :  2.1683897735595705
tp :  53028.0
fp :  46972.0
tn :  353028.0
fn :  46972.0
accuracy :  0.8121113777160645
precision :  0.5302799940109253
recall :  0.5302799940109253
auc :  0.8825699687004089

y_eval {0: 53028, 1: 46972}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53028     0     0     0     0]
 [46972     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2604419       0       0       0       0]
 [ 265727       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.84669[0m
[33m[INFO] metrics:[0m
loss :  0.7145480386349559
tp :  84669.0
fp :  15331.0
tn :  384669.0
fn :  15331.0
accuracy :  0.9386759996414185
precision :  0.8466899991035461
recall :  0.8466899991035461
auc :  0.9616724848747253

y_eval {0: 84669, 1: 15331}
pred {0: 100000}
[INFO] confusion matrix for file 
[[84669     0     0     0     0]
 [15331     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2689088       0       0       0       0]
 [ 281058       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2789088       0       0       0       0]
 [ 281058       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2889088       0       0       0       0]
 [ 281058       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2989088       0       0       0       0]
 [ 281058       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-01_203011_118.log.part06_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9988%,1.0:0.0008%,0.0:0.0004%]
[INFO] ** type:[1.0:99.9986%,0.5:0.001%,0.0:0.0004%]
[INFO] ** i/f_name:[0.0:99.998%,0.5:0.002%]
[INFO] ** i/f_dir:[0.0:99.9982%,1.0:0.0018%]
[INFO] ** src:[0.0666666667:38.138%,0.9333333333:26.0904%,0.6666666667:18.1762%,0.3333333333:17.5892%,0.2:0.0018%,0.0:0.0016%,0.1333333333:0.0012%,0.8:0.0008%,0.5333333333:0.0006%,0.4:0.0002%]
[INFO] ** dst:[0.1764705882:43.3838%,0.9411764706:20.845%,0.8823529412000001:18.1758%,0.5294117647:17.589%,0.2941176471:0.002%,0.3529411765:0.0014%,0.0:0.0014%,0.5882352941:0.0004%,0.4705882353:0.0004%,0.23529411760000002:0.0004%,0.058823529400000005:0.0004%]
[INFO] ** proto:[0.5:99.9954%,1.0:0.0026%,0.0:0.002%]
[INFO] ** appi_name:[0.0:99.9944%,0.0384615385:0.002%,0.0769230769:0.0008%,0.4230769231:0.0006%,0.9230769231:0.0004%,0.34615384619999995:0.0004%,0.3076923077:0.0004%,0.9615384615000001:0.0004%,0.3846153846:0.0002%,0.6153846154:0.0002%,0.5769230769:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.138%,0.0:26.0904%,0.9333333333:18.1762%,0.4:17.5892%,0.5333333333:0.002%,0.0666666667:0.0018%,0.1333333333:0.0016%,0.6:0.0006%,1.0:0.0002%]
[INFO] ** modbus_function_code:[0.9743589744:99.9944%,0.0:0.0052%,1.0:0.0004%]
[INFO] ** modbus_function_description:[0.2:49.998%,0.0:49.9964%,0.4:0.0052%,0.6:0.0004%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:26.0894%,0.6:20.8438%,0.8:18.1758%,0.0:17.5888%,0.4:17.294%,0.2:0.0082%]
[INFO] ** service:[0.7025755984000001:99.9954%,0.0:0.002%,0.0021633145999999997:0.0008%,0.0021476384:0.0006%,0.08391465880000001:0.0004%,0.0297847659:0.0004%,0.08394601119999999:0.0004%]
[INFO] ** s_port:[0.834280824:26.0898%,0.8139250565:20.844%,0.8029830673999999:18.1758%,0.8149336757:17.589%,0.8137722355:17.294%,0.0:0.002%,0.7435203863:0.0008%,0.0021089309:0.0008%,0.0020936488:0.0006%,0.8059172320999999:0.0006%,0.8343113882:0.0006%,0.7967938137999999:0.0004%,0.0290360046:0.0004%,0.0818051226:0.0004%,0.8030136315999999:0.0004%,0.7431230515:0.0002%,0.814841983:0.0002%]
[INFO] ** classification:[normal:90.7904%,Single Stage Multi Point:5.7378%,Single Stage Single Point:3.4718%]
[INFO] columns with count within 2-10 {'orig': 3, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'proto': 3, 'proxy_src_ip': 9, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 7, 'classification': 3}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3089088       0       0       0       0]
 [ 281058       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3189088       0       0       0       0]
 [ 281058       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3289088       0       0       0       0]
 [ 281058       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.82641[0m
[33m[INFO] metrics:[0m
loss :  0.8077306515187025
tp :  82641.0
fp :  17359.0
tn :  382641.0
fn :  17359.0
accuracy :  0.9305639266967773
precision :  0.8264099955558777
recall :  0.8264099955558777
auc :  0.9566025137901306

y_eval {0: 82641, 1: 17359}
pred {0: 100000}
[INFO] confusion matrix for file 
[[82641     0     0     0     0]
 [17359     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[3371729       0       0       0       0]
 [ 298417       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 2 2] (100000,)
[INFO] Validation score: [33m0.71311[0m
[33m[INFO] metrics:[0m
loss :  3.1127371864050626
tp :  71311.0
fp :  28689.0
tn :  371311.0
fn :  28689.0
accuracy :  0.8852441906929016
precision :  0.7131100296974182
recall :  0.7131100296974182
auc :  0.7848324775695801

y_eval {0: 71311, 2: 28689}
pred {0: 100000}
[INFO] confusion matrix for file 
[[71311     0     0     0     0]
 [    0     0     0     0     0]
 [28689     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[3443040       0       0       0       0]
 [ 298417       0       0       0       0]
 [  55741       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-01_203011_118.log.part07_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9996%,1.0:0.0004%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[0.0:99.9994%,0.5:0.0006%]
[INFO] ** i/f_dir:[0.0:99.9994%,1.0:0.0006%]
[INFO] ** src:[0.0666666667:38.0718%,0.9333333333:26.1174%,0.6666666667:18.2344%,0.3333333333:17.5754%,0.8:0.0008%,0.1333333333:0.0002%]
[INFO] ** dst:[0.1764705882:43.3758%,0.9411764706:20.813%,0.8823529412000001:18.2342%,0.5294117647:17.5754%,0.2941176471:0.0006%,0.0:0.0004%,0.3529411765:0.0002%,0.4705882353:0.0002%,0.23529411760000002:0.0002%]
[INFO] ** proto:[0.5:99.999%,0.0:0.0006%,1.0:0.0004%]
[INFO] ** appi_name:[0.0:99.999%,0.0384615385:0.0006%,0.4230769231:0.0002%,0.3076923077:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.0718%,0.0:26.1174%,0.9333333333:18.2344%,0.4:17.5754%,0.5333333333:0.0006%,0.4666666667:0.0004%]
[INFO] ** modbus_function_code:[0.9743589744:99.999%,0.0:0.001%]
[INFO] ** modbus_function_description:[0.2:49.9996%,0.0:49.9994%,0.4:0.001%]
[INFO] ** modbus_transaction_id:65301 (13.0602%)
[INFO] ** scada_tag:[1.0:26.1164%,0.6:20.813%,0.8:18.2338%,0.0:17.575%,0.4:17.2586%,0.2:0.0032%]
[INFO] ** service:[0.7025755984000001:99.999%,0.0:0.0006%,0.08394601119999999:0.0002%,0.0021476384:0.0002%]
[INFO] ** s_port:[0.834280824:26.1168%,0.8139250565:20.813%,0.8029830673999999:18.234%,0.8149336757:17.5752%,0.8137722355:17.2588%,0.0:0.0006%,0.8030136315999999:0.0002%,0.8343113882:0.0002%,0.8030441959000001:0.0002%,0.814841983:0.0002%,0.8344030809:0.0002%,0.8345253376999999:0.0002%,0.0020936488:0.0002%,0.8683752063:0.0002%]
[INFO] ** classification:[normal:89.2092%,Single Stage Multi Point:10.7908%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 6, 'dst': 9, 'proto': 3, 'appi_name': 4, 'proxy_src_ip': 6, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 4, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [2 0 0 ... 2 0 0] (100000,)
[INFO] Validation score: [33m0.53027[0m
[33m[INFO] metrics:[0m
loss :  5.0900900353240965
tp :  53027.0
fp :  46973.0
tn :  353027.0
fn :  46973.0
accuracy :  0.8121077418327332
precision :  0.530269980430603
recall :  0.530269980430603
auc :  0.6477024555206299

y_eval {0: 53027, 2: 46973}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53027     0     0     0     0]
 [    0     0     0     0     0]
 [46973     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[3496067       0       0       0       0]
 [ 298417       0       0       0       0]
 [ 102714       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 2 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.93019[0m
[33m[INFO] metrics:[0m
loss :  0.7650903070735932
tp :  93019.0
fp :  6981.0
tn :  393019.0
fn :  6981.0
accuracy :  0.9720761179924011
precision :  0.9301900267601013
recall :  0.9301900267601013
auc :  0.9476425647735596

y_eval {0: 93019, 2: 6981}
pred {0: 100000}
[INFO] confusion matrix for file 
[[93019     0     0     0     0]
 [    0     0     0     0     0]
 [ 6981     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[3589086       0       0       0       0]
 [ 298417       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3689086       0       0       0       0]
 [ 298417       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3789086       0       0       0       0]
 [ 298417       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3889086       0       0       0       0]
 [ 298417       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-02_014558_119.log.part06_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.997%,1.0:0.003%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[0.0:99.9964%,0.5:0.0036%]
[INFO] ** i/f_dir:[0.0:99.9964%,1.0:0.0036%]
[INFO] ** src:[0.0666666667:38.0288%,0.9333333333:26.1242%,0.6666666667:18.2114%,0.3333333333:17.6294%,0.8:0.003%,0.2666666667:0.0008%,1.0:0.0006%,0.1333333333:0.0006%,0.5333333333:0.0004%,0.4:0.0004%,0.6:0.0002%,0.0:0.0002%]
[INFO] ** dst:[0.1764705882:43.357%,0.9411764706:20.7952%,0.8823529412000001:18.2116%,0.5294117647:17.629%,0.2941176471:0.0036%,0.0:0.0012%,0.6470588235:0.0008%,0.3529411765:0.0004%,0.7058823529000001:0.0004%,0.7647058823999999:0.0004%,1.0:0.0002%,0.23529411760000002:0.0002%]
[INFO] ** proto:[0.5:99.9958%,0.0:0.0036%,1.0:0.0006%]
[INFO] ** appi_name:[0.0:99.9942%,0.0384615385:0.0036%,0.7692307692:0.0008%,0.4230769231:0.0004%,0.5384615385:0.0002%,0.0769230769:0.0002%,0.11538461539999999:0.0002%,0.1538461538:0.0002%,0.4615384615:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.0288%,0.0:26.1242%,0.9333333333:18.2114%,0.4:17.6294%,0.5333333333:0.0036%,0.8:0.0008%,0.7333333333:0.0006%,1.0:0.0004%,0.6:0.0004%,0.3333333333:0.0002%,0.1333333333:0.0002%]
[INFO] ** modbus_function_code:[0.9743589744:99.9942%,0.0:0.0058%]
[INFO] ** modbus_function_description:[0.2:49.9974%,0.0:49.9968%,0.4:0.0058%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:26.123%,0.6:20.7952%,0.8:18.211%,0.0:17.6288%,0.4:17.2336%,0.2:0.0084%]
[INFO] ** service:[0.7025755984000001:99.9942%,0.0:0.0036%,0.0208806885:0.0008%,0.0021789908:0.0004%,0.0021476384:0.0004%,0.0021633145999999997:0.0002%,0.08543524949999999:0.0002%,0.002116286:0.0002%]
[INFO] ** s_port:[0.834280824:26.1234%,0.8139250565:20.7952%,0.8029830673999999:18.2112%,0.8149336757:17.629%,0.8137722355:17.2336%,0.0:0.0036%,0.8343113882:0.0006%,0.0020936488:0.0004%,0.9310776942:0.0004%,0.8059172320999999:0.0004%,0.8147502904:0.0002%,0.814841983:0.0002%,0.15243902439999998:0.0002%,0.8344030809:0.0002%,0.0021089309:0.0002%,0.8411730545999999:0.0002%,0.7593068036:0.0002%,0.15240846019999998:0.0002%,0.8030136315999999:0.0002%,0.315972859:0.0002%,0.7586191087:0.0002%]
[INFO] ** classification:[normal:81.41%,Single Stage Single Point:18.59%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'proto': 3, 'appi_name': 9, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 8, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 1 0 1] (100000,)
[INFO] Validation score: [33m0.67398[0m
[33m[INFO] metrics:[0m
loss :  1.508116529456675
tp :  67398.0
fp :  32602.0
tn :  367398.0
fn :  32602.0
accuracy :  0.8695923686027527
precision :  0.6739799976348877
recall :  0.6739799976348877
auc :  0.9184949994087219

y_eval {0: 67398, 1: 32602}
pred {0: 100000}
[INFO] confusion matrix for file 
[[67398     0     0     0     0]
 [32602     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[3956484       0       0       0       0]
 [ 331019       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [1 0 1 ... 1 0 0] (100000,)
[INFO] Validation score: [33m0.53052[0m
[33m[INFO] metrics:[0m
loss :  2.167287021331787
tp :  53052.0
fp :  46948.0
tn :  353052.0
fn :  46948.0
accuracy :  0.812207818031311
precision :  0.5305200219154358
recall :  0.5305200219154358
auc :  0.8826299905776978

y_eval {0: 53052, 1: 46948}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53052     0     0     0     0]
 [46948     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[4009536       0       0       0       0]
 [ 377967       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 1 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.866[0m
[33m[INFO] metrics:[0m
loss :  0.6258223871016503
tp :  86600.0
fp :  13400.0
tn :  386600.0
fn :  13400.0
accuracy :  0.946399986743927
precision :  0.8659999966621399
recall :  0.8659999966621399
auc :  0.9664999842643738

y_eval {0: 86600, 1: 13400}
pred {0: 100000}
[INFO] confusion matrix for file 
[[86600     0     0     0     0]
 [13400     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[4096136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4196136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4296136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-02_121729_121.log.part12_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9986%,0.0:0.0008%,1.0:0.0006%]
[INFO] ** type:[1.0:99.9984%,0.5:0.0014%,0.0:0.0002%]
[INFO] ** i/f_name:[0.0:99.9978%,0.5:0.0022%]
[INFO] ** i/f_dir:[0.0:99.998%,1.0:0.002%]
[INFO] ** src:[0.0666666667:38.1136%,0.9333333333:26.1176%,0.6666666667:18.2158%,0.3333333333:17.5472%,0.1333333333:0.0016%,0.0:0.0014%,0.2:0.001%,0.8:0.0006%,0.2666666667:0.0004%,0.5333333333:0.0004%,0.4:0.0002%,1.0:0.0002%]
[INFO] ** dst:[0.1764705882:43.4022%,0.9411764706:20.8284%,0.8823529412000001:18.2156%,0.5294117647:17.547%,0.2941176471:0.0022%,0.0:0.002%,0.3529411765:0.0008%,0.5882352941:0.0004%,0.7647058823999999:0.0004%,1.0:0.0004%,0.4705882353:0.0002%,0.23529411760000002:0.0002%,0.058823529400000005:0.0002%]
[INFO] ** proto:[0.5:99.996%,0.0:0.0022%,1.0:0.0018%]
[INFO] ** appi_name:[0.0:99.9946%,0.0384615385:0.0022%,0.4230769231:0.0006%,0.9230769231:0.0004%,0.0769230769:0.0004%,0.1538461538:0.0002%,0.3846153846:0.0002%,1.0:0.0002%,0.34615384619999995:0.0002%,0.6153846154:0.0002%,0.3076923077:0.0002%,0.4615384615:0.0002%,0.9615384615000001:0.0002%,0.5769230769:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.1136%,0.0:26.1176%,0.9333333333:18.2158%,0.4:17.5472%,0.5333333333:0.0022%,0.1333333333:0.0014%,0.0666666667:0.001%,0.6:0.0004%,0.8:0.0004%,1.0:0.0002%,0.7333333333:0.0002%]
[INFO] ** modbus_function_code:[0.9743589744:99.9946%,0.0:0.0052%,1.0:0.0002%]
[INFO] ** modbus_function_description:[0.2:49.9984%,0.0:49.9962%,0.4:0.0052%,0.6:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:26.1164%,0.6:20.8284%,0.8:18.2154%,0.0:17.5466%,0.4:17.285%,0.2:0.0082%]
[INFO] ** service:[0.7025755984000001:99.9954%,0.0:0.0022%,0.0021476384:0.0006%,0.0021789908:0.0004%,0.0021633145999999997:0.0004%,0.08391465880000001:0.0004%,0.0839773636:0.0002%,0.0297847659:0.0002%,0.08394601119999999:0.0002%]
[INFO] ** s_port:[0.834280824:26.1168%,0.8139250565:20.8284%,0.8029830673999999:18.2154%,0.8149336757:17.5468%,0.8137722355:17.2852%,0.0:0.0022%,0.696222263:0.0008%,0.0020936488:0.0006%,0.8059172320999999:0.0004%,0.8343113882:0.0004%,0.0021089309:0.0004%,0.0818051226:0.0004%,0.9385047986:0.0004%,0.814841983:0.0004%,0.8030441959000001:0.0002%,0.9925728957:0.0002%,0.8344030809:0.0002%,0.9705208142:0.0002%,0.8345253376999999:0.0002%,0.0290360046:0.0002%,0.8030136315999999:0.0002%]
[INFO] ** classification:[normal:99.9996%,Single Stage Multi Point:0.0004%]
[INFO] columns with count within 2-10 {'orig': 3, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'proto': 3, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 9, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4396136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4496136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4596136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4696136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.99998[0m
[33m[INFO] metrics:[0m
loss :  0.010335028273761272
tp :  99998.0
fp :  2.0
tn :  399998.0
fn :  2.0
accuracy :  0.9999920129776001
precision :  0.9999799728393555
recall :  0.9999799728393555
auc :  0.9999849796295166

y_eval {0: 99998, 2: 2}
pred {0: 100000}
[INFO] confusion matrix for file 
[[99998     0     0     0     0]
 [    0     0     0     0     0]
 [    2     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[4796134       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109697       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-02_121729_121.log.part13_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9996%,1.0:0.0004%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[0.0:99.9994%,0.5:0.0006%]
[INFO] ** i/f_dir:[0.0:99.9994%,1.0:0.0006%]
[INFO] ** src:[0.0666666667:38.162%,0.9333333333:26.1664%,0.6666666667:18.0742%,0.3333333333:17.5958%,0.8:0.0008%,0.5333333333:0.0002%,0.7333333333:0.0002%,0.6:0.0002%,0.1333333333:0.0002%]
[INFO] ** dst:[0.1764705882:43.4352%,0.9411764706:20.8932%,0.8823529412000001:18.0744%,0.5294117647:17.5952%,0.2941176471:0.0006%,0.4705882353:0.0006%,0.0:0.0006%,0.3529411765:0.0002%]
[INFO] ** proto:[0.5:99.9986%,1.0:0.0008%,0.0:0.0006%]
[INFO] ** appi_name:[0.0:99.9986%,0.0384615385:0.0006%,0.3076923077:0.0006%,0.4230769231:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.162%,0.0:26.1664%,0.9333333333:18.0742%,0.4:17.5958%,0.5333333333:0.0006%,0.4666666667:0.0004%,0.2666666667:0.0002%,0.6:0.0002%,0.3333333333:0.0002%]
[INFO] ** modbus_function_code:[0.9743589744:99.9986%,0.0:0.0014%]
[INFO] ** modbus_function_description:[0.2:49.9998%,0.0:49.9988%,0.4:0.0014%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:26.166%,0.6:20.893%,0.8:18.0738%,0.0:17.5948%,0.4:17.2688%,0.2:0.0036%]
[INFO] ** service:[0.7025755984000001:99.9986%,0.08394601119999999:0.0006%,0.0:0.0006%,0.0021476384:0.0002%]
[INFO] ** s_port:[0.834280824:26.1662%,0.8139250565:20.8932%,0.8029830673999999:18.074%,0.8149336757:17.5952%,0.8137722355:17.2688%,0.0:0.0006%,0.814841983:0.0004%,0.9945442875:0.0004%,0.8059172320999999:0.0002%,0.8147502904:0.0002%,0.8030441959000001:0.0002%,0.8344030809:0.0002%,0.0020936488:0.0002%,0.8683752063:0.0002%]
[INFO] ** classification:[normal:92.8338%,Multi Stage Single Point:7.1662%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 9, 'dst': 8, 'proto': 3, 'appi_name': 4, 'proxy_src_ip': 9, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 4, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4896134       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109697       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.88734[0m
[33m[INFO] metrics:[0m
loss :  1.1941712086513638
tp :  88734.0
fp :  11266.0
tn :  388734.0
fn :  11266.0
accuracy :  0.9549478888511658
precision :  0.8873400092124939
recall :  0.8873400092124939
auc :  0.9155051112174988

y_eval {0: 88734, 3: 11266}
pred {0: 100000}
[INFO] confusion matrix for file 
[[88734     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [11266     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[4984868       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109697       0       0       0       0]
 [  11266       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.92435[0m
[33m[INFO] metrics:[0m
loss :  0.80519746255368
tp :  92435.0
fp :  7565.0
tn :  392435.0
fn :  7565.0
accuracy :  0.9697391986846924
precision :  0.9243500232696533
recall :  0.9243500232696533
auc :  0.94326251745224

y_eval {0: 92435, 3: 7565}
pred {0: 100000}
[INFO] confusion matrix for file 
[[92435     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [ 7565     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[5077303       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109697       0       0       0       0]
 [  18831       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5177303       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109697       0       0       0       0]
 [  18831       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.83[0m
[33m[INFO] metrics:[0m
loss :  1.7968125074759125
tp :  83000.0
fp :  17000.0
tn :  383000.0
fn :  17000.0
accuracy :  0.9320096969604492
precision :  0.8299999833106995
recall :  0.8299999833106995
auc :  0.872499942779541

y_eval {0: 83000, 3: 17000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[83000     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [17000     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[5260303       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109697       0       0       0       0]
 [  35831       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-02_121729_121.log.part14_sorted-labeled.csv
[INFO] process dataset, shape: (439824, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (439824, 16)

[INFO] analyzing data
[INFO] 439824 rows
[INFO] ** orig:[0.5:99.99955%,1.0:0.00045%]
[INFO] ** type:[1.0:99.99977%,0.5:0.00023%]
[INFO] ** i/f_name:[0.0:99.99864%,0.5:0.00136%]
[INFO] ** i/f_dir:[0.0:99.99886%,1.0:0.00114%]
[INFO] ** src:[0.0666666667:38.09456%,0.9333333333:26.09703%,0.6666666667:18.22161%,0.3333333333:17.58408%,0.1333333333:0.00091%,0.5333333333:0.00068%,0.8:0.00068%,0.4:0.00023%,1.0:0.00023%]
[INFO] ** dst:[0.1764705882:43.35416%,0.9411764706:20.83674%,0.8823529412000001:18.22115%,0.5294117647:17.58385%,0.0:0.00159%,0.2941176471:0.00136%,0.23529411760000002:0.00045%,0.3529411765:0.00023%,0.5882352941:0.00023%,0.4117647059:0.00023%]
[INFO] ** proto:[0.5:99.99818%,0.0:0.00136%,1.0:0.00045%]
[INFO] ** appi_name:[0.0:99.99795%,0.0384615385:0.00136%,0.9230769231:0.00023%,0.7307692308:0.00023%,0.0769230769:0.00023%]
[INFO] ** proxy_src_ip:[0.6666666667:38.09456%,0.0:26.09703%,0.9333333333:18.22161%,0.4:17.58408%,0.5333333333:0.00136%,0.6:0.00068%,1.0:0.00023%,0.7333333333:0.00023%,0.4666666667:0.00023%]
[INFO] ** modbus_function_code:[0.9743589744:99.99795%,0.0:0.00205%]
[INFO] ** modbus_function_description:[0.2:49.99955%,0.0:49.99841%,0.4:0.00205%]
[INFO] ** modbus_transaction_id:65536 (14.90051%)
[INFO] ** scada_tag:[1.0:26.09612%,0.6:20.83652%,0.8:18.22092%,0.0:17.5834%,0.4:17.25758%,0.2:0.00546%]
[INFO] ** service:[0.7025755984000001:99.99795%,0.0:0.00136%,0.0021633145999999997:0.00023%,0.08391465880000001:0.00023%,0.0012540954:0.00023%]
[INFO] ** s_port:[0.834280824:26.09635%,0.8139250565:20.83674%,0.8029830673999999:18.22115%,0.8149336757:17.58362%,0.8137722355:17.25781%,0.0:0.00136%,0.8059172320999999:0.00068%,0.8030136315999999:0.00045%,0.8343113882:0.00045%,0.814841983:0.00045%,0.0818051226:0.00023%,0.0021089309:0.00023%,0.8030441959000001:0.00023%,0.8345253376999999:0.00023%]
[INFO] ** classification:[normal:93.34597%,Single Stage Single Point:4.48861%,Multi Stage Single Point:2.16541%]
[INFO] columns with count within 2-10 {'orig': 2, 'type': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 9, 'proto': 3, 'appi_name': 5, 'proxy_src_ip': 9, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 5, 'classification': 3}
[INFO] processing batch 0-100000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [3 0 0 ... 1 0 0] (100000,)
[INFO] Validation score: [33m0.86777[0m
[33m[INFO] metrics:[0m
loss :  1.1810494357207417
tp :  86777.0
fp :  13223.0
tn :  386777.0
fn :  13223.0
accuracy :  0.9471138119697571
precision :  0.8677700161933899
recall :  0.8677700161933899
auc :  0.9193224906921387

y_eval {0: 86777, 1: 3699, 3: 9524}
pred {0: 100000}
[INFO] confusion matrix for file 
[[86777     0     0     0     0]
 [ 3699     0     0     0     0]
 [    0     0     0     0     0]
 [ 9524     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[5347080       0       0       0       0]
 [ 395066       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.83957[0m
[33m[INFO] metrics:[0m
loss :  0.747263097166717
tp :  83957.0
fp :  16043.0
tn :  383957.0
fn :  16043.0
accuracy :  0.9358352422714233
precision :  0.8395699858665466
recall :  0.8395699858665466
auc :  0.9598925113677979

y_eval {0: 83957, 1: 16043}
pred {0: 100000}
[INFO] confusion matrix for file 
[[83957     0     0     0     0]
 [16043     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[5431037       0       0       0       0]
 [ 411109       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5531037       0       0       0       0]
 [ 411109       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5631037       0       0       0       0]
 [ 411109       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/439824
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-02_172943_122.log.part03_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9976%,1.0:0.002%,0.0:0.0004%]
[INFO] ** type:[1.0:99.9988%,0.5:0.001%,0.0:0.0002%]
[INFO] ** i/f_name:[0.0:99.9944%,0.5:0.0056%]
[INFO] ** i/f_dir:[0.0:99.9946%,1.0:0.0054%]
[INFO] ** src:[0.0666666667:38.2234%,0.9333333333:26.124%,0.6666666667:18.075%,0.3333333333:17.571%,0.1333333333:0.0036%,0.8:0.0022%,0.2666666667:0.0004%,0.2:0.0002%,0.0:0.0002%]
[INFO] ** dst:[0.1764705882:43.4342%,0.9411764706:20.913%,0.8823529412000001:18.0748%,0.5294117647:17.5708%,0.2941176471:0.0056%,0.0:0.0006%,0.5882352941:0.0004%,0.4705882353:0.0002%,0.23529411760000002:0.0002%,0.058823529400000005:0.0002%]
[INFO] ** proto:[0.5:99.9936%,0.0:0.0056%,1.0:0.0008%]
[INFO] ** appi_name:[0.0:99.9934%,0.0384615385:0.0056%,0.9230769231:0.0004%,0.34615384619999995:0.0002%,0.3076923077:0.0002%,0.9615384615000001:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.2234%,0.0:26.124%,0.9333333333:18.075%,0.4:17.571%,0.5333333333:0.0056%,0.8:0.0004%,0.4666666667:0.0002%,0.0666666667:0.0002%,0.1333333333:0.0002%]
[INFO] ** modbus_function_code:[0.9743589744:99.9934%,0.0:0.0064%,1.0:0.0002%]
[INFO] ** modbus_function_description:[0.2:49.997%,0.0:49.9964%,0.4:0.0064%,0.6:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:26.1234%,0.6:20.9128%,0.8:18.0748%,0.0:17.5704%,0.4:17.3102%,0.2:0.0084%]
[INFO] ** service:[0.7025755984000001:99.9936%,0.0:0.0056%,0.08391465880000001:0.0004%,0.0297847659:0.0002%,0.08394601119999999:0.0002%]
[INFO] ** s_port:[0.834280824:26.1238%,0.8139250565:20.913%,0.8029830673999999:18.0748%,0.8149336757:17.5706%,0.8137722355:17.3104%,0.0:0.0056%,0.0818051226:0.0004%,0.814841983:0.0004%,0.9715599976:0.0002%,0.8030136315999999:0.0002%,0.696222263:0.0002%,0.9535729568000001:0.0002%,0.8345253376999999:0.0002%]
[INFO] ** classification:[normal:94.9296%,Single Stage Single Point:5.0704%]
[INFO] columns with count within 2-10 {'orig': 3, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'src': 9, 'proto': 3, 'appi_name': 6, 'proxy_src_ip': 9, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 5, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5731037       0       0       0       0]
 [ 411109       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5831037       0       0       0       0]
 [ 411109       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5931037       0       0       0       0]
 [ 411109       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[6031037       0       0       0       0]
 [ 411109       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.74648[0m
[33m[INFO] metrics:[0m
loss :  1.1749933230701088
tp :  74648.0
fp :  25352.0
tn :  374648.0
fn :  25352.0
accuracy :  0.8986006379127502
precision :  0.7464799880981445
recall :  0.7464799880981445
auc :  0.9366199970245361

y_eval {0: 74648, 1: 25352}
pred {0: 100000}
[INFO] confusion matrix for file 
[[74648     0     0     0     0]
 [25352     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6105685       0       0       0       0]
 [ 436461       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-02_172943_122.log.part04_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.995%,1.0:0.005%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[0.0:99.9944%,0.5:0.0056%]
[INFO] ** i/f_dir:[0.0:99.9944%,1.0:0.0056%]
[INFO] ** src:[0.0666666667:38.203%,0.9333333333:26.1368%,0.6666666667:18.1014%,0.3333333333:17.5508%,0.8:0.005%,1.0:0.0008%,0.5333333333:0.0006%,0.1333333333:0.0006%,0.2666666667:0.0004%,0.4:0.0004%,0.6:0.0002%]
[INFO] ** dst:[0.1764705882:43.4462%,0.9411764706:20.893%,0.8823529412000001:18.1012%,0.5294117647:17.5504%,0.2941176471:0.0056%,0.0:0.0016%,0.6470588235:0.0008%,0.3529411765:0.0006%,0.7058823529000001:0.0004%,0.23529411760000002:0.0002%]
[INFO] ** proto:[0.5:99.9938%,0.0:0.0056%,1.0:0.0006%]
[INFO] ** appi_name:[0.0:99.9926%,0.0384615385:0.0056%,0.7692307692:0.0008%,0.0769230769:0.0004%,0.5384615385:0.0002%,0.4230769231:0.0002%,0.11538461539999999:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.203%,0.0:26.1368%,0.9333333333:18.1014%,0.4:17.5508%,0.5333333333:0.0056%,0.7333333333:0.0008%,0.6:0.0006%,1.0:0.0004%,0.8:0.0004%,0.3333333333:0.0002%]
[INFO] ** modbus_function_code:[0.9743589744:99.9926%,0.0:0.0074%]
[INFO] ** modbus_function_description:[0.2:49.9972%,0.0:49.9954%,0.4:0.0074%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:26.1358%,0.6:20.8928%,0.8:18.1008%,0.0:17.55%,0.4:17.31%,0.2:0.0106%]
[INFO] ** service:[0.7025755984000001:99.9926%,0.0:0.0056%,0.0208806885:0.0008%,0.0021633145999999997:0.0004%,0.08543524949999999:0.0002%,0.002116286:0.0002%,0.0021476384:0.0002%]
[INFO] ** s_port:[0.834280824:26.136%,0.8139250565:20.893%,0.8029830673999999:18.101%,0.8149336757:17.5502%,0.8137722355:17.31%,0.0:0.0056%,0.8343113882:0.0006%,0.8059172320999999:0.0006%,0.0021089309:0.0004%,0.814841983:0.0004%,0.8147502904:0.0002%,0.7593068036:0.0002%,0.7586191087:0.0002%,0.15243902439999998:0.0002%,0.15240846019999998:0.0002%,0.8411730545999999:0.0002%,0.8030136315999999:0.0002%,0.8345253376999999:0.0002%,0.0020936488:0.0002%,0.315972859:0.0002%,0.8030441959000001:0.0002%]
[INFO] ** classification:[normal:64.3482%,Single Stage Single Point:35.6518%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'proto': 3, 'appi_name': 7, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 7, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 1 1 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.64457[0m
[33m[INFO] metrics:[0m
loss :  1.6432497500610352
tp :  64457.0
fp :  35543.0
tn :  364457.0
fn :  35543.0
accuracy :  0.8578357100486755
precision :  0.644569993019104
recall :  0.644569993019104
auc :  0.9111424684524536

y_eval {0: 64457, 1: 35543}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64457     0     0     0     0]
 [35543     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6170142       0       0       0       0]
 [ 472004       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [1 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.64588[0m
[33m[INFO] metrics:[0m
loss :  1.6372305587387086
tp :  64588.0
fp :  35412.0
tn :  364588.0
fn :  35412.0
accuracy :  0.8583595156669617
precision :  0.6458799839019775
recall :  0.6458799839019775
auc :  0.9114699959754944

y_eval {0: 64588, 1: 35412}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64588     0     0     0     0]
 [35412     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6234730       0       0       0       0]
 [ 507416       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 1 0 ... 1 0 0] (100000,)
[INFO] Validation score: [33m0.64276[0m
[33m[INFO] metrics:[0m
loss :  1.6515663413619994
tp :  64276.0
fp :  35724.0
tn :  364276.0
fn :  35724.0
accuracy :  0.8571111559867859
precision :  0.6427599787712097
recall :  0.6427599787712097
auc :  0.9106900095939636

y_eval {0: 64276, 1: 35724}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64276     0     0     0     0]
 [35724     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6299006       0       0       0       0]
 [ 543140       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [1 1 1 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.64281[0m
[33m[INFO] metrics:[0m
loss :  1.65133660446167
tp :  64281.0
fp :  35719.0
tn :  364281.0
fn :  35719.0
accuracy :  0.8571314215660095
precision :  0.6428099870681763
recall :  0.6428099870681763
auc :  0.9107024669647217

y_eval {0: 64281, 1: 35719}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64281     0     0     0     0]
 [35719     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6363287       0       0       0       0]
 [ 578859       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [1 0 0 ... 1 1 1] (100000,)
[INFO] Validation score: [33m0.64139[0m
[33m[INFO] metrics:[0m
loss :  1.6578612243652344
tp :  64139.0
fp :  35861.0
tn :  364139.0
fn :  35861.0
accuracy :  0.8565624356269836
precision :  0.6413900256156921
recall :  0.6413900256156921
auc :  0.9103475213050842

y_eval {0: 64139, 1: 35861}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64139     0     0     0     0]
 [35861     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6427426       0       0       0       0]
 [ 614720       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-02_172943_122.log.part05_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9992%,1.0:0.0008%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[0.0:99.9984%,0.5:0.0016%]
[INFO] ** i/f_dir:[0.0:99.9984%,1.0:0.0016%]
[INFO] ** src:[0.0666666667:38.0648%,0.9333333333:26.1164%,0.6666666667:18.2044%,0.3333333333:17.6118%,0.8:0.001%,0.1333333333:0.0008%,0.2666666667:0.0004%,1.0:0.0004%]
[INFO] ** dst:[0.1764705882:43.368%,0.9411764706:20.8128%,0.8823529412000001:18.2044%,0.5294117647:17.6114%,0.2941176471:0.0016%,0.0:0.0006%,0.6470588235:0.0004%,0.3529411765:0.0002%,0.4705882353:0.0002%,0.4117647059:0.0002%,0.23529411760000002:0.0002%]
[INFO] ** proto:[0.5:99.998%,0.0:0.0016%,1.0:0.0004%]
[INFO] ** appi_name:[0.0:99.9974%,0.0384615385:0.0016%,0.5384615385:0.0006%,0.4230769231:0.0002%,0.3076923077:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.0648%,0.0:26.1164%,0.9333333333:18.2044%,0.4:17.6118%,0.5333333333:0.0016%,0.7333333333:0.0004%,0.8:0.0004%,0.4666666667:0.0002%]
[INFO] ** modbus_function_code:[0.9743589744:99.9974%,0.0:0.0026%]
[INFO] ** modbus_function_description:[0.2:49.9992%,0.0:49.9982%,0.4:0.0026%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:26.1154%,0.6:20.8126%,0.8:18.204%,0.0:17.6112%,0.4:17.2518%,0.2:0.005%]
[INFO] ** service:[0.7025755984000001:99.9974%,0.0:0.0016%,0.002116286:0.0006%,0.08394601119999999:0.0002%,0.0021476384:0.0002%]
[INFO] ** s_port:[0.834280824:26.1158%,0.8139250565:20.8128%,0.8029830673999999:18.204%,0.8149336757:17.6114%,0.8137722355:17.252%,0.0:0.0016%,0.8343113882:0.0004%,0.8147502904:0.0002%,0.7853933615:0.0002%,0.8030136315999999:0.0002%,0.9882022128:0.0002%,0.814841983:0.0002%,0.8344030809:0.0002%,0.9406137294:0.0002%,0.0020936488:0.0002%,0.7943945229:0.0002%,0.8030441959000001:0.0002%]
[INFO] ** classification:[normal:97.0224%,Single Stage Single Point:2.9776%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 8, 'proto': 3, 'appi_name': 5, 'proxy_src_ip': 8, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 5, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [1 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.85112[0m
[33m[INFO] metrics:[0m
loss :  0.6941930830019712
tp :  85112.0
fp :  14888.0
tn :  385112.0
fn :  14888.0
accuracy :  0.9404467940330505
precision :  0.8511199951171875
recall :  0.8511199951171875
auc :  0.9627799987792969

y_eval {0: 85112, 1: 14888}
pred {0: 100000}
[INFO] confusion matrix for file 
[[85112     0     0     0     0]
 [14888     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6512538       0       0       0       0]
 [ 629608       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[6612538       0       0       0       0]
 [ 629608       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[6712538       0       0       0       0]
 [ 629608       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[6812538       0       0       0       0]
 [ 629608       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.010118735022842884
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[6912538       0       0       0       0]
 [ 629608       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
--- 220.72840428352356 seconds ---
