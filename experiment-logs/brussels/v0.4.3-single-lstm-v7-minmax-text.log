2020-02-09 12:33:30.618818: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-02-09 12:33:30.618870: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-02-09 12:33:30.618876: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-02-09 12:33:31.109698: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-02-09 12:33:31.109717: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-02-09 12:33:31.109732: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (brussels): /proc/driver/nvidia/version does not exist
2020-02-09 12:33:31.109836: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-09 12:33:31.133787: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3312000000 Hz
2020-02-09 12:33:31.133975: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5b98fd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-09 12:33:31.133987: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow backend.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
2020-02-09 12:33:35.372054: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-09 12:33:35.394255: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 12:33:35.403275: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 12:33:35.481452: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-09 12:33:35.486330: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-09 12:33:35.492884: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 12:33:35.498894: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 12:33:35.516639: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-09 12:33:42.971401: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-09 12:33:42.976263: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 12:33:42.978594: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 12:33:42.995016: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-09 12:33:42.996117: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-09 12:33:42.997668: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 12:33:42.999226: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 12:33:43.005402: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
=================================================
        TRAINING v0.4.5 (binary)
=================================================
Date: 2020-02-09 12:33:31.106350
------------DNN info-------------
dnnBatchSize 16
wrapLayerSize 16
coreLayerSize 64
numCoreLayers 3
outputLayerActivation sigmoid
output_dim 2
loss binary_crossentropy
optimizer sgd
------------DNN info-------------
[INFO] input_shape (16, 107)
[INFO] LSTM first and last layer neurons: 16
[INFO] adding core layer 0
[INFO] adding core layer 1
[INFO] adding core layer 2
[INFO] created DNN
[33m[INFO] epoch 1/3[0m
[33m[INFO] loading file 1-50/1 on epoch 1/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] Shape when encoding dataset: (500000, 17)
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
missing 24
adding missing-0
adding missing-1
adding missing-2
adding missing-3
adding missing-4
adding missing-5
adding missing-6
adding missing-7
adding missing-8
adding missing-9
adding missing-10
adding missing-11
adding missing-12
adding missing-13
adding missing-14
adding missing-15
adding missing-16
adding missing-17
adding missing-18
adding missing-19
adding missing-20
adding missing-21
adding missing-22
adding missing-23
adding missing-24
len(df.columns) 108
numFeatures 107
[INFO] Shape AFTER encoding dataset: (500000, 108)
[INFO] processing batch 0-256000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 9s - loss: 0.5018 - tp: 191488.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 512.0000 - accuracy: 0.9987 - precision: 1.0000 - recall: 0.9973 - auc: 0.9999 - val_loss: 0.3559 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-001-files-0-50-batch-0-256000
[33m[LOSS] 0.35587241077423093[0m
[33m[INFO] epoch 2/3[0m
[33m[INFO] loading file 1-50/1 on epoch 2/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] Shape when encoding dataset: (500000, 17)
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
missing 24
adding missing-0
adding missing-1
adding missing-2
adding missing-3
adding missing-4
adding missing-5
adding missing-6
adding missing-7
adding missing-8
adding missing-9
adding missing-10
adding missing-11
adding missing-12
adding missing-13
adding missing-14
adding missing-15
adding missing-16
adding missing-17
adding missing-18
adding missing-19
adding missing-20
adding missing-21
adding missing-22
adding missing-23
adding missing-24
len(df.columns) 108
numFeatures 107
[INFO] Shape AFTER encoding dataset: (500000, 108)
[INFO] processing batch 0-256000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.2770 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2024 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-002-files-0-50-batch-0-256000
[33m[LOSS] 0.20242344546318053[0m
[33m[INFO] epoch 3/3[0m
[33m[INFO] loading file 1-50/1 on epoch 3/3[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] Shape when encoding dataset: (500000, 17)
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
missing 24
adding missing-0
adding missing-1
adding missing-2
adding missing-3
adding missing-4
adding missing-5
adding missing-6
adding missing-7
adding missing-8
adding missing-9
adding missing-10
adding missing-11
adding missing-12
adding missing-13
adding missing-14
adding missing-15
adding missing-16
adding missing-17
adding missing-18
adding missing-19
adding missing-20
adding missing-21
adding missing-22
adding missing-23
adding missing-24
len(df.columns) 108
numFeatures 107
[INFO] Shape AFTER encoding dataset: (500000, 108)
[INFO] processing batch 0-256000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.25
[INFO] using LSTM layers
[INFO] fitting model. xtrain.shape: (12000, 16, 107) y_train.shape: (12000, 16, 2)
Train on 12000 samples, validate on 4000 samples
Epoch 1/1
 - 8s - loss: 0.1739 - tp: 192000.0000 - fp: 0.0000e+00 - tn: 192000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1263 - val_tp: 64000.0000 - val_fp: 0.0000e+00 - val_tn: 64000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/lstm-epoch-003-files-0-50-batch-0-256000
[33m[LOSS] 0.12633623445034028[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.12633623445034028  <  0.001
--- 32.846094846725464 seconds ---
2020-02-09 12:34:04.850501: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-02-09 12:34:04.850547: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-02-09 12:34:04.850553: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-02-09 12:34:05.339418: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-02-09 12:34:05.339439: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-02-09 12:34:05.339454: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (brussels): /proc/driver/nvidia/version does not exist
2020-02-09 12:34:05.339552: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-09 12:34:05.361787: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3312000000 Hz
2020-02-09 12:34:05.361969: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x585e990 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-09 12:34:05.361981: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow backend.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
2020-02-09 12:34:10.020342: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-09 12:34:10.024593: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 12:34:10.026659: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 12:34:10.041225: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2020-02-09 12:34:10.042212: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] remapper failed: Invalid argument: MutableGraphView::MutableGraphView error: node 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat' has self cycle fanin 'loss/dense_2_loss/binary_crossentropy/weighted_loss/concat'.
2020-02-09 12:34:10.043611: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 12:34:10.044976: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:717] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2020-02-09 12:34:10.048585: W tensorflow/core/common_runtime/process_function_library_runtime.cc:697] Ignoring multi-device function optimization failure: Invalid argument: The graph couldn't be sorted in topological order.
=================================================
        SCORING v0.4.5 (binary)
=================================================
Date: 2020-02-09 12:34:05.336133
------------DNN info-------------
dnnBatchSize 16
wrapLayerSize 16
coreLayerSize 64
numCoreLayers 3
outputLayerActivation sigmoid
output_dim 2
loss binary_crossentropy
optimizer sgd
------------DNN info-------------
[INFO] input_shape (16, 107)
[INFO] LSTM first and last layer neurons: 16
[INFO] adding core layer 0
[INFO] adding core layer 1
[INFO] adding core layer 2
[INFO] created DNN
loading weights: checkpoints/*
loading file checkpoints/lstm-epoch-003-files-0-50-batch-0-256000
[33m[INFO] model summary:[0m
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 16, 16)            7936      
_________________________________________________________________
dropout_1 (Dropout)          (None, 16, 16)            0         
_________________________________________________________________
lstm_2 (LSTM)                (None, 16, 64)            20736     
_________________________________________________________________
dropout_2 (Dropout)          (None, 16, 64)            0         
_________________________________________________________________
lstm_3 (LSTM)                (None, 16, 64)            33024     
_________________________________________________________________
dropout_3 (Dropout)          (None, 16, 64)            0         
_________________________________________________________________
lstm_4 (LSTM)                (None, 16, 64)            33024     
_________________________________________________________________
dropout_4 (Dropout)          (None, 16, 64)            0         
_________________________________________________________________
lstm_5 (LSTM)                (None, 16, 16)            5184      
_________________________________________________________________
dropout_5 (Dropout)          (None, 16, 16)            0         
_________________________________________________________________
dense_1 (Dense)              (None, 16, 1)             17        
_________________________________________________________________
dropout_6 (Dropout)          (None, 16, 1)             0         
_________________________________________________________________
dense_2 (Dense)              (None, 16, 2)             4         
=================================================================
Total params: 99,925
Trainable params: 99,925
Non-trainable params: 0
_________________________________________________________________
[INFO] reading file data/SWaT2015-Attack-Files-v0.4.3-minmax-text/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
[INFO] columns: Index(['unixtime', 'orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst',
       'proto', 'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] Shape when encoding dataset: (500000, 17)
[33mencode_text_dummy orig[0m
[33mencode_text_dummy type[0m
[33mencode_text_dummy i/f_name[0m
[33mencode_text_dummy i/f_dir[0m
[33mencode_text_dummy src[0m
[33mencode_text_dummy dst[0m
[33mencode_text_dummy proto[0m
[33mencode_text_dummy appi_name[0m
[33mencode_text_dummy proxy_src_ip[0m
[33mencode_text_dummy modbus_function_description[0m
[33mencode_text_dummy scada_tag[0m
missing 58
adding missing-0
adding missing-1
adding missing-2
adding missing-3
adding missing-4
adding missing-5
adding missing-6
adding missing-7
adding missing-8
adding missing-9
adding missing-10
adding missing-11
adding missing-12
adding missing-13
adding missing-14
adding missing-15
adding missing-16
adding missing-17
adding missing-18
adding missing-19
adding missing-20
adding missing-21
adding missing-22
adding missing-23
adding missing-24
adding missing-25
adding missing-26
adding missing-27
adding missing-28
adding missing-29
adding missing-30
adding missing-31
adding missing-32
adding missing-33
adding missing-34
adding missing-35
adding missing-36
adding missing-37
adding missing-38
adding missing-39
adding missing-40
adding missing-41
adding missing-42
adding missing-43
adding missing-44
adding missing-45
adding missing-46
adding missing-47
adding missing-48
adding missing-49
adding missing-50
adding missing-51
adding missing-52
adding missing-53
adding missing-54
adding missing-55
adding missing-56
adding missing-57
adding missing-58
len(df.columns) 108
numFeatures 107
[INFO] Shape AFTER encoding dataset: (500000, 108)
[INFO] processing batch 0-256000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (256000, 107)
y_eval [1 0 1 ... 0 0 0] (256000,)
[INFO] reshape for using LSTM layers
[33m[INFO] metrics:[0m
loss :  0.5940441272258759
tp :  196643.0
fp :  59357.0
tn :  196643.0
fn :  59357.0
accuracy :  0.768136739730835
precision :  0.768136739730835
recall :  0.768136739730835
auc :  0.7679300308227539

y_eval {0: 196643, 1: 59357}
pred {0: 256000}
[INFO] confusion matrix for file 
[[196643      0]
 [ 59357      0]]
[INFO] confusion matrix after adding it to total:
[[196643      0]
 [ 59357      0]]
--- 7.809051513671875 seconds ---
